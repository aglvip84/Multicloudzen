processes. Using existing management and identity provisioning processes can
decrease some risks but can also create the risk of an attacker compromising an
on-premises account and pivoting to the cloud. You might want to use a different
strategy for different roles (for example, IT admins vs. business unit admins). You
have two options. First option is to create Azure AD Accounts that aren’t
synchronized with your on-premises Active Directory instance. Join your admin
workstation to Azure AD, which you can manage and patch by using Microsoft
Intune. Second option is to use existing admin accounts by synchronizing to your
on-premises Active Directory instance. Use existing workstations in your Active
Directory domain for management and security.

Manage connected tenants
Your security organization needs visibility to assess risk and to determine whether the
policies of your organization, and any regulatory requirements, are being followed. You
should ensure that your security organization has visibility into all subscriptions
connected to your production environment and network (via Azure ExpressRoute or
site-to-site VPN). A Global Administrator in Azure AD can elevate their access to the
User Access Administrator role and see all subscriptions and managed groups
connected to your environment.
See elevate access to manage all Azure subscriptions and management groups to
ensure that you and your security group can view all subscriptions or management
groups connected to your environment. You should remove this elevated access after
you’ve assessed risks.

Enable single sign-on
In a mobile-first, cloud-first world, you want to enable single sign-on (SSO) to devices,
apps, and services from anywhere so your users can be productive wherever and
whenever. When you have multiple identity solutions to manage, this becomes an
administrative problem not only for IT but also for users who have to remember
multiple passwords.
By using the same identity solution for all your apps and resources, you can achieve
SSO. And your users can use the same set of credentials to sign in and access the
resources that they need, whether the resources are located on-premises or in the
cloud.

Best practice: Enable SSO.
Detail: Azure AD extends on-premises Active Directory to the cloud. Users can use their
primary work or school account for their domain-joined devices, company resources,
and all of the web and SaaS applications that they need to get their jobs done. Users
don’t have to remember multiple sets of usernames and passwords, and their
application access can be automatically provisioned (or deprovisioned) based on their
organization group memberships and their status as an employee. And you can control
that access for gallery apps or for your own on-premises apps that you’ve developed
and published through the Azure AD Application Proxy.
Use SSO to enable users to access their SaaS applications based on their work or school
account in Azure AD. This is applicable not only for Microsoft SaaS apps, but also other
apps, such as Google Apps and Salesforce. You can configure your application to use
Azure AD as a SAML-based identity provider. As a security control, Azure AD does not
issue a token that allows users to sign in to the application unless they have been
granted access through Azure AD. You can grant access directly, or through a group that
users are a member of.
Organizations that don’t create a common identity to establish SSO for their users and
applications are more exposed to scenarios where users have multiple passwords. These
scenarios increase the likelihood of users reusing passwords or using weak passwords.

Turn on Conditional Access
Users can access your organization's resources by using a variety of devices and apps
from anywhere. As an IT admin, you want to make sure that these devices meet your
standards for security and compliance. Just focusing on who can access a resource is not
sufficient anymore.
To balance security and productivity, you need to think about how a resource is
accessed before you can make a decision about access control. With Azure AD
Conditional Access, you can address this requirement. With Conditional Access, you can
make automated access control decisions based on conditions for accessing your cloud
apps.
Best practice: Manage and control access to corporate resources.
Detail: Configure common Azure AD Conditional Access policies based on a group,
location, and application sensitivity for SaaS apps and Azure AD–connected apps.
Best practice: Block legacy authentication protocols.
Detail: Attackers exploit weaknesses in older protocols every day, particularly for
password spray attacks. Configure Conditional Access to block legacy protocols.

Plan for routine security improvements
Security is always evolving, and it is important to build into your cloud and identity
management framework a way to regularly show growth and discover new ways to
secure your environment.
Identity Secure Score is a set of recommended security controls that Microsoft publishes
that works to provide you a numerical score to objectively measure your security
posture and help plan future security improvements. You can also view your score in
comparison to those in other industries as well as your own trends over time.
Best practice: Plan routine security reviews and improvements based on best practices
in your industry.
Detail: Use the Identity Secure Score feature to rank your improvements over time.

Enable password management
If you have multiple tenants or you want to enable users to reset their own passwords ,
it’s important that you use appropriate security policies to prevent abuse.
Best practice: Set up self-service password reset (SSPR) for your users.
Detail: Use the Azure AD self-service password reset feature.
Best practice: Monitor how or if SSPR is really being used.
Detail: Monitor the users who are registering by using the Azure AD Password Reset
Registration Activity report. The reporting feature that Azure AD provides helps you
answer questions by using prebuilt reports. If you're appropriately licensed, you can also
create custom queries.
Best practice: Extend cloud-based password policies to your on-premises infrastructure.
Detail: Enhance password policies in your organization by performing the same checks
for on-premises password changes as you do for cloud-based password changes. Install
Azure AD password protection for Windows Server Active Directory agents on-premises
to extend banned password lists to your existing infrastructure. Users and admins who
change, set, or reset passwords on-premises are required to comply with the same
password policy as cloud-only users.

Enforce multi-factor verification for users
We recommend that you require two-step verification for all of your users. This includes
administrators and others in your organization who can have a significant impact if their
account is compromised (for example, financial officers).

There are multiple options for requiring two-step verification. The best option for you
depends on your goals, the Azure AD edition you’re running, and your licensing
program. See How to require two-step verification for a user to determine the best
option for you. See the Azure AD

and Azure AD Multi-Factor Authentication

pricing

pages for more information about licenses and pricing.
Following are options and benefits for enabling two-step verification:
Option 1: Enable MFA for all users and login methods with Azure AD Security Defaults
Benefit: This option enables you to easily and quickly enforce MFA for all users in your
environment with a stringent policy to:
Challenge administrative accounts and administrative logon mechanisms
Require MFA challenge via Microsoft Authenticator for all users
Restrict legacy authentication protocols.
This method is available to all licensing tiers but is not able to be mixed with existing
Conditional Access policies. You can find more information in Azure AD Security Defaults
Option 2: Enable Multi-Factor Authentication by changing user state.
Benefit: This is the traditional method for requiring two-step verification. It works with
both Azure AD Multi-Factor Authentication in the cloud and Azure AD Multi-Factor
Authentication Server. Using this method requires users to perform two-step verification
every time they sign in and overrides Conditional Access policies.
To determine where Multi-Factor Authentication needs to be enabled, see Which version
of Azure AD MFA is right for my organization?.
Option 3: Enable Multi-Factor Authentication with Conditional Access policy.
Benefit: This option allows you to prompt for two-step verification under specific
conditions by using Conditional Access. Specific conditions can be user sign-in from
different locations, untrusted devices, or applications that you consider risky. Defining
specific conditions where you require two-step verification enables you to avoid
constant prompting for your users, which can be an unpleasant user experience.
This is the most flexible way to enable two-step verification for your users. Enabling a
Conditional Access policy works only for Azure AD Multi-Factor Authentication in the
cloud and is a premium feature of Azure AD. You can find more information on this
method in Deploy cloud-based Azure AD Multi-Factor Authentication.
Option 4: Enable Multi-Factor Authentication with Conditional Access policies by
evaluating Risk-based Conditional Access policies.
Benefit: This option enables you to:

Detect potential vulnerabilities that affect your organization’s identities.
Configure automated responses to detected suspicious actions that are related to
your organization’s identities.
Investigate suspicious incidents and take appropriate action to resolve them.
This method uses the Azure AD Identity Protection risk evaluation to determine if twostep verification is required based on user and sign-in risk for all cloud applications. This
method requires Azure Active Directory P2 licensing. You can find more information on
this method in Azure Active Directory Identity Protection.
７ Note
Option 2, enabling Multi-Factor Authentication by changing the user state,
overrides Conditional Access policies. Because options 3 and 4 use Conditional
Access policies, you cannot use option 2 with them.
Organizations that don’t add extra layers of identity protection, such as two-step
verification, are more susceptible for credential theft attack. A credential theft attack can
lead to data compromise.

Use role-based access control
Access management for cloud resources is critical for any organization that uses the
cloud. Azure role-based access control (Azure RBAC) helps you manage who has access
to Azure resources, what they can do with those resources, and what areas they have
access to.
Designating groups or individual roles responsible for specific functions in Azure helps
avoid confusion that can lead to human and automation errors that create security risks.
Restricting access based on the need to know

and least privilege

security principles

is imperative for organizations that want to enforce security policies for data access.
Your security team needs visibility into your Azure resources in order to assess and
remediate risk. If the security team has operational responsibilities, they need additional
permissions to do their jobs.
You can use Azure RBAC to assign permissions to users, groups, and applications at a
certain scope. The scope of a role assignment can be a subscription, a resource group,
or a single resource.
Best practice: Segregate duties within your team and grant only the amount of access to
users that they need to perform their jobs. Instead of giving everybody unrestricted

permissions in your Azure subscription or resources, allow only certain actions at a
particular scope.
Detail: Use Azure built-in roles in Azure to assign privileges to users.
７ Note
Specific permissions create unneeded complexity and confusion, accumulating into
a “legacy” configuration that’s difficult to fix without fear of breaking something.
Avoid resource-specific permissions. Instead, use management groups for
enterprise-wide permissions and resource groups for permissions within
subscriptions. Avoid user-specific permissions. Instead, assign access to groups in
Azure AD.
Best practice: Grant security teams with Azure responsibilities access to see Azure
resources so they can assess and remediate risk.
Detail: Grant security teams the Azure RBAC Security Reader role. You can use the root
management group or the segment management group, depending on the scope of
responsibilities:
Root management group for teams responsible for all enterprise resources
Segment management group for teams with limited scope (commonly because of
regulatory or other organizational boundaries)
Best practice: Grant the appropriate permissions to security teams that have direct
operational responsibilities.
Detail: Review the Azure built-in roles for the appropriate role assignment. If the built-in
roles don't meet the specific needs of your organization, you can create Azure custom
roles. As with built-in roles, you can assign custom roles to users, groups, and service
principals at subscription, resource group, and resource scopes.
Best practices: Grant Microsoft Defender for Cloud access to security roles that need it.
Defender for Cloud allows security teams to quickly identify and remediate risks.
Detail: Add security teams with these needs to the Azure RBAC Security Admin role so
they can view security policies, view security states, edit security policies, view alerts and
recommendations, and dismiss alerts and recommendations. You can do this by using
the root management group or the segment management group, depending on the
scope of responsibilities.
Organizations that don’t enforce data access control by using capabilities like Azure
RBAC might be giving more privileges than necessary to their users. This can lead to
data compromise by allowing users to access types of data (for example, high business
impact) that they shouldn’t have.

Lower exposure of privileged accounts
Securing privileged access is a critical first step to protecting business assets. Minimizing
the number of people who have access to secure information or resources reduces the
chance of a malicious user getting access, or an authorized user inadvertently affecting a
sensitive resource.
Privileged accounts are accounts that administer and manage IT systems. Cyber
attackers target these accounts to gain access to an organization’s data and systems. To
secure privileged access, you should isolate the accounts and systems from the risk of
being exposed to a malicious user.
We recommend that you develop and follow a roadmap to secure privileged access
against cyber attackers. For information about creating a detailed roadmap to secure
identities and access that are managed or reported in Azure AD, Microsoft Azure,
Microsoft 365, and other cloud services, review Securing privileged access for hybrid and
cloud deployments in Azure AD.
The following summarizes the best practices found in Securing privileged access for
hybrid and cloud deployments in Azure AD:
Best practice: Manage, control, and monitor access to privileged accounts.
Detail: Turn on Azure AD Privileged Identity Management. After you turn on Privileged
Identity Management, you’ll receive notification email messages for privileged access
role changes. These notifications provide early warning when additional users are added
to highly privileged roles in your directory.
Best practice: Ensure all critical admin accounts are managed Azure AD accounts. Detail:
Remove any consumer accounts from critical admin roles (for example, Microsoft
accounts like hotmail.com, live.com, and outlook.com).
Best practice: Ensure all critical admin roles have a separate account for administrative
tasks in order to avoid phishing and other attacks to compromise administrative
privileges.
Detail: Create a separate admin account that’s assigned the privileges needed to
perform the administrative tasks. Block the use of these administrative accounts for daily
productivity tools like Microsoft 365 email or arbitrary web browsing.
Best practice: Identify and categorize accounts that are in highly privileged roles.
Detail: After turning on Azure AD Privileged Identity Management, view the users who
are in the global administrator, privileged role administrator, and other highly privileged
roles. Remove any accounts that are no longer needed in those roles, and categorize the
remaining accounts that are assigned to admin roles:

Individually assigned to administrative users, and can be used for nonadministrative purposes (for example, personal email)
Individually assigned to administrative users and designated for administrative
purposes only
Shared across multiple users
For emergency access scenarios
For automated scripts
For external users
Best practice: Implement “just in time” (JIT) access to further lower the exposure time of
privileges and increase your visibility into the use of privileged accounts.
Detail: Azure AD Privileged Identity Management lets you:
Limit users to only taking on their privileges JIT.
Assign roles for a shortened duration with confidence that the privileges are
revoked automatically.
Best practice: Define at least two emergency access accounts.
Detail: Emergency access accounts help organizations restrict privileged access in an
existing Azure Active Directory environment. These accounts are highly privileged and
are not assigned to specific individuals. Emergency access accounts are limited to
scenarios where normal administrative accounts can’t be used. Organizations must limit
the emergency account's usage to only the necessary amount of time.
Evaluate the accounts that are assigned or eligible for the global admin role. If you don’t
see any cloud-only accounts by using the *.onmicrosoft.com domain (intended for
emergency access), create them. For more information, see Managing emergency access
administrative accounts in Azure AD.
Best practice: Have a “break glass" process in place in case of an emergency.
Detail: Follow the steps in Securing privileged access for hybrid and cloud deployments
in Azure AD.
Best practice: Require all critical admin accounts to be password-less (preferred), or
require Multi-Factor Authentication.
Detail: Use the Microsoft Authenticator app to sign in to any Azure AD account without
using a password. Like Windows Hello for Business, the Microsoft Authenticator uses
key-based authentication to enable a user credential that’s tied to a device and uses
biometric authentication or a PIN.
Require Azure AD Multi-Factor Authentication at sign-in for all individual users who are
permanently assigned to one or more of the Azure AD admin roles: Global
Administrator, Privileged Role Administrator, Exchange Online Administrator, and

SharePoint Online Administrator. Enable Multi-Factor Authentication for your admin
accounts and ensure that admin account users have registered.
Best practice: For critical admin accounts, have an admin workstation where production
tasks aren’t allowed (for example, browsing and email). This will protect your admin
accounts from attack vectors that use browsing and email and significantly lower your
risk of a major incident.
Detail: Use an admin workstation. Choose a level of workstation security:
Highly secure productivity devices provide advanced security for browsing and
other productivity tasks.
Privileged Access Workstations (PAWs)

provide a dedicated operating system

that’s protected from internet attacks and threat vectors for sensitive tasks.
Best practice: Deprovision admin accounts when employees leave your organization.
Detail: Have a process in place that disables or deletes admin accounts when employees
leave your organization.
Best practice: Regularly test admin accounts by using current attack techniques.
Detail: Use Microsoft 365 Attack Simulator or a third-party offering to run realistic attack
scenarios in your organization. This can help you find vulnerable users before a real
attack occurs.
Best practice: Take steps to mitigate the most frequently used attacked techniques.
Detail: Identify Microsoft accounts in administrative roles that need to be switched to
work or school accounts
Ensure separate user accounts and mail forwarding for global administrator accounts
Ensure that the passwords of administrative accounts have recently changed
Turn on password hash synchronization
Require Multi-Factor Authentication for users in all privileged roles as well as exposed
users
Obtain your Microsoft 365 Secure Score (if using Microsoft 365)
Review the Microsoft 365 security guidance (if using Microsoft 365)
Configure Microsoft 365 Activity Monitoring (if using Microsoft 365)
Establish incident/emergency response plan owners
Secure on-premises privileged administrative accounts

If you don’t secure privileged access, you might find that you have too many users in
highly privileged roles and are more vulnerable to attacks. Malicious actors, including
cyber attackers, often target admin accounts and other elements of privileged access to
gain access to sensitive data and systems by using credential theft.

Control locations where resources are created
Enabling cloud operators to perform tasks while preventing them from breaking
conventions that are needed to manage your organization's resources is very important.
Organizations that want to control the locations where resources are created should
hard code these locations.
You can use Azure Resource Manager to create security policies whose definitions
describe the actions or resources that are specifically denied. You assign those policy
definitions at the desired scope, such as the subscription, the resource group, or an
individual resource.
７ Note
Security policies are not the same as Azure RBAC. They actually use Azure RBAC to
authorize users to create those resources.
Organizations that are not controlling how resources are created are more susceptible
to users who might abuse the service by creating more resources than they need.
Hardening the resource creation process is an important step to securing a multitenant
scenario.

Actively monitor for suspicious activities
An active identity monitoring system can quickly detect suspicious behavior and trigger
an alert for further investigation. The following table lists Azure AD capabilities that can
help organizations monitor their identities:
Best practice: Have a method to identify:
Attempts to sign in without being traced.
Brute force attacks against a particular account.
Attempts to sign in from multiple locations.
Sign-ins from infected devices.
Suspicious IP addresses.

Detail: Use Azure AD Premium anomaly reports. Have processes and procedures in
place for IT admins to run these reports on a daily basis or on demand (usually in an
incident response scenario).
Best practice: Have an active monitoring system that notifies you of risks and can adjust
risk level (high, medium, or low) to your business requirements.
Detail: Use Azure AD Identity Protection, which flags the current risks on its own
dashboard and sends daily summary notifications via email. To help protect your
organization's identities, you can configure risk-based policies that automatically
respond to detected issues when a specified risk level is reached.
Organizations that don’t actively monitor their identity systems are at risk of having user
credentials compromised. Without knowledge that suspicious activities are taking place
through these credentials, organizations can’t mitigate this type of threat.

Use Azure AD for storage authentication
Azure Storage supports authentication and authorization with Azure AD for Blob storage
and Queue storage. With Azure AD authentication, you can use the Azure role-based
access control to grant specific permissions to users, groups, and applications down to
the scope of an individual blob container or queue.
We recommend that you use Azure AD for authenticating access to storage

.

Next step
See Azure security best practices and patterns for more security best practices to use
when you’re designing, deploying, and managing your cloud solutions by using Azure.

Network security
Article • 04/21/2023

Protect assets by placing controls on network traffic originating in Azure, between onpremises and Azure hosted resources, and traffic to and from Azure. If security measures
aren't in place, attackers can gain access, for instance, by scanning across public IP
ranges. Proper network security controls can provide defense-in-depth elements that
help detect, contain, and stop attackers who gain entry into your cloud deployments.
７ Note
Network security, segmentation, and connectivity could be defined as part of the
workload architecture. More commonly, networking is often addressed at an
organizational level by central IT, cloud center of excellence, or a cloud platform
team. For any networking configuration defined outside of the scope of your
workload architecture, reference Cloud Adoption Framework's Azure landing
zones. Network topology and connectivity outlines the best practice
recommendations and considerations for centralized networking and network
security.

Checklist
How have you secured the network of your workload?
＂ Segment your network footprint and create secure communication paths between
segments. Align the network segmentation with overall enterprise segmentation
strategy.
＂ Design security controls that identify and allow or deny traffic, access requests, and
application communication between segments.
＂ Protect all public endpoints with Azure Front Door, Application Gateway, Azure
Firewall, and Azure DDoS Protection.
＂ Mitigate DDoS attacks with Azure DDoS Protection for critical workloads.
＂ Keep virtual machines private and secure when connecting to the internet with
Azure NAT Gateway.
＂ Control network traffic between subnets (east-west) and application tiers (northsouth).
＂ Protect from data exfiltration attacks through a defense-in-depth approach with
controls at each layer.

Azure security benchmark
The Azure Security Benchmark includes a collection of high-impact security
recommendations you can use to help secure the services you use in Azure:

The questions in this section are aligned to the Azure Security Benchmarks
Network Security.

Azure services
Azure Virtual Network
Azure Firewall
Azure NAT Gateway
Azure ExpressRoute
Azure Private Link
Azure DDoS Protection

Reference architecture
Here are some reference architectures related to network security:
Hub-spoke network topology in Azure
Deploy highly available NVAs
Baseline architecture for an Azure Kubernetes Service (AKS) cluster

Next steps
We recommend applying as many as of the best practices as early as possible, and then
working to retrofit any gaps over time as you mature your security program.
Data protection

Related links
Combine network controls with application, identity, and other technical control types.
This approach is effective in preventing, detecting, and responding to threats outside
the networks you control. For more information, see these articles:
Applications and services

Azure identity and access management considerations
Data protection considerations
Ensure that resource grouping and administrative privileges align to the segmentation
model. For more information, see Administrative account security.
Go back to the main article: Overview of the security pillar

Implement network segmentation
patterns on Azure
Article • 11/30/2022

A unified enterprise segmentation strategy guides technical teams to consistently
segment access using networking, applications, identity, and any other access controls.
Create segmentation in your network footprint by defining perimeters. The main
reasons for segmentation are:
The ability to group related assets that are a part of (or support) workload
operations.
Isolation of resources.
Governance policies set by the organization.
Assume compromise is the recommended cybersecurity mindset and the ability to
contain an attacker is vital in protecting information systems. Model an attacker able to
achieve a foothold at various points within the workload and establish controls to
mitigate further expansion.
Network controls can secure interactions between perimeters. This approach can
strengthen the security posture and contain risks in a breach because the controls can
detect, contain, and stop attackers from gaining access to an entire workload.
Containment of attack vectors within an environment is critical. However, to be effective
in cloud environments, traditional approaches may prove inadequate and security
organizations may need to evolve their methods.
Traditional segmentation approaches typically fail to achieve their goals as they have not
been developed in a method to align with business use cases and application workloads.
Often this results in overwhelming complexity requiring broad firewall exceptions.
An evolving emerging best practice recommendation is to adopt a Zero Trust strategy
based on user, device, and application identities. In contrast to network access controls
that are based on elements such as source and destination IP address, protocols, and
port numbers, Zero Trust enforces and validates access control at access time. This
avoids the need to play a prediction game for an entire deployment, network, or subnet
— only the destination resource needs to provide the necessary access controls.
Azure Network Security Groups can be used for basic layer 3 and 4 access controls
between Azure Virtual Networks, their subnets, and the internet.

Azure Web Application Firewall and the Azure Firewall can be used for more
advanced network access controls that require application layer support.
Local Admin Password Solution (LAPS) or a third-party Privileged Access
Management can set strong local admin passwords and just-in-time access to
them.
How does the organization implement network segmentation?
This article highlights some Azure networking features that create segments and restrict
access to individual services.
） Important
Align your network segmentation strategy with the enterprise segmentation model.
This will reduce confusion and challenges with different technical teams
(networking, identity, applications, and so on). Each team should not develop their
own segmentation and delegation models that don't align with each other.

Key points
Create software-defined perimeters in your networking footprint and secure
communication paths between them.
Establish a complete zero trust segmentation strategy.
Align technical teams in the enterprise on micro segmentation strategies for legacy
applications.
Azure Virtual Networks (VNets) are created in private address spaces. By default,
no traffic is allowed between any two VNets. Open paths only when it's really
needed.
Use Network Security Groups (NSG) to secure communication between resources
within a VNet.
Use Application Security Groups (ASGs) to define traffic rules for the underlying
VMs that run the workload.
Use Azure Firewall to filter traffic flowing between cloud resources, the internet,
and on-premise.
Place resources in a single VNet, if you don't need to operate in multiple regions.
If you need to be in multiple regions, have multiple VNets that are connected
through peering.
For advanced configurations, use a hub-spoke topology. A VNet is designated as a
hub in a given region for all the other VNets as spokes in that region.

What is segmentation?
You can create software-defined perimeters in your networking footprint by using the
various Azure services and features. When a workload (or parts of a given workload) is
placed into separate segments, you can control traffic from/to those segments to secure
communication paths. If a segment is compromised, you will be able to better contain
the impact and prevent it from laterally spreading through the rest of your network. This
strategy aligns with the key principle of Zero Trust model published by Microsoft

that

aims to bring world class security thinking to your organization.

Suggested actions
Create a risk containment strategy that blends proven approaches including:
Existing network security controls and practices
Native security controls available in Azure
Zero trust approaches

Learn more
For information about creating a segmentation strategy, see Enterprise segmentation
strategy.

Azure features for segmentation
When you operate on Azure, you have many segmentation options.

1. Subscription: A high-level construct, which provides platform powered separation
between entities. It's intended to carve out boundaries between large

organizations within a company and communication between resources in
different subscriptions needs to be explicitly provisioned.
2. Virtual Network (VNets): Created within a subscription in private address spaces.
They provide network level containment of resources with no traffic allowed by
default between any two virtual networks. Like subscriptions, any communication
between virtual networks needs to be explicitly provisioned.
3. Network Security Groups (NSG): An access control mechanisms for controlling
traffic between resources within a virtual network and also with external networks,
such as the internet, other virtual networks. NSGs can take your segmentation
strategy to a granular level by creating perimeters for a subnet, a VM, or a group
of VMs. For information about possible operations with subnets in Azure, see
Subnets (Azure Virtual Networks).
4. Application Security Groups (ASGs): Similar to NSGs but are referenced with an
application context. It allows you to group a set of VMs under an application tag
and define traffic rules that are then applied to each of the underlying VMs.
5. Azure Firewall: A cloud native stateful Firewall as a service, which can be deployed
in your VNet or in Azure Virtual WAN hub deployments for filtering traffic flowing
between cloud resources, the internet, and on-premise. You create rules or policies
(using Azure Firewall or Azure Firewall Manager) specifying allow/deny traffic using
layer 3 to layer 7 controls. You can also filter traffic going to the internet using
both Azure Firewall and third parties by directing some or all traffic through thirdparty security providers for advanced filtering & user protection.

Segmentation patterns
Here are some common patterns for segmenting a workload in Azure from a networking
perspective. Each pattern provides a different type of isolation and connectivity. Choose
a pattern based on your organization's needs.

Pattern 1: Single VNet
All the components of the workload reside in a single VNet. This pattern is appropriate
you are operating in a single region because a VNet cannot span multiple regions.
Common ways for securing segments, such as subnets or application groups, are by
using NSGs and ASGs. You can also use a Network Virtualized Appliance (NVAs) from
Azure Marketplace or Azure Firewall to enforce and secure this segmentation.

In this image, Subnet1 has the database workload. Subnet2 has the web workloads. You
can configure NSGs that allow Subnet1 to only communicate with Subnet2 and Subnet2
can only communicate with the internet.

Consider a use case where you have multiple workloads that are placed in separate
subnets. You can place controls that will allow one workload to communicate to the
backend of another workload.

Pattern 2: Multiple VNets that communicate
through with peering
The resources are spread or replicated in multiple VNets. The VNets can communicate
through peering. This pattern is appropriate when you need to group applications into
separate VNets. Or, you need multiple Azure regions. One benefit is the built-in
segmentation because you have to explicitly peer one VNet to another. Virtual network
peering is not transitive. You can further segment within a VNet by using NSGs and
ASGs as shown in pattern 1.

Pattern 3: Multiple VNets in a hub and spoke
model
A VNet is designated as a hub in a given region for all the other VNets as spokes in that
region. The hub and its spokes are connected through peering. All traffic passes through
the hub that can act as a gateway to other hubs in different regions. In this pattern, the
security controls are set up at the hubs so that they get to segment and govern the
traffic in between other VNets in a scalable way. One benefit of this pattern is, as your
network topology grows, the security posture overhead does not grow (except when
you expand to new regions).

The recommended native option is Azure Firewall. This option works across both VNets
and subscriptions to govern traffic flows using layer 3 to layer 7 controls. You can define
your communication rules and apply them consistently. Here are some examples:
VNet 1 cannot communicate with VNet 2, but it can communicate VNet 3.
VNet 1 cannot access public internet except for *.github.com.
With Azure Firewall Manager preview, you can centrally manage policies across multiple
Azure Firewalls and enable DevOps teams to further customize local policies.
 Tip
Here are some resources that illustrate provisioning of resources in a hub and
spoke topology:

GitHub: Hub and Spoke Topology Sandbox .
The design considerations are described in Hub-spoke network topology in Azure.

Pattern comparison
Considerations

Pattern 1

Pattern 2

Pattern 3

Considerations

Pattern 1

Pattern 2

Pattern 3

Connectivity/routing:
how each segment
communicates to

System routing
provides default
connectivity to

Same as a
pattern 1.

No default connectivity between
spoke networks. A layer 3 router, such
as the Azure Firewall, in the hub is

each other

any workload in
any subnet.

Network level traffic
filtering

Traffic is allowed
by default. Use
NSG, ASG to filter
traffic.

Same as a
pattern 1.

Traffic between spoke virtual networks
is denied by default. Open selected
paths to allow traffic through Azure
Firewall configuration.

Centralized logging

NSG, ASG logs for

Aggregate

Azure Firewall logs all

the virtual
network.

NSG, ASG
logs across
all virtual
networks.

accepted/denied traffic sent through
the hub. View the logs in Azure
Monitor.

DevOps can
accidentally open

Same as a
pattern 1.

Accidentally opened public endpoint
in a spoke will not enable access

Unintended open
public endpoints

required to enable connectivity.

a public endpoint
through incorrect
NSG, ASG rules.
Application level
protection

NSG or ASG
provides network
layer support only.

because the return packet will get
dropped through stateful firewall
(asymmetric routing).
Same as a
pattern 1.

Azure Firewall supports FQDN filtering
for HTTP/S and MSSQL for outbound
traffic and across virtual networks.

Next step
Secure network connectivity

Related links
For information about setting up peering, reference Virtual network peering.
For best practices about using Azure Firewall in various configurations, reference
Azure Firewall Architecture Guide.
For information about different access policies and control flow within a VNet,
reference Azure Virtual Network Subnet
Back to the main article: Network security

Azure services for securing network
connectivity
Article • 11/30/2022

It's often the case that the workload and the supporting components of a cloud
architecture will need to access external assets. These assets can be on-premises,
devices outside the main virtual network, or other Azure resources. Those connections
can be over the internet or networks within the organization.

Key points
Protect non-publicly accessible services with network restrictions and IP firewall.
Use Network Security Groups (NSGs) or Azure Firewall to protect and control traffic
within the VNet.
Use Service Endpoints or Private Link for accessing Azure PaaS services.
Use Azure Firewall to protect against data exfiltration attacks.
Restrict access to backend services to a minimal set of public IP addresses.
Use Azure controls over third-party solutions for basic security needs. These
controls are native to the platform and are easy to configure and scale.
Define access policies based on the type of workload and control flow between the
different application tiers.

Connectivity between network segments
When designing a workload, you'll typically start by provisioning an Azure Virtual
Network (VNet) in a private address space which has the workload. No traffic is allowed
by default between any two virtual networks. If there's a need, define the
communication paths explicitly. One way of connecting VNets is through Virtual
network peering.
A key aspect of protecting VMs in a VNet is to control the flow of network traffic. The
network interfaces on the VMs allow them to communicate with other VMs, the internet,
and on-premises networks. To control traffic on VMs within a VNet (and subnet), use
Application Security Groups (ASGs). ASGs allow you to group a set of VMs under an
application tag and define traffic rules. Those rules are then applied to each of the
underlying VMs.
A VNet is segmented into subnets based on business requirements. Ensure that proper
network security controls are configured to allow or deny inbound network traffic to, or

outbound network traffic from, within larger network space.
By default VMs are provisioned with private IP addresses. This allows you to take
advantage of the Azure IP address to determine incoming traffic, how and where it's
translated on to the virtual network.
A good Azure IP addressing schema provides flexibility, room for growth, and
integration with on-premises networks. The schema ensures that communication works
for deployed resources, minimizes public exposure of systems, and gives the
organization flexibility in its network. If not properly designed, systems might not be
able to communicate, and additional work will be required to remediate.
How do you isolate and protect traffic within the workload VNet?
To secure communication within a VNet, set rules that inspect traffic. Then, allow or deny
traffic to, or from specific sources, and route them to the specified destinations.
Review the rule set and confirm that the required services are not
unintentionally blocked.
For traffic between subnets (also referred to as east-west traffic), it's recommended to
use Network Security Groups (NSG). NSGs allow you to define rules that check the
source and destination address, protocol and port of Inbound and Outbound traffic. The
address can be a single IP address, multiple IP addresses, an Azure service tag or an
entire subnet.
If NSGs are being used to isolate and protect the application, the rule set should be
reviewed to confirm that required services are not unintentionally blocked, or more
permissive access than expected is allowed.
For advanced networking controls, use Azure Firewall. It can be used to perform deep
packet inspection on both east-west and north-south traffic. Firewalls rules can be
defined as policies and centrally managed. An alternative solution is to use network
virtual appliances (NVAs) that check inbound (ingress) and outbound (egress) traffic and
filters based on rules.
How do you route network traffic through NVAs for security boundary policy
enforcement, auditing, and inspection?
Use User Defined Routes (UDR) to control the next hop for traffic between Azure, onpremises, and internet resources. The routes can be applied to virtual appliance, virtual
network gateway, virtual network, or internet.

For example, you need to inspect all ingress traffic from a public load balancer. One way
is to host an NVA in a subnet that allows traffic only if certain criteria is met. That traffic
is sent to the subnet that hosts an internal load balancer that routes that traffic to the
backend services.
You can also use NVAs for egress traffic. For instance, all workload traffic is routed by
using UDR to another subnet. That subnet has an internal load balancer that distributes
requests to the NVA (or a set of NVAs). These NVAs direct traffic to the internet using
their individual public IP addresses.
 Tip
Here are the resources for the preceding example:
GitHub: Automated failover for network virtual appliances .
The design considerations are described in Deploy highly available NVAs.
Azure Firewall can serve as an NVA. Azure supports third-party network device
providers. They're available in Azure Marketplace.
How do you get insights about ingoing and outgoing traffic of this workload?
As a general rule, configure and collect network traffic logs. If you use NSGs, capture
and analyze NSG flow logs to monitor performance and security. The NSG flow logs
enable Traffic Analytics to gain insights into internal and external traffic flows of the
application.
For information about defining network perimeters, see Network segmentation.
Can the VNet and subnet handle growth?
Typically, you'll add more network resources as the design matures. Most organizations
end up adding more resources to networks than initially planned. Refactoring to
accommodate the extra resources is a labor-intensive process. There is limited security
value in creating a very large number of small subnets and then trying to map network
access controls (such as security groups) to each of them.
Plan your subnets based on roles and functions that use the same protocols. That way,
you can add resources to the subnet without making changes to security groups that
enforce network level access controls.

Don't use all open rules that allow inbound and outbound traffic to and from 0.0.0.0255.255.255.255. Use a least-privilege approach and only allow relevant protocols. It will
reduce your overall network attack surface on the subnet. All open rules provide a false
sense of security because such a rule enforces no security.
The exception is when you want to use security groups only for network logging
purposes.
Design virtual networks and subnets for growth. We recommend planning subnets
based on common roles and functions that use common protocols for those roles and
functions. This allows you to add resources to the subnet without making changes to
security groups that enforce network level access controls.

Suggested actions
Use NSG or consider using Azure Firewall to protect and control traffic within the VNET.

Learn more
Azure firewall documentation
Design virtual network subnet security
Design an IP addressing schema for your Azure deployment
Network security groups

Internet edge traffic
As you design the workload, consider security for internet traffic. Does the workload or
parts of it need to be accessible from public IP addresses? What level of access should
be given to prevent unauthorized access?
Internet edge traffic (also called North-South traffic) represents network connectivity
between resources used by the workload and the internet. An internet edge strategy
should be designed to mitigate as many attacks from the internet to detect or block
threats. There are two primary choices that provide security controls and monitoring:
Azure solutions such as Azure Firewall and Web Application Firewall (WAF).
Azure provides networking solutions to restrict access to individual services. Use
multiple levels of security, such as combination of IP filtering, firewall rules to prevent
application services from being accessed by unauthorized actors.

Network virtual appliances (NVAs). You can use Azure Firewall or third-party
solutions available in Azure Marketplace.
Azure security features are sufficient for common attacks, easy to configure, and scale.
Third-party solutions often have advanced features but they can be hard to configure if
they don't integrate well with fabric controllers. From a cost perspective, Azure options
tend to be cheaper than partner solutions.
Information revealing the application platform, such as HTTP banners containing
framework information ( X-Powered-By , X-ASPNET-VERSION ), are commonly used by
malicious actors when mapping attack vectors of the application.
HTTP headers, error messages, and website footers should not contain information
about the application platform. Azure CDN can be used to separate the hosting
platform from end users. Azure API Management offers transformation policies that
allow you to modify HTTP headers and remove sensitive information.
Suggested action
Consider using CDN for the workload to limit platform detail exposure to attackers.
Learn more
Azure CDN documentation

Communication with backend services
Most workloads are composed of multiple tiers where several services can serve each
tier. Common examples of tiers are web front ends, business processes, reporting and
analysis, backend infrastructure, and so on.
Application resources allowing multiple methods to publish app content (such as FTP,
Web Deploy) should have the unused endpoints disabled. For Azure Web Apps, SCM is
the recommended endpoint and it can be protected separately with network restrictions
for sensitive scenarios.
Public access to any workload should be judiciously approved and planned, as public
entry points represent a key possible vector of compromise. When allowing access from
public IPs to any back-end service, limiting the range of allowed IPs can significantly
reduce the attack surface of that service. For example, if using Azure Front Door, you can
limit backend tiers to allow Front Door IPs only; or if a partner uses your API, limit access
to only their nominated public IP(s).
How do you configure traffic flow between multiple application tiers?

Use Azure Virtual Network Subnet to allocate separate address spaces for different
elements or tiers within the workload. Then, define different access policies to control
traffic flows between those tiers and restrict access. You can implement those
restrictions through IP filtering or firewall rules.
Do you need to restrict access to the backend infrastructure?
Restrict access to backend services to a minimal set of public IP addresses with App
Services IP restrictions or Azure Front Door.
Web applications typically have one public entry point and don't expose subsequent
APIs and database servers over the internet. Expose only a minimal set of public IP
addresses based on need and only those who really need it. For example, when using
gateway services, such as Azure Front Door, it's possible to restrict access only to a set
of Front Door IP addresses and lock down the infrastructure completely.
Suggested action
Restrict and protect application publishing methods.
Learn more
Set up Azure App Service access restrictions
Azure Front Door documentation
Deploy your app to Azure App Service using FTP/S

Connection with Azure PaaS services
The workload will often need to communicate with other Azure services. For example, it
might need to get secrets from Azure Key Vault. Avoid making connections over the
public internet.
Does the workload use secure ways to access Azure PaaS services?
Common approaches for accessing PaaS services are Service Endpoints or Private Links.
Both approaches restrict access to PaaS endpoints only from authorized virtual
networks, effectively mitigating data intrusion risks and associated impact to application
availability.
With Service Endpoints, the communication path is secure because you can reach the
PaaS endpoint without needing a public IP address on the VNet. Most PaaS services
support communication through service endpoints. For a list of generally available
services, see Virtual Network service endpoints.

Another mechanism is through Azure Private Link. Private Endpoint uses a private IP
address from your VNet, effectively bringing the service into your VNet. For details, see
What is Azure Private Link?.
Service Endpoints provide service level access to a PaaS service, whereas Private Link
provides direct access to a specific PaaS resource to mitigate data exfiltration risks, such
as malicious admin access. Private Link is a paid service and has meters for inbound and
outbound data processed. Private Endpoints are also charged.
How do you control outgoing traffic of Azure PaaS services where Private Link isn't
available?
Use NVAs and Azure Firewall (for supported protocols) as a reverse proxy to restrict
access to only authorized PaaS services for services where Private Link isn't supported.
Use Azure Firewall to protect against data exfiltration concerns.

On-premises to cloud connectivity
In a hybrid architecture, the workload runs partly on-premises and partly in Azure. Have
security controls that check traffic entering Azure virtual network from on-premises data
center.
How do you establish cross premises connectivity?
Use Azure ExpressRoute to set up cross premises connectivity to on-premises networks.
This service uses a private, dedicated connection through a third-party connectivity
provider. The private connection extends your on-premises network into Azure. This
way, you can reduce the risk of potential of access to company's information assets onpremises.
How do you access VMs?
Use Azure Bastion to log into your VMs and avoid public internet exposure using SSH
and RDP with private IP addresses only. You can also disable RDP/SSH access to VMs
and use VPN, ExpressRoute to access these virtual machines for remote management.
Do the cloud or on-premises VMs have direct internet connectivity for users that may
perform interactive logins?
Attackers constantly scan public cloud IP ranges for open management ports and
attempt low-cost attacks such as common passwords and known unpatched
vulnerabilities. Develop processes and procedures to prevent direct internet access of
VMs with logging and monitoring to enforce policies.

How is internet traffic routed?
Decide how to route internet traffic. You can use on-premises security devices (also
called forced tunneling) or allow connectivity through cloud-based network security
devices.
For production enterprise, allow cloud resources to start and respond to internet
request directly through cloud network security devices defined by your internet edge
strategy. This approach fits the Nth datacenter paradigm, that is Azure datacenters are a
part of your enterprise. It scales better for an enterprise deployment because it removes
hops that add load, latency, and cost.
Another option is to force tunnel all outbound internet traffic from on-premises through
site-to-site VPN. Or, use a cross-premise WAN link. Network security teams have greater
security and visibility to internet traffic. Even when your resources in the cloud try to
respond to incoming requests from the internet, the responses are force tunneled. This
option fits a datacenter expansion use case and can work well for a quick proof of
concept, but scales poorly because of the increased traffic load, latency, and cost. For
those reasons, we recommend that you avoid forced tunneling.

Next step
Secure endpoints

Related links
For information about controlling next hop for traffic, see Azure Virtual Network User
Defined Routes (UDR).
For information about web application firewalls, see Application Gateway WAF.
For information about Network Appliances from Azure Marketplace, see Network
Appliances

.

For information about cross premises connectivity, see Azure site-to-site VPN or
ExpressRoute.
For information about using VPN/ExpressRoute to access these virtual machines for
remote management, see Disable RDP/SSH access to Azure Virtual Machines.
Go back to the main article: Network security

Best practices for endpoint security on
Azure
Article • 11/30/2022

An endpoint is an address exposed by a web application so that external entities can
communicate with it. A malicious or an inadvertent interaction with the endpoint can
compromise the security of the application and even the entire system. One way to
protect the endpoint is by placing filter controls on the network traffic that it receives,
such as defining rule sets. A defense-in-depth approach can further mitigate risks.
Include supplemental controls that protect the endpoint if the primary traffic controls
fail.
This article describes way in which you can protect web applications with Azure services
and features. For product documentation, see Related links.

Key points
Protect all public endpoints with Azure Front Door, Application Gateway, Azure
Firewall, Azure DDoS Protection.
Use web application firewall (WAF) to protect web workloads.
Protect workload publishing methods and restrict ways that are not in use.
Mitigate DDoS attacks. Use Standard protection for critical workloads where
outage would have business impact. Also consider CDN as another layer of
protection.
Develop processes and procedures to prevent direct internet access of virtual
machines (such as proxy or firewall) with logging and monitoring to enforce
policies.
Implement an automated and gated CI/CD deployment process.

Public endpoints
A public endpoint receives traffic over the internet. The endpoints make the service
easily accessible to attackers.
Service Endpoints and Private Link can be leveraged to restrict access to PaaS endpoints
only from authorized virtual networks, effectively mitigating data intrusion risks and
associated impact to application availability. Service Endpoints provide service level
access to a PaaS service, while Private Link provides direct access to a specific PaaS
resource to mitigate data exfiltration risks such as malicious admin scenarios.

Configure service endpoints and private links where appropriate.
Are all public endpoints of this workload protected?
An initial design decision is to assess whether you need a public endpoint at all. If you
do, protect it by using these mechanisms.
For more information, see Virtual Network service endpoints and What is Azure Private
Endpoint?

Web application firewalls (WAFs)
WAFs provide a basic level of security for web applications. WAFs are appropriate if the
organizations that have invested in application security as WAFs provide additional
defense-in-depth mitigation.
WAFs mitigate the risk of an attacker to exploit commonly seen security vulnerabilities
for applications. WAFs provide a basic level of security for web applications. This
mechanism is an important mitigation because attackers target web applications for an
ingress point into an organization (similar to a client endpoint).
External application endpoints should be protected against common attack vectors,
from Denial of Service (DoS) attacks to app-level exploits, to prevent potential
application downtime due to malicious intent. Azure-native technologies such as Azure
Firewall, Application Gateway/Azure Front Door, WAF, and DDoS Network Protection
can be used to achieve requisite protection (Azure DDoS Protection).
Azure Application Gateway has WAF capabilities to inspect web traffic and detect attacks
at the HTTP layer. It's a load balancer and HTTP(S) full reverse proxy that can do secure
socket layer (SSL) encryption and decryption.
For example, your workload is hosted in Application Service Environments(ILB ASE). The
APIs are consolidated internally and exposed to external users. This external exposure
could be achieved using an Application Gateway. This service is a load balancer. It
forwards request to the internal API Management service, which in turn consumes the
APIs deployed in the ASE. Application Gateway is also configured over port 443 for
secured and reliable outbound calls.
 Tip
The design considerations for the preceding example are described in Publishing
internal APIs to external users.

Azure Front Door and Azure Content Delivery Network (CDN) also have WAF
capabilities.

Suggestion actions
Protect all public endpoints with appropriate solutions such as Azure Front Door,
Application Gateway, Azure Firewall, Azure DDOS Protection, or any third-party solution.
Learn more
What is Azure Firewall?
Azure DDoS Protection overview
Azure Front Door documentation
What is Azure Application Gateway?

Azure Firewall
Protect the entire virtual network against potentially malicious traffic from the internet
and other external locations. It inspects incoming traffic and only passes the allowed
requests to pass through.
A common design is to implement a DMZ or a perimeter network in front of the
application. The DMZ is a separate subnet with the firewall.
 Tip
The design considerations are described in Deploy highly available NVAs.

Combination approach
When you want higher security and there's a mix of web and non-web workloads in the
virtual network use both Azure Firewall and Application Gateway. There are several ways
in which those two services can work together.
For example, you want to filter egress traffic. You want to allow connectivity to a specific
Azure Storage Account but not others. You'll need fully qualified domain name (FQDN)based filters. In this case run Firewall and Application Gateway in parallel.
Another popular design is when you want Azure Firewall to inspect all traffic and WAF to
protect web traffic, and the application needs to know the client's source IP address. In
this case, place Application Gateway in front of Firewall. Conversely, you can place

Firewall in front of WAF if you want to inspect and filter traffic before it reaches the
Application Gateway.
For more information, see Firewall and Application Gateway for virtual networks.
It's challenging to write concise firewall rules for networks where different cloud
resources dynamically spin up and down. Use Microsoft Defender for Cloud to detect
misconfiguration risks.

Authentication
Disable insecure legacy protocols for internet-facing services. Legacy authentication
methods are among the top attack vectors for cloud-hosted services. Those methods
don't support other factors beyond passwords and are prime targets for password
spraying, dictionary, or brute force attacks.

Mitigate DDoS attacks
In a distributed denial-of-service (DDoS) attack, the server is overloaded with fake traffic.
DDoS attacks are common and can be debilitating. An attack can completely block
access or take down services. Make sure all business-critical web application and
services have DDoS mitigation beyond the default defenses so that the application
doesn't experience downtime because that can negatively impact business.
Microsoft recommends adopting advanced protection for any services where downtime
will have negative impact on the business.
How do you implement DDoS protection?
Here are some considerations:
DDoS protection at the infrastructure level in which your workload runs. Azure
infrastructure has built-in defenses for DDoS attacks.
DDoS protection at the network (layer 3) layer. Azure provides additional
protection for services provisioned in a virtual network.
DDoS protection with caching. Content delivery network (CDN) can add another
layer of protection. In a DDoS attack, a CDN intercepts the traffic and stops it from
reaching the backend server. Azure CDN is natively protected. Azure also supports
popular CDNs that are protected with proprietary DDoS mitigation platform.
Advanced DDoS protection. In your security baseline, consider features with
monitoring techniques that use machine learning to detect anomalous traffic and
proactively protect your application before service degradation occurs.

For information about Azure DDoS Protection services, see Azure DDoS Protection
documentation.

Suggested action
Identify critical workloads that are susceptible to DDoS attacks and enable Distributed
Denial of Service (DDoS) mitigations for all business-critical web applications and
services.

Learn more
For a list of reference architectures that demonstrate the use of DDoS protection, see
Azure DDoS Protection reference architectures.

Adopt DevOps
Developers shouldn't publish their code directly to app servers.
Does the organization have an CI/CD process for publishing code in this workload?
Implement lifecycle of continuous integration, continuous delivery (CI/CD) for
applications. Have processes and tools in place that aid in an automated and gated
CI/CD deployment process.
How are the publishing methods secured?
Application resources allowing multiple methods to publish app content, such as FTP,
Web Deploy should have the unused endpoints disabled. For Azure Web Apps, SCM is
the recommended endpoint. It can be protected separately with network restrictions for
sensitive use cases.

Next step
Data flow

Related links
Azure Firewall
What is Azure Web Application Firewall on Azure Application Gateway?
Azure DDoS Protection

Go back to the main article: Network security

Traffic flow security in Azure
Article • 11/30/2022

Protect data anywhere it goes including cloud services, mobile devices, workstations, or
collaboration platforms. In addition to using access control and encryption mechanisms,
apply strong network controls that detect, monitor, and contain attacks.

Key points
Control network traffic between subnets (east-west) and application tiers (northsouth).
Apply a layered defense-in-depth approach that starts with Zero-Trust policies.
Use a cloud application security broker (CASB).

East-west and north-south traffic
When analyzing the network flow of a workload, distinguish between east-west traffic
from north-south traffic. Most cloud architectures use a combination of both types.
Is the traffic between subnets, Azure components and tiers of the workload managed
and secured?
North-south traffic
North-south refers to the traffic that flows in and out of a datacenter. For example,
traffic from an application to a backend service. This type of traffic is a typical
target for attack vectors because it flows over the public internet. Proper network
controls must be in place so that the queries to and from a data center are secure.
Consider a typical flow in an Azure Kubernetes Service (AKS) cluster. The cluster
receives incoming (ingress) traffic from HTTP requests. The cluster can also send
outgoing (egress) traffic to send queries to other services, such as pulling a
container image.
Your design can use Web Application Firewall on Application Gateway to secure
ingress traffic, and Azure Firewall to secure outgoing (egress) traffic.
East-west traffic
East-west traffic refers to traffic between or within data centers. For this type of
traffic, several resources of the network infrastructure communicate with each

other. Those resources can be virtual networks, subnets within those virtual
networks, and so on. Security of east-west traffic can get overlooked even though
it makes up a large portion of the workload traffic. It's assumed that the
infrastructure firewalls are sufficient to block attacks. Make sure there are proper
controls between network resources.
Extending the example of the AKS cluster to this concept, east-west traffic is the
traffic within the cluster. For example, communication between pods, such as the
ingress controller and the workload. If your workload is composed of multiple
applications, the communication between those applications would fall into this
category.
By using Kubernetes network policies, you can restrict which pods can
communicate, starting from a Zero-Trust policy and then opening specific
communication paths as needed.
 Tip
Here are the resources for the preceding AKS example:

GitHub: Azure Kubernetes Service (AKS) Secure Baseline Reference
Implementation .
The design considerations are described in Azure Kubernetes Service (AKS)
production baseline.

Data exfiltration
Data exfiltration is a common attack where an internal or external malicious actor does
an unauthorized data transfer. Most often access is gained because of lack of network
controls.
Network virtual appliance (NVA) solutions and Azure Firewall (for supported protocols)
can be leveraged as a reverse proxy to restrict access to only authorized PaaS services
for services where Private Link is not yet supported (Azure Firewall).
Configure Azure Firewall or a third-party next generation firewall to protect against data
exfiltration concerns.
Are there controls in the workload design to detect and protect from data
exfiltration?

Choose a defense-in-depth design that can protect network communications at various
layers, such as a hub-spoke topology. Azure provides several controls to support the
layered design:
Use Azure Firewall to allow or deny traffic using layer 3 to layer 7 controls.
Use Azure Virtual Network User Defined Routes (UDR) to control next hop for
traffic.
Control traffic with Network Security Groups (NSGs) between resources within a
virtual network, internet, and other virtual networks.
Secure the endpoints through Azure PrivateLink and Private Endpoints.
Detect and protect at deep levels through packet inspection.
Detect attacks and respond to alerts through Microsoft Sentinel and Microsoft
Defender for Cloud.
） Important
Network controls are not sufficient in blocking data exfiltration attempts. Harden
the protection with proper identity controls, key protection, and encryption. For
more information, see these sections:
Data protection considerations
Identity and access management considerations
Have you considered a cloud application security broker (CASB) for this workload?
CASBs provide a central point of control for enforcing policies. They provide rich
visibility, control over data travel, and sophisticated analytics to identify and combat
cyberthreats across all Microsoft and third-party cloud services.

Learn more
Azure firewall documentation
Azure Marketplace networking apps

Related links
Azure Firewall
Network Security Groups (NSG)
What is Azure Web Application Firewall on Azure Application Gateway?
What is Azure Private Link?

Go back to the main article: Network security

Azure best practices for network
security
Article • 03/17/2023

This article discusses a collection of Azure best practices to enhance your network
security. These best practices are derived from our experience with Azure networking
and the experiences of customers like yourself.
For each best practice, this article explains:
What the best practice is
Why you want to enable that best practice
What might be the result if you fail to enable the best practice
Possible alternatives to the best practice
How you can learn to enable the best practice
These best practices are based on a consensus opinion, and Azure platform capabilities
and feature sets, as they exist at the time this article was written. Opinions and
technologies change over time and this article will be updated regularly to reflect those
changes.

Use strong network controls
You can connect Azure virtual machines (VMs)

and appliances to other networked

devices by placing them on Azure virtual networks. That is, you can connect virtual
network interface cards to a virtual network to allow TCP/IP-based communications
between network-enabled devices. Virtual machines connected to an Azure virtual
network can connect to devices on the same virtual network, different virtual networks,
the internet, or your own on-premises networks.
As you plan your network and the security of your network, we recommend that you
centralize:
Management of core network functions like ExpressRoute, virtual network and
subnet provisioning, and IP addressing.
Governance of network security elements, such as network virtual appliance
functions like ExpressRoute, virtual network and subnet provisioning, and IP
addressing.
If you use a common set of management tools to monitor your network and the security
of your network, you get clear visibility into both. A straightforward, unified security

strategy reduces errors because it increases human understanding and the reliability of
automation.

Logically segment subnets
Azure virtual networks are similar to LANs on your on-premises network. The idea
behind an Azure virtual network is that you create a network, based on a single private
IP address space, on which you can place all your Azure virtual machines. The private IP
address spaces available are in the Class A (10.0.0.0/8), Class B (172.16.0.0/12), and Class
C (192.168.0.0/16) ranges.
Best practices for logically segmenting subnets include:
Best practice: Don't assign allow rules with broad ranges (for example, allow 0.0.0.0
through 255.255.255.255).
Detail: Ensure troubleshooting procedures discourage or ban setting up these types of
rules. These allow rules lead to a false sense of security and are frequently found and
exploited by red teams.
Best practice: Segment the larger address space into subnets.
Detail: Use CIDR

-based subnetting principles to create your subnets.

Best practice: Create network access controls between subnets. Routing between
subnets happens automatically, and you don't need to manually configure routing
tables. By default, there are no network access controls between the subnets that you
create on an Azure virtual network.
Detail: Use a network security group to protect against unsolicited traffic into Azure
subnets. Network security groups (NSGs) are simple, stateful packet inspection devices.
NSGs use the 5-tuple approach (source IP, source port, destination IP, destination port,
and layer 4 protocol) to create allow/deny rules for network traffic. You allow or deny
traffic to and from a single IP address, to and from multiple IP addresses, or to and from
entire subnets.
When you use network security groups for network access control between subnets, you
can put resources that belong to the same security zone or role in their own subnets.
Best practice: Avoid small virtual networks and subnets to ensure simplicity and
flexibility. Detail: Most organizations add more resources than initially planned, and
reallocating addresses is labor intensive. Using small subnets adds limited security value,
and mapping a network security group to each subnet adds overhead. Define subnets
broadly to ensure that you have flexibility for growth.

Best practice: Simplify network security group rule management by defining Application
Security Groups.
Detail: Define an Application Security Group for lists of IP addresses that you think
might change in the future or be used across many network security groups. Be sure to
name Application Security Groups clearly so others can understand their content and
purpose.

Adopt a Zero Trust approach
Perimeter-based networks operate on the assumption that all systems within a network
can be trusted. But today's employees access their organization's resources from
anywhere on various devices and apps, which makes perimeter security controls
irrelevant. Access control policies that focus only on who can access a resource aren't
enough. To master the balance between security and productivity, security admins also
need to factor in how a resource is being accessed.
Networks need to evolve from traditional defenses because networks might be
vulnerable to breaches: an attacker can compromise a single endpoint within the trusted
boundary and then quickly expand a foothold across the entire network. Zero Trust
networks eliminate the concept of trust based on network location within a perimeter.
Instead, Zero Trust architectures use device and user trust claims to gate access to
organizational data and resources. For new initiatives, adopt Zero Trust approaches that
validate trust at the time of access.
Best practices are:
Best practice: Give Conditional Access to resources based on device, identity, assurance,
network location, and more.
Detail: Azure AD Conditional Access lets you apply the right access controls by
implementing automated access control decisions based on the required conditions. For
more information, see Manage access to Azure management with Conditional Access.
Best practice: Enable port access only after workflow approval.
Detail: You can use just-in-time VM access in Microsoft Defender for Cloud to lock down
inbound traffic to your Azure VMs, reducing exposure to attacks while providing easy
access to connect to VMs when needed.
Best practice: Grant temporary permissions to perform privileged tasks, which prevents
malicious or unauthorized users from gaining access after the permissions have expired.
Access is granted only when users need it.
Detail: Use just-in-time access in Azure AD Privileged Identity Management or in a
third-party solution to grant permissions to perform privileged tasks.

Zero Trust is the next evolution in network security. The state of cyberattacks drives
organizations to take the "assume breach" mindset, but this approach shouldn't be
limiting. Zero Trust networks protect corporate data and resources while ensuring that
organizations can build a modern workplace by using technologies that empower
employees to be productive anytime, anywhere, in any way.

Control routing behavior
When you put a virtual machine on an Azure virtual network, the VM can connect to any
other VM on the same virtual network, even if the other VMs are on different subnets.
This is possible because a collection of system routes enabled by default allows this type
of communication. These default routes allow VMs on the same virtual network to
initiate connections with each other, and with the internet (for outbound
communications to the internet only).
Although the default system routes are useful for many deployment scenarios, there are
times when you want to customize the routing configuration for your deployments. You
can configure the next-hop address to reach specific destinations.
We recommend that you configure user-defined routes when you deploy a security
appliance for a virtual network. We talk about this recommendation in a later section
titled secure your critical Azure service resources to only your virtual networks.
７ Note
User-defined routes aren't required, and the default system routes usually work.

Use virtual network appliances
Network security groups and user-defined routing can provide a certain measure of
network security at the network and transport layers of the OSI model . But in some
situations, you want or need to enable security at high levels of the stack. In such
situations, we recommend that you deploy virtual network security appliances provided
by Azure partners.
Azure network security appliances can deliver better security than what network-level
controls provide. Network security capabilities of virtual network security appliances
include:
Firewalling
Intrusion detection/intrusion prevention

Vulnerability management
Application control
Network-based anomaly detection
Web filtering
Antivirus
Botnet protection
To find available Azure virtual network security appliances, go to the Azure
Marketplace

and search for "security" and "network security."

Deploy perimeter networks for security zones
A perimeter network (also known as a DMZ) is a physical or logical network segment
that provides an extra layer of security between your assets and the internet. Specialized
network access control devices on the edge of a perimeter network allow only desired
traffic into your virtual network.
Perimeter networks are useful because you can focus your network access control
management, monitoring, logging, and reporting on the devices at the edge of your
Azure virtual network. A perimeter network is where you typically enable distributed
denial of service (DDoS) protection, intrusion detection/intrusion prevention systems
(IDS/IPS), firewall rules and policies, web filtering, network antimalware, and more. The
network security devices sit between the internet and your Azure virtual network and
have an interface on both networks.
Although this is the basic design of a perimeter network, there are many different
designs, like back-to-back, tri-homed, and multi-homed.
Based on the Zero Trust concept mentioned earlier, we recommend that you consider
using a perimeter network for all high security deployments to enhance the level of
network security and access control for your Azure resources. You can use Azure or a
third-party solution to provide an extra layer of security between your assets and the
internet:
Azure native controls. Azure Firewall and Azure Web Application Firewall offer
basic security advantages. Advantages are a fully stateful firewall as a service, builtin high availability, unrestricted cloud scalability, FQDN filtering, support for
OWASP core rule sets, and simple setup and configuration.
Third-party offerings. Search the Azure Marketplace

for next-generation firewall

(NGFW) and other third-party offerings that provide familiar security tools and
enhanced levels of network security. Configuration might be more complex, but a
third-party offering might allow you to use existing capabilities and skillsets.

Avoid exposure to the internet with dedicated
WAN links
Many organizations have chosen the hybrid IT route. With hybrid IT, some of the
company's information assets are in Azure, and others remain on-premises. In many
cases, some components of a service are running in Azure while other components
remain on-premises.
In a hybrid IT scenario, there's usually some type of cross-premises connectivity. Crosspremises connectivity allows the company to connect its on-premises networks to Azure
virtual networks. Two cross-premises connectivity solutions are available:
Site-to-site VPN. It's a trusted, reliable, and established technology, but the
connection takes place over the internet. Bandwidth is constrained to a maximum
of about 1.25 Gbps. Site-to-site VPN is a desirable option in some scenarios.
Azure ExpressRoute. We recommend that you use ExpressRoute for your crosspremises connectivity. ExpressRoute lets you extend your on-premises networks
into the Microsoft cloud over a private connection facilitated by a connectivity
provider. With ExpressRoute, you can establish connections to Microsoft cloud
services like Azure, Microsoft 365, and Dynamics 365. ExpressRoute is a dedicated
WAN link between your on-premises location or a Microsoft Exchange hosting
provider. Because this is a telco connection, your data doesn't travel over the
internet, so it isn't exposed to the potential risks of internet communications.
The location of your ExpressRoute connection can affect firewall capacity, scalability,
reliability, and network traffic visibility. You'll need to identify where to terminate
ExpressRoute in existing (on-premises) networks. You can:
Terminate outside the firewall (the perimeter network paradigm). Use this
recommendation if you require visibility into the traffic, if you need to continue an
existing practice of isolating datacenters, or if you're solely putting extranet
resources on Azure.
Terminate inside the firewall (the network extension paradigm). This is the default
recommendation. In all other cases, we recommend treating Azure as another
datacenter.

Optimize uptime and performance
If a service is down, information can't be accessed. If performance is so poor that the
data is unusable, you can consider the data to be inaccessible. From a security

perspective, you need to do whatever you can to make sure that your services have
optimal uptime and performance.
A popular and effective method for enhancing availability and performance is load
balancing. Load balancing is a method of distributing network traffic across servers that
are part of a service. For example, if you have front-end web servers as part of your
service, you can use load balancing to distribute the traffic across your multiple frontend web servers.
This distribution of traffic increases availability because if one of the web servers
becomes unavailable, the load balancer stops sending traffic to that server and redirects
it to the servers that are still online. Load balancing also helps performance, because the
processor, network, and memory overhead for serving requests is distributed across all
the load-balanced servers.
We recommend that you employ load balancing whenever you can, and as appropriate
for your services. Following are scenarios at both the Azure virtual network level and the
global level, along with load-balancing options for each.
Scenario: You have an application that:
Requires requests from the same user/client session to reach the same back-end
virtual machine. Examples of this are shopping cart apps and web mail servers.
Accepts only a secure connection, so unencrypted communication to the server
isn't an acceptable option.
Requires multiple HTTP requests on the same long-running TCP connection to be
routed or load balanced to different back-end servers.
Load-balancing option: Use Azure Application Gateway, an HTTP web traffic load
balancer. Application Gateway supports end-to-end TLS encryption and TLS termination
at the gateway. Web servers can then be unburdened from encryption and decryption
overhead and traffic flowing unencrypted to the back-end servers.
Scenario: You need to load balance incoming connections from the internet among your
servers located in an Azure virtual network. Scenarios are when you:
Have stateless applications that accept incoming requests from the internet.
Don't require sticky sessions or TLS offload. Sticky sessions is a method used with
Application Load Balancing, to achieve server-affinity.
Load-balancing option: Use the Azure portal to create an external load balancer that
spreads incoming requests across multiple VMs to provide a higher level of availability.

Scenario: You need to load balance connections from VMs that are not on the internet.
In most cases, the connections that are accepted for load balancing are initiated by
devices on an Azure virtual network, such as SQL Server instances or internal web
servers.
Load-balancing option: Use the Azure portal to create an internal load balancer that
spreads incoming requests across multiple VMs to provide a higher level of availability.
Scenario: You need global load balancing because you:
Have a cloud solution that is widely distributed across multiple regions and
requires the highest level of uptime (availability) possible.
Need the highest level of uptime possible to make sure that your service is
available even if an entire datacenter becomes unavailable.
Load-balancing option: Use Azure Traffic Manager. Traffic Manager makes it possible to
load balance connections to your services based on the location of the user.
For example, if the user makes a request to your service from the EU, the connection is
directed to your services located in an EU datacenter. This part of Traffic Manager global
load balancing helps to improve performance because connecting to the nearest
datacenter is faster than connecting to datacenters that are far away.

Disable RDP/SSH Access to virtual machines
It's possible to reach Azure virtual machines by using Remote Desktop Protocol
and the Secure Shell

(RDP)

(SSH) protocol. These protocols enable the management VMs

from remote locations and are standard in datacenter computing.
The potential security problem with using these protocols over the internet is that
attackers can use brute force

techniques to gain access to Azure virtual machines.

After the attackers gain access, they can use your VM as a launch point for
compromising other machines on your virtual network or even attack networked devices
outside Azure.
We recommend that you disable direct RDP and SSH access to your Azure virtual
machines from the internet. After direct RDP and SSH access from the internet is
disabled, you have other options that you can use to access these VMs for remote
management.
Scenario: Enable a single user to connect to an Azure virtual network over the internet.
Option: Point-to-site VPN is another term for a remote access VPN client/server
connection. After the point-to-site connection is established, the user can use RDP or
SSH to connect to any VMs located on the Azure virtual network that the user

connected to via point-to-site VPN. This assumes that the user is authorized to reach
those VMs.
Point-to-site VPN is more secure than direct RDP or SSH connections because the user
has to authenticate twice before connecting to a VM. First, the user needs to
authenticate (and be authorized) to establish the point-to-site VPN connection. Second,
the user needs to authenticate (and be authorized) to establish the RDP or SSH session.
Scenario: Enable users on your on-premises network to connect to VMs on your Azure
virtual network.
Option: A site-to-site VPN connects an entire network to another network over the
internet. You can use a site-to-site VPN to connect your on-premises network to an
Azure virtual network. Users on your on-premises network connect by using the RDP or
SSH protocol over the site-to-site VPN connection. You don't have to allow direct RDP
or SSH access over the internet.
Scenario: Use a dedicated WAN link to provide functionality similar to the site-to-site
VPN.
Option: Use ExpressRoute. It provides functionality similar to the site-to-site VPN. The
main differences are:
The dedicated WAN link doesn't traverse the internet.
Dedicated WAN links are typically more stable and perform better.

Secure your critical Azure service resources to
only your virtual networks
Use Azure Private Link to access Azure PaaS Services (for example, Azure Storage and
SQL Database) over a private endpoint in your virtual network. Private Endpoints allow
you to secure your critical Azure service resources to only your virtual networks. Traffic
from your virtual network to the Azure service always remains on the Microsoft Azure
backbone network. Exposing your virtual network to the public internet is no longer
necessary to consume Azure PaaS Services.
Azure Private Link provides the following benefits:
Improved security for your Azure service resources: With Azure Private Link,
Azure service resources can be secured to your virtual network using private
endpoint. Securing service resources to a private endpoint in virtual network
provides improved security by fully removing public internet access to resources,
and allowing traffic only from private endpoint in your virtual network.

Privately access Azure service resources on the Azure platform: Connect your
virtual network to services in Azure using private endpoints. There's no need for a
public IP address. The Private Link platform will handle the connectivity between
the consumer and services over the Azure backbone network.
Access from On-premises and peered networks: Access services running in Azure
from on-premises over ExpressRoute private peering, VPN tunnels, and peered
virtual networks using private endpoints. There's no need to configure
ExpressRoute Microsoft peering or traverse the internet to reach the service.
Private Link provides a secure way to migrate workloads to Azure.
Protection against data leakage: A private endpoint is mapped to an instance of a
PaaS resource instead of the entire service. Consumers can only connect to the
specific resource. Access to any other resource in the service is blocked. This
mechanism provides protection against data leakage risks.
Global reach: Connect privately to services running in other regions. The
consumer's virtual network could be in region A and it can connect to services in
region B.
Simple to set up and manage: You no longer need reserved, public IP addresses in
your virtual networks to secure Azure resources through an IP firewall. There are no
NAT or gateway devices required to set up the private endpoints. Private endpoints
are configured through a simple workflow. On service side, you can also manage
the connection requests on your Azure service resource with ease. Azure Private
Link works for consumers and services belonging to different Azure Active
Directory tenants too.
To learn more about private endpoints and the Azure services and regions that private
endpoints are available for, see Azure Private Link.

Next steps
See Azure security best practices and patterns for more security best practices to use
when you're designing, deploying, and managing your cloud solutions by using Azure.

Data protection considerations
Article • 12/27/2022

Classify, protect, and monitor sensitive data assets using access control, encryption, and
logging in Azure. Provide controls on data at rest and in transit.

Checklist
How are you managing encryption for this workload?
＂ Use identity based storage access controls.
＂ Use built-in features for data encryption for Azure services.
＂ Classify all stored data and encrypt it.
＂ Protect data moving over a network through encryption at all points so that it's not
accessed unauthorized users.
＂ Store keys in managed key vault service with identity-based access control and
audit policies.
＂ Rotate keys and other secrets frequently.

Azure security benchmark
The Azure Security Benchmark includes a collection of high-impact security
recommendations you can use to help secure the services you use in Azure:

The questions in this section are aligned to the Azure Security Benchmarks
Data Protection.

Reference architecture
Here are some reference architectures related to secure storage:
Using Azure file shares in a hybrid environment
DevSecOps in Azure

Next steps
We recommend that you review the practices and tools implemented as part of the
development cycle.

Design Storage Encryption

Related links
Back to the main article: Security

Data encryption in Azure
Article • 11/30/2022

Data can be categorized by its state:
Data at rest. All information storage objects, containers, and types that exist
statically on physical media, whether magnetic or optical disk.
Data in transit. Data that is being transferred between components, locations, or
programs.
In a cloud solution, a single business transaction can lead to multiple data operations
where data moves from one storage medium to another. To provide complete data
protection, it must be encrypted on storage volumes and while it's transferred from one
point to another.

Key points
Use identity-based storage access controls.
Use standard and recommended encryption algorithms.
Use only secure hash algorithms (SHA-2 family).
Classify your data at rest and use encryption.
Encrypt virtual disks.
Use an additional key encryption key (KEK) to protect your data encryption key
(DEK).
Protect data in transit through encrypted network channels (TLS/HTTPS) for all
client/server communication. Use TLS 1.2 on Azure.

Azure encryption features
Azure provides built-in features for data encryption in many layers that participate in
data processing. We recommend that for each service, enable the encryption capability.
The encryption is handled automatically using Azure-managed keys. This almost
requires no user interaction.
We recommend implementing identity-based storage access controls. Authentication
with a shared key (like a Shared Access Signature) doesn't permit the same flexibility and
control as identity-based access control. The leak of a shared key might allow indefinite
access to a resource, whereas a role-based access control can be identified and
authenticated more strongly.

Storage in a cloud service like Azure is architected and implemented quite differently
than on-premises solutions to enable massive scaling, modern access through REST
APIs, and isolation between tenants. Cloud service providers make multiple methods of
access control over storage resources available. Examples include shared keys, shared
signatures, anonymous access, and identity provider-based methods.
Consider some built-in features of Azure Storage:
Identity-based access. Supports access through Azure Active Directory (Azure AD)
and key-based authentication mechanisms, such as Symmetric Shared Key
Authentication, or Shared Access Signature (SAS).
Built-in encryption. All stored data is encrypted by Azure storage. Data cannot be
read by a tenant if it has not been written by that tenant. This feature provides
control over cross tenant data leakage.
Region-based controls. Data remains only in the selected region and three
synchronous copies of data are maintained within that region. Azure storage
provides detailed activity logging is available on an opt-in basis.
Firewall features. The firewall provides an additional layer of access control and
storage threat protection to detect anomalous access and activities.
For the complete set of features, see Azure Storage Service encryption.

Suggested action
Identify provider methods of authentication and authorization that are the least likely to
be compromised, and enable more fine-grained role-based access controls over storage
resources.
Learn more
For more information, reference Authorize access to blobs using Azure Active Directory.

Standard encryption algorithms
Does the organization use industry standard encryption algorithms instead of
creating their own?
Organizations should not develop and maintain their own encryption algorithms. Avoid
using custom encryption algorithms or direct cryptography in your workload. These
methods rarely stand up to real world attacks.

Secure standards already exist on the market and should be preferred. If custom
implementation is required, developers should use well-established cryptographic
algorithms and secure standards. Use Advanced Encryption Standard (AES) as a
symmetric block cipher, AES-128, AES-192, and AES-256 are acceptable.
Developers should use cryptography APIs built into operating systems instead of nonplatform cryptography libraries. For .NET, follow the .NET Cryptography Model.
We advise using standard and recommended encryption algorithms.
For more information, refer to Choose an algorithm.
Are modern hashing functions used?
Applications should use the SHA-2 family of hash algorithms (SHA-256, SHA-384, SHA512).

Data at rest
All important data should be classified and encrypted with an encryption standard.
Classify and protect all information storage objects. Use encryption to make sure the
contents of files cannot be accessed by unauthorized users.
Data at rest is encrypted by default in Azure, but is your critical data classified and
tagged, or labeled so that it can be audited?
Your most sensitive data might include business, financial, healthcare, or personal
information. Discovering and classifying this data can play a pivotal role in your
organization's information protection approach. It can serve as infrastructure for:
Helping to meet standards for data privacy and requirements for regulatory
compliance.
Various security scenarios, such as monitoring (auditing) and alerting on
anomalous access to sensitive data.
Controlling access to and hardening the security of databases that contain highly
sensitive data.
Suggested action
Classify your data. Consider using Data Discovery & Classification in Azure SQL
Database.

Data classification

A crucial initial exercise for protecting data is to organize it into categories based on
certain criteria. The classification criteria can be your business needs, compliance
requirements, and the type of data.
Depending on the category, you can protect it through:
Standard encryption mechanisms.
Enforce security governance through policies.
Conduct audits to make sure the security measures are compliant.
One way of classifying data is through the use of tags.
Does the organization encrypt virtual disk files for virtual machines that are
associated with this workload?
There are many options to store files in the cloud. Cloud-native apps typically use Azure
Storage. Apps that run on VMs use them to store files. VMs use virtual disk files as
virtual storage volumes and exist in a blob storage.
Consider a hybrid solution. Files can move from on-premises to the cloud, from the
cloud to on-premises, or between services hosted in the cloud. One strategy is to make
sure that the files and their contents aren't accessible to unauthorized users. You can use
authentication-based access controls to prevent unauthorized downloading of files.
However, that is not enough. Have a backup mechanism to secure the virtual disk files in
case authentication and authorization or its configuration is compromised. There are
several approaches. You can encrypt the virtual disk files. If an attempt is made to mount
disk files, the contents of the files cannot be accessed because of the encryption.
We recommend that you enable virtual disk encryption. For information about how to
encrypt Windows VM disks, see Quickstart: Create and encrypt a Windows VM with the
Azure CLI.
Azure-based virtual disks are stored as files in a Storage account. If no encryption is
applied to a virtual disk, and an attacker manages to download a virtual disk image file,
it can be mounted and inspected at the attacker's leisure as if they had physical access
to the source computer. Encrypting virtual disk files helps prevent attackers from
gaining access to the contents of those disk files in the event they are able to download
them. Depending on the sensitivity of the information stored on the disk, unencrypted
access could represent a critical risk to confidential business data (such as a SQL
database) or identity (such as an AD Domain Controller).
An example of virtual disk encryption is Azure Disk Encryption.

Azure Disk Encryption helps protect and safeguard your data to meet your
organizational security and compliance commitments. It uses the Bitlocker-feature of
Windows (or DM-Crypt on Linux) to provide volume encryption for the OS and data
disks of Azure virtual machines (VMs). It is integrated with Azure Key Vault to help you
control and manage the disk encryption keys, and secrets.
Virtual machines use virtual disk files as storage volumes and exist in a cloud service
provider's blob storage system. These files can be moved from on-premises to cloud
systems, from cloud systems to on-premises, or between cloud systems. Due to the
mobility of these files, it's recommended that the files and the contents are not
accessible to unauthorized users.
Does the organization use identity-based storage access controls for this workload?
There are many ways to control access to data: shared keys, shared signatures,
anonymous access, identity provider-based. Use Azure Active Directory (Azure AD) and
role-based access control (RBAC) to grant access. For more information, see Identity and
access management considerations.
Does the organization protect keys in this workload with an additional key encryption
key (KEK)?
Use more than one encryption key in an encryption at rest implementation. Storing an
encryption key in Azure Key Vault ensures secure key access and central management of
keys.
Use an additional key encryption key (KEK) to protect your data encryption key (DEK).
Suggested actions
Identify unencrypted virtual machines via Microsoft Defender for Cloud or script, and
encrypt via Azure Disk Encryption. Ensure all new virtual machines are encrypted by
default and regularly monitor for unprotected disks.
Learn more
Azure Disk Encryption for virtual machines and virtual machine scale sets

Data in transit
Data in transit should be encrypted at all points to ensure data integrity.
Protecting data in transit should be an essential part of your data protection strategy.
Because data is moving back and forth from many locations, we generally recommend

that you always use SSL/TLS protocols to exchange data across different locations.
For data moving between your on-premises infrastructure and Azure, consider
appropriate safeguards such as HTTPS or VPN. When sending encrypted traffic between
an Azure virtual network and an on-premises location over the public internet, use Azure
VPN Gateway.
Does the workload communicate over encrypted network traffic only?
Any network communication between client and server where man-in-the-middle
attacks can occur, must be encrypted. All website communication should use HTTPS, no
matter the perceived sensitivity of transferred data. Man-in-the-middle attacks can
occur anywhere on the site, not just login forms.
This mechanism can be applied to use cases such as:
Web applications and APIs for all communication with clients.
Data moving across a service bus from on-premises to the cloud and other way
around, or during an input/output process.
In certain architecture styles such as microservices, data must be encrypted during
communication between the services.
What TLS version is used across workloads?
Using the latest version of TLS is preferred. All Azure services support TLS 1.2 on public
HTTPS endpoints. Migrate solutions to support TLS 1.2 and use this version by default.
When traffic from clients using older versions of TLS is minimal, or it's acceptable to fail
requests made with an older version of TLS, consider enforcing a minimum TLS version.
For information about TLS support in Azure Storage, see Remediate security risks with a
minimum version of TLS.
Sometimes you need to isolate your entire communication channel between your onpremises and the cloud infrastructure by using either a virtual private network (VPN) or
ExpressRoute. For more information, see these articles:
Extending on-premises data solutions to the cloud
Configure a Point-to-Site VPN connection to a VNet using native Azure certificate
authentication: Azure portal
For more information, see Protect data in transit.
Is there any portion of the application that doesn't secure data in transit?

All data should be encrypted in transit using a common encryption standard. Determine
if all components in the solution are using a consistent standard. There are times when
encryption is not possible because of technical limitations, make sure the reason is clear
and valid.

Suggested actions
Identify workloads using unencrypted sessions and configure the service to require
encryption.

Learn more
Encrypt data in transit
Azure encryption overview

Next steps
While it's important to protect data through encryption, it's equally important to protect
they keys that provide access to the data.
Key and secret management

Related links
Identity and access management services authenticate and grant permission to users,
partners, customers, applications, services, and other entities. For security
considerations, see Azure identity and access management considerations.
Back to the main article: Data protection

Key and secret management
considerations in Azure
Article • 11/30/2022

Encryption is an essential tool for security because it restricts access. However, it's
equally important to protect the secrets (keys, certificates) key that provide access to the
data.

Key points
Use identity-based access control instead of cryptographic keys.
Use standard and recommended encryption algorithms.
Store keys and secrets in managed key vault service. Control permissions with an
access model.
Rotate keys and other secrets frequently. Replace expired or compromised secrets.

Identity-based access control
Organizations shouldn't develop and maintain their own encryption algorithms. There
are many ways to provide access control over storage resources available, such as:
Shared keys
Shared signatures
Anonymous access
Identity provider-based methods
Secure standards already exist on the market and should be preferred. AES should be
used as symmetric block cipher, AES-128 , AES-192 , and AES-256 are acceptable. Crypto
APIs built into operating systems should be used where possible, instead of nonplatform crypto libraries. For .NET, make sure you follow the .NET Cryptography Model.
Do you prioritize authentication through identity services for a workload over
cryptographic keys?
Protection of cryptographic keys can often get overlooked or implemented poorly.
Managing keys securely with application code is especially difficult and can lead to
mistakes such as accidentally publishing sensitive access keys to public code
repositories.

Use of identity-based options for storage access control is recommended. This option
uses role-based access controls (RBAC) over storage resources. Use RBAC to assign
permissions to users, groups, and applications at a certain scope. Identity systems such
as Azure Active Directory (Azure AD) offer secure and usable experience for access
control with built-in mechanisms for handling key rotation, monitoring for anomalies,
and others.
７ Note
Grant access based on the principle of least privilege. Risk of giving more privileges
than necessary can lead to data compromise.
Suppose you need to store sensitive data in Azure Blob Storage. You can use Azure AD
and RBAC to authenticate a service principal that has the required permissions to access
the storage. For more information about the feature, reference Authorize access to
blobs and queues using Azure Active Directory.
 Tip
Using SAS tokens is a common way to control access. SAS tokens are created by
using the service owner's Azure AD credentials. The tokens are created per resource
and you can use Azure RBAC to restrict access. SAS tokens have a time limit, which
controls the window of exposure.

Key storage
To prevent security leaks, store the following keys and secrets in a secure store:
API keys
Database connection strings
Data encryption keys
Passwords
Sensitive information shouldn't be stored within the application code or configuration.
An attacker gaining read access to source code shouldn't gain knowledge of application
and environment-specific secrets.
Store all application keys and secrets in a managed key vault service such as Azure Key
Vault or HashiCorp Vault . Storing encryption keys in a managed store further limits

access. The workload can access the secrets by authenticating against Key Vault by using
managed identities. That access can be restricted with Azure RBAC.
Make sure no keys and secrets for any environment types (Dev, Test, or Production) are
stored in application configuration files or CI/CD pipelines. Developers can use Visual
Studio Connected Services or local-only files to access credentials.
Have processes that periodically detect exposed keys in your application code. An
option is Credential Scanner. For information about the configuring task, reference
Credential Scanner task.
Do you have an access model for key vaults to grant access to keys and secrets?
To secure access to your key vaults, control permissions to keys and secrets through an
access model. For more information, reference Access model overview.
Suggested actions
Consider using Azure Key Vault for secrets and keys.

Operational considerations
Who is responsible for managing keys and secrets in the application context?
Key and certificate rotation is often the cause of application outages. Even Azure has
experienced expired certificates. It's critical that the rotation of keys and certificates be
scheduled and fully operationalized. The rotation process should be automated and
tested to ensure effectiveness. Azure Key Vault supports key rotation and auditing.
Central SecOps team provides guidance on how keys and secrets are managed
(governance). Application DevOps team is responsible for managing the applicationrelated keys and secrets.
What types of keys and secrets are used and how are those generated?
The following approaches include:
Microsoft-managed Keys
Customer-managed Keys
Bring Your Own Key
The decision is often driven by security, compliance, and specific data classification
requirements. Develop a clear understanding of these requirements to determine the
most suitable type of keys.

Are keys and secrets rotated frequently?
To reduce the attack vectors, secrets require rotation and are prone to expiration. The
process should be automated and executed without any human interactions. Storing
them in a managed store simplifies those operational tasks by handling key rotation.
Replace secrets after they've reached the end of their active lifetime or if they've been
compromised. Renewed certificates should also use a new key. Have a process for
situations where keys get compromised (leaked) and need to be regenerated ondemand. For example, secrets rotation in SQL Database.
For more information, reference Key Vault Key Rotation.
By using managed identities, you remove the operational overhead for storing the
secrets or certificates of service principals.
Are the expiration dates of SSL/TLS certificates monitored and are processes in place
to renew them?
A common cause of application outage is expired SSL/TLS certificates.
Avoid outages by tracking the expiration dates of SSL/TLS certificates and renewing
them in due time. Ideally, the process should be automated, although this often
depends on used certificate authority (CA). If not automated, use alerts to make sure
expiration dates don't go unnoticed.

Suggested actions
Implement a process for SSL certificate management and the automated renewal
process with Azure Key Vault.

Learn more
Tutorial: Configure certificate auto-rotation in Key Vault

Related content
Identity and access management services authenticate and grant permission to the
following groups:
Users
Partners

Customers
Applications
Services
Other entities
For security considerations, reference Azure identity and access management
considerations.
Back to the main article: Data protection

Next steps
Protect data at rest and in transit through encryption. Make sure you use standard
encryption algorithms.
Data encryption

Azure encryption overview
Article • 02/23/2023

This article provides an overview of how encryption is used in Microsoft Azure. It covers
the major areas of encryption, including encryption at rest, encryption in flight, and key
management with Azure Key Vault. Each section includes links to more detailed
information.

Encryption of data at rest
Data at rest includes information that resides in persistent storage on physical media, in
any digital format. The media can include files on magnetic or optical media, archived
data, and data backups. Microsoft Azure offers a variety of data storage solutions to
meet different needs, including file, disk, blob, and table storage. Microsoft also
provides encryption to protect Azure SQL Database, Azure Cosmos DB, and Azure Data
Lake.
Data encryption at rest is available for services across the software as a service (SaaS),
platform as a service (PaaS), and infrastructure as a service (IaaS) cloud models. This
article summarizes and provides resources to help you use the Azure encryption
options.
For a more detailed discussion of how data at rest is encrypted in Azure, see Azure Data
Encryption-at-Rest.

Azure encryption models
Azure supports various encryption models, including server-side encryption that uses
service-managed keys, customer-managed keys in Key Vault, or customer-managed
keys on customer-controlled hardware. With client-side encryption, you can manage
and store keys on-premises or in another secure location.

Client-side encryption
Client-side encryption is performed outside of Azure. It includes:
Data encrypted by an application that’s running in the customer’s datacenter or by
a service application.
Data that is already encrypted when it is received by Azure.

With client-side encryption, cloud service providers don’t have access to the encryption
keys and cannot decrypt this data. You maintain complete control of the keys.

Server-side encryption
The three server-side encryption models offer different key management characteristics,
which you can choose according to your requirements:
Service-managed keys: Provides a combination of control and convenience with
low overhead.
Customer-managed keys: Gives you control over the keys, including Bring Your
Own Keys (BYOK) support, or allows you to generate new ones.
Service-managed keys in customer-controlled hardware: Enables you to manage
keys in your proprietary repository, outside of Microsoft control. This characteristic
is called Host Your Own Key (HYOK). However, configuration is complex, and most
Azure services don’t support this model.

Azure disk encryption
You can protect your managed disks by using Azure Disk Encryption for Linux VMs,
which uses DM-Crypt , or Azure Disk Encryption for Windows VMs, which uses
Windows BitLocker, to protect both operating system disks and data disks with full
volume encryption.
Encryption keys and secrets are safeguarded in your Azure Key Vault subscription. By
using the Azure Backup service, you can back up and restore encrypted virtual machines
(VMs) that use Key Encryption Key (KEK) configuration.

Azure Storage Service Encryption
Data at rest in Azure Blob storage and Azure file shares can be encrypted in both serverside and client-side scenarios.
Azure Storage Service Encryption (SSE) can automatically encrypt data before it is
stored, and it automatically decrypts the data when you retrieve it. The process is
completely transparent to users. Storage Service Encryption uses 256-bit Advanced
Encryption Standard (AES) encryption , which is one of the strongest block ciphers
available. AES handles encryption, decryption, and key management transparently.

Client-side encryption of Azure blobs

You can perform client-side encryption of Azure blobs in various ways.
You can use the Azure Storage Client Library for .NET NuGet package to encrypt data
within your client applications prior to uploading it to your Azure storage.
To learn more about and download the Azure Storage Client Library for .NET NuGet
package, see Windows Azure Storage 8.3.0 .
When you use client-side encryption with Key Vault, your data is encrypted using a onetime symmetric Content Encryption Key (CEK) that is generated by the Azure Storage
client SDK. The CEK is encrypted using a Key Encryption Key (KEK), which can be either a
symmetric key or an asymmetric key pair. You can manage it locally or store it in Key
Vault. The encrypted data is then uploaded to Azure Storage.
To learn more about client-side encryption with Key Vault and get started with how-to
instructions, see Tutorial: Encrypt and decrypt blobs in Azure Storage by using Key Vault.
Finally, you can also use the Azure Storage Client Library for Java to perform client-side
encryption before you upload data to Azure Storage, and to decrypt the data when you
download it to the client. This library also supports integration with Key Vault

for

storage account key management.

Encryption of data at rest with Azure SQL Database
Azure SQL Database is a general-purpose relational database service in Azure that
supports structures such as relational data, JSON, spatial, and XML. SQL Database
supports both server-side encryption via the Transparent Data Encryption (TDE) feature
and client-side encryption via the Always Encrypted feature.

Transparent Data Encryption
TDE is used to encrypt SQL Server

, Azure SQL Database, and Azure Synapse Analytics

data files in real time, using a Database Encryption Key (DEK), which is stored in the
database boot record for availability during recovery.
TDE protects data and log files, using AES and Triple Data Encryption Standard (3DES)
encryption algorithms. Encryption of the database file is performed at the page level.
The pages in an encrypted database are encrypted before they are written to disk and
are decrypted when they’re read into memory. TDE is now enabled by default on newly
created Azure SQL databases.

Always Encrypted feature

With the Always Encrypted feature in Azure SQL you can encrypt data within client
applications prior to storing it in Azure SQL Database. You can also enable delegation of
on-premises database administration to third parties and maintain separation between
those who own and can view the data and those who manage it but should not have
access to it.

Cell-level or column-level encryption
With Azure SQL Database, you can apply symmetric encryption to a column of data by
using Transact-SQL. This approach is called cell-level encryption or column-level
encryption (CLE), because you can use it to encrypt specific columns or even specific
cells of data with different encryption keys. Doing so gives you more granular
encryption capability than TDE, which encrypts data in pages.
CLE has built-in functions that you can use to encrypt data by using either symmetric or
asymmetric keys, the public key of a certificate, or a passphrase using 3DES.

Azure Cosmos DB database encryption
Azure Cosmos DB is Microsoft's globally distributed, multi-model database. User data
that's stored in Azure Cosmos DB in non-volatile storage (solid-state drives) is encrypted
by default. There are no controls to turn it on or off. Encryption at rest is implemented
by using a number of security technologies, including secure key storage systems,
encrypted networks, and cryptographic APIs. Encryption keys are managed by Microsoft
and are rotated per Microsoft internal guidelines. Optionally, you can choose to add a
second layer of encryption with keys you manage using the customer-managed keys or
CMK feature.

At-rest encryption in Data Lake
Azure Data Lake is an enterprise-wide repository of every type of data collected in a
single place prior to any formal definition of requirements or schema. Data Lake Store
supports "on by default," transparent encryption of data at rest, which is set up during
the creation of your account. By default, Azure Data Lake Store manages the keys for
you, but you have the option to manage them yourself.
Three types of keys are used in encrypting and decrypting data: the Master Encryption
Key (MEK), Data Encryption Key (DEK), and Block Encryption Key (BEK). The MEK is used
to encrypt the DEK, which is stored on persistent media, and the BEK is derived from the
DEK and the data block. If you are managing your own keys, you can rotate the MEK.

Encryption of data in transit
Azure offers many mechanisms for keeping data private as it moves from one location
to another.

Data-link Layer encryption in Azure
Whenever Azure Customer traffic moves between datacenters-- outside physical
boundaries not controlled by Microsoft (or on behalf of Microsoft)-- a data-link layer
encryption method using the IEEE 802.1AE MAC Security Standards

(also known as

MACsec) is applied from point-to-point across the underlying network hardware. The
packets are encrypted on the devices before being sent, preventing physical “man-inthe-middle” or snooping/wiretapping attacks. Because this technology is integrated on
the network hardware itself, it provides line rate encryption on the network hardware
with no measurable link latency increase. This MACsec encryption is on by default for all
Azure traffic traveling within a region or between regions, and no action is required on
customers’ part to enable.

TLS encryption in Azure
Microsoft gives customers the ability to use Transport Layer Security

(TLS) protocol to

protect data when it’s traveling between the cloud services and customers. Microsoft
datacenters negotiate a TLS connection with client systems that connect to Azure
services. TLS provides strong authentication, message privacy, and integrity (enabling
detection of message tampering, interception, and forgery), interoperability, algorithm
flexibility, and ease of deployment and use.
Perfect Forward Secrecy

(PFS) protects connections between customers’ client systems

and Microsoft cloud services by unique keys. Connections also use RSA-based 2,048-bit
encryption key lengths. This combination makes it difficult for someone to intercept and
access data that is in transit.

Azure Storage transactions
When you interact with Azure Storage through the Azure portal, all transactions take
place over HTTPS. You can also use the Storage REST API over HTTPS to interact with
Azure Storage. You can enforce the use of HTTPS when you call the REST APIs to access
objects in storage accounts by enabling the secure transfer that's required for the
storage account.

Shared Access Signatures (SAS), which can be used to delegate access to Azure Storage
objects, include an option to specify that only the HTTPS protocol can be used when
you use Shared Access Signatures. This approach ensures that anybody who sends links
with SAS tokens uses the proper protocol.
SMB 3.0, which used to access Azure Files shares, supports encryption, and it's available
in Windows Server 2012 R2, Windows 8, Windows 8.1, and Windows 10. It allows crossregion access and even access on the desktop.
Client-side encryption encrypts the data before it’s sent to your Azure Storage instance,
so that it’s encrypted as it travels across the network.

SMB encryption over Azure virtual networks
By using SMB 3.0

in VMs that are running Windows Server 2012 or later, you can

make data transfers secure by encrypting data in transit over Azure Virtual Networks. By
encrypting data, you help protect against tampering and eavesdropping attacks.
Administrators can enable SMB encryption for the entire server, or just specific shares.
By default, after SMB encryption is turned on for a share or server, only SMB 3.0 clients
are allowed to access the encrypted shares.

In-transit encryption in VMs
Data in transit to, from, and between VMs that are running Windows can be encrypted
in a number of ways, depending on the nature of the connection.

RDP sessions
You can connect and sign in to a VM by using the Remote Desktop Protocol (RDP) from
a Windows client computer, or from a Mac with an RDP client installed. Data in transit
over the network in RDP sessions can be protected by TLS.
You can also use Remote Desktop to connect to a Linux VM in Azure.

Secure access to Linux VMs with SSH
For remote management, you can use Secure Shell (SSH) to connect to Linux VMs
running in Azure. SSH is an encrypted connection protocol that allows secure sign-ins
over unsecured connections. It is the default connection protocol for Linux VMs hosted

in Azure. By using SSH keys for authentication, you eliminate the need for passwords to
sign in. SSH uses a public/private key pair (asymmetric encryption) for authentication.

Azure VPN encryption
You can connect to Azure through a virtual private network that creates a secure tunnel
to protect the privacy of the data being sent across the network.

Azure VPN gateways
You can use an Azure VPN gateway to send encrypted traffic between your virtual
network and your on-premises location across a public connection, or to send traffic
between virtual networks.
Site-to-site VPNs use IPsec

for transport encryption. Azure VPN gateways use a set of

default proposals. You can configure Azure VPN gateways to use a custom IPsec/IKE
policy with specific cryptographic algorithms and key strengths, rather than the Azure
default policy sets.

Point-to-site VPNs
Point-to-site VPNs allow individual client computers access to an Azure virtual network.
The Secure Socket Tunneling Protocol (SSTP) is used to create the VPN tunnel. It can
traverse firewalls (the tunnel appears as an HTTPS connection). You can use your own
internal public key infrastructure (PKI) root certificate authority (CA) for point-to-site
connectivity.
You can configure a point-to-site VPN connection to a virtual network by using the
Azure portal with certificate authentication or PowerShell.
To learn more about point-to-site VPN connections to Azure virtual networks, see:
Configure a point-to-site connection to a virtual network by using certification
authentication: Azure portal
Configure a point-to-site connection to a virtual network by using certificate
authentication: PowerShell

Site-to-site VPNs
You can use a site-to-site VPN gateway connection to connect your on-premises
network to an Azure virtual network over an IPsec/IKE (IKEv1 or IKEv2) VPN tunnel. This

type of connection requires an on-premises VPN device that has an external-facing
public IP address assigned to it.
You can configure a site-to-site VPN connection to a virtual network by using the Azure
portal, PowerShell, or Azure CLI.
For more information, see:
Create a site-to-site connection in the Azure portal
Create a site-to-site connection in PowerShell
Create a virtual network with a site-to-site VPN connection by using CLI

In-transit encryption in Data Lake
Data in transit (also known as data in motion) is also always encrypted in Data Lake
Store. In addition to encrypting data prior to storing it in persistent media, the data is
also always secured in transit by using HTTPS. HTTPS is the only protocol that is
supported for the Data Lake Store REST interfaces.
To learn more about encryption of data in transit in Data Lake, see Encryption of data in
Data Lake Store.

Key management with Key Vault
Without proper protection and management of the keys, encryption is rendered useless.
Key Vault is the Microsoft-recommended solution for managing and controlling access
to encryption keys used by cloud services. Permissions to access keys can be assigned to
services or to users through Azure Active Directory accounts.
Key Vault relieves organizations of the need to configure, patch, and maintain hardware
security modules (HSMs) and key management software. When you use Key Vault, you
maintain control. Microsoft never sees your keys, and applications don’t have direct
access to them. You can also import or generate keys in HSMs.

Next steps
Azure security overview
Azure network security overview
Azure database security overview
Azure virtual machines security overview

Data encryption at rest
Data security and encryption best practices

Applications and services
Article • 11/30/2022

Applications and the data associated with them act as the primary store of business
value on a cloud platform. Applications can play a role in risks to the business because:
Business processes are encapsulated and executed by applications and services
need to be available and provided with high integrity.
Business data is stored and processed by application workloads and requires high
assurances of confidentiality, integrity, and availability.

Identify and classify business critical
applications
Enterprise organizations typically have a large application portfolio, but not all
applications have equal importance. Applications can be classified based on a criticality
scale. For example, business-critical applications are designed to prevent financial losses,
safety-critical are focused on costs associated with loss of human life. Mission-critical
applications cover both aspects that can be impacted by unavailability or
underperformance.
Criticality should be identified and classified, to direct investment of monitoring, time,
and resources appropriately. You should also identify applications or systems with
significant access — those which might grant control over other critical systems or data.
For more information, see Criticality scale in Cloud Adoption Framework.

Suggested actions
Identify and classify key organizational applications according to organizational impact.

Next steps
See these best practices related to PaaS applications.
Securing PaaS deployments
Secure communication paths between applications and the services. Make sure that
there's a distinction between the endpoints exposed to the public internet and private
ones. Also, the public endpoints are protected with web application firewall.

Network security

Application classification for security
Article • 11/30/2022

Azure can host both legacy and modern applications through Infrastructure as a Service
(IaaS) virtual machines and Platform as a Service (PaaS). With legacy applications, you
have the responsibility of securing all dependencies including OS, middleware, and
other components. For PaaS applications, you don't need to manage and secure the
underlying server OS. You are responsible for the application configuration.
This article describes the considerations for understanding the hosting models and the
security responsibility of each, identifying critical applications.

Understand your responsibility as an owner

Securing an application requires security assurances for three aspects:
Application code. The logic that defines the custom application that you write.
Securing that code requires identifying and mitigating risks from the design and
implementation of the application and assessing supply chain risk of included
components.
Application services. The cloud services that the application uses such as
databases, identity providers, event hubs, IoT device management, and so on.
Security for cloud services is a shared responsibility. The cloud provider ensures
the security of the underlying service. The application owner is responsible for

security implications of the configuration and operation of the service instance(s)
used by the application including any data stored and processed on the service.
Application hosting platform. The computing environment where the application
runs. This could take many forms with significant variations on who is responsible
for security:
Legacy applications. typically require a full operating system (and any
middleware) hosted on physical or virtualized hardware. This operating system
and installed middleware/other components are operated and secured by the
application owner or their infrastructure team(s). The security responsibility for
the physical hardware and OS virtualization components (virtualization hosts,
operating systems, and management services) varies:
On-premises: The application owner is responsible for maintenance and
security.
IaaS: The cloud provider is responsible for the underlying infrastructure and
the application owner's organization is responsible for the VM configuration,
operating system, and any components installed on it.
Modern applications are hosted on PaaS environments such as an Azure
application service. The underlying operating system is secured by the cloud
provider. Application owners are responsible for the security of the application
service configurations.
Containers are an application packaging mechanism in which applications are
abstracted from the environment in which they run. The containerized
applications can run on a container service by the cloud provider (modern
applications) or on a server managed on premises or in IaaS.

Identify and classify applications
Identify applications that have a high potential impact and,or a high potential exposure
to risk.
Business critical data. Applications that process or store information must have
assurance of confidentiality, integrity, and availability.
Regulated data. Applications that handle monetary instruments and sensitive
personal information regulated by standards such as the payment card industry
(PCI), General Data Protection Regulation (GDPR), and Health Information
Portability and Accountability Act (HIPAA).
Business critical availability. Applications whose functionality is critical to the
business mission, such as production lines generating revenue, devices or services

critical to life and safety, and other critical functions.
Significant Access. Applications that have access to systems with a high impact
through technical means such as:
Stored Credentials or keys/certificates that grant access to the data/service.
Permissions granted through access control lists or other methods.
High exposure to attacks. Applications that are easily accessible to attackers such
as web applications on the public internet. Legacy applications can also be higher
exposure as attackers (and penetration testers) frequently target them because
they know these legacy applications often have vulnerabilities that are difficult to
fix.

Use Azure services for fundamental
components
Developers should use services available from a cloud provider for well-established
functions like databases, encryption, identity directory, and authentication, instead of
building or adopting custom implementations, or third-party solutions that require
integration with the cloud provider. These services provide better security, reliability,
and efficiency because cloud providers operate and secure them with dedicated teams
with deep expertise in those areas.
Using these services also frees your developer resources from reinventing the proverbial
wheel so that they can focus development time on your unique requirements for your
business. This practice should be followed to avoid risk during new application
development and to reduce risk in existing applications either during the planned
update cycle, or with a security-focused application update.
We recommend using cloud services from your cloud provider for identity, data
protection, key management, and application configurations:
Identity: User directories and other authentication functions are complex to
develop and critically important to security assurances. Avoid custom
authentication solutions. Instead choose native capabilities like Azure Active
Directory (Azure AD), Azure AD B2B, Azure AD B2C, or third-party solutions to
authenticate and grant permission to users, partners, customers, applications,
services, and other entities. For more information, see Security with identity and
access management (IAM) in Azure.
Data Protection: Use established capabilities from cloud providers such as native
encryption in cloud services to encrypt and protect data. If direct use of

cryptography is required, use well-established cryptographic algorithms and not
attempt to invent their own.
Key management: Always authenticate with identity services rather than handling
cryptographic key. For situations where you need to use keys, use a managed key
store such as Azure Key Vault. This will make sure keys are handled safely in
application code. Tools such as, CredScan can discover potentially exposed keys in
your application code.
Application Configurations: Inconsistent configurations for applications can create
security risks. Application configuration information can be stored with the
application itself or preferably using a dedicated configuration management
system like Azure App Configuration or Azure Key Vault. App Configuration
provides a service to centrally manage application settings and feature flags, which
helps mitigate this risk. Don't store keys and secrets in application configuration.
For more information about using cloud services instead of custom implementations,
reference Applications and services.

Use native capabilities
Use native security capabilities built into cloud services instead of adding external
security components, such as data encryption, network traffic filtering, threat detection,
and other functions.
Azure controls are maintained and supported by Microsoft. You don't have to invest in
additional security tooling.
List of Azure Services
Native security capabilities of each service

Next steps
Applications and services
Application classification
Application threat analysis
Regulatory compliance

Application threat analysis
Article • 11/30/2022

Do a comprehensive analysis to identify threats, attacks, vulnerabilities, and counter
measures. Having this information can protect the application and threats it might pose
to the system. Start with simple questions to gain insight into potential risks. Then,
progress to advanced techniques using threat modeling.

1- Gather information about the basic security
controls
A threat modeling tool will produce a report of all threats identified. This report is
typically uploaded into a tracking tool, or converted to work items that can be validated
and addressed by the developers. As new features are added to the solution, the threat
model should be updated and integrated into the code management process. If a
security issue is found, there should be a process to triage issue severity and determine
when and how to remediate (such as in the next release cycle, or a faster release).
Start by gathering information about each component of the application. The answers
to these questions will identify gaps in basic protection and clarify the attack vectors.
Ask this question ...

To determine controls that ...

Are connections authenticated using Azure AD, TLS (with
mutual authentication), or another modern security protocol

Prevent unauthorized access to
the application component and

approved by the security team?
Between users and the application
Between different application components and services

data.

Are you limiting access to only those accounts that have the
need to write or modify data in the application

Prevent unauthorized data
tampering or alteration.

Is the application activity logged and fed into a Security
Information and Event Management (SIEM) through Azure
Monitor or a similar solution?

Detect and investigate attacks
quickly.

Is critical data protected with encryption that has been
approved by the security team?

Prevent unauthorized copying
of data at rest.

Is inbound and outbound network traffic encrypted using TLS?

Prevent unauthorized copying
of data in transit.

Ask this question ...

To determine controls that ...

Is the application protected against Distributed Denial of

Detect attacks designed to

Service (DDoS) attacks using services such as Azure DDoS
protection?

overload the application so it
can't be used.

Does the application store any logon credentials or keys to
access other applications, databases, or services?

Identify whether an attack can
use your application to attack
other systems.

Do the application controls allow you to fulfill regulatory
requirements?

Protect user's private data and
avoid compliance fines.

Suggested actions
Assign tasks to the individual people who are responsible for a particular risk identified
during threat modeling.
Learn more
Threat modeling

2- Evaluate the application design progressively
Analyze application components and connections and their relationships. Threat
modeling is a crucial engineering exercise that includes defining security requirements,
identifying and mitigating threats, and validating those mitigations. This technique can
be used at any stage of application development or production, but it's most effective
during the design stages of a new functionality.
Popular methodologies include:
STRIDE:
Spoofing
Tampering
Repudiation
Information Disclosure
Denial of Service
Elevation of Privilege
Microsoft Security Development Lifecycle uses STRIDE and provides a tool to assist with
this process. This tool is available at no additional cost. For more information, see
Microsoft Threat Modeling Tool .

Open Web Application Security Project (OWASP)

has documented a threat

modeling approach for applications.
Integrate threat modeling through automation using secure operations. Here
are some resources:
Toolkit for Secure DevOps on Azure .
Guidance on DevOps pipeline security

by OWASP.

3- Mitigate the identified threats
The threat modeling tool produces a report of all the threats identified. After a potential
threat is identified, determine how it can be detected and the response to that attack.
Define a process and timeline which minimizes exposure to any identified vulnerabilities
in the workload, so that those vulnerabilities cannot be left unaddressed.
Use the Defense-in-Depth approach. This can help identify controls needed in the design
to mitigate risk if a primary security control fails. Evaluate how likely it is for the primary
control to fail. If it does, what is the extent of the potential organizational risk? Also,
what is the effectiveness of the additional control (especially in cases that would cause
the primary control to fail). Based on the evaluation apply Defense-in-Depth measures
to address potential failures of security controls.
The principle of least privilege is one way of implementing Defense-in-Depth. It limits
the damage that can be done by a single account. Grant least number of privileges to
accounts that allows them to accomplish with the required permissions within a time
period. This helps mitigate the damage of an attacker who gains access to the account
to compromise security assurances.
There's often a disconnect between organizational leadership and technical teams
regarding business requirements for critical workloads. This can create undesired
outcomes and is especially sensitive when it pertains to information security. Routinely
reviewing business critical workload requirements with executive sponsors to define
requirements provides an opportunity to align expectations and ensure operational
resource allocation to the initiative.
How are threats addressed once found?
Here are some best practices:
Make sure the results are communicated to the interested teams.
Prioritize the vulnerabilities and fix the most important in a timely manner.

Upload the threat modeling report to a tracking tool. Create work items that can
be validated and addressed by the developers. Cyber security teams can also use
the report to determine attack vectors during a penetration test.
As new features are added to the application, update the threat model report and
integrate it into the code management process. Triage security issues into the next
release cycle or a faster release, depending on the severity.
For information about mitigation strategies, see RapidAttack.
How long does it typically take to deploy a security fix into production?
If a security vulnerability is discovered, update the software with the fix as soon as
possible. Have processes, tools, and approvals in place to roll out the fix quickly.

Learn more
Threat modeling

Next steps
Applications and services
Application classification
Regulatory compliance

Securing PaaS deployments
Article • 04/02/2023

This article provides information that helps you:
Understand the security advantages of hosting applications in the cloud
Evaluate the security advantages of platform as a service (PaaS) versus other cloud
service models
Change your security focus from a network-centric to an identity-centric perimeter
security approach
Implement general PaaS security best practices recommendations
Develop secure applications on Azure is a general guide to the security questions and
controls you should consider at each phase of the software development lifecycle when
developing applications for the cloud.

Cloud security advantages
It's important to understand the division of responsibility between you and Microsoft.
On-premises, you own the whole stack but as you move to the cloud some
responsibilities transfer to Microsoft.
There are security advantages to being in the cloud. In an on-premises environment,
organizations likely have unmet responsibilities and limited resources available to invest
in security, which creates an environment where attackers are able to exploit
vulnerabilities at all layers.
Organizations are able to improve their threat detection and response times by using a
provider's cloud-based security capabilities and cloud intelligence. By shifting
responsibilities to the cloud provider, organizations can get more security coverage,
which enables them to reallocate security resources and budget to other business
priorities.

Security advantages of a PaaS cloud service
model
Let's look at the security advantages of an Azure PaaS deployment versus on-premises.

Starting at the bottom of the stack, the physical infrastructure, Microsoft mitigates
common risks and responsibilities. Because the Microsoft cloud is continually monitored
by Microsoft, it is hard to attack. It doesn't make sense for an attacker to pursue the
Microsoft cloud as a target. Unless the attacker has lots of money and resources, the
attacker is likely to move on to another target.
In the middle of the stack, there is no difference between a PaaS deployment and onpremises. At the application layer and the account and access management layer, you
have similar risks. In the next steps section of this article, we will guide you to best
practices for eliminating or minimizing these risks.
At the top of the stack, data governance and rights management, you take on one risk
that can be mitigated by key management. (Key management is covered in best
practices.) While key management is an additional responsibility, you have areas in a
PaaS deployment that you no longer have to manage so you can shift resources to key
management.
The Azure platform also provides you strong DDoS protection by using various networkbased technologies. However, all types of network-based DDoS protection methods
have their limits on a per-link and per-datacenter basis. To help avoid the impact of
large DDoS attacks, you can take advantage of Azure's core cloud capability of enabling
you to quickly and automatically scale out to defend against DDoS attacks. We'll go into
more detail on how you can do this in the recommended practices articles.

Modernizing the Defender for Cloud's mindset
With PaaS deployments come a shift in your overall approach to security. You shift from
needing to control everything yourself to sharing responsibility with Microsoft.

Another significant difference between PaaS and traditional on-premises deployments,
is a new view of what defines the primary security perimeter. Historically, the primary
on-premises security perimeter was your network and most on-premises security
designs use the network as its primary security pivot. For PaaS deployments, you are
better served by considering identity to be the primary security perimeter.

Adopt a policy of identity as the primary
security perimeter
One of the five essential characteristics of cloud computing is broad network access,
which makes network-centric thinking less relevant. The goal of much of cloud
computing is to allow users to access resources regardless of location. For most users,
their location is going to be somewhere on the Internet.
The following figure shows how the security perimeter has evolved from a network
perimeter to an identity perimeter. Security becomes less about defending your network
and more about defending your data, as well as managing the security of your apps and
users. The key difference is that you want to push security closer to what's important to
your company.

Initially, Azure PaaS services (for example, web roles and Azure SQL) provided little or no
traditional network perimeter defenses. It was understood that the element's purpose
was to be exposed to the Internet (web role) and that authentication provides the new
perimeter (for example, BLOB or Azure SQL).
Modern security practices assume that the adversary has breached the network
perimeter. Therefore, modern defense practices have moved to identity. Organizations
must establish an identity-based security perimeter with strong authentication and
authorization hygiene (best practices).
Principles and patterns for the network perimeter have been available for decades. In
contrast, the industry has relatively less experience with using identity as the primary
security perimeter. With that said, we have accumulated enough experience to provide
some general recommendations that are proven in the field and apply to almost all PaaS
services.
The following are best practices for managing the identity perimeter.
Best practice: Secure your keys and credentials to secure your PaaS deployment. Detail:
Losing keys and credentials is a common problem. You can use a centralized solution
where keys and secrets can be stored in hardware security modules (HSMs). Azure Key
Vault safeguards your keys and secrets by encrypting authentication keys, storage
account keys, data encryption keys, .pfx files, and passwords using keys that are
protected by HSMs.
Best practice: Don't put credentials and other secrets in source code or GitHub. Detail:
The only thing worse than losing your keys and credentials is having an unauthorized
party gain access to them. Attackers can take advantage of bot technologies to find keys
and secrets stored in code repositories such as GitHub. Do not put key and secrets in
these public code repositories.
Best practice: Protect your VM management interfaces on hybrid PaaS and IaaS services
by using a management interface that enables you to remote manage these VMs
directly. Detail: Remote management protocols such as SSH

, RDP

, and PowerShell

remoting can be used. In general, we recommend that you do not enable direct remote
access to VMs from the internet.
If possible, use alternate approaches like using virtual private networks in an Azure
virtual network. If alternative approaches are not available, ensure that you use complex
passphrases and two-factor authentication (such as Azure AD Multi-Factor
Authentication).

Best practice: Use strong authentication and authorization platforms. Detail: Use
federated identities in Azure AD instead of custom user stores. When you use federated
identities, you take advantage of a platform-based approach and you delegate the
management of authorized identities to your partners. A federated identity approach is
especially important when employees are terminated and that information needs to be
reflected through multiple identity and authorization systems.
Use platform-supplied authentication and authorization mechanisms instead of custom
code. The reason is that developing custom authentication code can be error prone.
Most of your developers are not security experts and are unlikely to be aware of the
subtleties and the latest developments in authentication and authorization. Commercial
code (for example, from Microsoft) is often extensively security reviewed.
Use two-factor authentication. Two-factor authentication is the current standard for
authentication and authorization because it avoids the security weaknesses inherent in
username and password types of authentication. Access to both the Azure management
(portal/remote PowerShell) interfaces and customer-facing services should be designed
and configured to use Azure AD Multi-Factor Authentication.
Use standard authentication protocols, such as OAuth2 and Kerberos. These protocols
have been extensively peer reviewed and are likely implemented as part of your
platform libraries for authentication and authorization.

Use threat modeling during application design
The Microsoft Security Development Lifecycle

specifies that teams should engage in a

process called threat modeling during the design phase. To help facilitate this process,
Microsoft has created the SDL Threat Modeling Tool. Modeling the application design
and enumerating STRIDE

threats across all trust boundaries can catch design errors

early on.
The following table lists the STRIDE threats and gives some example mitigations that use
Azure features. These mitigations won't work in every situation.
Threat

Security
property

Potential Azure platform mitigations

Spoofing

Authentication

Require HTTPS connections.

Tampering

Integrity

Validate TLS/SSL certificates.

Repudiation

Non-

Enable Azure monitoring and diagnostics.

repudiation

Threat

Security
property

Potential Azure platform mitigations

Information

Confidentiality

Encrypt sensitive data at rest by using service certificates.

Denial of
service

Availability

Monitor performance metrics for potential denial-of-service
conditions. Implement connection filters.

Elevation of
privilege

Authorization

Use Privileged Identity Management.

disclosure

Develop on Azure App Service
Azure App Service is a PaaS offering that lets you create web and mobile apps for any
platform or device and connect to data anywhere, in the cloud or on-premises. App
Service includes the web and mobile capabilities that were previously delivered
separately as Azure Websites and Azure Mobile Services. It also includes new capabilities
for automating business processes and hosting cloud APIs. As a single integrated
service, App Service brings a rich set of capabilities to web, mobile, and integration
scenarios.
Following are best practices for using App Service.
Best practice: Authenticate through Azure Active Directory. Detail: App Service provides
an OAuth 2.0 service for your identity provider. OAuth 2.0 focuses on client developer
simplicity while providing specific authorization flows for web applications, desktop
applications, and mobile phones. Azure AD uses OAuth 2.0 to enable you to authorize
access to mobile and web applications.
Best practice: Restrict access based on the need to know and least privilege security
principles. Detail: Restricting access is imperative for organizations that want to enforce
security policies for data access. You can use Azure RBAC to assign permissions to users,
groups, and applications at a certain scope. To learn more about granting users access
to applications, see Get started with access management.
Best practice: Protect your keys. Detail: Azure Key Vault helps safeguard cryptographic
keys and secrets that cloud applications and services use. With Key Vault, you can
encrypt keys and secrets (such as authentication keys, storage account keys, data
encryption keys, .PFX files, and passwords) by using keys that are protected by hardware
security modules (HSMs). For added assurance, you can import or generate keys in
HSMs. See Azure Key Vault to learn more. You can also use Key Vault to manage your
TLS certificates with auto-renewal.

Best practice: Restrict incoming source IP addresses. Detail: App Service Environment
has a virtual network integration feature that helps you restrict incoming source IP
addresses through network security groups. Virtual networks enable you to place Azure
resources in a non-internet, routable network that you control access to. To learn more,
see Integrate your app with an Azure virtual network.
Best practice: Monitor the security state of your App Service environments. Detail: Use
Microsoft Defender for Cloud to monitor your App Service environments. When
Defender for Cloud identifies potential security vulnerabilities, it creates
recommendations that guide you through the process of configuring the needed
controls.

Azure Cloud Services
Azure Cloud Services is an example of a PaaS. Like Azure App Service, this technology is
designed to support applications that are scalable, reliable, and inexpensive to operate.
In the same way that App Service is hosted on virtual machines (VMs), so too is Azure
Cloud Services. However, you have more control over the VMs. You can install your own
software on VMs that use Azure Cloud Services, and you can access them remotely.

Install a web application firewall
Web applications are increasingly targets of malicious attacks that exploit common
known vulnerabilities. Common among these exploits are SQL injection attacks, cross
site scripting attacks to name a few. Preventing such attacks in application code can be
challenging and may require rigorous maintenance, patching and monitoring at many
layers of the application topology. A centralized web application firewall helps make
security management much simpler and gives better assurance to application
administrators against threats or intrusions. A WAF solution can also react to a security
threat faster by patching a known vulnerability at a central location versus securing each
of individual web applications.
Web Application Firewall (WAF) provides centralized protection of your web applications
from common exploits and vulnerabilities.

DDoS protection
Azure DDoS Protection, combined with application-design best practices, provides
enhanced DDoS mitigation features to provide more defense against DDoS attacks. You
should enable Azure DDOS Protection on any perimeter virtual network.

Monitor the performance of your applications
Monitoring is the act of collecting and analyzing data to determine the performance,
health, and availability of your application. An effective monitoring strategy helps you
understand the detailed operation of the components of your application. It helps you
increase your uptime by notifying you of critical issues so that you can resolve them
before they become problems. It also helps you detect anomalies that might be security
related.
Use Azure Application Insights to monitor availability, performance, and usage of your
application, whether it's hosted in the cloud or on-premises. By using Application
Insights, you can quickly identify and diagnose errors in your application without waiting
for a user to report them. With the information that you collect, you can make informed
choices on your application's maintenance and improvements.
Application Insights has extensive tools for interacting with the data that it collects.
Application Insights stores its data in a common repository. It can take advantage of
shared functionality such as alerts, dashboards, and deep analysis with the Kusto query
language.

Perform security penetration testing
Validating security defenses is as important as testing any other functionality. Make
penetration testing a standard part of your build and deployment process. Schedule
regular security tests and vulnerability scanning on deployed applications, and monitor
for open ports, endpoints, and attacks.
Fuzz testing is a method for finding program failures (code errors) by supplying
malformed input data to program interfaces (entry points) that parse and consume this
data.

Next steps
In this article, we focused on security advantages of an Azure PaaS deployment and
security best practices for cloud applications. Next, learn recommended practices for
securing your PaaS web and mobile solutions using specific Azure services. We'll start
with Azure App Service, Azure SQL Database and Azure Synapse Analytics, Azure
Storage, and Azure Cloud Services. As articles on recommended practices for other
Azure services become available, links will be provided in the following list:
Azure App Service

Azure SQL Database and Azure Synapse Analytics
Azure Storage
Azure Cloud Services
Azure Cache for Redis
Azure Service Bus
Web Application Firewall
See Develop secure applications on Azure for security questions and controls you
should consider at each phase of the software development lifecycle when developing
applications for the cloud.
See Azure security best practices and patterns for more security best practices to use
when you're designing, deploying, and managing your cloud solutions by using Azure.
The following resources are available to provide more general information about Azure
security and related Microsoft services:
Microsoft Product Lifecycle - for consistent and predictable guidelines for support
throughout the life of a product
Microsoft Security Response Center

- where Microsoft security vulnerabilities,

including issues with Azure, can be reported or via email to secure@microsoft.com

Secure application configuration and
dependencies
Article • 11/30/2022

Security of an application that is hosted in Azure is a shared responsibility between you
as the application owner and Azure. For IaaS, you're responsible for configurations
related to VM, operating system, and components installed on it. For PaaS, you're
responsible for the security of the application service configurations and making sure
that the dependencies used by the application are also secure.

Key points
＂ Don't store secrets in source code or configuration files. Instead, keep them in a
secure store, such as Azure App Configuration or Azure Key Vault.
＂ Don't expose detailed error information when handling application exceptions.
＂ Don't expose platform-specific information.
＂ Store application configuration outside of the application code to update it
separately and to have tighter access control.
＂ Restrict access to Azure resources that don't meet the security requirements.
＂ Validate the security of any open-source code added to your application.
＂ Update frameworks and libraries as part of the application lifecycle.

Configuration security
During the design phase, consider the way you store secrets and handle exceptions.
Here are some points.
How is application configuration stored and how does the application access it?
Application configuration information can be stored with the application. However,
that's not a recommended practice. Consider using a dedicated configuration
management system such as Azure App Configuration or Azure Key Vault. That way, it
can be updated independently of the application code.
Applications can include secrets like database connection strings, certificate keys, and so
on. Don't store secrets in source code or configuration files. Instead, keep them in a
secure store, such as Azure Key Vault. Identify secrets in code with static code scanning
tools. Add the scanning process in your continuous integration (CI) pipeline.
For more information about secret management, reference Key and secret management.

Are errors and exceptions handled properly without exposing that information to
users?
When handling application exceptions, make the application fail gracefully and log the
error. Don't provide detailed information related to the failure, such as call stack, SQL
queries, or out of range errors. This information can provide attackers with valuable
information about the internals of the application.
Can configuration settings be changed or modified without rebuilding or redeploying
the application?
Application code and configuration shouldn't share the same lifecycle to enable
operational activities. These activities include those that change and update specific
configurations without developer involvement or redeployment.
Is platform-specific information removed from server-client communication?
Don't reveal information about the application platform. Such information (for example,
X-Powered-By , X-ASPNET-VERSION ) can get exposed through HTTP banners, HTTP

headers, error messages, and website footers. Malicious actors can use this information
when mapping attack vectors of the application.
Suggested actions
Consider using Azure Front Door or API Management to remove platform-specific HTTP
headers. Instead, use Azure CDN to separate the hosting platform from end users. Azure
API Management offers transformation policies that allow you to modify HTTP headers
and remove sensitive information.
Learn more
Azure Front Door Rules Engine Actions
API Management documentation
Are Azure policies used to control the configuration of the solution resources?
Use Azure Policy to deploy settings where applicable. Block resources that don't meet
the proper security requirements defined during service enablement.

Dependencies, frameworks, and libraries
What are the frameworks and libraries used by the application?

Application frameworks are frequently updated and released by the vendor or
communities. It's vital to track the frameworks and libraries used by the application
including any resulting vulnerabilities they introduce. These frameworks and libraries
include custom, OSS, third party, and others. Understand and manage the technologies
the application uses, such as:
.NET Core
Spring
Node.js
Automated solutions can help with this assessment.
Consider the following best practices:
Validate the security of any open-source code added to your application. Free
tools to help with this assessment include:
OWASP Dependency-Check
NPM audit
WhiteSource Bolt
GitHub Dependabot
These tools find outdated components and update them to the latest versions.
Maintain a list of frameworks and libraries as part of the application inventory.
Also, keep track of versions in use. If vulnerabilities are published, this awareness
helps to identify affected workloads.
Update frameworks and libraries as part of the application lifecycle. Prioritize
critical security patches.
Are the expiry dates of SSL/TLS certificates monitored and are processes in place to
renew them?
Tracking expiry dates of SSL/TLS certificates and renewing them in due time is highly
critical. Ideally, the process should be automated, although this often depends on the
CA used for the certificate. If not automated, sufficient alerting should be applied to
ensure expiry dates don't go unnoticed.
Learn more
WhiteSource Bolt
npm-audit
OWASP Dependency-Check
GitHub Dependabot

Referenced Azure services
Azure Key Vault
Azure CDN
Azure Policy
Azure Front Door
Azure API Management

Next steps
Applications and services
Application classification
Application threat analysis
Regulatory compliance

Community resources
OWASP Dependency-Check
NPM audit

Secure deployment in Azure
Article • 11/30/2022

Have teams, processes, and tools that can quickly deploy security fixes? A DevOps or
multidisciplinary approach is recommended. Multiple teams work together with efficient
practices and tools. Essential DevOps practices include change management of the
workload through continuous integration, continuous delivery (CI/CD).
Continuous integration (CI) is an automated process where code changes trigger the
building and testing of the application. Continuous Delivery (CD) is an automated
process to build, test, configure, and deploy the application from a build to production
environment.
Those processes allow you to rapidly address the security concerns without waiting for a
longer planning and testing cycle.
Building a DevOps process which includes a security discipline helps incorporate security
concepts and enhancements earlier in the application development process. An
organization's ability to rapidly address security and operational concerns increases
through the combination of the Secure Development Lifecycle (SDL) and Operations
Lifecycle related to application creation, maintenance, and updates.
Many traditional IT operating models aren't compatible with the cloud, and
organizations must undergo operational and organizational transformation to deliver
against enterprise migration targets. We recommend using a DevOps approach for both
application and central teams.

Checklist
Have you adopted a secure DevOps approach to ensure security and feature
enhancements can be quickly deployed?
＂ Establish a cross-functional DevOps platform team to build, manage, and maintain
your workload.
＂ Involve the security team in the planning and design of the DevOps process to
integrate preventive and detective controls for security risks.
＂ Clearly define CI/CD roles and permissions and minimize the number of people who
have access to secure information or resources.
＂ Configure quality gate approvals in DevOps release process.
＂ Integrate scanning tools within CI/CD pipeline.
＂ No infrastructure changes, provisioning or configuring, should be done manually
outside of IaC.

In this section
Follow these questions to assess the workload at a deeper level.
Assessment

Description

Do you clearly define CI/CD roles

Define CI/CD permissions such that only users responsible

and permissions for this workload?

for production releases can start the process and that only
developers can access the source code.

Are any resources provisioned or

Always use Infrastructure as code (IaC) to make even the

operationally configured with user
tools such as the Azure portal or

smallest of changes. This approach makes it easy to track
code because the provisioned infrastructure is

via Azure CLI?

reproducible and reversible.

Can you roll back or forward code

Automated deployment pipelines should allow for quick

quickly through automated

roll-forward and roll-back deployments to address critical

pipelines?

bugs and code updates outside of the normal deployment
lifecycle.

Azure security benchmark
The Azure Security Benchmark includes a collection of high-impact security
recommendations. Use them to secure the services and processes you use to run the
workload in Azure:

The questions in this section are aligned to the Azure Security Benchmark
controls.

Reference architecture
Here are some reference architectures related to building CI/CD pipelines:
CI/CD for microservices architectures
CI/CD for microservices on Kubernetes

Next step
We recommend monitoring activities that maintain the security posture. These activities
can highlight, if the current security practices are effective or are there new
requirements.
Security monitoring

Related link
Go back to the main article: Security

Learn more
Secure DevOps Kit for Azure
Agile Principles in Practice
Platform automation and DevOps
PsRules for Azure
Azure Deployment Environments

Governance considerations for secure
deployment in Azure
Article • 11/30/2022

The automated continuous integration, continuous delivery (CI/CD) processes must have
built-in governance that authorize and authenticate the identities to do the tasks within
a defined scope.

Key points
＂ Clearly define CI/CD roles and permissions.
＂ Implement just-in-time privileged access management.
＂ Limit long-standing write access to production environments.
＂ Limit the scope of execution in the pipelines.
＂ Configure quality gate approvals in DevOps release process.

Minimize access
Minimize the number of people who have access to secure information or resources.
This strategy will reduce the chance of a malicious actor gaining access or an authorized
user inadvertently impacting a sensitive resource. Here are some considerations:
Use the principle of least privilege when assigning roles and permissions. Only
users responsible for production releases should start the process and only
developers should access the source code.
A pipeline should use one or more service principals. Ideally, they should be
managed identity, and delivered by the platform and never directly defined within
a pipeline. The identity should only have the Azure RBAC permissions necessary to
do the task. All service principals should be bound to that pipeline and not shared
across pipelines.
How do you define CI/CD roles and permissions?
Azure DevOps offers built-in roles that can be assigned to individual users of
groups. If built-in roles are insufficient to define least privilege for a pipeline,
consider creating custom Azure RBAC roles. Make sure those roles align with the
action and the organization's teams and responsibilities.

To support security of your pipeline operations, you can add users to a built-in
security group, set individual permissions for a user or group, or add users to predefined roles. You manage security for the following objects from Azure Pipelines
in the web portal, either from the user or admin context.
For more information, see Get started with permissions, access, and security
groups.
For permissions, you grant or restrict permissions by setting the permission state
to Allow or Deny, either for a security group or an individual user. For a role, you
add a user or group to the role.
Use separate pipeline identities between pre-production and production
environments. If available, take advantage of pipeline features such as
Environments to encapsulate last-mile authentication external to the executing
pipeline.
If the pipeline runs infrequently and has high privileges, consider removing
standing permissions for that identity. Use just-in-time (JIT) role assignments, timebased, and approval-based role activation. This strategy will mitigate the risks of
excessive, unnecessary, or misused access permissions on crucial resources. Azure
AD Privileged Identity Management supports all those modes of activation.
Review the organization's CI/CD pipeline and refine role assignment to create a
clear delineation between development and production responsibilities.
Learn more
For more information about pipeline permission and security roles, reference Set
different levels of pipeline permissions.

Execution scope
Where practical, limit the scope of execution in the pipelines.
Consider creating a multi-stage pipeline. Divide the work into discrete units and that can
be isolated in a separate pipeline. Limit the identities only to the scope of the unit so
that it has minimal privileges enough to do the action. For example, you can have two
units, one to deploy and another that builds source code. Only allow the deploy unit to
have access to the identity, not the build unit. If the build unit is compromised, it could
start tampering with the infrastructure.

Gated approval process
Do you have release gate approvals configured in the DevOps release process?
Pull Requests and code reviews serve as the first line of approvals during development
cycle. Before releasing an update to production, require a process that mandates
security review and approval.
Make sure that you involve the security team in the planning, design, and DevOps
process. This collaboration will help them implement security controls, auditing, and
response processes.
Are branch policies used in source control management of this workload? How are
they configured?
Establish branch policies that provide an extra level of control over the code that is
committed to the repository. Lack of secure branch policy might allow poor, rogue or
broken code to be checked-in and deployed. It's a common practice to deny pushes to
the main branch if the change isn't approved. For example, you can require pull-request
(PR) with code review before merging the changes by at least one reviewer, other than
the change author.
Having multiple branches is recommended where each branch has a purpose and access
level. For example, feature branches are created by developers and are open to push.
Integration branch requires PR and code-review. Production branch requires another
approval from the team lead before merging.

Suggested actions
Configure quality gate approvals in DevOps release process.
Follow the guidance in the linked articles to deploy and adopt branch strategy.

Learn more
About branches and branch policies
Adopt a Git branching strategy
Release deployment control using gates
Azure Deployment Environments

Next

Secure infrastructure deployments

Related links
Go back to the main article: Secure deployment and testing in Azure

Infrastructure provisioning
considerations in Azure
Article • 11/30/2022

Azure resources can be provisioned by code or user tools such as the Azure portal or via
Azure CLI. It's not recommended that resources are provisioned or configured manually.
Those methods are error prone and can lead to security gaps. Even the smallest of
changes should be through code. The recommended approach is Infrastructure as code
(IaC). It's easy to track because the provisioned infrastructure can be fully reproduced
and reversed.

Key points
＂ No infrastructure changes should be done manually outside of IaC.
＂ Store keys and secrets outside of deployment pipeline in Azure Key Vault or in
secure store for the pipeline.
＂ Incorporate security fixes and patching to the operating system and all parts of the
codebase, including dependencies (preinstalled tools, frameworks, and libraries).

Infrastructure as code (IaC)
Make all operational changes and modifications through IaC. This is a key DevOps
practice, and it's often used with continuous delivery. IaC manages the infrastructure such as networks, virtual machines, and others - with a descriptive model, using a
versioning system that is similar to what is used for source code. IaC model generates
the same environment every time it's applied. Common examples of IaC are Azure
Resource Manager, Azure Deployment Environments, Bicep or Terraform.
IaC reduces configuration effort and automates full environment deployment
(production and pre-production). Also, IaC allows you to develop and release changes
faster. All those factors enhance the security of the workload.
For detailed information about IaC, see What is Infrastructure as code (IaC).

Pipeline secret management
How are credentials, certificates, and other secrets used in the operations for the
workload managed during deployment?

Store keys and secrets outside of deployment pipeline in a managed key store, such as
Azure Key Vault. Or, in a secure store for the pipeline. When deploying application
infrastructure with Azure Resource Manager, Bicep or Terraform, the process might
generate credentials and keys. Store them in a managed key store and make sure the
deployed resources reference the store. Do not hard-code credentials.
Secret scanning tools like GitHub Secret Scanner

can be used to scan for existing

hard-coded credentials. Add the scanning process in your continuous integration (CI)
pipeline to prevent new hard-coded credentials from being added.

Build environments
Does the organization apply security controls (IP firewall restrictions, update
management) to self-hosted build agents for this workload?
Custom build agents add management complexity and can become an attack vector.
Build machine credentials must be stored securely and the file system needs to be
cleaned of any temporary build artifacts regularly. Network isolation can be achieved by
only allowing outgoing traffic from the build agent, because it's using the pull model of
communication with Azure DevOps.
As part of the operational lifecycle, incorporate security fixes and patching to the
operating system and all parts of the codebase, including dependencies (preinstalled
tools, frameworks, and libraries).
Apply security controls to self-hosted build agents in the same manner as with other
Azure IaaS VMs. These should be minimalistic environments as a way to reduce the
attack surface.

Learn more
Azure Pipelines agents
I'm running a firewall and my code is in Azure Repos. What URLs does the agent
need to communicate with?

Next step
Secure code deployments

Related links

Go back to the main article: Secure deployment and testing in Azure

Code deployments
Article • 11/30/2022

The automated build and release pipelines should update a workload to a new version
seamlessly without breaking dependencies. Augment the automation with processes
that allow high priority fixes to get deployed quickly.
Organizations should leverage existing guidance and automation when securing
applications in the cloud, rather than starting from zero. Using resources and lessons
learned by external organizations that are early adopters of these models can accelerate
the improvement of an organizations security posture with less expenditure of effort
and resources.

Key points
＂ Involve the security team in the planning and design of the DevOps process to
integrate preventive and detective controls for security risks.
＂ Design automated deployment pipelines that allow for quick roll-forward and
rollback deployments to address critical bugs and code updates outside of the
normal deployment lifecycle.
＂ Integrate code scanning tools within CI/CD pipeline.

Rollback and roll-forward
If something goes wrong, the pipeline should roll back to a previous working version. N1 and N+1 refer to rollback and roll-forward versions. Automated deployment pipelines
should allow for quick roll-forward and rollback deployments to address critical bugs
and code updates outside of the normal deployment lifecycle.
Can N-1 or N+1 versions be deployed via automated pipelines where N is current
deployment version in production?
Because security updates are a high priority, design a pipeline that supports regular
updates and critical security fixes.
A release is typically associated with approval processes with multiple sign-offs, quality
gates, and so on. If the workload deployment is small with minimal approvals, you can
usually use the same process and pipeline to release a security fix.
An approval process that is complex and takes a significant amount of time can delay a
fix. Consider building an emergency process to accelerate high priority fixes. The process

might be business and, or communication process between teams. Another way is to
build a pipeline that might not include all the gated approvals, but should be able to
push out the fix quickly. The pipeline should allow for quick roll-forward and rollback
deployments that address security fixes, critical bugs, and code updates outside of the
regular deployment life cycle.
） Important
Deploying a security fix is a priority, but it shouldn't be at the cost of introducing a
regression or bug. When designing an emergency pipeline, carefully consider which
automated tests can be bypassed. Evaluate the value of each test against the
execution time. For example, unit tests usually complete quickly. Integration or
end-to-end tests can run for a long time.
Involve the security team in the planning and design of the DevOps process. Your
automated pipeline design should have the flexibility to support both regular and
emergency deployments. This is important to support the rapid and responsible
application of both security fixes and other urgent, important fixes.

Suggested action
Implement an automated deployment process with support for rollback scenarios via
Azure App Services deployment slots.
Learn more
Set up staging environments in Azure App Service

Credential scanning
Credentials, keys, and certificates grant access to the data or service used by the
workload. Storing credentials in code poses a significant security risk. Ensure that static
code scanning tools are an integrated part of the continuous integration (CI) process.
Are code scanning tools an integrated part of the continuous integration (CI) process
for this workload?
To prevent credentials from being stored in the source code or configuration files,
integrate code scanning tools within the CI/CD pipeline:
During design time, use code analyzers to prevent credentials from getting pushed
to the source code repository. For example, .NET Compiler Platform (Roslyn)

Analyzers inspect your C# or Visual Basic code.
During the build process, use pipeline add-ons to catch credentials in the source
code. Some options include GitHub Advanced Security

and OWASP source code

analysis tools .
Scan all dependencies, such as third-party libraries and framework components, as
part of the CI process. Investigate vulnerable components that are flagged by the
tool. Combine this task with other code scanning tasks that inspect code churn,
test results, and coverage.
Use a combination of dynamic application security testing (DAST) and static
application security testing (SAST). DAST tests the application while its in use. SAST
scans the source code and detects vulnerabilities based on its design or
implementation. Some technology options are provided by OWASP. For more
information, see SAST Tools

and Vulnerability Scanning Tools .

Use scanning tools that are specialized in technologies used by the workload. For
example, if the workload is containerized, run container-aware scanning tools to
detect risks in the container registry, before use, and during use.

Suggested actions
Incorporate Secure DevOps on Azure toolkit and the guidance published by the
Organization for Web App Security Project (OWASP), or an equivalent guiding
organization.

Learn more
Follow DevOps security guidance
Getting started with Credential Scanner (CredScan)

Community links
OWASP source code analysis tools
GitHub Advanced Security
Vulnerability Scanning Tools
Go back to the main article: Secure deployment and testing in Azure

Security monitoring and remediation in
Azure
Article • 11/30/2022

Regularly monitor resources to maintain the security posture and detect vulnerabilities.
Detection can take the form of reacting to an alert of suspicious activity or proactively
hunting for anomalous events in the enterprise activity logs. vigilantly responding to
anomalies and alerts to prevent security assurance decay, and designing for defense in
depth and least privilege strategies.

Checklist
How are you monitoring security-related events in this workload?
＂ Use native tools in Azure to monitor the workload resources and the infrastructure
in which it runs.
＂ Consider investing in a Security Operations Center (SOC), or SecOps team and
incident response plan.
＂ Monitor traffic, access requests, and application communication between segments.
＂ Discover and remediate common risks to improve secure score in Microsoft
Defender for Cloud.
＂ Use an industry standard benchmark to evaluate the security posture by learning
from external organizations.
＂ Send logs and alerts to a central security log management for analysis.
＂ Perform regular internal and external compliance audits, including regulatory
compliance attestations.
＂ Regularly test your security design and implementation using test cases based on
real-world attacks.

Azure security benchmark
The Azure Security Benchmark includes a collection of high-impact security
recommendations. Use them to secure the services and processes you use to run the
workload in Azure:

The questions in this section are aligned to these controls:
Azure Security Benchmarks Logging and threat detection.

Azure Security Benchmarks Incident response.
Posture and Vulnerability Management

Reference architecture
Hybrid Security Monitoring using Microsoft Defender for Cloud and Microsoft
Sentinel
This reference architecture illustrates how to use Microsoft Defender for Cloud and
Microsoft Sentinel to monitor the security configuration and telemetry of onpremises and Azure operating system workloads.
Azure security solutions for AWS
This article provides AWS identity architects, administrators, and security analysts
with immediate insights and detailed guidance for deploying several Microsoft
security solutions.

Next step
We recommend applying as many best practices as early as possible, and then working
to retrofit any gaps over time as you mature your security program.

Related link
Go back to the main article: Security

Azure security monitoring tools
Article • 03/24/2023

The leverage native control security principle tells us to use native controls built over
third-party solutions. Native reduce the effort required to integrate external security
tooling and update those integrations over time.
Azure provides several monitoring tools that observe the operations and detect
anomalous behavior. These tools can detect threats at different levels and report issues.
Addressing the issues early in the operational lifecycle will strengthen your overall
security posture.

Tools
Service

Use case

Microsoft
Defender for
Cloud

Strengthens the security posture of your data centers, and provides advanced
threat protection across your workloads in the cloud (whether they're in Azure or
not) and on-premises. Get a unified view into the infrastructure and resources
provisioned for the workload.

Microsoft
Sentinel

Use the native security information event management (SIEM) and security
orchestration automated response (SOAR) solution on Azure. Receive intelligent
security analytics and threat intelligence across the enterprise.

Azure DDoS
Protection

Defend against distributed denial of service (DDoS) attacks.

Azure Rights

Protect files and emails across multiple devices.

Management
(RMS)
Microsoft
Purview
Information

Secure email, documents, and sensitive data that you share outside your
company.

Protection
Azure

Gain granular insight into policies, Azure role-based access control (Azure RBAC),

Governance
Visualizer

Azure Blueprints, subscriptions, and more.

PSRule for
Azure

Scans Azure Infrastructure as Code (IaC) artifacts for issues across Azure WellArchitected pillars.

Microsoft Defender for Cloud
Enable Microsoft Defender for Cloud at the subscription level to monitor all resource
provisioned in that scope. At no additional cost, it provides continuous observability into
resources, reports issues, and recommends fixes. By regularly reviewing and fixing
issues, you can improve the security posture, detect threats early, prevent breaches.
Beyond just observability, Defender for Cloud offers an advanced mode through its
integration with Microsoft Defender for Cloud. When these plans are enabled, built-in
policies, custom policies, and initiatives protect resources and block malicious actors.
You can also monitor compliance with regulatory standards - such as NIST, Azure CIS,
Azure Security Benchmark. For pricing details, see Defender for Cloud pricing .

Microsoft Sentinel
Your organization might run workloads on multiple cloud platforms, and, or across
cloud and on-premises, or managed by various teams within the organization. Having a
centralized view of all data is recommended. To get that view you need security
information event management (SIEM) and security orchestration automated response
(SOAR) solutions. These solutions connect to all security sources, monitor them, and
analyze the correlated data.
Microsoft Sentinel and is a native control that combines SIEM and SOAR capabilities. It
analyzes events and logs from various connected sources. Based on the data sources
and their alerts, Sentinel creates incidents, performs threat analysis for early detection.
Through intelligent analytics and queries, you can be proactive with hunting activities. In
case of incidents, you can automate workflows. Also, with workbook templates you can
quickly gain insights through visualization.

Azure DDoS Protection
A Distributed Denial of Service (DDoS) attack attempts to exhaust an application's
resources, making the application unavailable to legitimate users. DDoS attacks can be
targeted at any endpoint that is publicly reachable through the internet.
Every property in Azure is protected by Azure's infrastructure DDoS (Basic) Protection at
no additional cost. The scale and capacity of the globally deployed Azure network
provides defense against common network-layer attacks through always-on traffic
monitoring and real-time mitigation. DDoS Infrastructure Protection requires no user
configuration or application changes. DDoS Infrastructure Protection helps protect all
Azure services, including PaaS services like Azure DNS.

Azure DDoS Protection provides enhanced DDoS mitigation features to defend against
DDoS attacks. It's automatically tuned to help protect your specific Azure resources in a
virtual network. Protection is simple to enable on any new or existing virtual network,
and it requires no application or resource changes. It has several advantages over the
basic service, including logging, alerting, telemetry, SLA guarantee, and cost protection.
Azure DDoS Network Protection is designed for services that are deployed in a virtual
network. For other services, the default DDoS Infrastructure Protection service applies.
To learn more about supported architectures, see DDoS Protection reference
architectures.

Azure Rights Management (RMS)
Your business may encounter challenges with protecting documents and emails. For
example, file protection, collaboration, and sharing may be issues. You also might be
experiencing problems regarding platform support or infrastructure.
Azure Rights Management (RMS) is a cloud-based protection service. RMS uses
encryption, identity, and authorization policies to help secure files and emails across
devices, including phones, tablets, and PCs.
To learn more about how RMS can address these issues, see Business problems solved
by Azure Rights Management.

Microsoft Purview Information Protection
The data classification process categorizes data by sensitivity and business impact in
order to identify risks. When data is classified, you can manage it in ways that protect
sensitive or important data from theft or loss.
With proper file protection, you can analyze data flows to gain insight into your business,
detect risky behaviors and take corrective measures, track access to documents, and
more. The protection technology in AIP uses encryption, identity, and authorization
policies. Protection stays with the documents and emails, independently of the location,
regardless of whether they're inside or outside your organization, networks, file servers,
and applications
Azure Information Protection (AIP) is part of Microsoft Purview Information Protection
solution, and extends the labeling and classification functionality provided by Microsoft
365. For more information, see this article about classification.

Azure Governance Visualizer
Azure Governance Visualizer is a PowerShell script that iterates through an Azure
tenant's management group hierarchy down to the subscription level. You can run the
script either for your Tenant Root Group or any other Management Group. It captures
data from the most relevant Azure governance capabilities such as Azure Policy, Azure
role-based access control (Azure RBAC), and Azure Blueprints. From the collected data,
the visualizer shows your hierarchy map, creates a tenant summary, and builds granular
scope insights about your management groups and subscriptions.
The visualizer provides a holistic overview of your technical Azure Governance
implementation by connecting the dots.

PSRule for Azure
PSRule for Azure is a set of tests and documentation to help you configure Azure
solutions. These tests allow you to check your Azure Template or Bicep Infrastructure as
Code (IaC) before deployment to Azure. PSRule for Azure includes tests that check how
IaC is written and how Azure resources are configured.

Next
Monitor workload resources in Microsoft Defender for Cloud

Related links
For information on the Microsoft Defender for Cloud tools, see Strengthen security
posture.
For frequently asked questions on Microsoft Defender for Cloud, see FAQ - General
Questions.
For information on the Microsoft Sentinel tools that will help to meet these
requirements, see What is Microsoft Sentinel?
For types of DDoS attacks that DDoS Protection mitigates as well as more features, see
Azure DDoS Protection overview.

Monitor Azure resources in Microsoft
Defender for Cloud
Article • 04/19/2023

Most cloud architecture have compute, networking, data, and identity components and
each require different monitoring mechanisms. Even Azure services have individual
monitoring needs. For instance, to monitor Azure Functions you want to enable Azure
Application Insights.
Microsoft Defender for Cloud has many plans that monitor the security posture of
machines, networks, storage and data services, and applications to discover potential
security issues. Common issues include internet connected VMs, or missing security
updates, missing endpoint protection or encryption, deviations from baseline security
configurations, missing Web Application Firewall (WAF), and more.

Key points
＂ Enable Microsoft Defender for Cloud as a defense-in-depth measure. Use resourcespecific Defender for Cloud features such as Microsoft Defender for servers,
Microsoft Defender for Endpoint, Microsoft Defender for Storage.
＂ Observe container hygiene through container aware tools and regular scanning.
＂ Review all network flow logs through network watcher. See diagnostic logs in
Microsoft Defender for Cloud.
＂ Integrate all logs in a central SIEM solution to analyze and detect suspicious
behavior.
＂ Monitor identity-related risk events in Azure AD reporting and Azure Active
Directory Identity Protection.

General best practices
Identifying common security activities will significantly reduce the overall risk.
Monitor suspicious activities from administrative accounts.
Monitor the location from where Azure resources are being managed.
Monitor attempts to access deactivated credentials.
Use automated tools to monitor network resource configurations and detect
changes.
For more information, see Azure security baseline for Azure Monitor.

IaaS and PaaS security
In an IaaS model, you can host the workload on Azure infrastructure. Azure provides
security assurances that maintain isolation and timely security updates to the
infrastructure. For greater control, you host the entire IaaS solution on-premises or in a
hosted data center and are responsible for security. You must implement security on the
host, virtual machine, network, and storage. For instance if you have your own VNet,
consider enabling Azure Private Link over Azure Monitor so you can access this over a
private endpoint.
In PaaS, you have shared responsibility with Azure in protecting the data.

Virtual machines
If you're running your own Windows and Linux virtual machines, use Microsoft Defender
for Cloud. Take advantage of the free services to check for missing OS patches, security
misconfiguration, and basic network security. Enabling Microsoft Defender for Cloud is
highly recommended because you get features that provide adaptive application
controls, file integrity monitoring (FIM), and others.
For example, a common risk is the virtual machines don't have vulnerability scanning
solutions that check for threats. Microsoft Defender for Cloud reports those machines.
You can remediate in Microsoft Defender for Cloud by deploying a scanning solution.
You can use the built-in vulnerability scanner for virtual machines. You don't need a
license. Instead, you can bring your license for supported partner solutions.
７ Note
Vulnerability assessments are also available for container images, and SQL servers.
Attackers constantly scan public cloud IP ranges for open management ports, which can
lead to attacks such as common passwords and known unpatched vulnerabilities. JIT
(Just In Time) access allows you to lock down the inbound traffic to the virtual machines
while providing easy access to connect to machines when needed. Defender for Cloud
identifies which machines should have JIT applied.
With Microsoft Defender for Cloud, you also get Microsoft Defender for Endpoint. This
provides investigative tools Endpoint Detection and Response (EDR) that helps in threat
detection and analysis.
Microsoft Defender for servers also watches the network to and from virtual machines. If
you are using network security groups to control access to the virtual machines and the

rules are overpermissive, Defender for Cloud will flag them. Adaptive network hardening
provides recommendations to further harden the NSG rules.
For a full list of features, see Feature coverage for machines.

Remove direct internet connectivity
Make sure policies and processes require restricting and monitoring direct internet
connectivity by virtual machines.
For Azure, you can enforce policies by:
Enterprise-wide prevention: Prevent inadvertent exposure by following the
permissions and roles described in the reference model.
Ensures that network traffic is routed through approved egress points by
default.
Exceptions (such as adding a public IP address to a resource) must go through a
centralized group that evaluates exception requests and makes sure appropriate
controls are applied.
Identify and remediate exposed virtual machines by using the Microsoft Defender
for Cloud network visualization to quickly identify internet exposed resources.
Restrict management ports (RDP, SSH) using Just in Time access in Microsoft
Defender for Cloud.
One way of managing VMs in the virtual network is by using Azure Bastion. This service
allows you to log into VMs in the virtual network through SSH or remote desktop
protocol (RDP) without exposing the VMs directly to the internet. To see a reference
architecture that uses Bastion, see Network DMZ between Azure and an on-premises
datacenter.

Containers
Containerized workloads have an extra layer of abstraction and orchestration. That
complexity requires specific security measures that protect against common container
attacks such as supply chain attacks.
Use container registries that are validated for security. Images in public registries
might contain malware or unwanted applications that activate when the container
is running. Build a process for developers to request and rapidly get security

validation of new containers and images. The process should validate against your
security standards. This includes applying security updates, scanning for unwanted
code such as backdoors and illicit crypto coin miners, scanning for security
vulnerabilities, and application of secure development practices.
A popular process pattern is the quarantine pattern. This pattern allows you to get
your images on a dedicated container registry and subject them to security or
compliance scrutiny applicable for your organization. After it's validated, they can
then be released from quarantine and promoted to being available.
Microsoft Defender for Cloud identifies unmanaged containers hosted on IaaS
Linux VMs, or other Linux machines running Docker containers.
Make sure you use images from authorized registries. You can enforce this
restriction through Azure Policy. For example, for an Azure Kubernetes Service
(AKS) cluster, have policies that restrict the cluster to only pull images from Azure
Container Registry (ACR) that is deployed as part of the architecture.
 Tip
Here are the resources for the preceding example:

GitHub: Azure Kubernetes Service (AKS) Secure Baseline Reference
Implementation .
The design considerations are described in Baseline architecture for an AKS
cluster.
Regularly scan containers for known risks in the container registry, before use, and
during use.
Use security monitoring tools that are container aware to monitor for anomalous
behavior and enable investigation of incidents.
Microsoft Defender for container registries are designed to protect AKS clusters,
container hosts (virtual machines running Docker), and ACR registries. When
enabled, the images that are pulled or pushed to registries are subject to
vulnerability scans.
For more information, see these articles:
Container security in Defender for Cloud

Network
How do you monitor and diagnose conditions of the network?
As an initial step, enable and review all logs (including raw traffic) from your network
devices.
Security group logs – flow logs and diagnostic logs
Azure Network Watcher
Take advantage of the packet capture feature to set alerts and gain access to real-time
performance information at the packet level.
Packet capture tracks traffic in and out of virtual machines. It gives you the capability to
run proactive captures based on defined network anomalies including information
about network intrusions.
For an example, see Scenario: Get alerts when VM is sending you more TCP segments
than usual.
Then, focus on observability of specific services by reviewing the diagnostic logs. For
example, for Azure Application Gateway with integrated WAF, see Web application
firewall logs. Microsoft Defender for Cloud analyzes diagnostic logs on virtual networks,
gateways, network security groups and determines if the controls are secure enough.
For example:
Is your virtual machine exposed to public internet. If so, do you have tight rules on
network security groups to protect the machine?
Are the network security groups (NSG) and rules that control access to the virtual
machines overly permissive?
Are the storage accounts receiving traffic over secure connections?
Follow the recommendations provided by Defender for Cloud. For more information,
see Networking recommendations. Use Azure Firewall logs and metrics for observability
into operational and audit logs.
Integrate all logs into a security information and event management (SIEM) service, such
as Microsoft Sentinel. The SIEM solutions support ingestion of large amounts of
information and can analyze large datasets quickly. Based on those insights, you can:
Set alerts or block traffic crossing segmentation boundaries.
Identify anomalies.
Tune the intake to significantly reduce the false positive alerts.

Identity
Monitor identity-related risk events using adaptive machine learning algorithms,
heuristics quickly before the attacker can gain deeper access into the system.

Review identity risks
Most security incidents take place after an attacker initially gains access using a stolen
identity. Even if the identity has low privileges, the attacker can use it to traverse laterally
and gain access to more privileged identities. This way the attacker can control access to
the target data or systems.
Does the organization actively monitor identity-related risk events related to
potentially compromised identities?
Monitor identity-related risk events on potentially compromised identities and
remediate those risks. Review the reported risk events in these ways:
Azure AD reporting. For information, see users at risk security report and the risky
sign-ins security report.
Use the reporting capabilities of Azure Active Directory Identity Protection.
Use the Identity Protection risk events API to get programmatic access to security
detections by using Microsoft Graph. See riskDetection and riskyUser APIs.
Azure AD uses adaptive machine learning algorithms, heuristics, and known
compromised credentials (username/password pairs) to detect suspicious actions that
are related to your user accounts. These username/password pairs come from
monitoring public and dark web and by working with security researchers, law
enforcement, security teams at Microsoft, and others.
Remediate risks by manually addressing each reported account or by setting up a user
risk policy to require a password change for high risk events.

Regularly review critical access
Regularly review roles that are assigned privileges with a business-critical impact.
Set up a recurring review pattern to ensure that accounts are removed from permissions
as roles change. You can conduct the review manually or through an automated process
by using tools such as Azure AD access reviews.

Discover & replace insecure protocols

Discover and disable the use of legacy insecure protocols SMBv1, LM/NTLMv1, wDigest,
Unsigned LDAP Binds, and Weak ciphers in Kerberos.
Applications should use the SHA-2 family of hash algorithms (SHA-256, SHA-384, SHA512). Use of weaker algorithms, like SHA-1 and MD5, should be avoided.
Authentication protocols are a critical foundation of nearly all security assurances. These
older versions can be exploited by attackers with access to your network and are often
used extensively on legacy systems on Infrastructure as a Service (IaaS).
Here are ways to reduce your risk:
Discover protocol usage by reviewing logs with Microsoft Sentinel's Insecure
Protocol Dashboard or third-party tools.
Restrict or Disable use of these protocols by following guidance for SMB , NTLM,
WDigest .
Use only secure hash algorithms (SHA-2 family).
We recommend implementing changes using pilot or other testing methods to mitigate
risk of operational interruption.

Learn more
For more information about hash algorithms, see Hash and Signature Algorithms.

Connected tenants
Does your security team have visibility into all existing subscriptions and cloud
environments? How do they discover new ones?
Make sure the security team is aware of all enrollments and associated subscriptions
connected to your existing environment through ExpressRoute or Site-Site VPN. Monitor
them as part of the overall enterprise.
Assess if organizational policies and applicable regulatory requirements are followed for
the connected tenants. This applies to all Azure environments that connect to your
production environment network.
The organizations' cloud infrastructure should be well documented, with security team
access to all resources required for monitoring and insight. Conduct frequent scans of
the cloud-connected assets to ensure no additional subscriptions or tenants have been

added outside of organizational controls. Regularly review Microsoft guidance to ensure
security team access best practices are consulted and followed.

Suggested actions
Ensure all Azure environments that connect to your production environment and
network apply your organization's policy, and IT governance controls for security.
You can discover existing connected tenants using a tool provided by Microsoft.
Guidance on permissions you may assign to security is in the Assign privileges for
managing the environment section.

CI/CD pipelines
DevOps practices are for change management of the workload through continuous
integration, continuous delivery (CI/CD). Make sure you add security validation in the
pipelines. Follow the guidance described in Learn how to add continuous security
validation to your CI/CD pipeline.

Next steps
View logs and alerts

Security logs and alerts using Azure
services
Article • 11/30/2022

Logs provide insight into the operations of a workload, the infrastructure, network
communications, and so on. When suspicious activity is detected, use alerts as a way of
detecting potential threats. As part of your defense-in-depth strategy and continuous
monitoring, respond to the alerts to prevent security assurance from decaying over time.

Key points
＂ Configure central security log management.
＂ Enable audit logging for Azure resources.
＂ Collect security logs from operating systems.
＂ Configure security log storage retention.
＂ Enable alerts for anomalous activities.

Use native services
Azure Monitor provides observability across your entire environment. You
automatically get platform metrics, activity logs, and diagnostics logs from most of
your Azure resources with no configuration. The activity logs provide detailed
diagnostic and auditing information.
Microsoft Defender for Cloud generates notifications as security alerts by
collecting, analyzings, and integrating log data from your Azure resources and the
network. Alerts are available when you enable the Microsoft Defender plans. This
will add to the overall cost.
Microsoft Sentinel is a security information event management (SIEM) and security
orchestration automated response (SOAR) solution. It's a single solution for alert
detection, threat visibility, proactive hunting, and threat response.
Ideally use a combination of the preceding services to get a full view. For example, use
Azure Monitor to collect information about the operating system running on Azure
compute. If you're running your own compute, use Microsoft Defender for Cloud.

Audit logging

An important aspect of monitoring is tracking operations. For example, you want to
know who created, updated, deleted a resource. Or, get resource-specific information
such as when an image was pulled from Azure Container Registry. That information is
crucial for a Security Operations (SecOps) team in detecting the presence of adversaries,
reacting to an alert of suspicious activity, or proactively hunting for anomalous events.
They are also useful for security auditing and compliance and offline analysis.
On Azure, that information is emitted as platform logs by the resources and the
platform on which they run. They are tracked by Azure Resource Manager as and when
subscription-level events occur. Each resource emits logs specific to the service.
Consider storing your data for audit purposes or statistical analysis. You can retain data
in your log analytics workspace and specify the data type. This example sets the
retention for SecurityEvents to 730 days:
HTTP

PUT /subscriptions/00000000-0000-0000-000000000000000/resourceGroups/MyResourceGroupName/providers/Microsoft.Operation
alInsights/workspaces/MyWorkspaceName/Tables/SecurityEvent?api-version=201704-26-preview {"properties": {"retentionInDays": 730 } }

Retaining data in this manner can reduce your costs for data retention over time. For
information about the type of data you can retain, see security data types.
Another way is to send the logs to a storage account.

Alerts
Security alerts are notifications that are generated when anomalous activity is detected
on the resources used by the workload or the platform.
With the Microsoft Defender plans, Microsoft Defender for Cloud analyzes log data and
shows a list of alerts that's based on logs collected from resources within a scope. Alerts
include context information such as severity, status, activity time. Defender for Cloud
also provides a correlated view called incidents. Use this data to analyze what actions
the attacker took, and what resources were affected. Have strategies to react to alerts as
soon as they are generated. An option is to handle alerts in Azure Functions.
Use the data to support these activities:
Remediation of threats.
Investigation of an incident.

Proactive hunting activities.
For more information, see Security alerts and incidents.

Centralize logs and alerts
Organizations typically follow one of three models when deploying logs: centralized,
decentralized, or hybrid. The choice depends on organizational structures. For example,
if each team owns their resource group, log data is segregated per resource. While
access control to that data might be easy to set up, it's difficult to correlate logs. This
might be challenging for the SecOps team who need a holistic view to analyze the data.
Consider a central view of log and data, when applicable. Some advantages include:
The resources in the workload can share a common log workspace reducing
duplication.
Single point of observability with all log data makes it easier consume data for
hunting activities, querying, and statistical evaluation.
The integrated data can be fed into modern machine learning analytics platforms
support ingestion of large amounts of information and can analyze large datasets
quickly. In addition, these solutions can be tuned to significantly reduce the false
positive alerts.
You can collect logs and alerts from various sources centrally in a Log Analytics
Workspace, storage account, and Event Hubs. You can then review and query log data
efficiently. In Azure Monitor, use the diagnostic setting on resources to route specific
logs that are important for the organization. Logs vary by resource type. In Microsoft
Defender for Cloud, take advantage of the continuous export feature to route alerts.
７ Note
Platform logs are not available indefinitely. You'll need to keep them so that you
can review them later for auditing purposes or offline analysis. Use Azure Storage
Accounts for long-term/archival storage. In Azure Monitor, specify a retention
period when you enable diagnostic setting for your resources.
Another way to see all data in a single view is to integrate logs and alerts into Security
Information and Event Management (SIEM) solutions, such as Microsoft Sentinel. Other
popular third-party choices are Splunk, QRadar, ArcSight. Microsoft Defender for Cloud
and Azure Monitor supports all of those solutions.

Integrating more data can enrich alerts with additional context. However, collection is
not detection. Make sure a high volume of low value data doesn't flow into those
solutions.
If you don't have a reasonable expectation that the data will provide value, deprioritize
integration of these events. For example, high volume of firewall denies events may
create noise without actual actions.
That choice will help in rapid response and remediation by filtering out false positives,
and elevate true positives, and so on. Also it will lower SIEM cost, false positives, and
increase performance.
Other ways of log integration may involve a hybrid model that mixes centralized and
decentralized (distributed among teams) approaches. For details, see Important
considerations for an access control strategy.

Next
Responding to alerts is an essential way to prevent security assurance decay, and
designing for defense-in depth and least privilege strategies.
Remediate security risks

Related links
For more information, see these articles:
How to get started with Azure Monitor and third-party SIEM integration
How to collect platform logs and metrics with Azure Monitor
Export alerts
Understand Microsoft Defender for Cloud data collection
Go back to the main article: Monitor

Remediate security risks in Microsoft
Defender for Cloud
Article • 11/30/2022

Security controls must remain effective against attackers who continuously improve
their ways to attack the digital assets of an enterprise. Use the principle of drive
continuous improvement to make sure systems are regularly evaluated and improved.
Start by remediating common security risks. These risks are usually from wellestablished attack vectors. This will forces attackers to acquire use advanced and more
expensive attack methods.

Key points
Processes for handling incidents and post-incident activities, such as lessons
learned and evidence retention.
Remediate the common risks identified by Microsoft Defender for Cloud.
Track remediation progress with secure score and comparing against historical
results.
Address alerts and take action with remediation steps.

Track Secure Score
Do you review and remediate common risks in the workload boundary?
Monitor the security posture of VMs, networks, storage, data services, and various other
contributing factors. Secure Score in Microsoft Defender for Cloud shows a composite
score that represents the security posture at the subscription level.

Do you have a process for formally reviewing Secure Score on Microsoft Defender for
Cloud?
As you review the results and apply recommendations, track the progress and prioritize
ongoing investments. Higher score indicates a better security posture.
Set up a regular cadence (typically monthly) to review the secure score and plan
initiatives with specific improvement goals.
Assign stakeholders for monitoring and improving the score. Gamify the activity if
possible to increase engagement and focus from the responsible teams.
As a technical workload owner, work with your organization's dedicated team that
monitors Secure Score. In the DevOps model, workload teams may be responsible for
their own resources. Typically, these teams are responsible.
Security posture management team
Vulnerability management or governance, risk, and compliance team
Architecture team
Resource-specific technical teams responsible for improving secure score, as
shown in this table.
Category

Resources

Responsible team

Compute and
applications

App Services

Application Development/Security
Team(s)

Containers

Application Development and/or
Infrastructure/IT Operations

Category

Data and Storage

Identity and access

Resources

Responsible team

Virtual machines, scale sets,
compute

IT/Infrastructure Operations

SQL/Redis/Data Lake
Analytics/Data Lake Store

Database Team

Storage Accounts

Storage/Infrastructure Team

Subscriptions

Identity Team(s)

Key Vault

Information/Data Security Team

management

Networking

Networking Team and Network Security

Resources

Team

IoT Security

IoT Resources

The Azure Secure Score sample

IoT Operations Team

shows how to get your Azure Secure Score for a

subscription by calling the Microsoft Defender for Cloud REST API. The API methods
provide the flexibility to query the data and build your own reporting mechanism of
your secure scores over time.

Review and remediate recommendations
Microsoft Defender for Cloud monitors the security status of machines, networks,
storage and data services, and applications to discover potential security issues. Enable
this capability at no additional cost to detect vulnerable virtual machines connected to
internet, missing security updates, missing endpoint protection or encryption, deviations
from baseline security configurations, missing Web Application Firewall (WAF), and
more.
View the recommendations to see the potential security issues and apply the Microsoft
Defender for Cloud recommendations to execute technical remediations.

The recommendations are grouped by controls. Each recommendation has detailed
information such as severity, affected resources, and quick fixes where applicable. Start
with high severity items.
Defender for Cloud has the capability of exporting results at configured intervals.
Compare the results with previous sets to verify that issues have been remediated.
For more information, see Continuous export.

Policy remediation
A common approach for maintaining the security posture is through Azure Policy.
Along with organizational policies, a workload owner can use scoped policies for
governance purposes, such as check misconfiguration, prohibit certain resource types,
and others. The resources are evaluated against rules to identify unhealthy resources
that are risky. Post evaluation, certain actions are required as remediation. The actions
can be enforced through Azure Policy effects.
For example, a workload runs in an Azure Kubernetes Service (AKS) cluster. The business
goals require the workload to run in a highly restrictive environment. As a workload
owner, you want the resource group to contain AKS clusters that are private. You can
enforce that requirement with the Deny effect. It will prevent a cluster from being
created if that rule isn't satisfied.
That sort of isolation can be maintained through policies at a higher level such as the
subscription level or even management groups.

Another use case is that it can be automatically remediated by deploying related
resources. For example, the organization wants all storage resources in a subscription to
send logs to a common Log Analytics workspace. If a storage account doesn't pass the
policy, a deployment is automatically started as remediation. That remediation can be
enforced through DeployIfNotExist. There are some considerations.
There's a significant wait before the resource is updated and the deployment
starts. In the preceding example, there won't be logs captured during that wait
time. Avoid using this effect for resources that cannot tolerate a delay.
The resource deployed because of DeployIfNotExist are created by a separate
identity than that of the identity that did the original deployment. That identity
must have high enough privileges to make the required changes.

Manage alerts
Microsoft Defender for Cloud shows a list of alerts that's based on logs collected from
resources within a scope. Alerts include context information such as severity, status,
activity time. Most alerts have MITRE ATT&CK® tactics that can help you understand the
kill chain intent. Select the alert and investigate the problem with detailed information.
Finally take action. That action can be to fix the resources that are out of compliance
with actionable remediation steps. You can also suppress alerts that are false positives.
Make sure that you are integrating critical security alerts into Security Information and
Event Management (SIEM), Security Orchestration Automated Response (SOAR) without
introducing a high volume of low value data. Microsoft Defender for Cloud can stream
alerts to Microsoft Sentinel. You can also use a third-party solution by using Microsoft
Graph Security API.

Next
Azure security operations

Related links
Go back to the main article: Monitor

Security audits
Article • 03/24/2023

To make sure that the security posture doesn't degrade over time, have regular auditing
that checks compliance with organizational standards. Enable, acquire, and store audit
logs for Azure services.

Key points
＂ Improve secure score in Microsoft Defender for Cloud.
＂ Use an industry standard benchmark to evaluate your organizations current security
posture.
＂ Perform regular internal and external compliance audits, including regulatory
compliance attestations.
＂ Review the policy requirements.
＂ Use Azure Governance Visualizer

for a holistic overview of your technical Azure

Governance implementation.

Evaluate using standard benchmarks
Do you evaluate the security posture of this workload using standard benchmarks?
Use an industry standard benchmark to evaluate your organizations current security
posture.
Benchmarking allows you to improve your security program by learning from external
organizations. It lets you know how your current security state compares to that of other
organizations, providing both external validation for successful elements of your current
system and identifying gaps that serve as opportunities to enrich your team's overall
security strategy. Even if your security program isn't tied to a specific benchmark or
regulatory standard, you will benefit from understanding the documented ideal states
by those outside and inside of your industry.
As an example, the Center for Internet Security (CIS) has created security benchmarks for
Azure that map to the CIS Control Framework. Another reference example is the MITRE
ATT&CK™ framework that defines the various adversary tactics and techniques based on
real-world observations. These external references control mappings and help you to
understand any gaps between your current strategy, what you have, and what other
experts have in the industry.

Suggested action
Develop an Azure security benchmarking strategy aligned to industry standards.
As people in the organization and on the project change, it is crucial to make sure that
only the right people have access to the application infrastructure. Auditing and
reviewing access control reduces the attack vector to the application. Azure control
plane depends on Azure AD and access reviews are often centrally performed as part of
internal, or external audit activities.
Make sure that the security team is auditing the environment to report on compliance
with the security policy of the organization. Security teams may also enforce compliance
with these policies.

Audit regulatory compliance
Compliance is important for several reasons. Aside from signifying levels of standards,
like ISO 27001 and others, noncompliance with regulatory guidelines may bring
sanctions and penalties. Regularly review roles that have high privileges. Set up a
recurring review pattern to ensure that accounts are removed from permissions as roles
change. Consider auditing at least twice a year.

Suggested action
Use Microsoft Defender for Cloud to continuously assess and monitor your compliance
score.

Learn more
Assess your regulatory compliance
Have you established a monitoring and assessment solution for compliance?
Continuously assess and monitor the compliance status of your workload. Microsoft
Defender for Cloud provides a regulatory compliance dashboard that shows the current
security state of workload against controls mandated by the standard governments or
industry organizations and Azure Security Benchmark. Keep your resources in
compliance with those standards. Defender for Cloud tracks many standards. You can
set the standards by management groups in a subscription.
Consider using Azure Access Reviews or Entitlement Management to periodically review
access to the workload.

Consider using Azure Access Reviews or Entitlement Management to periodically review
access to the workload.
For Azure, use Azure Policy to create and manage policies that enforce compliance.
Azure Policies are built on the Azure Resource Manager capabilities. Azure Policy can
also be assigned through Azure Blueprints.
For more information, see Tutorial: Create and manage policies to enforce compliance.

Here's an example management group that is tracking compliance to the Payment Card
Industry (PCI) standard.

Do you have internal and external audits for this workload?
A workload should be audited internally, external, or both with the goal of discovering
security gaps. Make sure that the gaps are addressed through updates.
Auditing is important for workloads that follow a standard. Aside from signifying levels
of standards, noncompliance with regulatory guidelines may bring sanctions and
penalties.
Perform regulatory compliance attestation. Attestations are done by an independent
party that examines if the workload is in compliance with a standard.

Review critical access
Is access to the control plane and data plane of the application periodically reviewed?
Regularly review roles that have high privileges. Set up a recurring review pattern to
ensure that accounts are removed from permissions as roles change. Consider auditing
at least twice a year.
As people in the organization and on the project change, make sure that only the right
people, have access to the application infrastructure and just enough privileges to

complete the task. Auditing and reviewing the access control reduces the attack vector
to the application.
Azure control plane depends on Azure AD. You can conduct the review manually or
through an automated process by using tools such as Azure AD access reviews. These
reviews are often centrally performed often as part of internal or external audit activities.

Check policy compliance
Make sure that the security team is auditing the environment to report on compliance
with the security policy of the organization. Security teams may also enforce compliance
with these policies.
Enforce and audit industry, government, and internal corporate security policies. Policy
monitoring checks that initial configurations are correct and that it continues to be
compliant over time.
For Azure, use Azure Policy to create and manage policies that enforce compliance.
Azure Policies are built on the Azure Resource Manager capabilities. Azure Policy can
also be assigned through Azure Blueprints. For more information, see Tutorial: Create
and manage policies to enforce compliance.

Capture critical data
Azure Governance Visualizer

captures data from the most relevant Azure governance

capabilities such as Azure Policy, Azure role-based access control (Azure RBAC), and
Azure Blueprints. The visualizer PowerShell script iterates through an Azure tenant's
management group hierarchy down to the subscription level. From the collected data,
the visualizer shows your hierarchy map, creates a tenant summary, and builds granular
scope insights about your management groups and subscriptions.

Next steps
Remediate security risks in Microsoft Defender for Cloud

Related links
Secure score in Microsoft Defender for Cloud allows you view all the security
vulnerabilities into a single score.

Tutorial: Improve your regulatory compliance describes a step-by-step process to
evaluate regulatory requirements in Microsoft Defender for Cloud.

Azure security test practices
Article • 03/24/2023

Regularly test your security design and implementation, as part the organization's
operations. That integration will make sure the security assurances are effective and
maintained as per the security standards set by the organization.
A well-architected workload should be resilient to attacks. It should recover rapidly from
disruption and yet provide the security assurances of confidentiality, integrity, and
availability. Invest in simulated attacks as tests that can indicate gaps. Based on the
results of the results you can harden the defense and limit a real attacker's lateral
movement within your environment.
Simulated tests can also give you data to plan risk mitigation. Applications that are
already in production should use data from real-world attacks. New or updated
applications with new features, should rely on structured models for detecting risks
early, such as threat modeling.

Key points
Define test cases that are realistic and based on real-world attacks.
Identify and catalog lowest cost methods for preventing and detecting attacks.
Use penetration testing as a one-time attack to validate security defenses.
Simulate attacks through red teams for long-term persistent attacks.
Measure and reduce the potential attack surface that attackers target for
exploitation for resources within the environment.
Ensure proper follow-up to educate users about the various means that an attacker
may use.

Penetration testing (pentesting)
Do you perform penetration testing on the workload?
It's recommended that you simulate a one-time attack to detect vulnerabilities.
Pentesting is a popular methodology to validate the security defense of a system. The
practitioners are security experts who are not part of the organization's IT or application
teams. So, they look at the system in a way that malicious actors scope an attack
surface. The goal is to find security gaps by gathering information, analyzing
vulnerabilities, and reporting.

Penetration tests provide a point-in-time validation of security defenses. Red teams can
help provide ongoing visibility and assurance that your defenses work as designed,
potentially testing across different levels within your workload(s). Red team programs
can be used to simulate either one time, or persistent threats against an organization to
validate defenses that have been put in place to protect organizational resources.
Microsoft recommends penetration testing and red team exercises to validate security
defenses for your workload.
Penetration Testing Execution Standard (PTES)

provides guidelines about common

scenarios and the activities required to establish a baseline.
Azure uses shared infrastructure to host your assets and assets belonging to other
customers. In a pentesting exercise, the practitioners may need access to sensitive data
of the entire organization. Follow the rules of engagement to make sure that access and
the intent is not misused. For guidance about planning and executing simulated attacks,
see Penetration Testing Rules of Engagement

.

Learn more
Azure Penetration Testing
Penetration Testing

Simulate attacks
The way users interact with a system is critical in planning your defense. The risks are
even higher for critical impact accounts because they have elevated permissions and can
cause more damage.
Do you carry out simulated attacks on users of this workload?
Simulate a persistent threat actor targeting your environment through a red team. Here
are some advantages:
Periodic checks. The workload will get checked through a realistic attack to make
sure the defense is up to date and effective.
Educational purposes. Based on the learnings, upgrade the knowledge and skill
level. This will help the users understand the various means that an attacker may
use to compromise accounts.
A popular choice to simulate realistic attack scenarios is Office 365 Attack Simulator.
Is personal information detected and removed/obfuscated automatically?

Be cautious about using sensitive application information. Don't store personal
information such as contact information, payment information, and so on, in any
application logs. Apply protective measures, such as obfuscation. Machine learning tools
can help with this measure. For more information, see PII Detection cognitive skill.

Related links
Threat modeling is a structured process to identify the possible attack vectors. Based on
the results, prioritize the risk mitigate efforts. For more information, see Application
threat analysis.
For more information on current attacks, see the Microsoft Security Intelligence (SIR)
report.
Microsoft Cloud Red Teaming
Go back to the main article: Monitor

Security operations in Azure
Article • 04/10/2023

The responsibility of the security operation team (also known as Security Operations
Center (SOC), or SecOps) is to rapidly detect, prioritize, and triage potential attacks.
These operations help eliminate false positives and focus on real attacks, reducing the
mean time to remediate real incidents. Central SecOps team monitors security-related
telemetry data and investigates security breaches. It's important that any
communication, investigation, and hunting activities are aligned with the application
team.

Here are some general best practices for conducting security operations:
Follow the NIST Cybersecurity Framework functions as part of operations.
Detect the presence of adversaries in the system.
Respond by quickly investigating whether it's an actual attack or a false alarm.
Recover and restore the confidentiality, integrity, and availability of the
workload during and after an attack.
For information about the framework, see NIST Cybersecurity Framework .
Acknowledge an alert quickly. A detected adversary must not be ignored while
defenders are triaging false positives.
Reduce the time to remediate a detected adversary. Reduce their opportunity time
to conduct and attack and reach sensitive systems.
Prioritize security investments into systems that have high intrinsic value. For
example, administrator accounts.

Proactively hunt for adversaries as your system matures. This effort will reduce the
time that a higher skilled adversary can operate in the environment. For example,
skilled enough to evade reactive alerts.
For information about the metrics that the Microsoft's SOC team uses , see Microsoft
SOC

.

Tools
Here are some Azure tools that a SOC team can use investigate and remediate incidents.
Tool

Purpose

Microsoft Sentinel

Centralized Security Information and Event Management (SIEM) to get
enterprise-wide visibility into logs.

Microsoft Defender for
Cloud

Alert generation. Use security playbook in response to an alert.

Azure Monitor

Event logs from application and Azure services.

Azure Network Security

Visibility into network activities.

Group (NSG)
Azure Information

Secure email, documents, and sensitive data that you share outside

Protection

your company.

Investigation practices should use native tools with deep knowledge of the asset type
such as an Endpoint detection and response (EDR) solution, Identity tools, and Microsoft
Sentinel.
For more information about monitoring tools, see Security monitoring tools in Azure.

Assign incident notification contact
Security alerts need to reach the right people in your organization. Establish a
designated point of contact to receive Azure incident notifications from Microsoft
Defender for Cloud. In most cases, such notifications indicate that your resource is
compromised or attacking another customer. This enables your security operations team
to rapidly respond to potential security risks and remediate them.
This enables your security operations team to rapidly respond to potential security risks
and remediate them.

Ensure administrator contact information in the Azure enrollment portal includes
contact information that will notify security operations directly or rapidly through an
internal process.
Learn more
To learn more about establishing a designated point of contact to receive Azure incident
notifications from Microsoft, reference the following articles:
Update notification settings
Configure email notifications for security alerts

Incident response
Is the organization effectively monitoring security posture across workloads, with a
central SecOps team monitoring security-related telemetry data and investigating
possible security breaches? Communication, investigation, and hunting activities need to
be aligned with the application team(s).
Are operational processes for incident response defined and tested?
Actions executed during an incident and response investigation could impact
application availability or performance. Define these processes and align them with the
responsible (and in most cases central) SecOps team. The impact of such an
investigation on the application has to be analyzed.
Are there tools to help incident responders quickly understand the application and
components to do an investigation?
Incident responders are part of a central SecOps team and need to understand security
insights of an application. Security playbook in Microsoft Sentinel can help to
understand the security concepts and cover the typical investigation activities.

Suggested action
Consider using Microsoft Defender for Cloud to monitor security-related events and get
alerted automatically.
Learn more
Security alerts and incidents in Microsoft Defender for Cloud

Hybrid enterprise view

Security operations tooling and processes should be designed for attacks on cloud and
on-premises assets. Attackers don't restrict their actions to a particular environment
when targeting an organization. They attack resources on any platform using any
method available. They can pivot between cloud and on-premises resources using
identity or other means. This enterprise-wide view will enable SecOps to rapidly detect,
respond, and recover from attacks, reducing organizational risk.

Leverage native detections and controls
Use Azure security detections and controls instead of creating custom features for
viewing and analyzing event logs. Azure services are updated with new features and
have the ability to detect false positive with a higher accuracy rate.
Integrating logs from the network devices, and even raw network traffic itself, will
provide greater visibility into potential security threats flowing over the wire.
To get a unified view across the enterprise, feed the logs collected through native
detections (such as Azure Monitor) into a centralized security information and event
management (SIEM) solution like Microsoft Sentinel. Avoid using generalized log
analysis tools and queries. Within Azure Monitor, create Log Analytics Workspace to
store logs. You can also review logs and perform queries on log data. These tools can
offer high-quality alerts.
The modern machine learning-based analytics platforms support ingestion of extremely
large amounts of information and can analyze large datasets very quickly. In addition,
these solutions can be tuned to significantly reduce false positive alerts.
Examples of network logs that provide visibility include:
Security group logs - flow logs and diagnostic logs
Web application firewall logs
Virtual network taps and their equivalents
Azure Network Watcher

Suggested actions
Integrate network device log information in advanced SIEM solutions or other analytics
platforms.

Learn more
Enable enhanced network visibility

Next steps
Security health modeling
Security tools
Security logs and audits
Check for identity, network, data risks

Tradeoffs for security
Article • 11/30/2022

Security provides confidentiality, integrity, and availability assurances of an
organization's data and systems. When designing a system you can almost never
compromise on security controls. When you enhance security of an architecture there
might be impact on reliability, performance efficiency, cost, and operational excellence.
This article describes some of those considerations.

Security vs Reliability
Reliable applications are resilient and highly available. Every architectural component
factors in achieving your requirements for reliability. Workload security is often woven
into many layers of the workload's architecture, operations, and runtime requirements;
and may come with their own implications on resiliency or availability.
For example, identity providers and authorization services are critical dependencies to
consider. This includes the identity service (Microsoft Identity Platform) and any libraries
that help facilitate the use of those services. At some points in the architecture, a failure
at an identity layer is terminal. At other points, reliability can be still achieved through
strategies such as caching, taking advantage of TTLs on access tokens, and others.
OAuth2 claims validation can happen mostly disconnected from the claims provider.
However, not all authorization can be achieved that way. In those situations reliability
may be traded in favor of complete security.
Many workloads may quickly degrade in functionality with the loss of critical security
controls. Consider evaluating at each component of your architecture to detect that
condition.
Other security considerations that might impact reliability are:
Poor or manual certifications or key rotation practices. Failure to do those tasks can
lead to reliability issues.
Expired service principals. For example, a deployment pipeline that used a service
principal might fail at a later date, if that principal's access key has expired. Using
managed identities helps keep reliability high while also maintaining least
privileges on that identity.
High availability is often achieved by redundancy (actively or passively), and
security controls also need to align with the failover mechanism. For example,
failing over from one storage account to another for reliability may impact how the
client's active authorization session is handled. Using managed identity with Azure

AD integration for storage access can result in a higher reliability because the
client doesn't have to manage SAS tokens when switching to the new storage
account.

Security vs Cost Optimization
Increasing security of the workload will almost always lead to higher cost. There are
some ways to optimize cost.
Maximum security may not always be practical for all environments. Evaluate the
security requirements in pre-production and production environments. Are
services such as Azure DDoS Protection, Microsoft Sentinel, Dedicated HSMs,
Microsoft Defender for Cloud needed in pre-production? Is inner loop mocking of
security controls sufficient? If resources are not publicly accessible, can you dial
down some controls for cost savings? Always make those choices, if and only if, the
lowered environment still meets the business requirements.
Premium security features can increase the cost. There are areas you can reduce
cost by using native security features. For example, avoid implementing custom
roles if you can use built-in roles.
Every security control has an opportunity to impact workflows, and workflows that
involve people can be expensive. A security control that stops work from being
done should be evaluated as necessary or unnecessarily redundant. Total cost of
ownership (TCO) includes operational costs for developers, operators, IT SecOps
and onerous security protocols. Reach agreement about where "less" can br
"sufficient" to optimize costs.
TCO includes the time needed do tasks. Optimizing that time will optimize cost.
Using platform features can lower TCO and enhance the security posture. Instead
of training an engineer to manually review logs and correlate access patterns, use
intelligence in services, such as Microsoft Defender for Cloud or Sentinel alerts.

Security vs Operational Excellence
Operational Excellence involves understanding business and workload behavior, and
applying appropriate amounts of automation, and observability into those processes.
Release management
Your organization defines its quality gates (manual or automated) as part of its safe
deployment practices. Evaluate whether each gate is required or optional, taking

into consideration whether it's valuable to perform, at the added cost of
complexity (and time) for that release. Adding security checks into the process
makes the checks more valuable at that point in the process than any gains
(usually simplicity and time) by not having them in place.
Organizational policies
Teams can often benefit from collaborating and using cross-functional skills in all
stages of workload life cycle, from development all the way through production.
However, organizational policy or regulatory concerns may prevent such widereaching access. Consider, where possible, isolating those systems that do need
heightened access policies from those that do not. Avoid applying "one size fits all"
model to all components in the system. It's easier to optimize operations in
systems that allow more unregulated access. For systems that demand regulated
access, complexity is expected to increase leading to higher cost.
Supportability considerations
The most "serviceable" architectures are the ones that are the most transparent to
everyone involved, and those often have the least number of security controls.
Adding security controls to your architecture like filtered telemetry feeds, redacted
logs, runtime system access restrictions, and so on can all impact the supportability
of a solution. Adding security controls often require adding compensating or
compromised solutions for observability into the platform.

Related link
Go back to the main article: Security

Security patterns
Article • 11/30/2022

Security provides confidentiality, integrity, and availability assurances against malicious
attacks on information systems (and safety assurances for attacks on operational
technology systems). Losing these assurances can negatively impact your business
operations and revenue, as well as your organization's reputation in the marketplace.
Maintaining security requires following well-established practices (security hygiene) and
being vigilant to detect and rapidly remediate vulnerabilities and active attacks.

Patterns
Pattern

Summary

Federated
Identity

Delegate authentication to an external identity provider.

Gatekeeper

Protect applications and services by using a dedicated host instance that acts as a
broker between clients and the application or service, validates and sanitizes
requests, and passes requests and data between them.

Valet Key

Use a token or key that provides clients with restricted direct access to a specific
resource or service.

Key Security Resources
Resource

Summary

Azure Security

Prescriptive best practices and recommendations to integrate into architectures

Benchmarks

for securing workloads, data, services, and enterprise environments on Azure.

Microsoft

Native security controls to simplify integration of threat detection and

Defender for
Cloud

monitoring in Azure architectures

Security
Strategy

Building and updating a security strategy for cloud adoption and modern threat
environment

Guidance
Security Roles

Guidance on security roles and responsibilities including definitions of

and
Responsibilities

mission/outcome for each organizational function and how each should evolve
with the adoption of cloud.

Resource

Summary

Getting Started
Guide for
Security

Guidance for planning and implementing security throughout cloud adoption

Security Resiliency
Achieving security resilience requires a combination of preventive measures to block
attacks, responsive measures detect and quickly remediate active attacks, and
governance to ensure consistent application of best practices.
Security strategy should include lessons learned described in security strategy
guidance.
Azure security configurations should align to the best practices and controls in
the Azure Security Benchmark (ASB). Security configurations for Azure services
should align to the Security baselines for Azure in the ASB.
Azure architectures should integrate native security capabilities to protect and
monitor workloads including Microsoft Defender for Cloud, Azure DDoS
protection, Azure Firewall, and Azure Web Application Firewall (WAF).
For a more detailed discussion, see the Cybersecurity Resilience
workshop.

module in the CISO

Cost optimization documentation
Apply the cost principles in your architecture to accelerate your time to market while
avoiding capital-intensive solutions. Consider opportunity costs. Use the cost calculators
to estimate the initial and operational costs. Finally, establish policies, budgets, and
controls that set cost limits for your solution.

Key points

ｆ

QUICKSTART

Principles
Design checklist
Provision checklist
Monitor checklist
Optimize checklist
Tradeoffs

ｄ

TRAINING

Cost optimization

ｑ

VIDEO

What trade-offs have you made to optimize for cost?

Design within the cost limits

ｂ

GET STARTED

Organization structure
Capture clear requirements
Consider the cost constraints
Consider tradeoffs

ｐ

CONCEPT

Develop a cost model
Understand the usage meters
Cost impact across regions
Consumption or fixed?
Use PaaS
Estimate an initial cost

ｑ

VIDEO

How is your organization modeling cloud costs?

Provision the right resources

ｅ

OVERVIEW

AI + Machine Learning
Big Data
Data store
Networking

ｑ

VIDEO

How do you ensure that cloud resources are appropriately provisioned?
How do you manage the storage footprint of your digital assets?

Monitor your cloud spend

ｐ

CONCEPT

Review alerts
Generate cost reports
Conduct cost reviews

ｑ

VIDEO

How are you monitoring your costs?

Optimize based on audits

ｐ

CONCEPT

Autoscale instances
Right-size VMs
Cache data

ｑ

VIDEO

What actions are you taking to optimize cloud costs?

Cost tools and services

ｐ

CONCEPT

Azure Pricing Calculator
Azure Migrate
Microsoft Azure Total Cost of Ownership (TCO) Calculator
Azure Advisor
Advisor Score
Azure Cost Management
Visualize cost reports

Consumption APIs

ｉ

REFERENCE

Billing account API
Billing Periods API
Usage Detail API

Marketplace Store Charge API
Price Sheet API

Overview of the cost optimization pillar
Article • 03/30/2023

The cost optimization pillar provides principles for balancing business goals with budget
justification. The principles help you create a cost-effective workload while avoiding
capital-intensive solutions. Cost optimization is about looking at ways to reduce
unnecessary expenses and improve operational efficiencies.
Use the pay-as-you-go strategy for your architecture, and invest in scaling out, rather
than delivering a large investment-first version. Consider opportunity costs in your
architecture, and the balance between first mover advantage versus fast follow. Use the
cost calculators

to estimate the initial cost and operation costs. Finally, establish

policies, budgets, and controls that set cost limits for your solution.
To assess your workload using the tenets found in the Microsoft Azure Well-Architected
Framework, see the Microsoft Azure Well-Architected Review.
We recommend exploring the following videos to dive deeper into Azure cost
optimization:
https://learn.microsoft.com/shows/Azure-Enablement/Diving-deeper-into-Azure-costoptimization-Part-1-Cost-Optimization-Ep-2-Well-Architected-series/player
https://learn.microsoft.com/shows/Azure-Enablement/Diving-deeper-into-Azure-costoptimization-Part-2-Cost-Optimization-Ep-2-Well-Architected-series/player

Azure Well-Architected Framework cost
optimization articles
The Azure Well-Architected Framework includes the following articles in the cost
optimization pillar:
Cost area

Description

Capture cost
requirements

Start your planning with a careful enumeration of requirements. Make sure the
needs of the stakeholders are addressed. For strong alignment with business
goals, the stakeholders must define the needs not the vendors.

Cost of

Cost of an Azure service can vary between locations based on demand and local

resources in
Azure
regions

infrastructure costs.

Cost area

Description

Governance

Understand how governance can assist with cost management. This work benefits
your ongoing cost review process and offers a level of protection for new
resources.

Estimate the
initial cost

It's difficult to attribute costs before deploying a workload to the cloud. If you use
methods for on-premises estimation or directly map on-premises assets to cloud
resources, the estimate is inaccurate.

PaaS

Look for areas in the architecture where it might be natural to incorporate
platform-as-a-service (PaaS) options. These options include caching, queues, and
data storage. PaaS reduces time and cost of managing servers, storage,
networking, and other application infrastructure.

Consumption

A common way to estimate cost is by considering workloads on a peak
throughput. Under consistently high usage, consumption-based pricing can be
less efficient for estimating baseline costs when compared to the equivalent
provisioned pricing.

Provision

Deployment of workload cloud resources can optimize cost.

cloud
resources
Monitor cost

Azure Cost Management has an alert feature. Alerts are generated when
consumption reaches a threshold.

Optimize

Monitor and optimize the workload by using the right resources and sizes.

cost
Tradeoffs for

As you design the workload, consider tradeoffs between cost optimization and

costs

other aspects of the design, such as security, scalability, resilience, and operability.

Next section
Use the cost optimization principles to guide you in your overall strategy.
Principles

Cost optimization design principles
Article • 04/18/2023

Business goals and the return on investment (ROI) drive a cost-effective workload while
you keep to a given budget. The principles of cost optimization are important
considerations that help you achieve both business objectives and cost justification.
To assess your workload using the tenets you find in the Azure Well-Architected
Framework, see the Microsoft Azure Well-Architected Review.
The following design principles provide:
Context for questions
Why a certain aspect is important
How an aspect applies to cost optimization
Use these critical design principles as lenses to assess the cost optimization of an
application deployed on Azure. These lenses provide a framework for the application
assessment questions.

Choose the correct resources
Choose resources that align with business goals and can handle your workload
performance.
When onboarding new workloads, explore the possibility of modernization and cloud
native offerings where possible. It's typically more cost-effective to use platform as a
service (PaaS) or software as a service (SaaS), as opposed to infrastructure as a service
(IaaS).
An inappropriate or misconfigured service can affect cost. For example, building a multiregion service when the service levels don't require high-availability or geo-redundancy
increases cost without any reasonable business justification.

Set up budgets and maintain cost constraints
Every design choice has cost implications. Consider the budget constraints set by the
company before choosing:
An architectural pattern
The Azure service

A price model for the service
As part of design, identify acceptable boundaries on:
Scale
Redundancy
Performance against cost
After estimating the initial cost, set budgets and alerts at different scopes to measure
the cost. One cost driver can be unrestricted resources. These resources typically need
to scale and consume more cost to meet demand.

Dynamically allocate and deallocate resources
To match performance needs, dynamically allocate and deallocate resources.
Identify idle or underutilized resources through Azure Advisor or other tools, and:
Reconfigure
Consolidate (or)
Shut down

Optimize workloads, aim for scalable costs
A key benefit of the cloud is the ability to scale dynamically. The workload cost should
scale linearly with demand. You can save cost through automatic scaling.
Recommendations:
Consider usage metrics and performance to determine the number of instances.
Choose smaller instances for a highly variable workload.
Scale out, rather than up, to get the required level of performance. This choice
enables you to make your cost calculations and estimates granular.
The cost management process should be:
Rigorous
Iterative
A key principle of responsible cloud optimization

Continuously monitor and optimize cost
management

To provision resources dynamically and to scale with demand:
Conduct regular cost reviews
Measure capacity needs
Forecast capacity needs
If you're just starting this process, review enable success during a cloud adoption
journey.

Next step
Design checklist

Checklist - Design for cost
Article • 11/30/2022

Use this checklist when designing a cost-effective workload.

Cost model
Capture clear requirements. Gather detailed information about the business
workflow, regulatory, security, and availability.
Capture requirements
Estimate the initial cost. Use tools such as Azure pricing calculator

to assess cost

of the services you plan to use in the workload. Use Azure Migrate and Microsoft
Azure Total Cost of Ownership (TCO) Calculator

for migration projects.

Accurately reflect the cost associated with right storage type. Add hidden costs,
such as networking cost for large data download.
Estimate the initial cost
Define policies for the cost constraints defined by the organization. Understand
the constraints and define acceptable boundaries for quality pillars of scale,
availability, security.
Consider the cost constraints
Identify shared assets. Evaluate the business areas where you can use shared
resources. Review the billing meters build chargeback reports per consumer to
identify metered costs for shared cloud services.
Create a structured view of the organization in the cloud
Plan a governance strategy. Plan for cost controls through Azure Policy. Use
resource tags so that custom cost report can be created. Define budgets and alerts
to send notifications when certain thresholds are reached.
Governance

Architecture
Check the cost of resources in various Azure geographic regions. Check your
egress and ingress cost, within regions and across regions. Only deploy to multiple
regions if your service levels require it for either availability or geo-distribution.
Azure regions

Choose a subscription that is appropriate for the workload. Azure Dev/Test
subscription types are suitable for experimental or non-production workloads and
have lower prices on some Azure services such as specific VM sizes. If you can
commit to one or three years, consider subscriptions and offer types that support
Azure Reservations or savings plans.
Subscription and offer type
Choose the right resources to handle the performance. Understand the usage
meters and the number of meters for each resource in the workload. Consider
tradeoffs over time. For example, cheaper virtual machines may initially indicate a
lower cost but can be more expensive over time to maintain a certain performance
level. Be clear about the billing model of third-party services.
Azure resources
Use cost alerts to monitor usage and spending
Compare consumption-based pricing with pre-provisioned cost. Establish
baseline cost by considering the peaks and the frequency of peaks when analyzing
performance.
Consumption and fixed cost models
Use proof-of-concept deployments. The Azure Architecture Center has many
reference architectures and implementations that can serve as a starting point. The
Azure Tech Community

has architecture and services forums.

Choose managed services when possible. With PaaS and SaaS options, the cost of
running and maintaining the infrastructure is included in the service price.
Managed services

Develop a cost model
Article • 04/10/2023

Cost modeling is an exercise where you create logical groups of cloud resources that are
mapped to the organization's hierarchy and then estimate costs for those groups. The
goal of cost modeling is to estimate the overall cost of the organization in the cloud.
1. Understand how your responsibilities align with your organization
Map your organization's needs to logical groupings offered by cloud services. This
way the business leaders of the company get a clear view of the cloud services and
how they're controlled.
2. Capture clear requirements
Start your planning by carefully enumerating the requirements. From the high-level
requirements, narrow down each requirement before starting on the design of the
solution.
3. Consider the cost constraints
Evaluate the budget constraints on each business unit. Determine the governance
policies in Azure to lower cost by reducing wastage, over-provisioning, or
expensive provisioning of resources.
4. Consider tradeoffs
Optimal design doesn't equate to a lowest-cost design.
As you prioritize requirements, cost can be adjusted. Expect a series of tradeoffs in
the areas that you want to optimize, such as security, scalability, resilience, and
operability. If the cost to address the challenges in those areas is high,
stakeholders look for alternate options to reduce cost. There might be risky
choices made in favor of a cheaper solution.
5. Derive functional requirements from high-level goals
Break down the high-level goals into functional requirements for the solution's
components. Each requirement must be based on realistic metrics to estimate the
actual cost of the workload.
6. Consider the billing model for Azure resources

Azure services are offered with consumption-based prices where you're charged
for only what you use. There's also options for fixed price where you're charged for
provisioned resources.
Most services are priced based on units of size, amount of data, or operations.
Understand the meters that are available to track usage. For more information, see
Azure resources.
At the end of this exercise, you should have identified the lower and upper limits on cost
and set budgets for the workload. Azure lets you create and manage budgets in Azure
Cost Management. For more information, see Quickstart: Create a budget with an Azure
Resource Manager template.
Have frequent and clear communication with the stakeholders
In the initial stages, communication between stakeholders is vital. The overall team must
align on the requirements so that overall business goals are met. If not, the entire
solution might be at risk. For instance, the development team indicates that the
resilience of a monthly batch-processing job is low. They might request the job to work
as a single node without scaling capabilities. This request opposes the architect's
recommendation to automatically scale out and route requests to worker nodes.
This type of disagreement can introduce a point of failure into the system, risking the
service level agreement (SLA), and cause an increase in operational cost.

Organization structure
Map the organization's needs to logical groupings offered by cloud services. This way
the business leaders of the company get a clear view of the cloud services and how
they're controlled.
1. Understand how your workload fits into cost optimization across the portfolio of
cloud workloads.
If you're creating a workload that fits into a broader portfolio of workloads, see the
get started guide to document foundational decisions. The guide helps your team
capture the broader portfolio view of business units, resources organizations,
responsibilities, and a view of the long-term portfolio.
If a central team needs to run cost optimization across the portfolio, see get
started managing enterprise costs in Cloud Adoption Framework.
2. Encourage a culture of democratized cost optimization decisions.

As a workload owner, you can have a measurable effect on cost optimization.
There are other roles in the organization that can help improve cost management
activities. To help embed the pillar of cost optimization into your organization
beyond your workload team, see Build a cost-conscious organization.
3. Reduce costs through shared cloud services and landing zones.
If your workload has dependencies on shared assets like Active Directory, Network
connectivity, security devices, or other services that are also used by other
workloads, encourage your central IT organization to provide those services
through a centrally managed landing zone to reduce duplicate costs. See get
started with centralized design and configuration to start developing landing
zones.
4. Calculate the ROI by understanding what's included in each grouping and what
isn't.
Which aspects of the hierarchy are covered by cloud services?
The Azure pricing model is based on expenses incurred for the service. Expenses
include hardware, software, development, operations, security, and data center
space to name a few. Evaluate the cost benefit of shifting away from owned
technology infrastructure to leased technology solutions.
5. Identify scenarios where you can use shared cloud services to lower cost.
Can some services be shared by other consumers?
Identify areas where you can share a service or an application environment with
other business units.
Identify resources that you can use as shared services and review their billing
meters. Examples include a virtual network and its hybrid connectivity or a shared
app service environment (ASE). If the meter data isn't able to be split across
consumers, decide on custom solutions to allocate proportional costs. Move
shared services to dedicated resources for consumers for cost reporting.
Build chargeback reports per consumer to identify metered costs for
shared cloud services. Aim for granular reports to understand which workload
is consuming what amount of the shared cloud service.

Next step

Capture cost requirements

Cost constraints
Here are some considerations for determining the governance policies that can assist
with cost management.
What are the budget constraints set by the company for each business unit?
What are policies for the budget alert levels and associated actions?
Identify acceptable boundaries for scale, redundancy, and performance against
cost.
Assess the limits for security. Don't compromise on security. Premium cloud
security features can drive the cost up. It's not necessary to overinvest. Instead, use
the cost profile to drive a realistic threat profile.
Identify unrestricted resources. These resources typically need to scale and
consume more cost to meet demand.

Next step
Consider tradeoffs

Functional requirements
Break down high-level goals into functional requirements. For each of those
requirements, define metrics to calculate cost estimates accurately. Cloud services are
priced based on performance, features, and locations. When defining these metrics,
identify acceptable boundaries of performance, scale, resilience, and security. Start by
expressing your goals in number of business transactions over time, breaking them
down to fine-grain requirements.
What resources are needed for a single transaction, and how many transactions are
done per second, day, and year?
Start with a fixed cost of operations and a rough estimate of transaction
volume to work out a cost-per-transaction to establish a baseline. Consider the
difference between cost models based on fixed, static provisioning of services, more
variable costs based upon autoscaling such as serverless technologies.

Use T-shirt sizes for choosing SKUs

When choosing options for services, start with an abstract representation of size. For
example, if you choose a T-shirt size approach, small, medium, and large sizes can
represent an on-demand virtual machine. You pick a T-shirt size instead of picking
specific virtual machines or managed disks SKU sizes.
Abstract sizes give you an idea of the expected performance and cost requirements. It
sets the tone for various consumption units that measure compute resources for
performance. Also, it helps in understanding the on-demand consumption model of the
services.
For more information, see Estimate the initial cost.

Next steps
Estimate the initial cost

Capture cost requirements
Article • 11/30/2022

Start your planning with a careful enumeration of requirements. Make sure the needs of
the stakeholders are addressed. For strong alignment with business goals, those areas
must be defined by the stakeholders and shouldn't be collected from a vendor.
Capture requirements at these levels:
Business workflow
Compliance and regulatory
Security
Availability
What do you aim to achieve by building your architecture in the cloud?
Here are some common answers.
Take advantage of features only available in the cloud, such as intelligent security
systems, regions footprint, or resiliency features.
Use the on-demand nature of the cloud to meet peak or seasonal requirements,
then releasing that cost investment when it is no longer needed.
Consolidate physical systems.
Retire on-premises infrastructure.
Reduce hardware or data center management costs.
Increase performance or processing capabilities, through services like big data and
machine learning.
Meet regulatory considerations, including taking advantage of certified
infrastructure.
Narrow down each requirement before you start the design of the workload. Expect the
requirements to change over time as the solution is deployed and optimized.

Landing zone
Consider the cost implications of the geographic region to which the landing zone is
deployed.
The landing zone consists of the subscription and resource group, in which your cloud
infrastructure components exist. This zone impacts the overall cost. Consider the
tradeoffs. For example, there are additional costs for network ingress and egress for
cross-zonal traffic. For more information, see Azure regions and Azure resources.

For information about landing zone for the entire organization, see CAF: Implement
landing zone best practices.

Security
Security is one of the most important aspects of any architecture. Security measures
protect the valuable data of the organization. It provides confidentiality, integrity, and
availability assurances against attacks and misuse of the systems.
Factor in the cost of security controls, such as authentication, MFA, conditional access,
information protection, JIT/PIM, and premium Azure AD features. Those options will
drive up the cost.
For security considerations, see the Security Pillar.

Business continuity
Does the application have a Service Level Agreement that it must meet?
Factor in the cost when you create high availability and disaster recovery strategies.
Overall Service Level Agreement (SLA), Recovery Time Objective (RTO), and Recovery
Point Objective (RPO) may drive towards expensive design choices in order to support
higher availability requirements. For example, a choice might be to host the application
across regions, which is costlier than single region but supports high availability.
If your service SLAs, RTOs and RPOs allow, then consider cheaper options. For instance,
pre-build automation scripts and packages that would redeploy the disaster recovery
components of the solution from the ground-up in case a disaster occurs. Alternatively,
use Azure platform-managed replication. Both options can lower cost because fewer
cloud services are pre-deployed and managed, reducing wastage.
In general, if the cost of high availability exceeds the cost of application downtime, then
you could be over engineering the high availability strategy. Conversely, if the cost of
high availability is less than the cost of a reasonable period of downtime, you may need
to invest more.
Suppose the downtime costs are relatively low, you can save by using recovery from
your backup and disaster recovery processes. If the downtime is likely to cost a
significant amount per hour, then invest more in the high availability and disaster
recovery of the service. It's a three-way tradeoff between cost of service provision, the
availability requirements, and the organization's response to risk.

Application lifespan
Does your service run seasonally or follow long-term patterns?
For long-running applications, consider using Azure Reservations if you can commit to
one-year or three-year term.
Similarly, Azure savings plans is another option to save money when you have
consistent resource usage in your subscriptions and can commit to a fixed hourly spend
on compute services for a one-year or three-year period
If your application runs intermittently, consider using consumption billing plans where
they are offered on services in your architecture. For example, use Azure Functions in a
Consumption plan, so you only pay for compute resources you use.

Automation opportunities
Is it a business requirement to have the service be available 24x7?
You may not have a business goal to leave the service running all the time. Doing so will
incur a consistent cost. Can you save by shutting down the service or scaling it down
outside normal business hours? If you can,
Azure has a rich set of APIs, SDKs, and automation technology that utilizes DevOps
and traditional automation principles. Those technologies ensure that the
workload is available at an appropriate level of scale as needed.
Repurpose some compute and data resources for other tasks that run out of
regular business hours. Reference the Compute Resource Consolidation pattern
and consider containers or elastic pools for more compute and data cost flexibility.

Budget for staff education
Keep the technical staff up to date in cloud management skills so that the invested
services are optimally used.
Consider using resources such as FastTrack for Azure

and Microsoft Learn

training to onboard the staff. Those resources provide engineering investments at
no cost to customers.
Identify training requirements and costs for cloud migration projects, application
development, and architecture refinement.
Invest in key areas, such as identity management, security configuration, systems
monitoring, and automation.

Give the staff access to training and relevant announcements. This way, they can
be aware of new cloud capabilities and updates.
Provide opportunities to get real-world experience of customers across the globe
through conferences, specific cloud training, and passing dedicated Microsoft
Exams (AZ, MS, MB, etc.).

Standardization
Ensure that your cloud environments are integrated into any IT operations processes.
Those operations include user or application access provisioning, incident response, and
disaster recovery. That mapping may uncover areas where additional cloud cost is
needed.

Next step
Determine the cost constraints

Azure regions
Article • 04/18/2023

The cost of an Azure service can vary between locations based on demand and local
infrastructure costs. Consider the following geographical areas when choosing the
location of your resources to estimate costs.
Terminology

Description

Azure region

A set of data centers deployed within a latency-defined perimeter and connected
through a dedicated regional low-latency network.

Availability
zone

A unique physical location within a region with independent power, network, and
cooling to be tolerant to data center failures through redundancy and logical
isolation of services.

Billing zone

A geographic collection of regions that is used for billing.

Location

A region or a zone within a region. Azure has data centers all over the world and
each data center resides in a location.

Landing
zone

The ultimate location of your cloud solution or the landing zone. The landing
zone typically consists of logical containers like a subscription and resource
group, in which your cloud infrastructure components exist.

See the Azure global infrastructure

for a complete list of Azure geographies, regions,

and locations.
To see product availability by region, see Products available by region .

Tradeoff
Locating resources in a cheaper region shouldn't negate the cost of network
ingress and egress or by degraded application performance because of increased
latency.
Hosting an application in a single region can cost less than an application that's
hosted across regions because of replication costs or the need for extra nodes.

Compliance and regulatory
Azure offers differentiated cloud regions for specific security and compliance
requirements.

Does your solution need specific levels of security and compliance?
If your solution needs to follow certain government regulations, the cost is higher.
Otherwise you can meet less rigid compliance, through Azure Policy, which is free.
Certain Azure regions are built specifically for high compliance and security needs. For
example, with Azure Government (USA) you're given an isolated instance of Azure.
Azure Germany

has data centers that meet privacy certifications. These specialized

regions have higher cost.
Regulatory requirements can dictate restrictions on data residency. These requirements
can change your data replication options for resiliency and redundancy.

Traffic across billing zones and regions
Cross-regional traffic and cross-zonal traffic incur more costs.
Is the application critical enough to have the footprint of the resources cross zones
and,or cross regions?
Bandwidth refers to data moving in and out of Azure data centers. Inbound data
transfers, or data transfers going into Azure data centers, are free for most services. For
outbound data transfers, the billing zone determines the data transfer pricing. For more
information, see Bandwidth Pricing Details .
Suppose you want to build a cost-effective solution by provisioning resources in
locations that offer the lowest prices. The dependent resources and their users are
located in different parts of the world. In this case, data transfers between locations add
cost if there are meters tracking the volume of data moving across locations. The cost of
transferring the data could offset any savings from choosing the cheapest location.
The extra cross-regional and cross-zone costs don't apply to global services, such
as Azure Active Directory.
Not all Azure services support zones and not all regions in Azure support zones.
Before choosing a location, consider how important is the application to justify
the cost of having resources cross zones and/or cross regions. For non-mission
critical applications such as, developer or test, consider keeping the solution and its
dependencies in a single region or single zone to leverage the advantages of
choosing the lower-cost region.

Azure resources
Article • 11/30/2022

Just like on-premises equipment, there are several elements that affect monthly costs
when using Azure services.

Usage meters for resources
Most services are priced based on units of size, amount of data, or operations. When
you provision an Azure resource, Azure creates metered instances for that resource. The
meters track the resources' usage and generate a usage record that is used to calculate
your bill.
For example, you provision a virtual machine in Azure. Some meters that track its usage
include: Compute Hours, IP Address Hours, Data Transfer In, Data Transfer Out, Standard
Managed Disk, Standard Managed Disk Operations, Standard IO-Disk, Standard IO-Block
Blob Read, Standard IO-Block Blob Write, Standard IO-Block Blob Delete.
How is the usage tracked for each resource in the workload?
For each Azure resource, have a clear understanding of the meters that track usage and
the number of meters associated with the resource tier. The meters correlate to several
billable units. Those units are charged to the account for each billing period. The rate
per billable unit depends on the resource tier.
A resource tier impacts pricing because each tier offers levels of features such as
performance or availability. For example, a Standard HDD hard disk is cheaper than a
Premium SSD hard disk.
Start with a lower resource tier then scale the resource up as needed. Growing
a service with little to no downtime is easier when compared to downscaling a
service. Downscaling usually requires deprovisioning or downtime. In general,
choose scaling out instead of scaling up.
As part of the requirements, consider the metrics for each resource and build your alerts
on baseline thresholds for each metric. The alerts can be used to fine-tune the
resources. For more information, see Respond to cost alert.

Allocated usage for the resource

Another way to look at pricing is the allocated usage.
Suppose, you de-allocate the virtual machine. You'll not be billed for Compute Hours,
I/O reads or writes, and other compute meters because the virtual machine is not
running and has no given compute resources. However, you'll be charged for storage
costs for the disks.
Here are some considerations:
The meters and pricing vary per product and often have different pricing tiers
based on the location, size, or capacity of the resource.
Cost for associated with infrastructure is kept low with commodity hardware.
Failures cannot be prevented but the effects of failure can be minimized through
design choices. The resiliency features are factored in the price of a service and its
features.
Here are some examples:

Azure Disk
Start with a small size in GB for a managed disk instead of pay-per-GB model. It's cost
effective because cost is incurred on the allocated storage.

ExpressRoute
Start with a smaller bandwidth circuit and scale up as needed.

Compute infrastructure
Deploy an additional smaller instance of compute alongside a smaller unit in parallel.
That approach is more cost effective in comparison to restarting an instance to scale up.
For details about how billing works, see Azure Cost Management + Billing
documentation.

Subscription and offer type
What is the subscription and offer type in which resources are created?
Azure usage rates and billing periods can vary depending on the subscription and offer
type. Some subscription types also include usage allowances or lower prices. For
example, Azure Dev/Test subscription

offers lower prices on Azure services such as

specific VM sizes, PaaS web apps, and VM images with pre-installed software. Visual
Studio subscribers obtain as part of their benefits access to Azure subscriptions

with

monthly allowances.
For information about the subscription offers, see Microsoft Azure Offer Details .
As you decide on the offer type, consider the types supporting Azure reservations and
savings plans.
With Azure Reservations, you prepay for reserved capacity at a discount.
Reservations are suitable for workloads that have a long-term usage pattern.
Combining the offer type with reservations can significantly lower the cost. For
information about subscription and offer types that are eligible for reservations,
see Discounted subscription and offer types.
With Azure savings plans, you commit to a fixed hourly spend across all compute
services and apply to all participating compute services globally up to the hourly
commitment.

Billing structure for services in Azure
Marketplace
Are you considering third-party services through Azure Marketplace?
Azure Marketplace offers both the Azure products and services from third-party
vendors. Different billing structures apply to each of those categories. The billing
structures can range from free, pay-as-you-go, one-time purchase fee, or a managed
offering with support and licensing monthly costs.

Governance
Article • 04/21/2023

Governance helps with cost management. This work benefits your ongoing cost review
process and offers a level of protection for new resources.

Understand how centralized governance
functions can support your team
Centralized governance can relieve some of the burden related to on-going cost
monitoring and optimization. But it's an augmentation to the workload team's
responsibilities, not a replacement. To understand how centralized cloud governance
teams operate, see Govern methodology for the cloud.
For more detailed information on cost optimization, see Cost Management
discipline.
For an example of the types of guardrails provided by a governance team, see Cost
management discipline improvement. This article includes examples of suggested
tags and policies for improving cost governance.
If centralized governance teams don't support your team, see Cloud governance
function. This article helps you understand the activities your team might consider
including in each sprint.

Follow organizational policies that define cost
boundaries
Use policies to ensure compliance with identified cost boundaries. Policies eliminate the
need for manual resource approval and they speed up provisioning.
Azure Policy can set rules on management groups, subscriptions, and resources groups.
The policies control clouds service resource SKU size, replication features, and supported
locations. Use policies to prevent provisioning expensive resources. Identify the built-in
Azure policies that can help lower costs. For even more control, create custom policies.
For more information, see Create management groups for resource organization and
management.
For more information on how to control the group who manages resources in the
subscription, see Azure built-in roles.

Set limits or quotas to prevent unexpected costs. For more information, see Azure
subscription and service limits, quotas, and constraints.

Enforce resource tagging
Use tags on resources and resource groups to track incurred costs. Identify the service
meters that you can't tag or view in the cost analysis tool in the Azure portal.
The advantages of tagging include:
The cost can be reported to an owner, an application, a business department, or a
project initiative. This feature is useful because the overall cost can span multiple
resources, locations, and subscriptions.
Filter information. Use filtering in the Azure portal cost analysis tool to get granular
reports.
There are some limitations:
You can't tag all Azure resources and not all taggable resources in Azure are
accounted for in the Azure cost analysis tool.

Estimate the initial cost
Article • 04/20/2023

It's difficult to know your costs before deploying a workload to the cloud. If you use
methods for on-premises estimation or you directly map on-premises assets to cloud
resources, estimates are inaccurate. For example, if you build your own datacenter, your
costs might appear comparable to cloud. Most on-premises estimates don't account for
costs like cooling, electricity, IT and facilities labor, security, and disaster recovery.
Here are some best practices:
Use proof-of-concept deployments to help refine cost estimates.
Choose the right resources that can handle workload performance. For example,
cheaper virtual machines might initially show a lower cost but be more expensive
to maintain a certain performance level.
Accurately reflect the cost associated with right storage type.
Add hidden costs, such as networking expenses for large data downloads.

Migration workloads
Quantify the cost of running your business in Azure by calculating total cost ownership
(TCO) and the return on investment (ROI). Compare those metrics to existing onpremises equivalents.
It's difficult to know costs before migrating to the cloud.
Using on-premises calculation might not accurately reflect the cost of cloud resources.
Here are some challenges:
On-premises TCO might not accurately account for hidden expenses. These
expenses include under-utilization of purchased hardware or network maintenance
costs like labor and equipment failure.
Cloud TCO might not accurately account for a drop in the organization's
operational labor hours. Cloud provider's infrastructure, platform management
services, and other operational efficiencies are included in the cloud service
pricing. Especially at a smaller scale, the cloud provider's services don't result in
reduction of IT head count.
ROI might not accurately account for new organizational benefits because of cloud
capabilities. It's hard to quantify improved collaboration, reduced time to service
customers, and fast scaling with minimal or no downtime.

ROI might not accurately account for the business process re-engineering required
to fully adopt cloud benefits. In some cases, this re-engineering might not occur at
all, leaving an organization in a state where they use new technology inefficiently.
Azure provides the following tools to determine cost.
Microsoft Azure Total Cost of Ownership Calculator

to reflect all costs.

For migration projects, the TCO Calculator might help, because it populates
some common costs but it lets you modify the cost assumptions.
Azure pricing calculator

to assess costs of the services you plan to use in your

solution.
Azure Migrate to evaluate your organization's current workloads in on-premises
datacenters. Azure Migrate suggests an Azure replacement solution with virtual
machine sizes based on your workload. It also provides a cost estimate.

Example estimate for a microservices workload
Consider this scenario as an example. Use the Azure pricing calculator

to estimate the

initial cost before the workload deploys. The cost calculates per month or for 730 hours.
In this example, we've chosen the microservices pattern. As the container orchestrator,
one of the options could be Azure Kubernetes Service (AKS) that manages a cluster of
pods. Choose NGINX ingress controller because it's a well-known controller for such
workloads.
The example uses current prices and is subject to change. The example shows prices
and calculations for illustrative purposes only.

Compute
For AKS, there's no charge for cluster management.
For AKS agent nodes, there are many instance sizes and SKUs options. The example
workload is expected to follow a long running pattern and you can commit to three
years. An instance that's eligible for reserved instances would be a good choice. Lower
the cost by choosing the 3-year reserved plan.
The workload needs two virtual machines. One is for the backend services and the other
is for the utility services.

The B12MS instance with two virtual machines is sufficient for this initial estimation. We
can lower cost by choosing reserved instances.
Estimated Total: $327.17 per month with upfront payment of $11,778.17.

Application gateway
For this scenario, consider the Standard_v2 Tier of Azure Application Gateway because
of the autoscaling capabilities and performance benefits. Also, choose consumptionbased pricing, which calculates by capacity units (CU). Each capacity unit calculates
based on compute, persistent connections, or throughput. For Standard_v2 SKU, each
compute unit can handle approximately 50 connections per second with RSA 2048-bit
key TLS certificate. For this workload, estimate 10 capacity units.
Estimated Total: $248.64 per month.

Load balancer
NGINX ingress controller deploys a load balancer that routes internet traffic to the
ingress. Approximately 15 load balancer rules are needed. NAT rules are free. The main
cost driver is the amount of data processed inbound and outbound independent of
rules. The estimated traffic is 1 TB (inbound and outbound).
Estimated Total: $96.37 per month.

Bandwidth
The estimated outbound traffic is 2 TB. The first 5 GB/month are free in Zone 1, which
includes North America, Europe, and Australia. Between 5 GB and 10 TB /month is
charged $0.087 per GB.
Estimated Total: $177.74 per month

External data source
Because the schema-on read nature of the data handled by the workload, choose Azure
Cosmos DB as the external data store. By using the Azure Cosmos DB capacity
calculator , you can calculate the throughput to reserve.

Cost variables
For lower latency, in this scenario, enable geo-replication by using the Multiregions writes feature. By default, Azure Cosmos DB uses one region for writes and
the rest for reads.
Default choices in consistency model of Session and indexing policy to Automatic.
Automatic indexing makes Azure Cosmos DB indexes all properties in all items for
flexible and efficient queries. Custom indexing policy lets you include and exclude
properties from the index for lower write request units (RUs) and storage size.
Uploading a custom indexing policy can help you reduce costs.
Total data store isn't a significant cost driver. Here it's set to 500 GB.
The throughput is variable indicating peaks. The percentage of time at peak is set
to 10%.
The item size is an average of 90k. Using the capacity calculator, you can upload
sample json files. The sample json files include your document's data structure, the
average document's size, and the number of reads and writes per second. These

variables have the largest effect on cost because you use them to calculate the
throughput. The throughput values appear in the image.
Now, use those values in the Azure pricing calculator .

The average throughput based on these settings is 20,000 RUs per second, which is the
minimum throughput required for a 3-year reserved capacity plan.
Here's the total cost for three years using the reserved plan:
$1,635.20 Average per month ($58,867.20 charged upfront)
You save $700.00 by choosing the three-year reserved capacity over the pay-as-you-go
price.

CI/CD pipelines
With Azure DevOps, Basic plan is included for Visual Studio Enterprise, Professional, Test
Professional, and MSDN Platforms subscribers. And there's no charge for adding or
editing work items and bugs and viewing dashboards, backlogs, and Kanban boards for
stakeholders.
The Basic plan license for five users is free.

More services
For Microsoft Hosted Pipelines, the Free tier includes one parallel CI/CD job with 1,800
minutes (30 hours) per month. But you can select the Paid tier and have one CI/CD
parallel job ($40.00) in this tier. Each parallel CI/CD job includes unlimited minutes.
For this stage of cost estimation, the self-hosted pipelines isn't required because the
workload doesn't have custom software that runs in your build process and which
isn't included in the Microsoft-hosted option.
Azure Artifacts is a service you can use to create package feeds to publish and consume
Maven, npm, NuGet, Python, and universal packages. Azure Artifacts bills on a
consumption basis, and is free up to 2 GB of storage. For this scenario, we estimate 56
GB in artifacts ($56.00)
Azure DevOps offers a cloud-based solution for load testing your apps. Load tests are
measured and billed in virtual user minutes (VUMs). For this scenario, estimate a 200,000
VUMs ($72.00).
Estimated Total: $168.00 per month

Managed services
Article • 04/10/2023

Look for areas in the architecture where it makes sense to incorporate platform-as-aservice (PaaS) options. These include caching, queues, and data storage. PaaS reduces
time and cost of managing servers, storage, networking, and other application
infrastructure.
With PaaS, the infrastructure costs are included in the pricing model of the service. For
example, you can allocate a lower SKU virtual machine as a jump box. There are more
costs for storage and managing a separate server. You also need to configure a public IP
on the virtual machine, which we don't recommend. A managed service, such as Azure
Bastion, takes into consideration all those costs and offers better security.
Azure provides a wide range of PaaS resources. Here are some examples of when you
might consider PaaS options:
Task

Use

Host a web server

Azure App Service instead of setting up IIS servers.

Indexing and querying
heterogenous data

Azure Cognitive Search instead of ElasticSearch.

Host a database server

Azure offers many SQL and no-SQL options such as Azure SQL
Database and Azure Cosmos DB.

Secure access to virtual
machine

Azure Bastion instead of virtual machines as jump boxes.

Network security

Azure Firewall instead of virtual network appliances.

For more information, see Use platform as a service (PaaS) options.

Reference architecture
To see an implementation that provides better security and lowers cost through PaaS
services, go to Network DMZ between Azure and an on-premises datacenter.

Consumption and fixed cost models
Article • 04/06/2023

The common pricing options for Azure services are:
Consumption-based price - You're charged for only what you use. This model is
also known as the pay-as-you-go rate.
Fixed price - You provision resources and are charged for those instances whether
you use them or not.
A common way to estimate cost is by considering workloads on a peak throughput.
With consistently high utilization, consumption-based pricing can be less efficient for
estimating baseline costs when compared to the equivalent provisioned pricing.
Platform as a service (PaaS) and serverless technologies can help you understand the
economy cutoff point for consumption-based pricing.
See the difference between cost models based on fixed, static services provisioning, and
more variable costs based on autoscaling serverless technologies.

Start with a fixed minimum-level of performance and then use architectural patterns,
such as queue based load leveling and autoscaling services. With this approach, the
peaks are smoothed out into a more consistent flow of compute and data. This
approach should temporarily extend your burst performance when the service is under
sustained load. If cost is an important factor but you need to maintain service availability
under burst workloads, use the throttling pattern to maintain service quality under load.

Compare and contrast the options and understand how to provision workloads that can
potentially switch between the two models. The model is a tradeoff between scalability
and predictability. Ideally in the architecture, you blend the two aspects.

Provisioning cloud resources to
optimize cost
Article • 04/18/2023

Deployment of cloud resources of a workload is known as provisioning.
Use the Azure pricing calculator

to estimate the cost of your SKU choices. This list

describes some of your options:
AI + Machine Learning cost estimates
Big data analytics cost estimates
Compute cost estimates
Networking cost estimates
Data store cost estimates

AI + Machine Learning cost estimates
Article • 04/20/2023

Compute cost is the main cost driver for machine learning workloads. Those resources
are needed to run the training model and host the deployment. For information about
choosing a compute target, see What are compute targets in Azure Machine Learning?
The compute cost depends on cluster size, node type, and the number of nodes. Billing
occurs while the cluster nodes are starting, running, or shutting down.
With services such as Azure Machine Learning, you can create fixed-sized clusters or use
autoscaling.
If the amount of compute isn't known, start with a zero-node cluster. The
cluster scales up when it detects jobs in the queue. There is no charge for a zeronode cluster.
Fix-sized clusters are appropriate for jobs that run at a constant rate and the amount of
compute is known and measured beforehand. The time taken to spin up or down a
cluster incurs higher cost.
If you don't need retraining frequently, turn off the cluster when not in use.
To lower the cost for experimental or development workloads, choose Spot VMs. We
don't recommend Spot VMs for production workloads because Azure might evict them
at any time. For more information, see Use Azure Spot Virtual Machines.
For more information about the services that make up a machine learning workload, see
Compare Microsoft machine learning products and technologies.
This article provides cost considerations for some technology choices. This list isn't
meant to be exhaustive.

Azure Machine Learning
Training models don't incur the machine learning service surcharge. You're charged for
the following factors:
Compute choices, such as the virtual machine sizes and the region in which they're
available, drive costs. If you can commit to one or three years, choosing reserved

instances or savings plans can lower cost. For more information, see Reserved VMs
and Savings plans.
As part of provisioning Machine Learning resources, resources are deployed such
as Azure Container Registry

, Azure Blob Storage , and Key Vault . You incur

charges according to the pricing of those individual services.
If you deploy models to a Kubernetes Service cluster, Machine Learning

adds a

surcharge on top of the Kubernetes Service compute cost. This cost can be
lowered through autoscaling.
For more information, see Pricing calculator

Reference architecture
Distributed hyperparameter tuning for machine learning models
Distributed training of deep learning models on Azure
Batch scoring of Python models on Azure
Batch scoring for deep learning models using Azure Machine Learning pipelines
Real-time scoring of machine learning models in Python
MLOps for Python models using Azure Machine Learning
Batch scoring with R models to forecast sales
Real-time scoring of R machine learning models
Batch scoring of Spark models on Azure Databricks
Build an enterprise-grade conversational bot
Build a real-time recommendation API on Azure

Azure Cognitive Services
The billing depends on the type of service. The charges are based on the number of
transactions for each type of operation specific to a service. A certain number of
transactions are free. If you need more transactions, choose from the Standard
instances. For more information, see:
Pricing calculator
Azure Cognitive Services pricing

Azure Bot Service
The Azure Bot Service is a managed service purpose-built for enterprise-grade bot
development. Billing is based on the number of messages. A certain number of

messages are free. If you need to create custom channels, choose Premium channels,
which can drive up the cost of the workload.
For a Web App Bot, an App Service
Azure Monitor

is provisioned to host the bot. Also, an instance of

is provisioned. You're charged per the pricing of those individual

services.

Reference architecture for Azure Cognitive
Services and Azure Bot Service
Enterprise-grade conversational bot

Big data analytics cost estimates
Article • 05/25/2023

Most big data workloads are designed to do:
Batch processing of big data sources at rest.
Stream processing of data in motion.
Those workloads have different needs. Batch processing is done with long-running
batch jobs. For stream processing, the data ingestion component should be able to
capture, store, and in some cases buffer real-time messages. Both workloads have the
requirement to store a large volume of data then filter, aggregate, and prepare that data
for analysis.
For information about choosing technologies for each workload, see:
Batch processing
Technology choices for batch processing
Capability matrix
Stream processing
What are your options when choosing a technology for real-time processing?
Capability matrix
This article provides cost considerations for some of those choices.

Azure Synapse Analytics
The analytics resources are measured in Data Warehouse Units (DWUs), which tracks
CPU, memory, and IO. DWU also indicates the required level of performance. If you need
higher performance, add more DWU blocks.
You can provision the resources in one of two service levels.
Compute Optimized Gen1 tracks usage in DWUs and is a pay-as-you-go model.
Compute Optimized Gen2 tracks the compute DWUs (cDWUs) which lets you scale
the compute nodes. This level is intended for intensive workloads with higher
query performance and compute scalability. You can choose the pay-as-you-go
model or save 37% to 65% by using reserved instances if you can commit to one
or three years. For more information, see Reserved VMs.

Start with smaller DWUs and measure performance for resource intensive
operations, such as heavy data loading or transformation. This approach helps you
determine the number of units you need to increase or decrease. Measure usage
during the peak business hours so that you can assess the number of concurrent
queries and accordingly add units to increase the parallelism. Also, measure offpeak usage so that you can pause compute when needed.
In Azure Synapse Analytics, you can import or export data from an external data store,
such as Azure Blob Storage and Azure Data Lake Store. Storage and analytics resources
aren't included in the price. Moving data in and out of the data warehouse increases
bandwidth cost.
For more information, see:
Azure Synapse Analytics pricing
Manage compute for dedicated SQL pool in Azure Synapse Analytics

Synapse Analytics reference architecture
Automated enterprise BI
Enterprise business intelligence

Azure Databricks
Azure Databricks offers two SKUs, Standard and Premium, each with the following
options, in the order of least to most expensive:
Data Engineering Light is for data engineers to build and run jobs in automated
Spark clusters.
Data Engineering includes autoscaling and has features for machine learning
flows.
Data Analytics includes the preceding features. Data scientists can explore,
visualize, manipulate, and share data and insights interactively.
Choose a SKU depending on your workload. If you need features like log audit, which is
available in Premium, the overall cost can increase. If you need an autoscaling of clusters
to handle larger workloads or interactive Databricks dashboards, choose an option
higher than Data Engineering Light.
Here are factors that affect Databricks billing:
Azure location where the resource is provisioned.

The virtual machine instance tier and the number of hours that the instances run.
Databricks units (DBU), which is a unit of processing capability per hour, billed on
per-second usage.
This example is based on the current price and is subject to change. The calculation
shown is for example purposes only.
The following table provides an example for you running a Premium cluster for 100
hours in East US 2 with 10 DS13v2 instances.
Item

Example estimate

Cost for 10 DS13v2 instances

100 hours x 10 instances x $0.741/hour = $741.00

DBU cost for Data Analytics
workload

100 hours x 10 instances x 2 DBU per node x $0.55/DBU =
$1,100

Total

$1,841

For more information, see Azure Databricks pricing .
If you can commit to one or three years, opt for reserved instances, which can save 38%
to 59%. For more information, see Reserved VMs.
Turn off the Spark cluster when not in use to prevent unnecessary charges.

Databricks reference architecture
Stream processing with Azure Databricks
Build a Real-time Recommendation API on Azure
Batch scoring of Spark models on Azure Databricks

Azure Stream Analytics
Stream analytics uses streaming units (SUs) to measure the amount of compute,
memory, and throughput required to process data. When you provision a stream
processing job, specify an initial number of SUs. Higher streaming units incur a higher
cost because more resources are used.
Stream processing with low latency requires a significant amount of memory. The SU%
utilization metric tracks this resource. Lower utilization indicates that the workload

requires more compute resources. You can set an alert on the 80% SU Utilization metric
to prevent resource exhaustion.
To evaluate the number of units you need, process an amount of data that's
realistic for your production level workload, observe the SU% Utilization metric, and
adjust the SU value.
You can create stream processing jobs in Azure Stream Analytics and deploy them to
devices running Azure IoT Edge through Azure IoT Hub. The number of devices affects
the overall cost. Billing starts when a job is deployed to devices, regardless of the job
status (running, failed, stopped).
SUs are based on the partition configuration for the inputs and the query that's defined
within the job. For more information, see Calculate the max streaming units for a job
and Understand and adjust Stream Analytics streaming units.
For pricing details, see Azure Stream Analytics pricing

.

Stream Analytics reference architecture
Batch scoring of Python models on Azure
Azure IoT reference architecture

Azure Analysis Services
Big data solutions need to store data that you can use for reporting. Azure Analysis
Services supports the creation of tabular models to meet this need.
Here are the tiers:
Developer is recommended for evaluation, development, and test scenarios.
Basic is recommended for small production environment.
Standard is recommended for mission critical workloads.
Analysis Services uses Query Processing Units (QPUs) to determine the processing
power. A QPU is an abstracted measure of compute and data processing resources that
affect performance. A higher QPU results in higher performance.
Each tier offers one or more instances. The main cost drivers are the QPUs and memory
allocated for the tier instance. Start with a smaller instance, monitor the QPU usage, and
scale up or down by selecting a higher or lower instance within the tier. Also, monitor

usage during off-peak hours. You can pause the server when not in use. No charges
apply when you pause your instance. For more information, see:
The right tier when you need it
Monitor server metrics
Azure Analysis Services pricing

Analysis Services reference architecture
Enterprise business intelligence
Automated enterprise BI

Azure Data Factory V2
Azure Data Factory is a big data orchestrator. The service transfers data to and from
diverse types of data stores. It transforms the data by using other compute services. It
creates workflows that automate data movement and transformation. You're only
charged for consumption. The following factors measure consumption:
Pipeline activities that take the actions on the data. Those actions include copying
the data from various sources, transforming it, and controlling the flow. For more
information, see:
Copy activity in Azure Data Factory and Azure Synapse Analytics
Transform data in Azure Data Factory and Azure Synapse Analytics
Web activity in Azure Data Factory and Azure Synapse Analytics.
Actions measured in data integration units. Each unit tracks CPU, memory, and
network resource allocation. This measurement applies to Azure Integration
Runtime.
You're charged for the total activities in thousands. You're also charged for activities,
such as copying data, lookups, and external activities. Each activity is individually priced.
You're also charged for pipelines with no associated triggers or runs within the month.
All activities are prorated by the minute and rounded up.

Azure Data Factory V2 reference architecture
Automated enterprise BI
Enterprise business intelligence
Build an enterprise-grade conversational bot

