between the cluster admin and their resource provider, while workload security is the
domain of a developer. Azure Kubernetes Service has considerations and
recommendations for both of these roles.
In the design checklist and list of recommendations below, call-outs are made to
indicate whether each choice is applicable to cluster architecture, workload architecture,
or both.

Design checklist
＂ Cluster architecture: Use Managed Identities to avoid managing and rotating
service principles.
＂ Cluster architecture: Use Kubernetes role-based access control (RBAC) with Azure
AD for least privilege access and minimize granting administrator privileges to
protect configuration, and secrets access.
＂ Cluster architecture: Use Microsoft Defender for containers with Azure Sentinel to
detect and quickly respond to threats across your cluster and workloads running on
them.
＂ Cluster architecture: Deploy a private AKS cluster to ensure cluster management
traffic to your API server remains on your private network. Or use the API server
allow list for non-private clusters.
＂ Workload architecture: Use a Web Application Firewall to secure HTTP(S) traffic.
＂ Workload architecture: Ensure your CI/CID pipeline is hardened with containeraware scanning.

Recommendations
Explore the following table of recommendations to optimize your AKS configuration for
security.
Recommendation

Benefit

Cluster architecture: Use
Azure Active Directory

Using Azure AD centralizes the identity management component.
Any change in user account or group status is automatically updated

integration.

in access to the AKS cluster. The developers and application owners
of your Kubernetes cluster need access to different resources.

Cluster architecture:

AKS and Azure AD enables authentication with Azure Container

Authenticate with Azure
Active Directory (Azure
AD) to Azure Container

Registry without the use of imagePullSecrets secrets. Review

Registry.

Authenticate with Azure Container Registry from Azure Kubernetes
Service for more information.

Recommendation

Benefit

Cluster architecture:
Secure network traffic to

By default, network traffic between your node pools and the API
server travels the Microsoft backbone network; by using a private

your API server with
private AKS cluster.

cluster, you can ensure network traffic to your API server remains on
the private network only.

Cluster architecture: For
non-private AKS clusters,

When using public clusters, you can still limit the traffic that can
reach your clusters API server by using the authorized IP range

use API server authorized

feature. Include sources like the public IPs of your deployment build

IP ranges.

agents, operations management, and node pools' egress point (such
as Azure Firewall).

Cluster architecture:
Protect the API server with
Azure Active Directory
RBAC.

Securing access to the Kubernetes API Server is one of the most
important things you can do to secure your cluster. Integrate
Kubernetes role-based access control (RBAC) with Azure AD to
control access to the API server. Disable local accounts to enforce all
cluster access using Azure AD-based identities.

Cluster architecture: Use
Azure network policies or
Calico.

Secure and control network traffic between pods in a cluster.

Cluster architecture:
Secure clusters and pods
with Azure Policy.

Azure Policy can help to apply at-scale enforcement and safeguards
on your clusters in a centralized, consistent manner. It can also
control what functions pods are granted and if anything is running
against company policy.

Cluster architecture:
Secure container access to
resources.

Limit access to actions that containers can perform. Provide the least
number of permissions, and avoid the use of root or privileged
escalation.

Workload architecture:
Use a Web Application
Firewall to secure HTTP(S)

To scan incoming traffic for potential attacks, use a web application
firewall such as Azure Web Application Firewall (WAF) on Azure
Application Gateway or Azure Front Door.

traffic.
Cluster architecture:
Control cluster egress
traffic.

Ensure your cluster's outbound traffic is passing through a network
security point such as Azure Firewall or an HTTP proxy.

Cluster architecture: Use
the open-source Azure AD
Workload Identity and

Protect and rotate secrets, certificates, and connection strings in
Azure Key Vault with strong encryption. Provides an access audit log,
and keeps core secrets out of the deployment pipeline.

Secrets Store CSI Driver
with Azure Key Vault.
Cluster architecture: Use
Microsoft Defender for
Containers.

Monitor and maintain the security of your clusters, containers, and
their applications.

For more suggestions, see Principles of the security pillar.
Azure Advisor helps ensure and improve Azure Kubernetes service. It makes
recommendations on a subset of the items listed in the policy section below, such as
clusters without RBAC configured, missing Microsoft Defender configuration,
unrestricted network access to the API Server. Likewise, it makes workload
recommendations for some of the pod security initiative items. Review the
recommendations.

Policy definitions
Azure Policy offers various built-in policy definitions that apply to both the Azure
resource and AKS like standard policy definitions, and using the Azure Policy add-on for
Kubernetes, also within the cluster. Many of the Azure resource policies come in both
Audit/Deny, but also in a Deploy If Not Exists variant.
There are a numerous number of policies, and key policies related to this pillar are
summarized here. For a more detailed view, see built-in policy definitions for
Kubernetes.

Cluster architecture
Microsoft Defender for Cloud-based policies
Authentication mode and configuration policies (Azure AD, RBAC, disable local
authentication)
API Server network access policies, including private cluster

Cluster and workload architecture
Kubernetes cluster pod security initiatives Linux-based workloads
Include pod and container capability policies such as AppArmor, sysctl, security
caps, SELinux, seccomp, privileged containers, automount cluster API credentials
Mount, volume drivers, and filesystem policies
Pod/Container networking policies, such as host network, port, allowed external
IPs, HTTPs, and internal load balancers
Azure Kubernetes Service deployments often also use Azure Container Registry for Helm
charts and container images. Azure Container Registry also supports a wide variety of
Azure policies that spans network restrictions, access control, and Microsoft Defender
for Cloud, which complements a secure AKS architecture.

In addition to the built-in policies, custom policies can be created for both the AKS
resource and for the Azure Policy add-on for Kubernetes. This allows you to add
additional security constraints you'd like to enforce in your cluster and workload
architecture.
For more suggestions, see AKS security concepts and evaluate our security hardening
recommendations based on the CIS Kubernetes benchmark.

Cost optimization
Cost optimization is about understanding your different configuration options and
recommended best practices to reduce unnecessary expenses and improve operational
efficiencies. Before you follow the guidance in this article, we recommend you review
the following resources:
Cost optimization design principles.
How pricing and cost management work in Azure Kubernetes Service (AKS)
compared to Amazon Elastic Kubernetes Service (Amazon EKS).
If you are running AKS on-premises or at the edge, Azure Hybrid Benefit can also
be used to further reduce costs when running containerized applications in those
scenarios.
When discussing cost optimization with Azure Kubernetes Service, it's important to
distinguish between cost of cluster resources and cost of workload resources. Cluster
resources are a shared responsibility between the cluster admin and their resource
provider, while workload resources are the domain of a developer. Azure Kubernetes
Service has considerations and recommendations for both of these roles.
In the design checklist and list of recommendations, call-outs are made to indicate
whether each choice is applicable to cluster architecture, workload architecture, or both.
For cluster cost optimization, go to the Azure pricing calculator

and select Azure

Kubernetes Service from the available products. You can test different configuration
and payment plans in the calculator.

Design checklist
＂ Cluster architecture: Use appropriate VM SKU per node pool and reserved
instances where long-term capacity is expected.
＂ Cluster and workload architectures: Use appropriate managed disk tier and size.
＂ Cluster architecture: Review performance metrics, starting with CPU, memory,
storage, and network, to identify cost optimization opportunities by cluster, nodes,

and namespace.
＂ Cluster architecture: Use cluster autoscaler to scale in when workloads are less
active.

Recommendations
Explore the following table of recommendations to optimize your AKS configuration for
cost.
Recommendation

Benefit

Cluster and

Matching your selection to your workload demands ensures you don't

workload
architectures: Align
SKU selection and
managed disk size
with workload
requirements.

pay for unneeded resources.

Cluster architecture:
Select the right
virtual machine
instance type.

Selecting the right virtual machine instance type is critical as it directly
impacts the cost of running applications on AKS. Choosing a highperformance instance without proper utilization can lead to wasteful
spending, while choosing a powerful instance can lead to performance
issues and increased downtime. To determine the right virtual machine
instance type, consider workload characteristics, resource requirements,
and availability needs.

Cluster architecture:
Select virtual
machines based on
the Arm architecture.

AKS supports creating ARM64 Ubuntu agent nodes, as well as a of mix
Intel and ARM architecture nodes within a cluster that can bring better
performance at a lower cost.

Cluster architecture:
Select the

Due to many factors, cost of resources varies per region in Azure. Evaluate
the cost, latency, and compliance requirements to ensure you are running

appropriate region.

your workload cost-effectively and it doesn't affect your end-users or
create extra networking charges.

Workload
architecture:
Maintain small and
optimized images.

Streamlining your images helps reduce costs since new nodes need to
download these images. Build images in a way that allows the container
start as soon as possible to help avoid user request failures or timeouts
while the application is starting up, potentially leading to
overprovisioning.

Recommendation

Benefit

Cluster architecture:
Enable cluster
autoscaler to
automatically reduce
the number of agent

Automatically scale down the number of nodes in your AKS cluster lets
you run an efficient cluster when demand is low, scale up when demand
returns.

nodes in response to
excess resource
capacity.
Workload
architecture: Use the
Horizontal Pod

Adjust the number of pods in a deployment depending on CPU utilization
or other select metrics, which support cluster scale-in operations.

Autoscaler.
Workload
architecture: Use
Vertical Pod
Autoscaler (preview).

Rightsize your pods and dynamically set requests and limits based on
historic usage.

Workload
architecture: Use

Scale based on the number of events being processed. Choose from a
rich catalogue of 50+ KEDA scalers.

Kubernetes Event
Driven Autoscaling
(KEDA).
Cluster and
workload
architectures: Adopt
a cloud financial

The foundation of enabling cost optimization is the spread of a cost
saving cluster. A financial operations approach (FinOps) is often used to
help organizations reduce cloud costs. It is a practice involving
collaboration between finance, operations, and engineering teams to

discipline and
cultural practice to
drive ownership of
cloud usage.

drive alignment on cost saving goals and bring transparency to cloud
costs.

Cluster architecture:
Sign up for Azure

If you properly planned for capacity, your workload is predictable and
exists for an extended period of time, sign up for an Azure Reservation or

Reservations or
Azure Savings Plan.

a savings plan to further reduce your resource costs.

Cluster architecture:
Configure
monitoring of cluster
with Container

Container insights help provides actionable insights into your clusters idle
and unallocated resources. Container insights also supports collecting
Prometheus metrics and integrates with Azure Managed Grafana to get a
holistic view of your application and infrastructure.

insights.

For more suggestions, see Principles of the cost optimization pillar.

Policy definitions
While there are no built-in policies that are related to cost optimization, custom policies
can be created for both the AKS resource and for the Azure Policy add-on for
Kubernetes. This allows you to add additional cost optimization constraints you'd like to
enforce in your cluster and workload architecture.

Cloud efficiency
Making workloads more sustainable and cloud efficient, requires combining efforts
around cost optimization, reducing carbon emissions, and optimizing energy
consumption. Optimizing the application's cost is the initial step in making workloads
more sustainable.
Learn how to build sustainable and efficient AKS workloads, in Sustainable software
engineering principles in Azure Kubernetes Service (AKS).

Operational excellence
Monitoring and diagnostics are crucial. Not only can you measure performance
statistics, but also use metrics troubleshoot and remediate issues quickly. We
recommend you review the Operational excellence design principles and the Day-2
operations guide.
When discussing operational excellence with Azure Kubernetes Service, it's important to
distinguish between cluster operational excellence and workload operational excellence.
Cluster operations are a shared responsibility between the cluster admin and their
resource provider, while workload operations are the domain of a developer. Azure
Kubernetes Service has considerations and recommendations for both of these roles.
In the design checklist and list of recommendations below, call-outs are made to
indicate whether each choice is applicable to cluster architecture, workload architecture,
or both.

Design checklist
＂ Cluster architecture: Use a template-based deployment using Bicep, Terraform, or
others. Make sure that all deployments are repeatable, traceable, and stored in a
source code repo.
＂ Cluster architecture: Build an automated process to ensure your clusters are
bootstrapped with the necessary cluster-wide configurations and deployments. This

is often performed using GitOps.
＂ Workload architecture: Use a repeatable and automated deployment processes for
your workload within your software development lifecycle.
＂ Cluster architecture: Enable diagnostics settings to ensure control plane or core API
server interactions are logged.
＂ Cluster and workload architectures: Enable Container insights to collect metrics,
logs, and diagnostics to monitor the availability and performance of the cluster and
workloads running on it.
＂ Workload architecture: The workload should be designed to emit telemetry that
can be collected, which should also include liveliness and readiness statuses.
＂ Cluster and workload architectures: Use chaos engineering practices that target
Kubernetes to identify application or platform reliability issues.
＂ Workload architecture: Optimize your workload to operate and deploy efficiently in
a container.
＂ Cluster and workload architectures: Enforce cluster and workload governance
using Azure Policy.

Recommendations
Explore the following table of recommendations to optimize your AKS configuration for
operations.
Recommendation

Benefit

Cluster and workload architectures:

To build and run applications successfully in AKS, there

Review AKS best practices
documentation.

are key considerations to understand and implement.
These areas include multi-tenancy and scheduler
features, cluster, and pod security, or business
continuity and disaster recovery.

Cluster and workload architectures:

Azure Chaos Studio can help simulate faults and trigger

Review Azure Chaos Studio.

disaster recovery situations.

Cluster and workload architectures:

Container insights help monitor the performance of

Configure monitoring of cluster with
Container insights.

containers by collecting memory and processor metrics
from controllers, nodes, and containers that are
available in Kubernetes through the Metrics API and
container logs.

Workload architecture: Monitor

Configure Application Insights for code-based

application performance with Azure
Monitor.

monitoring of applications running in an AKS cluster.

Recommendation

Benefit

Workload architecture: Configure

Container insights, which are part of Azure Monitor,

scraping of Prometheus metrics with
Container insights.

provide a seamless onboarding experience to collect
Prometheus metrics. Reference Configure scraping of
Prometheus metrics for more information.

Cluster architecture: Adopt a

Internet facing workloads should leverage Azure Front

multiregion strategy by deploying AKS

Door or Azure Traffic Manager to route traffic globally

clusters deployed across different
Azure regions to maximize availability

across AKS clusters.

and provide business continuity.
Cluster architecture: Operationalize

Azure Policy can help to apply at-scale enforcement

clusters and pods configuration
standards with Azure Policy.

and safeguards on your clusters in a centralized,
consistent manner. It can also control what functions
pods are granted and if anything is running against
company policy.

Workload architecture: Use platform

Kubernetes and ingress controllers support many

capabilities in your release engineering
process.

advanced deployment patterns for inclusion in your
release engineering process. Consider patterns like
blue-greem deployments or canary releases.

Cluster and workload architectures:

Automate your mission-critical design areas, including

For mission-critical workloads, use

deployment and testing.

stamp-level blue/green deployments.

For more suggestions, see Principles of the operational excellence pillar.
Azure Advisor also makes recommendations on a subset of the items listed in the policy
section below, such unsupported AKS versions and unconfigured diagnostic settings.
Likewise, it makes workload recommendations around the use of the default
namespace.

Policy definitions
Azure Policy offers various built-in policy definitions that apply to both the Azure
resource and AKS like standard policy definitions, and using the Azure Policy add-on for
Kubernetes, also within the cluster. Many of the Azure resource policies come in both
Audit/Deny, but also in a Deploy If Not Exists variant.
There are a numerous number of policies, and key policies related to this pillar are
summarized here. For a more detailed view, see built-in policy definitions for
Kubernetes.

Cluster architecture
Azure Policy add-on for Kubernetes
GitOps configuration policies
Diagnostics settings policies
AKS version restrictions
Prevent command invoke

Cluster and workload architecture
Namespace deployment restrictions
In addition to the built-in policies, custom policies can be created for both the AKS
resource and for the Azure Policy add-on for Kubernetes. This allows you to add
additional security constraints you'd like to enforce in your cluster and workload
architecture.

Performance efficiency
Performance efficiency is the ability of your workload to scale to meet the demands
placed on it by users in an efficient manner. We recommend you review the
Performance efficiency principles.
When discussing performance with Azure Kubernetes Service, it's important to
distinguish between cluster performance and workload performance. Cluster
performance is a shared responsibility between the cluster admin and their resource
provider, while workload performance is the domain of a developer. Azure Kubernetes
Service has considerations and recommendations for both of these roles.
In the design checklist and list of recommendations below, call-outs are made to
indicate whether each choice is applicable to cluster architecture, workload architecture,
or both.

Design checklist
As you make design choices for Azure Kubernetes Service, review the Performance
efficiency principles.
＂ Cluster and workload architectures: Perform and iterate on a detailed capacity plan
exercise that includes SKU, autoscale settings, IP addressing, and failover
considerations.

＂ Cluster architecture: Enable cluster autoscaler to automatically adjust the number
of agent nodes in response workload demands.
＂ Cluster architecture: Use the Horizontal pod autoscaler to adjust the number of
pods in a deployment depending on CPU utilization or other select metrics.
＂ Cluster and workload architectures: Perform ongoing load testing activities that
exercise both the pod and cluster autoscaler.
＂ Cluster and workload architectures: Separate workloads into different node pools
allowing independent scalling.

Recommendations
Explore the following table of recommendations to optimize your Azure Kubernetes
Service configuration for performance.
Recommendation

Benefit

Cluster and workload

After formalizing your capacity plan, it should be frequently

architectures: Develop a
detailed capacity plan and

updated by continuously observing the resource utilization of
the cluster.

continually review and revise.
Cluster architecture: Enable

The ability to automatically scale up or down the number of

cluster autoscaler to
automatically adjust the

nodes in your AKS cluster lets you run an efficient, costeffective cluster.

number of agent nodes in
response to resource
constraints.
Cluster and workload
architectures: Separate

Unlike System node pools that always require running nodes,
user node pools allow you to scale up or down.

workloads into different node
pools and consider scaling user
node pools.
Workload architecture: Use
AKS advanced scheduler

Helps control balancing of resources for workloads that require
them.

features.
Workload architecture: Use

Not all scale decisions can be derived from CPU or memory

meaningful workload scaling

metrics. Often scale considerations will come from more

metrics.

complex or even external data points. Use KEDA to build a
meaningful auto scale ruleset based on signals that are specific
to your workload.

For more suggestions, see Principles of the performance efficiency pillar.

Policy definitions
Azure Policy offers various built-in policy definitions that apply to both the Azure
resource and AKS like standard policy definitions, and using the Azure Policy add-on for
Kubernetes, also within the cluster. Many of the Azure resource policies come in both
Audit/Deny, but also in a Deploy If Not Exists variant.
There are a numerous number of policies, and key policies related to this pillar are
summarized here. For a more detailed view, see built-in policy definitions for
Kubernetes.

Cluster and workload architecture
CPU and memory resource limits
In addition to the built-in policies, custom policies can be created for both the AKS
resource and for the Azure Policy add-on for Kubernetes. This allows you to add
additional security constraints you'd like to enforce in your cluster and workload
architecture.

Additional resources
Azure Architecture Center guidance
AKS baseline architecture
Advanced AKS microservices architecture
AKS cluster for a PCI-DSS workload
AKS baseline for multiregion clusters

Cloud Adoption Framework guidance
AKS Landing Zone Accelerator

Next steps
Deploy an Azure Kubernetes Service (AKS) cluster using the Azure CLI Quickstart:
Deploy an Azure Kubernetes Service (AKS) cluster using the Azure CLI

Azure Functions and security
Article • 11/30/2022

Azure Functions is a cloud service available on-demand that provides all the continually
updated infrastructure and resources needed to run your applications. Functions allow
you to write less code, maintain less infrastructure, and save on costs. Instead of
worrying about deploying and maintaining servers, the cloud infrastructure provides all
the up-to-date resources needed to keep your applications securely running.
For more information related to network security, reference Securing Azure Functions.
The following sections include a design consideration checklist and recommendations
specific to Azure Functions, and security.

Design consideration checklist
Have you designed your workload and configured Azure Functions with security in
mind?
＂ Evaluate if Azure Functions requires HTTP trigger.
＂ Treat Azure Functions code just like any other code.
＂ Use guidance available on Securing Azure Functions.
＂ Consider using Azure Functions Proxy to act as a facade.

Design consideration recommendations
The following table reflects design consideration recommendations and descriptions
related to Azure Functions:
Azure Functions
Design
Recommendations

Description

Azure Functions
Design

Description

Recommendations
Evaluate if Azure

Azure Functions supports multiple specific triggers and bindings. These

Functions requires
HTTP trigger.

include Azure Blob storage, Azure Cosmos DB, Azure Service Bus, and many
more. If HTTP trigger is needed, then consider protecting that HTTP
endpoint like any other web application. Common protection measures
include keeping HTTP endpoint internal to specific Azure virtual networks
by using Private endpoint connections or service endpoints. Consider using
guidance available on Azure Functions networking options for more
information. If Functions HTTP endpoint will be exposed to internet, then
it's recommended to secure the endpoint behind a web application firewall
(WAF).

Treat Azure

Subject Azure Functions code to code scanning tools that are integrated

Functions code just

with CI/CD pipeline.

like any other code.
Use guidance

This guidance addresses key security concerns such as operations,

available on
Securing Azure

deployment, and network security.

Functions.
Consider using

Functions Proxy can inspect and modify incoming requests and responses.

Azure Functions
Proxy to act as a
facade.

Next step
Azure Service Fabric and reliability

Azure Well-Architected Framework
review - Virtual Machines
Article • 08/02/2023

Virtual Machines is an on-demand, scalable computing resource that gives you the
flexibility of virtualization without having to buy and maintain physical hardware to run
it.
In this article, you learn architectural best practices for Azure Virtual Machines. The
guidance is based on the five pillars of architectural excellence:
Reliability
Security
Cost optimization
Operational excellence
Performance efficiency

Prerequisites
Understanding the Well-Architected Framework pillars can help produce a high
quality, stable, and efficient cloud architecture. We recommend that you review
your workload using the Microsoft Azure Well-Architected Review assessment.
Use a reference architecture to review the considerations based on the guidance
provided in this article. We recommend, you start with Run a Linux VM on Azure.

Reliability
As you make design choices for virtual machines, review the design principles for adding
reliability to the architecture.

Design checklist
＂ Review the SLAs for virtual machines .
＂ VMs should be deployed in a scale set using the Flexible orchestration mode.
＂ Deployed VMs across Availability Zones.
＂ Package and publish application artifacts with VM Applications and Azure Compute
Gallery.
＂ Install applications on Ephemeral OS disks.

＂ Use Maintenance Configurations to control and manage updates for VMs.

Recommendations
Explore the following table of recommendations to optimize your Virtual Machine
configuration for service reliability:
Recommendation

Benefit

Review SLAs for virtual
machines.

When defining test availability and recovery targets, make sure you
have a good understanding of the SLAs offered for VMs.

Deploy using Flexible
scale sets.

Even single instance VMs should be deployed into a scale set using the
Flexible orchestration mode to future-proof your application for scaling
and availability. Flexible orchestration offers high availability guarantees
(up to 1000 VMs) by spreading VMs across fault domains in a region or
within an Availability Zone.

Deploy across

Azure availability zones are physically separate locations within each

availability zones

Azure region that are tolerant to local failures.

Install applications on

Separating data from the OS disk makes it easier to recover from

Ephemeral OS disks.

failures, migrate workloads, and can improve performance.

Use Maintenance

Control and manage updates for both Windows and Linux VMs through

Configuration

a centralized view for OS patching.

 Tip
For more details on Reliability guidance for VMs, see Reliability in Azure Virtual
Machines - Azure Virtual Machines.
Azure Advisor helps you ensure and improve the continuity of your business-critical
applications. Review the Azure Advisor recommendations.

Security
This article provides an overview of the core Azure security features that can be used
with virtual machines.
As you make design choices for virtual machines, review the security principles and
Security best practices for adding security to the architecture.

Design checklist

As you make design choices for your virtual machine deployment, review the design
principles for security.
＂ Review the Linux security baseline.
＂ Review the Windows security baseline.
＂ Manage authentication and access control.
＂ Protect against malicious actor scenarios.
＂ Plan and implement managed updates.
＂ Classify and configure encryption.

Recommendations
Explore the following table of recommendations to optimize your virtual machine
configuration for security.
Recommendation

Benefit

Consider using Azure

Authentication and access control using Azure Bastion provides secure

Bastion

and seamless RDP/SSH connectivity to your virtual machines directly
from the Azure portal over TLS

Protect against
malware

Install antimalware protection to help identify and remove viruses.

Manage updates

Use a solution like Azure Automation to manage operating system
updates and maintain security compliance with critical updates.

Monitor for security

To monitor the security posture of your Windows and Linux VMs, use
Microsoft Defender for Cloud.

Use encryption

Use Azure Disk Encryption to protect your data.

For more suggestions, see Principles of the security pillar.
Azure Advisor helps you ensure and improve security. Review the security
recommendations.

Policy definitions
Deploy default Microsoft IaaSAntimalware extension for Windows Server - This

policy deploys a Microsoft IaaSAntimalware extension with a default configuration
when a VM is not configured with the antimalware extension.
Microsoft IaaSAntimalware extension should be deployed on Windows servers -

This policy audits any Windows server VM without Microsoft IaaSAntimalware
extension deployed.

Only approved VM extensions should be installed - This policy governs the virtual

machine extensions that are not approved.
Managed disks should be double encrypted with both platform-managed and
customer-managed keys - High security sensitive customers who are concerned of

the risk associated with any particular encryption algorithm, implementation, or
key being compromised can opt for additional layer of encryption using a different
encryption algorithm/mode at the infrastructure layer using platform managed
encryption keys. The disk encryption sets are required to use double encryption.
Learn more at https://aka.ms/disks-doubleEncryption

.

Managed disks should use a specific set of disk encryption sets for the
customer-managed key encryption - Requiring a specific set of disk encryption sets

to be used with managed disks give you control over the keys used for encryption
at rest. You are able to select the allowed encrypted sets and all others are rejected
when attached to a disk. Learn more at https://aka.ms/disks-cmk

.

Microsoft Antimalware for Azure should be configured to automatically update
protection signatures - This policy audits any Windows virtual machine not

configured with automatic update of Microsoft Antimalware protection signatures.
OS and data disks should be encrypted with a customer-managed key - Use

customer-managed keys to manage the encryption at rest of the contents of your
managed disks. By default, the data is encrypted at rest with platform-managed
keys, but customer-managed keys are commonly required to meet regulatory
compliance standards. Customer-managed keys enable the data to be encrypted
with an Azure Key Vault key created and owned by you. You have full control and
responsibility for the key lifecycle, including rotation and management. Learn more
at https://aka.ms/disks-cmk

.

Virtual machines and virtual machine scale sets should have encryption at host
enabled - Use encryption at host to get end-to-end encryption for your virtual

machine and virtual machine scale set data. Encryption at host enables encryption
at rest for your temporary disk and OS/data disk caches. Temporary and ephemeral
OS disks are encrypted with platform-managed keys when encryption at host is
enabled. OS/data disk caches are encrypted at rest with either customer-managed
or platform-managed key, depending on the encryption type selected on the disk.
Learn more at https://aka.ms/vm-hbe

.

Require automatic OS image patching on Virtual Machine Scale Sets - This policy

enforces enabling automatic OS image patching on Virtual Machine Scale Sets to
always keep virtual Machines secure by safely applying latest security patches
every month.
All built-in policy definitions related to Azure Virtual Machines are listed in Azure Policy
built-in definitions for Azure Virtual Machines.

Cost optimization
To optimize costs, review the design principles.
To estimate costs related to virtual machines, use these tools.
Identify the best VM for your workloads with the virtual machines selector. For
more information, see Linux
Use this pricing calculator

and Windows

pricing.

to configure and estimate the costs of your Azure

VMs.

Design considerations
＂ Shut down VM instances which aren't in use.
＂ Use Spot VMs when appropriate.
＂ Choose the right VM size for your workload.
＂ Use Azure Bastion to secure operational access to the workload VMs.
＂ Use a Premium SSD v2 disk and, based on your workload patterns,
programmatically adjust its performance to account for either higher or lower
demand.
＂ For other disk types, size your disks to achieve your desired performance without
the need for over-provisioning. Account for fluctuating workload patterns, and
minimizing unused provisioned capacity.
＂ Use Zone to Zone disaster recovery for virtual machines.
＂ Prepay for reserved instances or an Azure savings plan for compute

for significant

savings.
＂ Use hybrid benefit licensing.
＂ Deploy Azure Monitor Agent (AMA) to collect monitoring data from the guest
operating system.

Recommendations
Explore the following table of recommendations to optimize your Virtual Machine
configuration for service cost:
Recommendation

Benefit

Stop VMs during offhours

Configuring start and stop times will shut down instances that aren't
in use. The feature is suitable as a low-cost automation option.

Use Spot VMs when
appropriate.

Spot VMs are ideal for workloads that can be interrupted, such as
highly parallel batch processing jobs. These VMs take advantage of
the surplus capacity in Azure at a lower cost. They're also well suited

Recommendation

Benefit
for experimenting, developing, and testing large-scale solutions.
Check out our Azure Virtual Machine Spot Eviction guide to learn
how to create a reliable interruptible workload in Azure.

Right-size your VMs

Identify the best VM for your workloads with the virtual machines
selector. See Windows and Linux pricing.

Configure Azure Bastion

Azure Bastion is charged on a fix per-hour basis, and charges for

for operational access

outbound data transfers.

Utilize Premium SSD v2
effectively

Premium SSD v2 allows you to granularly adjust your performance
independent of the disk's size. Combining this adjustment ability with
an understanding workload patterns, offers an effective cost
optimization strategy for IaaS infrastructure, enabling high
performance without excessive over-provisioning and minimizing the
cost of unused capacity.

Optimize with managed
disks

Determine your performance needs in combination with your storage
capacity needs, accounting for fluctuating workload patterns.
Knowing your needs allows you to determine what disk type and disk
size you need. Some higher performance disk types offer extra cost
optimization features and strategies.

Prepay for added cost
savings

Purchasing reserved instances is a way to reduce Azure costs for
workloads with stable usage. Make sure you manage usage. If usage
is too low, then you're paying for resources that aren't used. Keep
reserved instances simple and keep management overhead low to
prevent increasing cost.

Use existing licensing

Hybrid benefit licensing is available for both Linux and Windows

through the hybrid
benefit licensing program
Deploy AMA

AMA supports Data Collection Rules (DCR) which allow filtering rules
and data transformation to reduce overall data volume being
uploaded, which lowers ingestion and storage costs.

Azure Advisor helps you ensure and improve cost optimization. Review the cost
recommendations.

Policy definitions
Consider setting an Allowed virtual machine SKU policy to limit the sizes that can
be used.
All built-in policy definitions related to Azure Virtual Machines are listed in Azure Policy
built-in definitions for Azure Virtual Machines.

Operational excellence
To ensure operational excellence, review the design principles.

Design checklist
＂ Monitor and measure health.
＂ Setup Azure Monitor alerts for detecting configuration changes in your
environment. > - Use the Application Insights extension to proactively understand
how an application is performing and reactively review application execution data
to determine the cause of an incident.
＂ Automate tasks like provisioning and updating.
＂ Build a robust testing environment.
＂ Right size your VMs.
＂ Manage your quota.
＂ Optimize with managed disks.

Recommendations
Recommendation

Benefit

Monitor and measure
health

In a production environment, it's important to monitor the health, and
performance of your VMs.

Setup Azure Monitor
alert rules

Determine important conditions in your monitoring data to identify and
address issues found in your system before customers are impacted.

Automate tasks

Building automation reduces deviations from your plans and reduces that
time it takes to manage your workload.

Build a robust testing
environment

Ideally, an organization will have multiple environments in which to test
deployments. These test environments should be similar enough to
production that deployment and run time issues are detected before
deployment to production.

Right-size your VMs

Choose the right VM family for your workload.

Manage your quota

Plan what level of quota will be required and review that level regularly as
the workload evolves and grows and request changes early

Optimize with
managed disks

Determine your performance needs in combination with your storage
capacity needs, accounting for fluctuating workload patterns. Knowing
your needs allows you to determine what disk type and disk size you
need. Some higher performance disk types offer extra cost optimization
features and strategies.

For more suggestions, see Principles of the operational excellence pillar.
Azure Advisor helps you ensure and improve the continuity of your business-critical
applications. Review the recommendations.

Policy definitions
Consider setting an Allowed virtual machine SKU policy
All built-in policy definitions related to Azure Virtual Machines are listed in Azure Policy
built-in definitions for Azure Virtual Machines.

Performance efficiency
Performance efficiency is matching the resources that are available to an application
with the demand that it's receiving. Performance efficiency includes scaling resources,
identifying and optimizing potential bottlenecks, and optimizing your application code
for peak performance.
As you make design choices for your virtual machine deployment, review Microsoft
Azure Well-Architected Framework - Performance efficiency for performance and
efficiency.

Design checklist
＂ Reduce latency by deploying VMs closer together in proximity placement groups.
＂ Convert disks from standard HDD to premium SSD.
＂ Utilize Premium SSD v2 effectively.
＂ Optimize with managed disks.
＂ Consider locally attached NVMe or similar devices for high-performance use cases.
＂ Enable Accelerated Networking to improve network performance and latency
＂ Autoscale your Flexible scale sets.

Recommendations
Explore the following table of recommendations to optimize your virtual machine
deployment configuration for performance and efficiency.
Recommendation

Benefit

Reduce latency

Consider deploying VMs in Creating and using proximity placement
groups using PowerShell.

Recommendation

Benefit

Convert disks from
standard HDD to
premium SSD

Azure premium SSDs deliver high-performance and low-latency disk
support for virtual machines (VMs) with input/output (IO)-intensive
workloads.

Utilize Premium SSD v2

Premium SSD v2 allows you to granularly adjust your performance

effectively

independent of the disk's size. Combining this adjustment ability with
an understanding workload patterns, offers an effective cost
optimization strategy for IaaS infrastructure, enabling high
performance without excessive over-provisioning and minimizing the
cost of unused capacity.

Optimize with managed

Determine your performance needs in combination with your storage

disks

capacity needs, accounting for fluctuating workload patterns. Knowing
your needs allows you to determine what disk type and disk size you
need.

Use locally attached
NVMe devices

When available on VM SKUs, locally attached NVMe or similar devices
can offer high performance, especially for use cases requiring high
IOPS and low latency.

Consider accelerated

Accelerated networking enables single root I/O virtualization (SR-IOV)

networking

to a VM, greatly improving its networking performance.

Use autoscaling

Automatically increase or decrease the number of VM instances that
run your application with autoscaling.

For more suggestions, see Principles of the performance efficiency pillar.
Azure Advisor helps you ensure and improve performance. Review the
recommendations

.

Azure Advisor recommendations
Azure Advisor is a personalized cloud consultant that helps you follow best practices to
optimize your Azure deployments. Here are some recommendations that can help you
improve the reliability, security, cost effectiveness, performance, and operational
excellence of your Virtual Machines.
Reliability
Cost Optimization
Performance
Operational excellence

Additional resources

Here are other resources to help you query for unhealthy instances.

Cost analysis
Planned versus actual spending can be managed through Azure Cost Management +
Billing. There are several options for grouping resources by billing unit.

Log Analytics
Collect logs and metrics from the Azure resources and Application Insights with Azure
Log Analytics to gain insights into the performance and health of your VMs. You can
also use Log Analytics to query and analyze the data collected by Azure Monitor Logs.

Next steps
Use the recommendations as you provision virtual machines for your solution.
Review the Learn module: Introduction to Azure virtual machines.
Review the Virtual Machine recommendations provided by Azure Advisor.
Review the built-in definitions provided by Azure Policy that apply to Virtual
Machines. All built-in policy definitions related to Azure Virtual Machines are listed
in Azure Policy built-in definitions for Azure Virtual Machines.

Azure Cache for Redis and reliability
Article • 11/30/2022

Azure Cache for Redis provides an in-memory data store based on the Redis (Remote
Dictionary Server)

software. It's a secure data cache and messaging broker that

provides high throughput and low-latency access to data for applications.
Key concepts and best practices that support reliability include:
High availability
Failover and patching
Connection resilience
The following sections include design considerations, a configuration checklist, and
recommended configuration options specific to Azure Cache for Redis.

Design considerations
The Azure Cache for Redis Service Level Agreements (SLA)

covers only Standard and

Premium tier caches. Basic tier isn't covered.
Redis is an in-memory cache for key value pairs and has High Availability (HA), by
default, except for Basic tier. There are three tiers for Azure Cache for Redis:
Basic: Not recommended for production workloads. Basic tier is ideal for:
Single node
Multiple sizes
Development
Test
Non-critical workloads
Standard: A replicated cache in a two-node primary and secondary configuration
managed by Microsoft, with a high availability SLA.
Premium: Includes all standard-tier features and includes the following other
features:
Faster hardware and performance compared to Basic or Standard tier.
Larger cache size, up to 120GB .
Data persistence , which includes Redis Database File (RDB) and Append Only
File (AOF).
VNET support.
Clustering

Geo-Replication: A secondary cache is in another region and replicates data
from the primary for disaster recovery. To failover to the secondary, the caches
need to be unlinked manually and then the secondary is available for writes. The
application writing to Redis needs to be updated with the secondary's cache
connection string.
Availability Zones: Deploy the cache and replicas across availability zones.
７ Note
By default, each deployment will have one replica per shard. Persistence,
clustering, and geo-replication are all disabled at this time with
deployments that have more than one replica. Your nodes will be
distributed evenly across all zones. You should have a replica count >=
number of zones.
Import and export.
Microsoft guarantees at least 99.9% of the time that customers will have connectivity
between the Cache Endpoints and Microsoft's Internet gateway.

Checklist
Have you configured Azure Cache for Redis with resiliency in mind?
＂ Schedule updates.
＂ Monitor the cache and set alerts.
＂ Deploy the cache within a VNET.
＂ Evaluate a partitioning strategy within Redis cache.
＂ Configure Data Persistence to save a copy of the cache to Azure Storage or use
Geo-Replication, depending on the business requirement.
＂ Implement retry policies in the context of your Azure Redis Cache.
＂ Use one static or singleton implementation of the connection multiplexer to Redis
and follow the best practices guide.
＂ Review How to administer Azure Cache for Redis.

Configuration recommendations
Explore the following table of recommendations to optimize your Azure Cache for Redis
configuration for service reliability:
Recommendation

Description

Recommendation

Description

Schedule updates.

Schedule the days and times that Redis Server updates will be applied to the
cache, which doesn't include Azure updates, or updates to the VM operating
system.

Monitor the cache
and set alerts.

Set alerts for exceptions, high CPU, high memory usage, server load, and
evicted keys for insights about when to scale the cache. If the cache needs to
be scaled, understanding when to scale is important because it will increase
CPU during the scaling event to migrate data.

Deploy the cache

Gives the customer more control over the traffic that can connect to the

within a VNET.

cache. Make sure that the subnet has sufficient address space available to
deploy the cache nodes and shards (cluster).

Evaluate a
partitioning

Partitioning a Redis data store involves splitting the data across instances of
the Redis server. Each instance makes up a single partition. Azure Redis

strategy within

Cache abstracts the Redis services behind a facade and doesn't expose them

Redis cache.

directly. The simplest way to implement partitioning is to create multiple
Azure Redis Cache instances and spread the data across them. You can
associate each data item with an identifier (a partition key) that specifies
which cache stores the data item. The client application logic can then use
this identifier to route requests to the appropriate partition. This scheme is
simple, but if the partitioning scheme changes (for example, if extra Azure
Redis Cache instances are created), client applications may need to be
reconfigured.

Configure Data

Data Persistence: if the master and replica reboot, the data will be loaded

Persistence to
save a copy of the
cache to Azure

automatically from the storage account. Geo-Replication: The secondary
cache needs to be unlinked from the primary. The secondary will now
become the primary and can receive writes.

Storage or use
Geo-Replication,
depending on the
business
requirement.
Implement retry

Most Azure services and client SDKs include a retry mechanism. These

policies in the
context of your
Azure Redis

mechanisms differ because each service has different characteristics and
requirements. Each retry mechanism is tuned to a specific service.

Cache.
Review How to
administer Azure

Understand how data loss can occur with cache reboots and how to test the
application for resiliency.

Cache for Redis.

Source artifacts

To identify Redis instances that aren't on the Premium tier, use the following query:
SQL

Resources
| where type == 'microsoft.cache/redis'
| where properties.sku.name != 'Premium'

Next step
Azure Cache for Redis and operational excellence

Azure Cache for Redis and operational
excellence
Article • 11/30/2022

Azure Cache for Redis provides an in-memory data store based on the Redis (Remote
Dictionary Server)

software. It's a secure data cache and messaging broker that

provides high throughput and low-latency access to data for applications.
Best practices that support operational excellence include:
Server load management
Memory management
Performance testing
The following sections include design considerations, a configuration checklist, and
recommended configuration options specific to Azure Cache for Redis.

Design considerations
The Azure Cache for Redis Service Level Agreements (SLA)

covers only Standard and

Premium tier caches. Basic tier isn't covered.
Redis is an in-memory cache for key value pairs and has High Availability (HA), by
default, except for Basic tier. There are three tiers for Azure Cache for Redis:
Basic: Not recommended for production workloads. Basic tier is ideal for:
Single node
Multiple sizes
Development
Test
Non-critical workloads
Standard: A replicated cache in a two-node primary and secondary configuration
managed by Microsoft, with a high availability SLA.
Premium: Includes all standard-tier features and includes the following other
features:
Faster hardware and performance compared to Basic or Standard tier.
Larger cache size, up to 120GB .
Data persistence , which includes Redis Database File (RDB) and Append Only
File (AOF).

VNET support.
Clustering
Geo-Replication: A secondary cache is in another region and replicates data
from the primary for disaster recovery. To failover to the secondary, the caches
need to be unlinked manually and then the secondary is available for writes. The
application writing to Redis will need to be updated with the secondary's cache
connection string.
Availability Zones: Deploy the cache and replicas across availability zones.
７ Note
By default, each deployment will have one replica per shard. Persistence,
clustering, and geo-replication are all disabled at this time with
deployments that have more than one replica. Your nodes will be
distributed evenly across all zones. You should have a replica count >=
number of zones.
Import and export.
Microsoft guarantees at least 99.9% of the time that customers will have connectivity
between the Cache Endpoints and Microsoft's Internet gateway.

Checklist
Have you configured Azure Cache for Redis with operational excellence in mind?
＂ Schedule updates.
＂ Monitor the cache and set alerts.
＂ Deploy the cache within a VNET.
＂ Use the correct caching type (local, in role, managed, redis) within your solution.
＂ Configure Data Persistence to save a copy of the cache to Azure Storage or use
Geo-Replication, depending on the business requirement.
＂ Use one static or singleton implementation of the connection multiplexer to Redis
and follow the best practices guide.
＂ Review How to administer Azure Cache for Redis.

Configuration recommendations
Explore the following table of recommendations to optimize your Azure Cache for Redis
configuration for operational excellence:

Recommendation

Description

Schedule updates.

Schedule the days and times that Redis Server updates will be
applied to the cache, which doesn't include Azure updates, or
updates to the VM operating system.

Monitor the cache and set

Set alerts for exceptions, high CPU, high memory usage, server

alerts.

load, and evicted keys for insights about when to scale the cache.
If the cache needs to be scaled, understanding when to scale is
important because it will increase CPU during the scaling event to
migrate data.

Deploy the cache within a

Gives the customer more control over the traffic that can connect

VNET.

to the cache. Make sure that the subnet has sufficient address
space available to deploy the cache nodes and shards (cluster).

Use the correct caching type

Distributed applications typically implement either or both of the

(local, in role, managed,
redis) within your solution.

following strategies when caching data:
- Using a private cache, where data is held locally on the machine
that's running an instance of an application or service.
- Using a shared cache, serving as a common source that can be
accessed by multiple processes and machines.
In both cases, caching can be performed client-side and serverside. Client-side caching is done by the process that provides the
user interface for a system, such as a web browser or desktop
application. Server-side caching is done by the process that
provides the business services that are running remotely.

Configure Data Persistence

Data Persistence: If the master and replica reboot, the data will be

to save a copy of the cache

loaded automatically from the storage account. Geo-Replication:

to Azure Storage or use
Geo-Replication, depending

The secondary cache needs to be unlinked from the primary. The
secondary will now become the primary and can receive writes.

on the business
requirement.
Review How to administer
Azure Cache for Redis.

Understand how data loss can occur with cache reboots and how
to test the application for resiliency.

Source artifacts
To identify Redis instances that aren't on the Premium tier, use the following query:
SQL

Resources
| where type == 'microsoft.cache/redis'
| where properties.sku.name != 'Premium'

Next step
Azure Databricks and security

Azure Databricks and security
Article • 01/11/2023

Azure Databricks is a data analytics platform optimized for Azure cloud services. It offers
three environments for developing data intensive applications:
Databricks SQL
Databricks Data Science and Engineering
Databricks Machine Learning
To learn more about how Azure Databricks improves the security of big data analytics,
reference Azure Databricks concepts.
The following sections include design considerations, a configuration checklist, and
recommended configuration options specific to Azure Databricks.

Design considerations
All users' notebooks and notebook results are encrypted at rest, by default. If other
requirements are in place, consider using customer-managed keys for notebooks.

Checklist
Have you configured Azure Databricks with security in mind?
＂ Use Azure Active Directory credential passthrough to avoid the need for service
principals when communicating with Azure Data Lake Storage.
＂ Isolate your workspaces, compute, and data from public access. Make sure that only
the right people have access and only through secure channels.
＂ Ensure that the cloud workspaces for your analytics are only accessible by properly
managed users.
＂ Implement Azure Private Link.
＂ Restrict and monitor your virtual machines.
＂ Use Dynamic IP access lists to allow admins to access workspaces only from their
corporate networks.
＂ Use the VNet injection functionality to enable more secure scenarios.
＂ Use diagnostic logs to audit workspace access and permissions.
＂ Consider using the Secure cluster connectivity feature and hub/spoke
architecture
cluster nodes.

to prevent opening ports, and assigning public IP addresses on

Configuration recommendations
Explore the following table of recommendations to optimize your Azure Databricks
configuration for security:
Recommendation

Description

Ensure that the cloud

Azure Active Directory can handle single sign-on for remote

workspaces for your
analytics are only accessible
by properly managed users.

access. For extra security, reference Conditional Access.

Implement Azure Private
Link.

Ensure all traffic between users of your platform, the notebooks,
and the compute clusters that process queries are encrypted and
transmitted over the cloud provider's network backbone,
inaccessible to the outside world.

Restrict and monitor your

Clusters, which execute queries, should have SSH and network

virtual machines.

access restricted to prevent installation of arbitrary packages.
Clusters should use only images that are periodically scanned for
vulnerabilities.

Use the VNet injection

Such as:

functionality to enable more

- Connecting to other Azure services using service endpoints.

secure scenarios.

- Connecting to on-premises data sources, taking advantage of
user-defined routes.
- Connecting to a network virtual appliance to inspect all
outbound traffic and take actions according to allow and deny
rules.
- Using custom DNS.
- Deploying Azure Databricks clusters in existing virtual networks.

Use diagnostic logs to audit

Use audit logs to see privileged activity in a workspace, cluster

workspace access and
permissions.

resizing, files, and folders shared on the cluster.

Source artifacts
Azure Databricks source artifacts include the Databricks blog: Best practices to secure an
enterprise-scale data platform .

Next step
Azure Database for MySQL and cost optimization

Azure Database for MySQL and cost
optimization
Article • 11/30/2022

Azure Database for MySQL is a relational database service in the Microsoft cloud based
on the MySQL Community Edition

. You can use either Single Server or Flexible Server

to host a MySQL database in Azure. It's a fully managed database as a service offering
that can handle mission-critical workloads with predictable performance and dynamic
scalability.
For more information about how Azure Database for MySQL supports cost optimization
for your workload, reference Server concepts, specifically, Stop/Start an Azure Database
for MySQL.
The following sections include design considerations, a configuration checklist, and
recommended configuration options specific to Azure Database for MySQL.

Design considerations
Azure Database for MySQL includes the following design considerations:
Take advantage of the scaling capabilities of Azure Database for MySQL to lower
consumption cost whenever possible. To scale your database up and down, as
needed, reference the following Microsoft Support article, which covers the
automation process using runbooks: How to autoscale an Azure Database for
MySQL/PostgreSQL instance with Azure run books and Python

.

Plan your Recovery Point Objective (RPO) according to your operation level
requirement. There's no extra charge for backup storage for up to 100% of your
total provisioned server storage. Extra consumption of backup storage will be
charged in GB/month .
The cloud native design of the Single-Server service allows it to support 99.99% of
availability, eliminating the cost of passive hot standby.
Consider using Flexible Server SKU for non-production workloads. Flexible servers
provide better cost optimization controls with ability to stop and start your server.
They provide a burstable compute tier that is ideal for workloads that don't need
continuous full compute capacity.

Checklist

Have you configured Azure Database for MySQL with cost optimization in mind?
＂ Choose the appropriate server size for your workload.
＂ Consider Reserved Capacity for Azure Database for MySQL Single Server.

Configuration recommendations
Explore the following table of recommendations to optimize your Azure Database for
MySQL configuration for cost optimization:
Recommendation

Description

Choose the

Configuration options: Single Server and Flexible Server.

appropriate server
size for your
workload.
Consider Reserved

Compute costs associated with Azure Database For MySQL Single Server

Capacity for Azure

Reservation Discount. Once you've determined the total compute capacity

Database for
MySQL Single

and performance tier for Azure Database for MySQL in a region, this
information can be used to reserve the capacity. The reservation can span

Server.

one or three years. You can realize significant cost optimization with this
commitment.

Azure Database for PostgreSQL and cost optimization

Azure Well-Architected Framework
review - Azure Database for PostgreSQL
Article • 09/19/2023

This article provides architectural best practices for Azure Database for PostgreSQL.
The guidance is based on the five pillars of architectural excellence:
Reliability
Security
Cost optimization
Operational excellence
Performance efficiency

Prerequisites
Understanding the Well-Architected Framework pillars can help produce a high-quality,
stable, and efficient cloud architecture. We recommend you review your workload using
the Azure Well-Architected Framework Review assessment.
Azure Database for PostgreSQL is a relational database service in Azure based on the
PostgreSQL open-source relational database. It's a fully managed database as a service
offering that can handle mission-critical workloads with predictable performance,
security, high availability, and dynamic scalability. Azure Database for PostgreSQL is built
on the community edition of the PostgreSQL database engine. It's compatible with the
PostgreSQL server community edition and supports PostgreSQL extension features such
as PostGIS and TimescaleDB.
７ Note
To explore a light-weight solution idea that uses Azure Database for PostgreSQL to
store analytical results from the Cognitive Services API, see Intelligent apps using
Azure Database for PostgreSQL.
For implementation guidance, see product documentation: Build scalable apps in
Azure Cosmos DB for PostgreSQL.

Reliability

Azure Database for PostgreSQL - Flexible Server offers high availability support by
provisioning physically separate primary and standby replicas either within the same
availability zone (zonal) or across availability zones (zone-redundant). This high
availability model ensures that committed data is never lost if a failure happens. The
model is also designed so the database doesn't become a single point of failure in your
software architecture. Azure Database for PostgreSQL - Flexible Server provides features
that protect data and mitigate downtime for your mission-critical databases during
planned and unplanned downtime events. Built on top of the Azure infrastructure that
offers robust resiliency and availability, the flexible server has business continuity
features that provide fault protection, address recovery time requirements, and reduce
data loss exposure.

Reliability design checklist
You should review the design principles to optimize the cost of your architecture.
＂ Defined targets for RPO (Recovery Point Objective) and RTO (Recovery Time
Objective) for workloads.
＂ Select the appropriate high-availability configuration.
＂ Configure geo-redundancy backup.
＂ Test your disaster recovery plan to ensure rapid data restoration in case of a failure.
＂ Test On-Demand Failover for your HA-enabled server to ensure our application
behaves as expected.
＂ Monitor your server to ensure it's healthy and performing as expected.

Reliability recommendations
Recommendation

Benefit

Defined targets for RPO

Derive these values by conducting a risk assessment and

(Recovery Point Objective) and

ensuring you understand the cost and risk of downtime and

RTO (Recovery Time Objective)
for workloads.

data loss. These are nonfunctional requirements of a system
and should be dictated by business requirements.

Select the appropriate high
availability configuration.

Azure Database for PostgreSQL Server offers high availability
configurations, ensuring that the service remains available if
there's a zone outage and no data is lost. When high
availability is configured, the Azure Database for PostgreSQL
server automatically provisions and manages a standby replica.

Configure geo-redundancy
backup.

Cross-region read replicas can be deployed to protect your
databases from region-level failures. Geo Redundant backups
are enabled in selected regions and help with disaster recovery
in the event the primary server region is down.

Recommendation

Benefit

Test your disaster recovery plan
to ensure rapid data restoration

Read replicas can be deployed on a different region and
promoted to a read-write server if disaster recovery is needed.

if there's a failure.
Monitor your server to ensure

We have database monitoring in place to monitor and alert on

it's healthy and performing as

database-level failures.

expected.

Security
Think about security throughout the entire lifecycle of an application, from design and
implementation to deployment and operations. The Azure platform protects against
various threats like network intrusion and DDoS attacks. You still need to build security
into your application and your DevOps processes.

Security design checklist
You should review the design principles to optimize the cost of your architecture.
＂ SSL and enforce encryption to secure data in transit.
＂ Implement network security groups and firewalls to control access to your
database.
＂ Use Azure Active Directory for authentication and authorization to enhance identity
management.
＂ Configure row-level security.

Security recommendations
Recommendation

Benefit

SSL and enforce encryption to
secure data in transit.

Deploy the DigiCert Global Root certificate from a trusted
Certificate Authority (CA) certificate needed to communicate
over SSL with client applications.

Implement network security

As part of the Zero Trust Model for security, network

groups and firewalls to control
access to your database.

segmentation is recommended where communication paths
between components (in this case, application and database
server) are restricted to only what's needed. This can be
implemented using Network Security Group and Application
Security Groups.

Recommendation

Benefit

Use Azure Active Directory for
authentication and

Microsoft Azure Active Directory (Azure AD) authentication is a
mechanism of connecting to Azure Database for PostgreSQL

authorization to enhance
identity management.

using identities defined in Azure AD.

Configure row-level security.

Row level security (RLS) is a PostgreSQL security feature that
allows database administrators to define policies to control
how specific rows of data display and operate for one or more
roles. Row-level security is an additional filter you can apply to
a PostgreSQL database table.

Cost optimization
Cost optimization is about understanding your configuration options and recommended
best practices to reduce unnecessary expenses and improve operational efficiencies. You
should review your workload to identify opportunities to reduce costs.

Cost design checklist
You should review the design principles to optimize the cost of your architecture.
＂ Pick the right tier and SKU.
＂ Understand high availability mode.
＂ Scale compute and storage tiers.
＂ Consider reserved instances.
＂ Use your provisioned storage.
＂ Understand geo-redundancy costs.
＂ Evaluate storage scale-up decisions.
＂ Deploy to the same region as an app.
＂ High availability oriented cost description.
＂ Consolidate databases and servers.

Cost recommendations
Recommendations

Benefits

Pick the right tier and

Pick the pricing tier and compute SKUs that support the specific needs

SKU.

of your workload. Azure Advisor gives you recommendations to
optimize and reduce your overall Azure spending. Recommendations
include server right-sizing that you should follow.

Recommendations

Benefits

Understand high
availability mode.

High availability makes a standby server always available within the
same zone or region. Enabling high availability doubles your cost.

Adjust compute and
storage tier.s

You should manually adjust the compute and storage tiers to meet the
application's requirements over time.

Use Start/Stop feature.

The Flexible server has a Start/Stop feature that you can use to stop the
server from running when you don't need it.

Consider reserved
instances.

Consider a one or three-year reservation to receive significant discounts
on computing. Use these reservations for workloads with consistent
compute usage for a year or more.

Use your provisioned
storage.

There's no extra charge for backup storage up to 100% of your total
provisioned server storage.

Understand

Geo-redundant storage (GRS) costs twice as much as local redundant

redundancy costs.

storage (LRS). GRS requires double the storage capacity of LRS.

Evaluate storage scaleup decisions.

You should evaluate your current and future storage needs before
scaling up your storage. After you scale up storage, you can't scale
down.

Deploy to the same
region as the app.

Deploy to the same region as the application(s) to minimize transfer
costs. When you use virtual network integration, applications in a
different virtual network don't have direct access to flexible servers. To
grant them access, you need to configure virtual network peering.
Virtual network peering has nominal inbound and outbound data
transfer costs.

High availability
oriented cost
description.

It's a trade-off of HA and costs. HA is double the cost for non-HA
configuration, but it's needed.

Consolidate databases

You can consolidate multiple databases and servers into a single server

and servers.

to reduce costs.

Azure policy definitions
Azure Policy definitions help you enforce specific rules and configurations for resources
within your Azure environment. To ensure cost optimization for Azure Database for
PostgreSQL, you can create custom Azure Policy definitions to enforce specific
configurations and best practices. Here's an example of some custom Azure Policy
definitions you can create for cost optimization:
Optimize costs

Operational excellence
The principles of operational excellence are a series of considerations that can help
achieve superior operational practices.
To achieve a higher competency in operations, consider and improve how software is
developed, deployed, operated, and maintained.

Operational excellence design checklist
You should review the design principles to optimize the cost of your architecture.
＂ Set up automated backups and retention policies to maintain data availability and
meet compliance requirements.
＂ Implement automated patching and updates to keep your PostgreSQL instance
secure and up-to-date.
＂ Monitor database health and performance using Azure Monitor and set up alerts
for critical metrics.

Operational excellence recommendations
Recommendation

Benefits

Set up automated backups and
retention policies to maintain data
availability and meet compliance
requirements.

Azure Database for PostgreSQL provides automated
backups and point-in-time restore for your database. You
can configure the retention period for backups up to 35
days.

Implement automated patching
and updates to keep your
PostgreSQL instance secure and
up-to-date.

Azure Database for PostgreSQL provides automated
patching and updates for your database. You can configure
the maintenance window for your server to minimize the
impact on your workload.

Monitor database health and
performance using Azure Monitor
and set up alerts for critical metrics.

Azure Database for PostgreSQL provides built-in
monitoring and alerting capabilities. You can monitor the
health and performance of your database using Azure
Monitor. You can also set up alerts for critical metrics to get
notified when your database isn't performing as expected.

Operational excellence policy definitions
Azure Policy definitions help you enforce specific rules and configurations for resources
within your Azure environment. To ensure Operational excellence for Azure Database for
PostgreSQL, you can create custom Azure Policy definitions to enforce specific

configurations and best practices. Here's an example of some custom Azure Policy
definitions you can create for Operational excellence:
Azure Policy Regulatory Compliance controls for Azure Database for PostgreSQL

Performance efficiency
Performance efficiency is the ability of your workload to scale to meet the demands
placed on it by users efficiently. We recommend you review the Performance efficiency
principles.
In the design checklist and list of recommendations below, call-outs indicate whether
each choice applies to cluster architecture, workload architecture, or both.

Performance efficiency design checklist
You should review the design principles to optimize the cost of your architecture.
＂ Design your schema and queries for efficiency to minimize resource consumption.
＂ Implement read replicas to offload read traffic and enhance overall performance.

Performance efficiency recommendations
Recommendation

Benefits

Design your schema and queries for efficiency
to minimize resource consumption.

You should design your schema and queries for
efficiency to minimize resource consumption.

Implement read replicas to offload read traffic
and enhance overall performance.

You can use read replicas to offload read traffic
and enhance performance.

Performance efficiency policy definitions
Azure Policy definitions help you enforce specific rules and configurations for resources
within your Azure environment. To ensure Performance efficiency for Azure Database for
PostgreSQL, you can create custom Azure Policy definitions to enforce specific
configurations and best practices. Here's an example of some custom Azure Policy
definitions you can create for Performance efficiency:

Extra resources
Consider more resources related to Azure Database for PostgreSQL.

Azure Architecture Center Guidance
Multitenancy and Azure Database for PostgreSQL
Best practices
Optimize performance
Tuning

Cloud Adoption Framework guidance
Batch Data application with Azure Database for PostgreSQL

Next steps
Azure pricing calculator to estimate and manage your costs effectively

Azure Well-Architected Framework
review - Azure SQL Database
Article • 06/24/2022

Azure SQL Database is a fully managed platform as a service (PaaS) database engine
that handles most of the database management functions without user involvement.
Management functions include upgrades, patches, backups, and monitoring.
The single database resource type creates a database in Azure SQL Database with its
own set of resources and is managed via a logical server. You can choose between the
DTU-based purchasing model or vCore-based purchasing model. You can create
multiple databases in a single resource pool, with elastic pools.
The following sections include a design checklist and recommended design options
specific to Azure SQL Database security. The guidance is based on the five pillars of
architectural excellence:
Reliability
Security
Cost optimization
Operational excellence
Performance efficiency

Prerequisites
Understanding the Well-Architected Framework pillars can help produce a high
quality, stable, and efficient cloud architecture. Check out the Azure WellArchitected Framework overview page to review the five pillars of architectural
excellence.
Review the core concepts of Azure SQL Database and What's new in Azure SQL
Database?.

Azure SQL Database and reliability
Azure SQL Database is a fully managed platform as a service (PaaS) database engine
that handles most of the database management functions without user involvement.
Management functions include:
Upgrades

Patches
Backups
Monitoring
This service allows you to create a highly available and high-performance data storage
layer for your Azure applications and workloads. Azure SQL Database is always running
on the latest stable version of the SQL Server database engine and patched OS with
99.99% availability.

For more information about how Azure SQL Database promotes reliability and enables
your business to continue operating during disruptions, reference Availability
capabilities.
The following sections include design considerations, a configuration checklist, and
recommended configuration options specific to Azure SQL Database and reliability.

Design considerations
Azure SQL Database includes the following design considerations:
Azure SQL Database Business Critical tier configured with geo-replication has a
guaranteed Recovery time objective (RTO) of 30 seconds for 100% of deployed
hours.
Use sharding to distribute data and processes across many identically structured
databases. Sharding provides an alternative to traditional scale-up approaches for
cost and elasticity. Consider using sharding to partition the database horizontally.
Sharding can provide fault isolation. For more information, reference Scaling out
with Azure SQL Database.
Azure SQL Database Business Critical or Premium tiers not configured for Zone
Redundant Deployments, General Purpose, Standard, or Basic tiers, or Hyperscale
tier with two or more replicas have an availability guarantee. For more information
about the availability guarantee, reference SLA for Azure SQL Database .
Provides built-in regional high availability and turnkey geo-replication to any Azure
region. It includes intelligence to support self-driving features, such as:
Performance tuning
Threat monitoring
Vulnerability assessments
Fully automated patching and updating of the code base

Define an application performance SLA and monitor it with alerts. Quickly detect
when your application performance inadvertently degrades below an acceptable
level, which is important to maintain high resiliency. Use the monitoring solution
previously defined to set alerts on key query performance metrics so you can take
action when the performance breaks the SLA. Go to Monitor Your Database and
alerting tools for more information.
Use geo-restore to recover from a service outage. You can restore a database on
any SQL Database server or an instance database on any managed instance in any
Azure region from the most recent geo-replicated backups. Geo-restore uses a
geo-replicated backup as its source. You can request geo-restore even if the
database or datacenter is inaccessible because of an outage. Geo-restore restores
a database from a geo-redundant backup. For more information, reference
Recover an Azure SQL database using automated database backups.
Use the Business Critical tier configured with geo-replication, which has a
guaranteed Recovery point objective (RPO) of 5 seconds for 100% of deployed
hours.
PaaS capabilities built into Azure SQL Database enable you to focus on the
domain-specific database administration and optimization activities that are critical
for your business.
Use point-in-time restore to recover from human error. Point-in-time restore
returns your database to an earlier point in time to recover data from changes
done inadvertently. For more information, read the Point-in-time restore (PITR)
documentation.
Business Critical or Premium tiers are configured as Zone Redundant Deployments
which have an availability guarantee. For more information about the availability
guarantee, reference SLA for Azure SQL Database .

Checklist
Have you configured Azure SQL Database with reliability in mind?
＂ Use Active Geo-Replication to create a readable secondary in a different region.
＂ Use Auto Failover Groups that can include one or multiple databases, typically used
by the same application.
＂ Use a Zone-Redundant database.
＂ Monitor your Azure SQL Database in near-real time to detect reliability incidents.
＂ Implement Retry Logic.
＂ Back up your keys.

Configuration recommendations
Explore the following table of recommendations to optimize your Azure SQL Database
configuration for reliability:
Recommendation

Description

Use Active GeoReplication to
create a readable

If your primary database fails, perform a manual failover to the secondary
database. Until you fail over, the secondary database remains read-only.
Active geo-replication enables you to create readable replicas and manually

secondary in a
different region.

failover to any replica if there is a datacenter outage or application upgrade.
Up to four secondaries are supported in the same or different regions, and
the secondaries can also be used for read-only access queries. The failover
must be initiated manually by the application or the user. After failover, the
new primary has a different connection end point.

Use Auto Failover

You can use the readable secondary databases to offload read-only query

Groups that can
include one or
multiple

workloads. Because autofailover groups involve multiple databases, these
databases must be configured on the primary server. Autofailover groups
support replication of all databases in the group to only one secondary

databases,
typically used by
the same

server or instance in a different region. Learn more about AutoFailover
Groups and DR design.

application.
Use a ZoneRedundant
database.

By default, the cluster of nodes for the premium availability model is created
in the same datacenter. With the introduction of Azure Availability Zones,
SQL Database can place different replicas of the Business Critical database to
different availability zones in the same region. To eliminate a single point of
failure, the control ring is also duplicated across multiple zones as three
gateway rings (GW). The routing to a specific gateway ring is controlled by
Azure Traffic Manager (ATM). Because the zone redundant configuration in
the Premium or Business Critical service tiers doesn't create extra database
redundancy, you can enable it at no extra cost. Learn more about Zoneredundant databases.

Monitor your
Azure SQL

Use one of the available solutions to monitor SQL DB to detect potential
reliability incidents early and make your databases more reliable. Choose a

Database in nearreal time to detect
reliability

near real-time monitoring solution to quickly react to incidents. Reference
Azure SQL Analytics for more information.

incidents.
Implement Retry
Logic.

Although Azure SQL Database is resilient when it concerns transitive
infrastructure failures, these failures might affect your connectivity. When a
transient error occurs while working with SQL Database, make sure your
code can retry the call. For more information, reference how to implement
retry logic.

Recommendation

Description

Back up your keys.

If you're not using encryption keys in Azure Key Vault to protect your data,
back up your keys.

Azure SQL Database and security
SQL Database provides a range of built-in security and compliance features to help your
application meet various security and compliance requirements.

Design checklist
Have you designed your workload and configured Azure SQL Database with security
in mind?
＂ Understand logical servers and how you can administer logins for multiple
databases when appropriate.
＂ Enable Azure AD authentication with Azure SQL. Azure AD authentication enables
simplified permission management and centralized identity management.
＂ Azure SQL logical servers should have an Azure Active Directory administrator
provisioned.
＂ Verify contact information email address in your Azure Subscription for service
administrator and co-administrators is reaching the correct parties inside your
enterprise. You don't want to miss or ignore important security notifications from
Azure!
＂ Review the Azure SQL Database connectivity architecture. Choose the Redirect or
Proxy connection policy as appropriate.

＂ Review Azure SQL Database firewall rules.
＂ Use virtual network rules to control communication from particular subnets in
virtual networks.
＂ If using the Azure Firewall, configure Azure Firewall application rules with SQL
FQDNs.

Recommendations
Recommendation

Benefit

Recommendation

Benefit

Review the
minimum TLS

Determine whether you have legacy applications that require older TLS or
unencrypted connections. After you enforce a version of TLS, it's not

version.

possible to revert to the default. Review and configure the minimum TLS
version for SQL Database connections via the Azure portal. If not, set the
latest TLS version to the minimum.

Ledger

Consider designing database tables based on the Ledger to provide
auditing, tamper-evidence, and trust of all data changes.

Always Encrypted

Consider designing application access based around Always Encrypted to
protect sensitive data inside applications by delegating data access to
encryption keys.

Private endpoints
and private link

Private endpoint connections enforce secure communication by enabling
private connectivity to Azure SQL Database. You can use a private endpoint
to secure connections and deny public network access by default. Azure
Private Link for Azure SQL Database is a type of private endpoint
recommended for Azure SQL Database.

Automated
vulnerability
assessments

Monitor for vulnerability assessment scan results and recommendations for
how to remediate database vulnerabilities.

Advanced Threat
Protection

Detect anomalous activities indicating unusual and potentially harmful
attempts to access or exploit databases with Advanced Threat Protection for
Azure SQL Database. Advanced Threat Protection integrates its alerts with
Microsoft Defender for Cloud .

Auditing

Track database events with Auditing for Azure SQL Database.

Managed
identities

Consider configuring a user-assigned managed identity (UMI). Managed
identities for Azure resources eliminate the need to manage credentials in
code.

Azure AD-only
authentication

Consider disabling SQL-based authentication and allowing only on Azure AD
authentication.

Policy definitions
Review the Azure security baseline for Azure SQL Database and Azure Policy built-in
definitions.
All built-in policy definitions related to Azure SQL are listed in Built-in policies.
Review Tutorial: Secure a database in Azure SQL Database.

Azure SQL Database and cost optimization
Azure SQL Database is a fully managed platform as a service (PaaS) database engine
that handles most of the database management functions without user involvement.
Management functions include:
Upgrades
Patches
Backups
Monitoring
This service allows you to create a highly available and high-performance data storage
layer for your Azure applications and workloads. SQL Database includes built-in
intelligence that helps you dramatically reduce the costs of running and managing
databases through automatic performance monitoring and tuning.
For more information about how Azure SQL Database provides cost-saving features,
reference Plan and manage costs for Azure SQL Database.
The following sections include a configuration checklist and recommended
configuration options specific to Azure SQL Database and cost optimization.

Checklist
Have you configured Azure SQL Database with cost optimization in mind?
＂ Optimize queries.
＂ Evaluate resource usage.
＂ Fine-tune backup storage consumption.
＂ Evaluate Azure SQL Database serverless.
＂ Consider reserved capacity for Azure SQL Database.
＂ Consider elastic pools for managing and scaling multiple databases.

Configuration recommendations
Explore the following table of recommendations to optimize your Azure SQL Database
configuration for cost savings:
Recommendation

Description

Optimize queries.

Optimize the queries, tables, and databases using Query Performance
Insights and Performance Recommendations to help reduce resource
consumption, and arrive at appropriate configuration.

Recommendation

Description

Evaluate resource
usage.

Evaluate the resource usage for all databases and determine if they've been
sized and provisioned correctly. For non-production databases, consider
scaling resources down as applicable. The DTUs or vCores for a database can
be scaled on demand, for example, when running a load test or user
acceptance test.

Fine-tune backup
storage
consumption

For vCore databases in Azure SQL Database, the storage consumed by each
type of backup (full, differential, and log) is reported on the database
monitoring pane as a separate metric. Backup storage consumption up to
the maximum data size for a database is not charged. Excess backup storage
consumption will depend on the workload and maximum size of the
individual databases. For more information, see Backup storage
consumption.

Evaluate Azure
SQL Database
Serverless.

Consider using Azure SQL Database serverless over the Provisioned
Computing Tier. Serverless is a compute tier for single databases that
automatically scales compute based on workload demand and bills for the
amount of compute used per second. The serverless compute tier also
automatically pauses databases during inactive periods when only storage is
billed. It automatically resumes databases when activity returns. Azure SQL
Database serverless isn't suited for all scenarios. If you have a database with
unpredictable or bursty usage patterns interspersed with periods of low or
idle usage, serverless is a solution that can help you optimize priceperformance.

Consider reserved
capacity for Azure
SQL Database.

You can reduce compute costs associated with Azure SQL Database by using
Reservation Discount. Once you've determined the total compute capacity
and performance tier for Azure SQL databases in a region, you can use this
information to reserve the capacity. The reservation can span one or three
years. For more information, reference Save costs for resources with reserved
capacity.

Elastic pools help
you manage and
scale multiple
databases in
Azure SQL

Azure SQL Database elastic pools are a simple, cost-effective solution for
managing and scaling multiple databases that have varying and
unpredictable usage demands. The databases in an elastic pool are on a
single server and share a set number of resources at a set price. For more
information, see Elastic pools for managing and scaling multiple databases.

Database

For more information, see Plan and manage costs for Azure SQL Database.

Azure SQL Database and operational excellence
Azure SQL Database is a fully managed platform as a service (PaaS) database engine
that handles most of the database management functions without user involvement.
Management functions include:

Upgrades
Patches
Backups
Monitoring
This service allows you to create a highly available and high-performance data storage
layer for your Azure applications and workloads. Azure SQL Database provides advanced
monitoring and tuning capabilities backed by artificial intelligence to help you
troubleshoot and maximize the performance of your databases and solutions.
For more information about how Azure SQL Database promotes operational excellence
and enables your business to continue operating during disruptions, reference
Monitoring and performance tuning in Azure SQL Database.
The following sections include design considerations, a configuration checklist, and
recommended configuration options specific to Azure SQL Database, and operational
excellence.

Design considerations
Azure SQL Database includes the following design considerations:
Azure SQL Database Business Critical tier configured with geo-replication has a
guaranteed Recovery time objective (RTO) of 30 seconds for 100% of deployed
hours.
Use sharding to distribute data and processes across many identically structured
databases. Sharding provides an alternative to traditional scale-up approaches for
cost and elasticity. Consider using sharding to partition the database horizontally.
Sharding can provide fault isolation. For more information, reference Scaling out
with Azure SQL Database.
Azure SQL Database Business Critical or Premium tiers not configured for Zone
Redundant Deployments, General Purpose, Standard, or Basic tiers, or Hyperscale
tier with two or more replicas have an availability guarantee. For more information,
reference SLA for Azure SQL Database .
Provides built-in regional high availability and turnkey geo-replication to any Azure
region. It includes intelligence to support self-driving features, such as:
Performance tuning
Threat monitoring
Vulnerability assessments
Fully automated patching and updating of the code base

Define an application performance SLA and monitor it with alerts. Quickly detect
when your application performance inadvertently degrades below an acceptable
level, which is important to maintain high resiliency. Use the monitoring solution
previously defined to set alerts on key query performance metrics so you can take
action when the performance breaks the SLA. Go to Monitor Your Database for
more information.
Use geo-restore to recover from a service outage. You can restore a database on
any SQL Database server or an instance database on any managed instance in any
Azure region from the most recent geo-replicated backups. Geo-restore uses a
geo-replicated backup as its source. You can request geo-restore even if the
database or datacenter is inaccessible because of an outage. Geo-restore restores
a database from a geo-redundant backup. For more information, reference
Recover an Azure SQL database using automated database backups.
Use the Business Critical tier configured with geo-replication, which has a
guaranteed Recovery point objective (RPO) of 5 seconds for 100% of deployed
hours.
PaaS capabilities built into Azure SQL Database enable you to focus on the
domain-specific database administration and optimization activities that are critical
for your business.
Use point-in-time restore to recover from human error. Point-in-time restore
returns your database to an earlier point in time to recover data from changes
done inadvertently. For more information, read the Point-in-time restore (PITR)
documentation.
Business Critical or Premium tiers are configured as Zone Redundant Deployments.
For more information about the availability guarantee, reference SLA for Azure SQL
Database

.

Checklist
Have you configured Azure SQL Database with operational excellence in mind?
＂ Use Active Geo-Replication to create a readable secondary in a different region.
＂ Use Auto Failover Groups that can include one or multiple databases, typically used
by the same application.
＂ Use a Zone-Redundant database.
＂ Monitor your Azure SQL Database in near-real time to detect reliability incidents.
＂ Implement retry logic.
＂ Back up your keys.

Configuration recommendations
Explore the following table of recommendations to optimize your Azure SQL Database
configuration for operational excellence:
Recommendation

Description

Use Active GeoReplication to
create a readable
secondary in a
different region.

If your primary database fails, perform a manual failover to the secondary
database. Until you fail over, the secondary database remains read-only.
Active geo-replication enables you to create readable replicas and manually
failover to any replica if there is a datacenter outage or application upgrade.
Up to four secondaries are supported in the same or different regions, and
the secondaries can also be used for read-only access queries. The failover
must be initiated manually by the application or the user. After failover, the
new primary has a different connection end point.

Use Auto Failover
Groups that can
include one or
multiple
databases,

You can use the readable secondary databases to offload read-only query
workloads. Because autofailover groups involve multiple databases, these
databases must be configured on the primary server. Autofailover groups
support replication of all databases in the group to only one secondary
server or instance in a different region. Learn more about Auto-Failover

typically used by
the same

Groups and DR design.

application.
Use a ZoneRedundant

By default, the cluster of nodes for the premium availability model is created
in the same datacenter. With the introduction of Azure Availability Zones,

database.

SQL Database can place different replicas of the Business Critical database to
different availability zones in the same region. To eliminate a single point of
failure, the control ring is also duplicated across multiple zones as three
gateway rings (GW). The routing to a specific gateway ring is controlled by
Azure Traffic Manager (ATM). Because the zone redundant configuration in
the Premium or Business Critical service tiers doesn't create extra database
redundancy, you can enable it at no extra cost. Learn more about Zoneredundant databases.

Monitor your

Use one of the available solutions to monitor SQL DB to detect potential

Azure SQL

reliability incidents early and make your databases more reliable. Choose a

Database in nearreal time to detect

near real-time monitoring solution to quickly react to incidents. Reference
Azure SQL Analytics for more information.

reliability
incidents.
Implement Retry
Logic.

Although Azure SQL Database is resilient when it concerns transitive
infrastructure failures, these failures might affect your connectivity. When a
transient error occurs while working with SQL Database, make sure your
code can retry the call. For more information, reference how to implement
retry logic and Configurable retry logic in SqlClient introduction.

Recommendation

Description

Back up your keys.

If you're not using encryption keys in Azure Key Vault to protect your data,
back up your keys.

Azure SQL Database and performance
efficiency
Azure SQL Database is a fully managed platform as a service (PaaS) database engine
that handles most of the database management functions without user involvement.
Management functions include:
Upgrades
Patches
Backups
Monitoring
The following sections include a design checklist and recommended design options
specific to Azure SQL Database performance efficiency.

Design checklist
Have you designed your workload and configured Azure SQL Database with
performance efficiency in mind?
＂ Review resource limits. For specific resource limits per pricing tier (also known as
service objective) for single databases, refer to either DTU-based single database
resource limits or vCore-based single database resource limits. For elastic pool
resource limits, refer to either DTU-based elastic pool resource limits or vCorebased elastic pool resource limits.
＂ Choose the right deployment model for your workload, vCore or DTU. Compare the
vCore and DTU-based purchasing models.
＂ Microsoft recommends the latest vCore database standard-series or premiumseries hardware. Older Gen4 hardware has been retired.
＂ When using elastic pools, familiarize yourself with resource governance.
＂ Review the default max degree of parallelism (MAXDOP) and configure as needed
based on a migrated or expected workload.
＂ Consider using read-only replicas of critical database to offload read-only query
workloads.
＂ Review the Performance Center for SQL Server Database Engine and Azure SQL
Database.

＂ Applications connecting to Azure SQL Database should use the latest connection
providers, for example the latest OLE DB Driver or ODBC Driver.

Recommendations
Recommendation

Benefit

Diagnose and
troubleshoot high

Azure SQL Database provides built-in tools to identify the causes of high
CPU usage and to optimize workload performance.

CPU utilization.
Understand
blocking and

Blocking due to concurrency and terminated sessions due to deadlocks have
different causes and outcomes.

deadlocking
issues.
Tune applications
and databases for

Tune your application and database to improve performance. Review best
practices.

performance.
Review Azure
portal utilization

After deployment, use built-in reporting in the Azure portal to regularly
review peak and average database utilization and right-size up or down. You

reporting and
scale as

can easily scale single databases or elastic pools with no data loss and
minimal downtime.

appropriate.
Review

In the Intelligent Performance menu of the database page in the Azure

Performance

portal, review and consider action on any of the Performance

Recommendations.

Recommendations and implement any index, schema, and parameterization
issues.

Review Query
Performance

Review Query Performance Insight for Azure SQL Database reports to
identify top resource-consuming queries, long running queries, and more.

Insight.
Configure

Provide peak performance and stable workloads through continuous

Automatic tuning.

performance tuning based on AI and machine learning. Consider using
Azure Automation to configure email notifications for automatic tuning.

Evaluate potential

In-memory technologies enable you to improve performance of your

use of in-memory
database objects.

application, and potentially reduce cost of your database. Consider
designing some database objects in high-volume OLTP applications.

Leverage the
Query Store.

Enabled by default in Azure SQL Database, the Query Store contains a
wealth of query performance and resource consumption data, as well as
advanced tuning features like Query Store hints and automatic plan
correction. Review Query Store defaults in Azure SQL Database.

Recommendation

Benefit

Implement retry
logic for transient

Applications should include automatic transaction retry logic for transient
errors including common connection errors. Leverage exponential retry

errors.

interval logic.

Additional resources
For information about supported features, see Features and Resolving Transact-SQL
differences during migration to SQL Database.
Migrating to Azure SQL Database? Review our Azure Database Migration Guides.
Watch episodes of Data Exposed covering Azure SQL topics and more.

Next steps
Try Azure SQL Database free with Azure free account, then get started with single
databases in Azure SQL Database.

Azure SQL Managed Instance and
reliability
Article • 11/30/2022

Azure SQL Managed Instance is the intelligent, scalable cloud database service that
combines the broadest SQL Server database engine compatibility with all the benefits of
a fully managed and evergreen platform as a service.
The goal of the high availability architecture in SQL Managed Instance is to guarantee
that your database is up and running without worrying about the impact of
maintenance operations and outages. This solution is designed to:
Ensure that committed data is never lost because of failures.
Ensure that maintenance failures don't affect your workload.
Ensure that the database won't be a single point of failure in your software
architecture.
For more information about how Azure SQL Managed Instance supports application and
workload resilience, reference the following articles:
High availability for Azure SQL Managed Instance
Use autofailover groups to enable transparent and coordinated geo-failover of
multiple databases
The following sections include design considerations, a configuration checklist, and
recommended configuration options specific to Azure SQL Managed Instance, and
reliability.

Design considerations
Azure SQL Managed Instance includes the following design considerations:
Define an application performance SLA and monitor it with alerts. Detecting
quickly when your application performance inadvertently degrades below an
acceptable level is important to maintain high resiliency. Use a monitoring solution
to set alerts on key query performance metrics so you can take action when the
performance breaks the SLA.
Use point-in-time restore to recover from human error. Point-in-time restore
returns your database to an earlier point in time to recover data from changes
done inadvertently. For more information, read the Point-in-time-restore (PITR)
documentation for managed instance.

Use geo-restore to recover from a service outage. Geo-restore restores a database
from a geo-redundant backup into a managed instance in a different region. For
more information, reference Recover a database using Geo-restore documentation.
Consider the time required for certain operations. Make sure you separate time to
thoroughly test the amount of time required to scale up and down your existing
managed instance, and to create a new managed instance. This timing practice
ensures that you understand completely how time consuming operations will
affect your RTO and RPO.

Checklist
Have you configured Azure SQL Managed Instance with reliability in mind?
＂ Use the Business Critical Tier.
＂ Configure a secondary instance and an Autofailover group to enable failover to
another region.
＂ Implement Retry Logic.
＂ Monitor your SQL MI instance in near-real time to detect reliability incidents.

Configuration recommendations
Explore the following table of recommendations to optimize your Azure SQL Managed
Instance configuration for reliability:
Recommendation

Description

Use the Business

This tier provides higher resiliency to failures and faster failover times

Critical Tier.

because of the underlying HA architecture, among other benefits. For
more information, reference SQL Managed Instance High availability.

Configure a

If an outage impacts one or more of the databases in the managed

secondary instance
and an Autofailover

instance, you can manually or automatically failover all the databases
inside the instance to a secondary region. For more information, read the

group to enable

Autofailover groups documentation for managed instance.

failover to another
region.
Implement Retry
Logic.

Although Azure SQL MI is resilient to transitive infrastructure failures,
these failures might affect your connectivity. When a transient error
occurs while working with SQL MI, make sure your code can retry the call.
For more information, reference how to implement retry logic.

Recommendation

Description

Monitor your SQL MI
instance in near-real

Use one of the available solutions to monitor your SQL MI to detect
potential reliability incidents early and make your databases more

time to detect

reliable. Choose a near real-time monitoring solution to quickly react to

reliability incidents.

incidents. For more information, check out the Azure SQL Managed
Instance monitoring options .

Next step
Azure SQL Managed Instance and operational excellence

Azure SQL Managed Instance and
operational excellence
Article • 11/30/2022

Azure SQL Managed Instance is the intelligent, scalable cloud database service that
combines the broadest SQL Server database engine compatibility with all the benefits of
a fully managed and evergreen platform as a service.
The goal of the high availability architecture in SQL Managed Instance is to guarantee
that your database is up and running without worrying about the impact of
maintenance operations and outages. This solution is designed to:
Ensure that committed data is never lost because of failures.
Ensure that maintenance failures don't affect your workload.
Ensure that the database won't be a single point of failure in your software
architecture.
For more information about how Azure SQL Managed Instance supports operational
excellence for your application workloads, reference the following articles:
Overview of Azure SQL Managed Instance management operations
Monitoring Azure SQL Managed Instance management operations
The following sections include design considerations, a configuration checklist, and
recommended configuration options specific to Azure SQL Managed Instance, and
operational excellence.

Design considerations
Azure SQL Managed Instance includes the following design considerations:
Define an application performance SLA and monitor it with alerts. Detecting
quickly when your application performance inadvertently degrades below an
acceptable level is important to maintain high resiliency. Use a monitoring solution
to set alerts on key query performance metrics so you can take action when the
performance breaks the SLA.
Use point-in-time restore to recover from human error. Point-in-time restore
returns your database to an earlier point in time to recover data from changes
done inadvertently. For more information, read the Point-in-time-restore (PITR)
documentation for managed instance.

Use geo-restore to recover from a service outage. Geo-restore restores a database
from a geo-redundant backup into a managed instance in a different region. For
more information, reference Recover a database using Geo-restore documentation.
Consider the time required for certain operations. Make sure you separate time to
thoroughly test the amount of time required to scale up and down your existing
managed instance, and to create a new managed instance. This timing practice
ensures that you understand completely how time consuming operations will
affect your RTO and RPO.

Checklist
Have you configured Azure SQL Managed Instance with operational excellence in
mind?
＂ Use the Business Critical Tier.
＂ Configure a secondary instance and an Autofailover group to enable failover to
another region.
＂ Implement Retry Logic.
＂ Monitor your SQL MI instance in near-real time to detect reliability incidents.

Configuration recommendations
Explore the following table of recommendations to optimize your Azure SQL Managed
Instance configuration for operational excellence:
Recommendation

Description

Use the Business

This tier provides higher resiliency to failures and faster failover times

Critical Tier.

because of the underlying HA architecture, among other benefits. For
more information, reference SQL Managed Instance High availability.

Configure a

If an outage impacts one or more of the databases in the managed

secondary instance
and an Autofailover

instance, you can manually or automatically failover all the databases
inside the instance to a secondary region. For more information, read the

group to enable

Autofailover groups documentation for managed instance.

failover to another
region.
Implement Retry
Logic.

Although Azure SQL MI is resilient to transitive infrastructure failures,
these failures might affect your connectivity. When a transient error
occurs while working with SQL MI, make sure your code can retry the call.
For more information, reference how to implement retry logic.

Recommendation

Description

Monitor your SQL MI
instance in near-real

Use one of the available solutions to monitor your SQL MI to detect
potential reliability incidents early and make your databases more

time to detect

reliable. Choose a near real-time monitoring solution to quickly react to

reliability incidents.

incidents. For more information, check out the Azure SQL Managed
Instance monitoring options .

Next step
Azure Cosmos DB and reliability

Azure Cosmos DB and reliability
Article • 11/30/2022

Azure Cosmos DB

is a fully managed NoSQL database for modern app development.

Key features include:
Guaranteed speed at any scale
Simplified application development
Mission-critical ready
Fully managed and cost effective
To understand how Azure Cosmos DB bolsters resiliency for your application workload,
reference the following articles:
Distribute your data globally with Azure Cosmos DB
How does Azure Cosmos DB provide high availability
Consistency levels in Azure Cosmos DB
Configure Azure Cosmos DB account with periodic backup
The following sections include design considerations, a configuration checklist,
recommended configuration options, and source artifacts specific to Azure Cosmos DB
and reliability.

Design considerations
Azure Cosmos DB includes the following design considerations:
SLA for read availability for Database Accounts spanning two or more Azure
regions.
SLAs for throughput, consistency, availability, and latency.
SLA for both read and write availability with the configuration of multiple Azure
regions as writable endpoints.
For more detailed information about SLAs specific to this product, see Azure Cosmos DB
Service Level Agreements

.

Checklist
Have you configured Azure Cosmos DB with reliability in mind?

＂ Deploy Azure Cosmos DB and the application in the region that corresponds to end
users.
＂ If the multi-master option is enabled on Azure Cosmos DB, it's important to
understand Conflict Types and Resolution Policies.
＂ Start with, Session, the default consistency level.
＂ Change the consistency level, depending on the data operation and usage.
＂ Evaluate connectivity modes and connection protocols in Azure Cosmos DB.
＂ Configure preferred locations.
＂ Specify index precisions.
＂ Use Azure Monitor to see the provisioned autoscale max RU/s (Autoscale Max
Throughput) and the RU/s the system is currently scaled to (Provisioned
Throughput).
＂ Understand your traffic pattern to pick the right option for provisioned throughput
types.
＂ New applications: If you don't know your traffic pattern yet, start at the entry point
RU/s to avoid over-provisioning in the beginning.

＂ Existing applications: Use Azure Monitor metrics to determine if your traffic pattern
is suitable for autoscale.
＂ Existing applications: Find the normalized request unit consumption metric of your
database or container.
＂ Existing applications: The closer the number is to 100% , the more you're fully using
your provisioned RU/s .
＂ Set provisioned RU/s to T for all hours in a month.
＂ Enable automatic failover when you configure Azure Cosmos DB accounts used for
production workloads.
＂ Implement retry logic in your client.
＂ For query-intensive workloads, use Windows 64-bit instead of Linux or Windows
32-bit host processing.

＂ To reduce latency and CPU jitter, enable accelerated networking on client virtual
machines in both Windows and Linux.
＂ Increase the number of threads and tasks.
＂ To avoid network latency, collocate client in the same region as Azure Cosmos DB.
＂ Call OpenAsync to avoid startup latency on first request.
＂ Scale out client applications across multiple servers if client consumes more than
50,000 RU/s .

＂ Select a partition key.
＂ Ensure the partition key is a property that has a value that doesn't change.
＂ You can't change a partition key after it's created with the collection.
＂ Ensure the partition key has a high cardinality.

＂ Ensure the partition key spreads RU consumption and data storage evenly across all
logical partitions.
＂ Ensure you're running read queries with the partitioned column to reduce RU
consumption and latency.
＂ Evaluate ways to improve data performance.
＂ Configure data replication to ensure Azure Cosmos DB meets the SLAs.

Configuration recommendations
Explore the following table of recommendations to optimize your Azure Cosmos DB
configuration for reliability:
Recommendation

Description

Deploy Azure
Cosmos DB and

There are two common scenarios for configuring two or more regions:
Delivering low-latency access to data to end users no matter where they're

the application in

located around the globe. Adding regional resiliency for business continuity

the region that
corresponds to

and disaster recovery (BCDR). For delivering low-latency to end users, it's
recommended to deploy both the application and add Azure Cosmos DB in

end users.

the regions that correspond to where the application's users are located.

Start with, Session,

It's the recommended consistency level to start with as it receives data later,

the default

but in the same order as the writes.

consistency level.
Change the

Depending on the type of data stored, different consistency levels may be

consistency level,
depending on the

changed on a per request basis. For example, if log data is written to Azure
Cosmos DB, an Eventual consistency may be relevant, but if writing e-

data operation
and usage.

commerce transactions, then Strong may be more appropriate.

Evaluate
connectivity

Azure Cosmos DB supports two connectivity modes. In Gateway mode,
requests are always made to the Azure Cosmos DB gateway, which forwards

modes and
connection
protocols in Azure

it to the corresponding data partitions. In Direct connectivity mode, the client
fetches the mapping of tables to partitions, and requests are made directly
against data partitions. We recommend Direct, the default mode. Azure

Cosmos DB.

Cosmos DB supports two connection protocols: HTTPS and TCP , which is the
default. TCP is recommended because it's more lightweight.

Recommendation

Description

Configure
preferred

Setting preferred locations can improve query performance. To take
advantage of global distribution, client applications can specify the ordered

locations.

preference list of regions to be used to perform document operations, which
can be done by setting the connection policy. Based on the Azure Cosmos
DB account configuration, current regional availability and the preference list
specified, the most optimal endpoint will be chosen by the SQL SDK to
perform write and read operations. This preference list is specified when
initializing a connection using the SQL SDKs. The SDKs accept an optional
parameter, PreferredLocations , that is an ordered list of Azure regions. The
SDK will automatically send all writes to the current write region. All reads
will be sent to the first available region in the PreferredLocations list. If the
request fails, the client will fail down the list to the next region, and so on.
The SDKs will only attempt to read from the regions specified in
PreferredLocations .

Specify index
precisions.

Setting these values appropriately can improve query performance and
reduce throughput requests. You can use index precision to make trade-offs
between index storage overhead and query performance. For numbers, we
recommend using the default precision configuration of -1 (maximum).
Because numbers are 8 bytes in JSON, this is equivalent to a configuration
of 8 bytes. Choosing a lower value for precision, such as 1 through 7 ,
means that values within some ranges map to the same index entry. You
reduce index storage space, but query execution might have to process
more documents. It consumes more throughput in request units. Index
precision configuration has more practical application with string ranges.
Because strings can be any arbitrary length, the choice of the index precision
might affect the performance of string range queries. It also may affect the
amount of index storage space that's required. String Range indexes can be
configured with 1 through 100 or -1 (maximum).

Existing

Normalized usage is a measure of how much you're currently using your

applications: Find
the normalized
request unit

standard (manual) provisioned throughput.

consumption
metric of your
database or
container.
Set provisioned
RU/s to T for all
hours in a month.

If you set provisioned RU/s to T and use the full amount for 66% of the
hours or more, it's estimated you'll save with standard (manual) provisioned
RU/s . If you set autoscale max RU/s to Tmax and use the full amount Tmax
for 66% of the hours or less, it's estimated you'll save with autoscale.

Recommendation

Description

Scale out client
applications
across multiple

There could be a bottleneck because of the machine capping out on CPU or
network usage.

servers if client
consumes more
than 50,000 RU/s .
Ensure the
partition key

This spread ensures even RU consumption and storage distribution across
your physical partitions.

spreads RU
consumption and
data storage
evenly across all
logical partitions.
Evaluate ways to

Best practices for query performance:

improve data
performance.

- Connection policy: Use direct connection mode.
- Connection Policy: Use the TCP protocol Call OpenAsync to avoid startup
latency on first request.
- Collocate clients in the same Azure region for performance.
- Increase number of threads and tasks.
- Install the most recent SDK.
- Use a singleton Azure Cosmos DB client for the lifetime of your application.
- Increase System.Net MaxConnections per host when using Gateway mode.
- Tune parallel queries for partitioned collections.
- Turn on server-side GC.
- Implement backoff at RetryAfter intervals.
- Scale out your client-workload.
- Cache document URIs for lower read latency.
- Tune the page size for queries and read feeds for better performance.
- Use 64-bit host processing.
- Exclude unused paths from indexing for faster writes.
- Measure and tune for lower request units and second usage.
- Handle rate limiting and request rates that are too large.
- Design for smaller documents for higher throughput.

Configure data

If you've replicated your data in more than one data center, Azure Cosmos

replication to
ensure Azure
Cosmos DB meets

DB automatically rolls over your operations should a regional data center go
offline. You can create a prioritized list of failover regions using the regions
in which your data is replicated. Even within a single data center, Azure

the SLAs

Cosmos DB automatically replicates data for high availability giving you the
choice of consistency levels.

Source artifacts

To check for cosmosdb instances where automatic failover isn't enabled, use the
following query:
SQL

Resources
|where type =~ 'Microsoft.DocumentDb/databaseAccounts'
|where properties.enableAutomaticFailover!=True

Use the following query to see the list of multiregion writes:
SQL

resources
| where type == "microsoft.documentdb/databaseaccounts"
and properties.enableMultipleWriteLocations == "true"

To view consistency levels for your Azure Cosmos DB accounts, use the following query:
SQL

Resources
| project name, type, location, consistencyLevel =
properties.consistencyPolicy.defaultConsistencyLevel
| where type == "microsoft.documentdb/databaseaccounts"
| order by name asc

To check if multilocation isn't selected, use the following query:
SQL

Resources
|where type =~ 'Microsoft.DocumentDb/databaseAccounts'
|where array_length( properties.locations) <=1

Learn more
High availability in Azure Cosmos DB
Autoscale FAQ
Performance tips for Azure Cosmos DB

Next step

Azure Cosmos DB and operational excellence

Azure Cosmos DB and operational
excellence
Article • 11/30/2022

Azure Cosmos DB

is a fully managed NoSQL database for modern app development.

Key features include:
Guaranteed speed at any scale
Simplified application development
Mission-critical ready
Fully managed and cost effective
To understand how Azure Cosmos DB promotes operational excellence for your
application workload, reference the following articles:
Monitor Azure Cosmos DB
Monitor and debug with insights in Azure Cosmos DB
Visualize Azure Cosmos DB data by using the Power BI connector
The following sections include design considerations, a configuration checklist,
recommended configuration options, and source artifacts specific to Azure Cosmos DB,
and operational excellence.

Design considerations
Azure Cosmos DB includes the following design considerations:
SLA for read availability for Database Accounts spanning two or more Azure
regions.
SLAs for throughput, consistency, availability, and latency.
SLA for both read and write availability with the configuration of multiple Azure
regions as writable endpoints.
For more granular information specific to this product, reference Azure Cosmos DB
Service Level Agreements

.

Checklist
Have you configured Azure Cosmos DB with operational excellence in mind?

＂ Monitor for normal and abnormal activity.
＂ If the multi-master option is enabled on Azure Cosmos DB, it's important to
understand Conflict Types and Resolution Policies.
＂ Start with, Session, the default consistency level.
＂ Use Azure Monitor to see the provisioned autoscale max RU/s (Autoscale Max
Throughput) and the RU/s the system is currently scaled to (Provisioned
Throughput).
＂ Understand your traffic pattern to pick the right option for provisioned throughput
types.
＂ New applications: If you don't know your traffic pattern yet, start at the entry point
RU/s to avoid over-provisioning in the beginning.

＂ Existing applications: Use Azure Monitor metrics to determine if your traffic pattern
is suitable for autoscale.
＂ Existing applications: Find the normalized request unit consumption metric of your
database or container.
＂ Existing applications: The closer the number is to 100% , the more you're fully using
your provisioned RU/s .
＂ Set provisioned RU/s to T for all hours in a month.
＂ Enable automatic failover when you configure Azure Cosmos DB accounts used for
production workloads.
＂ Implement retry logic in your client.
＂ For query-intensive workloads, use Windows 64-bit instead of Linux or Windows
32-bit host processing.

＂ To reduce latency and CPU jitter, enable accelerated networking on client virtual
machines in both Windows and Linux.
＂ Increase the number of threads and tasks.
＂ To avoid network latency, colocate the client in the same region as the Azure
Cosmos DB instance.
＂ Call OpenAsync to avoid startup latency on first request.
＂ Scale out client applications across multiple servers if client consumes more than
50,000 RU/s .

＂ Select a partition key.
＂ Ensure the partition key is a property that has a value that doesn't change.
＂ You can't change a partition key after it's created with the collection.
＂ Ensure the partition key has a high cardinality.
＂ Ensure the partition key spreads RU consumption and data storage evenly across all
logical partitions.
＂ Ensure you're running read queries with the partitioned column to reduce RU
consumption and latency.

Configuration recommendations
Explore the following table of recommendations to optimize operational excellence for
your Azure Cosmos DB configuration:
Recommendation

Description

Monitor for

The Azure Activity Log is a subscription log that provides insight into

normal and

subscription-level events that have occurred in Azure. The Activity Log

abnormal activity.

reports control plane events for your subscriptions under the Administrative
category. Using the Activity Log, you can determine the what, who, and
when for any write operations ( PUT , POST , DELETE ) taken on the resources in
your subscription. You can also understand the status of the operation and
other relevant properties. The Activity Log differs from Diagnostic Logs.
Activity Logs provide data about the operations on a resource from the
outside (the control plane). In the Azure Cosmos DB context, some of the
control plane operations include create collection, list keys, delete keys, list
database, and more. Diagnostic Logs are emitted by a resource and provide
information about the operation of that resource (the data plane). Some of
the data plane diagnostic log examples include delete, insert, ReadFeed
operation, and more.

Start with, Session,

It's the recommended consistency level to start with as it receives data later,

the default
consistency level.

but in the same order as the writes.

Existing
applications: Find

Normalized usage is a measure of how much you're currently using your
standard (manual) provisioned throughput.

the normalized
request unit
consumption
metric of your
database or
container.
Set provisioned
RU/s to T for all
hours in a month.

If you set provisioned RU/s to T and use the full amount for 66% of the
hours or more, it's estimated you'll save with standard (manual) provisioned
RU/s . If you set autoscale max RU/s to Tmax and use the full amount Tmax
for 66% of the hours or less, it's estimated you'll save with autoscale.

Scale out client

There could be a bottleneck because of the machine capping out on CPU or

applications
across multiple
servers if client

network usage.

consumes more
than 50,000 RU/s .

Recommendation

Description

Ensure the
partition key
spreads RU

This spread ensures even RU consumption and storage distribution across
your physical partitions.

consumption and
data storage
evenly across all
logical partitions.

Source artifacts
To check for cosmosdb instances where automatic failover isn't enabled, use the
following query:
SQL

Resources
|where type =~ 'Microsoft.DocumentDb/databaseAccounts'
|where properties.enableAutomaticFailover!=True

Use the following query to see the list of multiregion writes:
SQL

resources
| where type == "microsoft.documentdb/databaseaccounts"
and properties.enableMultipleWriteLocations == "true"

To view consistency levels for your Azure Cosmos DB accounts, use the following query:
SQL

Resources
| project name, type, location, consistencyLevel =
properties.consistencyPolicy.defaultConsistencyLevel
| where type == "microsoft.documentdb/databaseaccounts"
| order by name asc

To check if multilocation isn't selected, use the following query:
SQL

Resources
|where type =~ 'Microsoft.DocumentDb/databaseAccounts'
|where array_length( properties.locations) <=1

Learn more
Autoscale FAQ
Performance tips for Azure Cosmos DB

Next step
Azure Stack Hub and reliability

Azure Stack Hub and reliability
Article • 11/30/2022

Azure Stack Hub is a hybrid cloud platform that lets you provide Azure services from
your datacenter. It provides a way to run apps in an on-premises environment.
This service unlocks the following hybrid cloud use cases for customer-facing and
internal line-of-business apps:
Edge and disconnected solutions: Addresses latency and connectivity requirements
by processing data locally.
Cloud apps that meet varied regulations: Allows you to develop and deploy apps
with full flexibility to meet regulatory or policy requirements.
Cloud app model on-premises: Provides Azure services, containers, serverless, and
microservice architectures to update and extend existing apps or build new ones.
For more information, reference Azure Stack Hub overview.
To understand how Azure Stack Hub supports resiliency for your application workload,
reference the following articles:
Capacity planning for Azure Stack Hub overview
Storage Spaces Direct cache and capacity tiers
Datacenter integration planning considerations for Azure Stack Hub integrated
systems
The following sections include design considerations, a configuration checklist, and
recommended configuration options specific to Azure Stack Hub and reliability.

Design considerations
Azure Stack Hub includes the following design considerations:
Microsoft doesn't provide an SLA for Azure Stack Hub because Microsoft doesn't
have control over customer datacenter reliability, people, and processes.
Azure Stack Hub only supports a single Scale Unit (SU) within a single region,
which consists of between four and 16 servers that use Hyper-V failover clustering.
Each region serves as an independent Azure Stack Hub stamp with separate portal
and API endpoints.
Azure Stack Hub doesn't support Availability Zones because it consists of a single
region or a single physical location. High availability to cope with outages of a

single location should be implemented by using two Azure Stack Hub instances
deployed in different physical locations.
Azure Stack Hub supports premium storage to ensure compatibility. However,
provisioning premium storage accounts or disks doesn't guarantee that storage
objects will be allocated onto SSD or NVMe drives.
Azure Stack Hub supports only a subset of VPN Gateway SKUs available in Azure
with a limited bandwidth of 100 or 200 Mbps .
Only one site-to-site (S2S) VPN connection can be created between two Azure
Stack Hub deployments. This connection limit is because of a platform limitation
that allows only a single VPN connection to the same IP address. Multiple S2S VPN
connections with higher throughput can be established using third-party NVAs.
Apply general Azure configuration recommendations for all Azure Stack Hub
services.

Checklist
Have you configured Azure Stack Hub with reliability in mind?
＂ Treat Azure Stack Hub as a scale unit and deploy multiple instances to remove
Azure Stack Hub as a single point of failure for encompassed workloads.

Configuration recommendations
Consider the following recommendation table to optimize your Azure Stack Hub
configuration for reliability:
Recommendation

Description

Treat Azure Stack Hub as a scale unit and deploy

Deploy workloads in either an active-

multiple instances to remove Azure Stack Hub as a
single point of failure for encompassed workloads.

active or active-passive configuration
across Azure Stack Hub stamps or Azure.

Next step
Azure Stack Hub and operational excellence

Azure Stack Hub and operational
excellence
Article • 11/30/2022

Azure Stack Hub is a hybrid cloud platform that lets you provide Azure services from
your datacenter. It provides a way to run apps in an on-premises environment.
This service unlocks the following hybrid cloud use cases for customer-facing and
internal line-of-business apps:
Edge and disconnected solutions: Addresses latency and connectivity requirements
by processing data locally.
Cloud apps that meet varied regulations: Allows you to develop and deploy apps
with full flexibility to meet regulatory or policy requirements.
Cloud app model on-premises: Provides Azure services, containers, serverless, and
microservice architectures to update and extend existing apps or build new ones.
For more information, reference Azure Stack Hub overview.
To understand how Azure Stack Hub supports operational excellence for your
application workload, reference the following articles:
Monitor health and alerts in Azure Stack Hub
Monitor Azure Stack Hub hardware components
Manage network resources in Azure Stack Hub
The following sections include design considerations, a configuration checklist, and
recommended configuration options specific to Azure Stack Hub and operational
excellence.

Design considerations
Azure Stack Hub includes the following design considerations:
Microsoft doesn't provide an SLA for Azure Stack Hub because Microsoft doesn't
have control over customer datacenter reliability, people, and processes.
Azure Stack Hub only supports a single Scale Unit (SU) within a single region,
which consists of between four and 16 servers that use Hyper-V failover clustering.
Each region serves as an independent Azure Stack Hub stamp with separate portal
and API endpoints.

Azure Stack Hub doesn't support Availability Zones because it consists of a single
region or a single physical location. High availability to cope with outages of a
single location should be implemented by using two Azure Stack Hub instances
deployed in different physical locations.
Apply general Azure configuration recommendations for all Azure Stack Hub
services.

Checklist
Have you configured Azure Stack Hub with operational excellence in mind?
＂ Treat Azure Stack Hub as a scale unit and deploy multiple instances to remove
Azure Stack Hub as a single point of failure for encompassed workloads.

Configuration recommendations
Consider the following recommendation table to optimize your Azure Stack Hub
configuration for operational excellence:
Recommendation

Description

Treat Azure Stack Hub as a scale unit and deploy
multiple instances to remove Azure Stack Hub as a

Deploy workloads in either an activeactive or active-passive configuration

single point of failure for encompassed workloads.

across Azure Stack Hub stamps or Azure.

Next step
Storage Accounts and reliability

Storage Accounts and reliability
Article • 11/30/2022

Azure Storage Accounts are ideal for workloads that require fast and consistent
response times, or that have a high number of input output (IOP) operations per
second. Storage accounts contain all your Azure Storage data objects, which include:
Blobs
File shares
Queues
Tables
Disks
Storage accounts provide a unique namespace for your data that's accessible anywhere
over HTTP or HTTPS .
For more information about the different types of storage accounts that support
different features, reference Types of storage accounts.
To understand how an Azure storage account supports resiliency for your application
workload, reference the following articles:
Azure storage redundancy
Disaster recovery and storage account failover
The following sections include design considerations, a configuration checklist, and
recommended configuration options specific to Azure storage accounts and reliability.

Design considerations
Azure storage accounts include the following design considerations:
General purpose v1 storage accounts provide access to all Azure Storage services,
but may not have the latest features or the lower per-gigabyte pricing. It's
recommended to use general purpose v2 storage accounts, in most cases. Reasons
to use v1 include:
Applications require the classic deployment model.
Applications are transaction intensive or use significant geo-replication
bandwidth, but don't require large capacity.
The use of a Storage Service REST API that is earlier than February 14, 2014, or a
client library with a version earlier than 4.x is required. An application upgrade
isn't possible.

For more information, reference the Storage account overview.
Storage account names must be between three and 24 characters and may contain
numbers, and lowercase letters only.
For current SLA specifications, reference SLA for Storage Accounts .
Go to Azure Storage redundancy to determine which redundancy option is best for
a specific scenario.
Storage account names must be unique within Azure. No two storage accounts can
have the same name.

Checklist
Have you configured your Azure Storage Account with reliability in mind?
＂ Turn on soft delete for blob data.
＂ Use Azure AD to authorize access to blob data.
＂ Consider the principle of least privilege when you assign permissions to an Azure
AD security principal through Azure RBAC.
＂ Use managed identities to access blob and queue data.
＂ Use blob versioning or immutable blobs to store business-critical data.
＂ Restrict default internet access for storage accounts.
＂ Enable firewall rules.
＂ Limit network access to specific networks.
＂ Allow trusted Microsoft services to access the storage account.
＂ Enable the Secure transfer required option on all your storage accounts.
＂ Limit shared access signature (SAS) tokens to HTTPS connections only.
＂ Avoid and prevent using Shared Key authorization to access storage accounts.
＂ Regenerate your account keys periodically.
＂ Create a revocation plan and have it in place for any SAS that you issue to clients.
＂ Use near-term expiration times on an impromptu SAS, service SAS, or account SAS.

Configuration recommendations
Consider the following recommendations to optimize reliability when configuring your
Azure Storage Account:
Recommendation

Description

Turn on soft

Soft delete for Azure Storage blobs enables you to recover blob data after it

delete for blob

has been deleted.

data.

Recommendation

Description

Use Azure AD to
authorize access

Azure AD provides superior security and ease of use over Shared Key for
authorizing requests to blob storage. It's recommended to use Azure AD

to blob data.

authorization with your blob and queue applications when possible to
minimize potential security vulnerabilities inherent in Shared Key. For more
information, reference Authorize access to Azure blobs and queues using
Azure Active Directory.

Consider the

When assigning a role to a user, group, or application, grant that security

principle of least

principal only those permissions necessary for them to perform their tasks.

privilege when
you assign

Limiting access to resources helps prevent both unintentional and malicious
misuse of your data.

permissions to an
Azure AD security
principal through
Azure RBAC.
Use managed
identities to

Azure Blob and Queue storage support Azure AD authentication with
managed identities for Azure resources. Managed identities for Azure

access blob and

resources can authorize access to blob and queue data using Azure AD

queue data.

credentials from applications running in Azure virtual machines (VMs),
function apps, virtual machine scale sets, and other services. By using
managed identities for Azure resources together with Azure AD
authentication, you can avoid storing credentials with your applications that
run in the cloud and issues with expiring service principals. Reference
Authorize access to blob and queue data with managed identities for Azure
resources for more information.

Use blob
versioning or

Consider using Blob versioning to maintain previous versions of an object or
the use of legal holds and time-based retention policies to store blob data in

immutable blobs
to store businesscritical data.

a WORM (Write Once, Read Many) state. Immutable blobs can be read, but
can't be modified or deleted during the retention interval. For more
information, reference Store business-critical blob data with immutable
storage.

Restrict default
internet access for

By default, network access to Storage Accounts isn't restricted and is open to
all traffic coming from the internet. Access to storage accounts should be

storage accounts.

granted to specific Azure Virtual Networks only whenever possible or use
private endpoints to allow clients on a virtual network (VNet) to access data
securely over a Private Link. Reference Use private endpoints for Azure
Storage for more information. Exceptions can be made for Storage Accounts
that need to be accessible over the internet.

Enable firewall
rules.

Configure firewall rules to limit access to your storage account to requests
that originate from specified IP addresses or ranges, or from a list of subnets
in an Azure Virtual Network (VNet). For more information about configuring
firewall rules, reference Configure Azure Storage firewalls and virtual
networks.

Recommendation

Description

Limit network
access to specific

Limiting network access to networks hosting clients requiring access reduces
the exposure of your resources to network attacks either by using the built-

networks.

in Firewall and virtual networks functionality or by using private endpoints.

Allow trusted
Microsoft services
to access the

Turning on firewall rules for storage accounts blocks incoming requests for
data by default, unless the requests originate from a service operating within
an Azure Virtual Network (VNet) or from allowed public IP addresses.

storage account.

Blocked requests include those requests from other Azure services, from the
Azure portal, from logging and metrics services, and so on. You can permit
requests from other Azure services by adding an exception to allow trusted
Microsoft services to access the storage account. For more information
about adding an exception for trusted Microsoft services, reference
Configure Azure Storage firewalls and virtual networks.

Enable the Secure
transfer required
option on all your

When you enable the Secure transfer required option, all requests made
against the storage account must take place over secure connections. Any
requests made over HTTP will fail. For more information, reference Require

storage accounts.

secure transfer in Azure Storage.

Limit shared
access signature

Requiring HTTPS when a client uses a SAS token to access blob data helps to

(SAS) tokens to
HTTPS connections

minimize the risk of eavesdropping. For more information, reference Grant
limited access to Azure Storage resources using shared access signatures
(SAS).

only.
Avoid and prevent
using Shared Key

It's recommended to use Azure AD to authorize requests to Azure Storage
and to prevent Shared Key Authorization. For scenarios that require Shared

authorization to
access storage
accounts.

Key authorization, always prefer SAS tokens over distributing the Shared Key.

Regenerate your
account keys
periodically.

Rotating the account keys periodically reduces the risk of exposing your data
to malicious actors.

Create a

If a SAS is compromised, you'll want to revoke that SAS immediately. To

revocation plan
and have it in
place for any SAS

revoke a user delegation SAS, revoke the user delegation key to quickly
invalidate all signatures associated with that key. To revoke a service SAS
that's associated with a stored access policy, you can delete the stored

that you issue to
clients.

access policy, rename the policy, or change its expiry time to a time that is in
the past.

Use near-term

If a SAS is compromised, it's valid only for a short time. This practice is

expiration times
on an impromptu
SAS, service SAS,

especially important if you can't reference a stored access policy. Near-term
expiration times also limit the amount of data that can be written to a blob
by limiting the time available to upload to it. Clients should renew the SAS

or account SAS.

well before the expiration to allow time for retries if the service providing the
SAS is unavailable.

Next step
Storage Accounts and security

Storage Accounts and security
Article • 11/30/2022

Azure Storage Accounts are ideal for workloads that require fast and consistent
response times, or that have a high number of input output (IOP) operations per
second. Storage accounts contain all your Azure Storage data objects, which include:
Blobs
File shares
Queues
Tables
Disks
Storage accounts provide a unique namespace for your data that's accessible anywhere
over HTTP or HTTPS .
For more information about the different types of storage accounts that support
different features, reference Types of storage accounts.
To understand how an Azure storage account boosts security for your application
workload, reference the following articles:
Azure security baseline for Azure Storage
Azure Storage encryption for data at rest
Use private endpoints for Azure Storage
The following sections include design considerations, a configuration checklist, and
recommended configuration options specific to Azure storage accounts and security.

Design considerations
Azure storage accounts include the following design considerations:
Storage account names must be between three and 24 characters and may contain
numbers, and lowercase letters only.
For current SLA specifications, reference SLA for Storage Accounts .
Go to Azure Storage redundancy to determine which redundancy option is best for
a specific scenario.
Storage account names must be unique within Azure. No two storage accounts can
have the same name.

Checklist
Have you configured your Azure Storage Account with security in mind?
＂ Enable Azure Defender for all your storage accounts.
＂ Turn on soft delete for blob data.
＂ Use Azure AD to authorize access to blob data.
＂ Consider the principle of least privilege when you assign permissions to an Azure
AD security principal through Azure RBAC.
＂ Use managed identities to access blob and queue data.
＂ Use blob versioning or immutable blobs to store business-critical data.
＂ Restrict default internet access for storage accounts.
＂ Enable firewall rules.
＂ Limit network access to specific networks.
＂ Allow trusted Microsoft services to access the storage account.
＂ Enable the Secure transfer required option on all your storage accounts.
＂ Limit shared access signature (SAS) tokens to HTTPS connections only.
＂ Avoid and prevent using Shared Key authorization to access storage accounts.
＂ Regenerate your account keys periodically.
＂ Create a revocation plan and have it in place for any SAS that you issue to clients.
＂ Use near-term expiration times on an impromptu SAS, service SAS, or account SAS.

Configuration recommendations
Consider the following recommendations to optimize security when configuring your
Azure Storage Account:
Recommendation

Description

Enable Azure

Azure Defender for Azure Storage provides an extra layer of security

Defender for all
your storage

intelligence that detects unusual and potentially harmful attempts to access
or exploit storage accounts. Security alerts are triggered in Azure Security

accounts.

Center when anomalies in activity occur. Alerts are also sent through email
to subscription administrators, with details of suspicious activity and
recommendations on how to investigate, and remediate threats. For more
information, reference Configure Azure Defender for Azure Storage.

Turn on soft

Soft delete for Azure Storage blobs enables you to recover blob data after it

delete for blob

has been deleted.

data.

Recommendation

Description

Use Azure AD to

Azure AD provides superior security and ease of use over Shared Key for

authorize access
to blob data.

authorizing requests to blob storage. It's recommended to use Azure AD
authorization with your blob and queue applications when possible to
minimize potential security vulnerabilities inherent in Shared Key. For more
information, reference Authorize access to Azure blobs and queues using
Azure Active Directory.

Consider the
principle of least

When assigning a role to a user, group, or application, grant that security
principal only those permissions necessary for them to complete their tasks.

privilege when

Limiting access to resources helps prevent both unintentional and malicious

you assign
permissions to an

misuse of your data.

Azure AD security
principal through
Azure RBAC.
Use managed
identities to

Azure Blob and Queue storage support Azure AD authentication with
managed identities for Azure resources. Managed identities for Azure

access blob and

resources can authorize access to blob and queue data using Azure AD

queue data.

credentials from applications running in Azure virtual machines (VMs),
function apps, virtual machine scale sets, and other services. By using
managed identities for Azure resources together with Azure AD
authentication, you can avoid storing credentials with your applications that
run in the cloud and issues with expiring service principals. Reference
Authorize access to blob and queue data with managed identities for Azure
resources for more information.

Use blob

Consider using Blob versioning to maintain previous versions of an object or

versioning or
immutable blobs

the use of legal holds and time-based retention policies to store blob data in
a WORM (Write Once, Read Many) state. Immutable blobs can be read, but

to store businesscritical data.

can't be modified or deleted during the retention interval. For more
information, reference Store business-critical blob data with immutable
storage.

Restrict default
internet access for
storage accounts.

By default, network access to Storage Accounts isn't restricted and is open to
all traffic coming from the internet. Access to storage accounts should be
granted to specific Azure Virtual Networks only whenever possible or use
private endpoints to allow clients on a virtual network (VNet) to access data
securely over a Private Link. Reference Use private endpoints for Azure
Storage for more information. Exceptions can be made for Storage Accounts
that need to be accessible over the internet.

Enable firewall
rules.

Configure firewall rules to limit access to your storage account to requests
that originate from specified IP addresses or ranges, or from a list of subnets
in an Azure Virtual Network (VNet). For more information about configuring
firewall rules, reference Configure Azure Storage firewalls and virtual
networks.

Recommendation

Description

Limit network
access to specific
networks.

Limiting network access to networks hosting clients requiring access reduces
the exposure of your resources to network attacks either by using the builtin Firewall and virtual networks functionality or by using private endpoints.

Allow trusted

Turning on firewall rules for storage accounts blocks incoming requests for

Microsoft services
to access the
storage account.

data by default, unless the requests originate from a service operating within
an Azure Virtual Network (VNet) or from allowed public IP addresses.
Blocked requests include those requests from other Azure services, from the
Azure portal, from logging and metrics services, and so on. You can permit
requests from other Azure services by adding an exception to allow trusted
Microsoft services to access the storage account. For more information
about adding an exception for trusted Microsoft services, reference
Configure Azure Storage firewalls and virtual networks.

Enable the Secure

When you enable the Secure transfer required option, all requests made

transfer required
option on all your
storage accounts.

against the storage account must take place over secure connections. Any
requests made over HTTP will fail. For more information, reference Require
secure transfer in Azure Storage.

Limit shared
access signature
(SAS) tokens to

Requiring HTTPS when a client uses a SAS token to access blob data helps to

HTTPS connections

minimize the risk of eavesdropping. For more information, reference Grant
limited access to Azure Storage resources using shared access signatures
(SAS).

only.
Avoid and prevent
using Shared Key
authorization to

It's recommended to use Azure AD to authorize requests to Azure Storage
and to prevent Shared Key Authorization. For scenarios that require Shared
Key authorization, always prefer SAS tokens over distributing the Shared Key.

access storage
accounts.
Regenerate your

Rotating the account keys periodically reduces the risk of exposing your data

account keys
periodically.

to malicious actors.

Create a
revocation plan

If a SAS is compromised, you'll want to revoke that SAS immediately. To
revoke a user delegation SAS, revoke the user delegation key to quickly

and have it in
place for any SAS
that you issue to

invalidate all signatures associated with that key. To revoke a service SAS
that's associated with a stored access policy, you can delete the stored
access policy, rename the policy, or change its expiry time to a time that is in

clients.

the past.

Use near-term
expiration times

If a SAS is compromised, it's valid only for a short time. This practice is
especially important if you can't reference a stored access policy. Near-term

on an impromptu
SAS, service SAS,
or account SAS.

expiration times also limit the amount of data that can be written to a blob
by limiting the time available to upload to it. Clients should renew the SAS
well before the expiration to allow time for retries if the service providing the
SAS is unavailable.

Next step
Storage Accounts and cost optimization

Storage Accounts and cost optimization
Article • 11/30/2022

Azure Storage Accounts are ideal for workloads that require fast and consistent
response times, or that have a high number of input output (IOP) operations per
second. Storage accounts contain all your Azure Storage data objects, which include:
Blobs
File shares
Queues
Tables
Disks
Storage accounts provide a unique namespace for your data that's accessible anywhere
over HTTP or HTTPS .
For more information about the different types of storage accounts that support
different features, reference Types of storage accounts.
To understand how an Azure storage account can optimize costs for your workload,
reference the following articles:
Plan and manage costs for Azure Blob Storage
Optimize costs for Blob storage with reserved capacity
Understand how reservation discounts are applied to Azure storage services
The following sections include design considerations, a configuration checklist, and
recommended configuration options specific to Azure storage accounts and cost
optimization.

Design considerations
Azure storage accounts include the following design considerations:
Periodically dispose and clean up unused storage resources, such as unattached
disks and old snapshots.
Consider Azure Blob access time tracking and access time-based lifecycle
management.
Transition your data from a hotter access tier to a cooler access tier if there's no
access for a period.
Delete your data if there's no access for an extended period.

Considerations

Description

Periodically dispose and clean up unused

Unused storage resources can incur cost and it's a

storage resources, such as unattached
disks and old snapshots.

good idea to regularly perform cleanup to reduce
cost.

Consider Azure Blob access time tracking
and access time-based lifecycle
management.

Minimize your storage cost automatically by setting
up a policy based on last access time to: costeffective backup storage options.

Transition your data from a hotter access
tier to a cooler access tier if there's no

For example:
- Hot to cool

access for a period

- Cool to archive
- Hot to archive

Checklist
Have you configured your Azure Storage Account with cost optimization in mind?
＂ Consider cost savings by reserving data capacity for block blob storage.
＂ Organize data into access tiers.
＂ Use lifecycle policy to move data between access tiers.

Configuration recommendations
Consider the following recommendations to optimize costs when configuring your
Azure Storage Account:
Recommendation

Description

Consider cost

Save money by reserving capacity for block blob and for Azure Data Lake

savings by

Storage gen 2 data in standard storage account when customer commits to

reserving data
capacity for block

one or three years reservation.

blob storage.
Organize data into

You can reduce cost by placing blob data into the most cost-effective access

access tiers.

tier. Place frequently accessed data in a hot tier, less frequent in a cold or
archive tier. Use Premium storage for workloads with high transaction
volumes or workloads where latency is critical.

Recommendation

Description

Use lifecycle policy
to move data

Lifecycle management policy periodically moves data between tiers. Policies
can move data based on rules specified by the user. For example, you can

between access

create rules that move blobs to the archive tier if that blob has been

tiers.

modified in 90 days. Unused data can be removed completely using a policy.
By creating policies that adjust the access tier of your data, you can design
the least expensive storage options for your requirements.

Next step
Storage Accounts and operational excellence

Storage Accounts and operational
excellence
Article • 11/30/2022

Azure Storage Accounts are ideal for workloads that require fast and consistent
response times, or that have a high number of input output (IOP) operations per
second. Storage accounts contain all your Azure Storage data objects, which include:
Blobs
File shares
Queues
Tables
Disks
Storage accounts provide a unique namespace for your data that's accessible anywhere
over HTTP or HTTPS .
For more information about the different types of storage accounts that support
different features, reference Types of storage accounts.
To understand how an Azure storage account can promote operational excellence for
your workload, reference the following articles:
Best practices for monitoring Azure Blob Storage
Use Azure Storage analytics to collect logs and metrics data
Azure Storage analytics logging
The following sections include design considerations, a configuration checklist, and
recommended configuration options specific to Azure storage accounts and operational
excellence.

Design considerations
Azure storage accounts include the following design considerations:
General purpose v1 storage accounts provide access to all Azure Storage services,
but may not have the latest features or the lower per-gigabyte pricing. It's
recommended to use general purpose v2 storage accounts, in most cases. Reasons
to use v1 include:
Applications require the classic deployment model.

Applications are transaction intensive or use significant geo-replication
bandwidth, but don't require large capacity.
The use of a Storage Service REST API that is earlier than February 14, 2014, or a
client library with a version earlier than 4.x is required. An application upgrade
isn't possible.
For more information, reference the Storage account overview.
Storage account names must be between three and 24 characters and may contain
numbers, and lowercase letters only.
For current SLA specifications, reference SLA for Storage Accounts .
Go to Azure Storage redundancy to determine which redundancy option is best for
a specific scenario.
Storage account names must be unique within Azure. No two storage accounts can
have the same name.

Checklist
Have you configured your Azure Storage Account with operational excellence in
mind?
＂ Enable Azure Defender for all your storage accounts.
＂ Turn on soft delete for blob data.
＂ Use Azure AD to authorize access to blob data.
＂ Consider the principle of least privilege when you assign permissions to an Azure
AD security principal through Azure RBAC.
＂ Use managed identities to access blob and queue data.
＂ Use blob versioning or immutable blobs to store business-critical data.
＂ Restrict default internet access for storage accounts.
＂ Enable firewall rules.
＂ Limit network access to specific networks.
＂ Allow trusted Microsoft services to access the storage account.
＂ Enable the Secure transfer required option on all your storage accounts.
＂ Limit shared access signature (SAS) tokens to HTTPS connections only.
＂ Avoid and prevent using Shared Key authorization to access storage accounts.
＂ Regenerate your account keys periodically.
＂ Create a revocation plan and have it in place for any SAS that you issue to clients.
＂ Use near-term expiration times on an impromptu SAS, service SAS, or account SAS.

Configuration recommendations

Consider the following recommendations to optimize operational excellence when
configuring your Azure Storage Account:
Recommendation

Description

Enable Azure
Defender for all

Azure Defender for Azure Storage provides an extra layer of security
intelligence that detects unusual and potentially harmful attempts to access

your storage

or exploit storage accounts. Security alerts are triggered in Azure Security

accounts.

Center when anomalies in activity occur. Alerts are also sent through email
to subscription administrators, with details of suspicious activity and
recommendations on how to investigate, and remediate threats. For more
information, reference Configure Azure Defender for Azure Storage.

Turn on soft

Soft delete for Azure Storage blobs enables you to recover blob data after it

delete for blob

has been deleted.

data.
Use Azure AD to

Azure AD provides superior security and ease of use over Shared Key for

authorize access
to blob data.

authorizing requests to blob storage. It's recommended to use Azure AD
authorization with your blob and queue applications when possible to
minimize potential security vulnerabilities inherent in Shared Key. For more
information, reference Authorize access to Azure blobs and queues using
Azure Active Directory.

Consider the
principle of least

When assigning a role to a user, group, or application, grant that security
principal only those permissions necessary for them to complete their tasks.

privilege when

Limiting access to resources helps prevent both unintentional and malicious

you assign
permissions to an

misuse of your data.

Azure AD security
principal through
Azure RBAC.
Use managed

Azure Blob and Queue storage support Azure AD authentication with

identities to
access blob and
queue data.

managed identities for Azure resources. Managed identities for Azure
resources can authorize access to blob and queue data using Azure AD
credentials from applications running in Azure virtual machines (VMs),
function apps, virtual machine scale sets, and other services. By using
managed identities for Azure resources together with Azure AD
authentication, you can avoid storing credentials with your applications that
run in the cloud and issues with expiring service principals. Reference
Authorize access to blob and queue data with managed identities for Azure
resources for more information.

Use blob
versioning or
immutable blobs

Consider using Blob versioning to maintain previous versions of an object or
the use of legal holds and time-based retention policies to store blob data in
a WORM (Write Once, Read Many) state. Immutable blobs can be read, but

to store businesscritical data.

can't be modified or deleted during the retention interval. For more
information, reference Store business-critical blob data with immutable
storage.

Recommendation

Description

Restrict default
internet access for

By default, network access to Storage Accounts isn't restricted and is open to
all traffic coming from the internet. Access to storage accounts should be

storage accounts.

granted to specific Azure Virtual Networks only whenever possible or use
private endpoints to allow clients on a virtual network (VNet) to access data
securely over a Private Link. Reference Use private endpoints for Azure
Storage for more information. Exceptions can be made for Storage Accounts
that need to be accessible over the internet.

Enable firewall

Configure firewall rules to limit access to your storage account to requests

rules.

that originate from specified IP addresses or ranges, or from a list of subnets
in an Azure Virtual Network (VNet). For more information about configuring
firewall rules, reference Configure Azure Storage firewalls and virtual
networks.

Limit network
access to specific
networks.

Limiting network access to networks hosting clients requiring access reduces
the exposure of your resources to network attacks either by using the builtin Firewall and virtual networks functionality or by using private endpoints.

Allow trusted
Microsoft services
to access the

Turning on firewall rules for storage accounts blocks incoming requests for
data by default, unless the requests originate from a service operating within
an Azure Virtual Network (VNet) or from allowed public IP addresses.

storage account.

Blocked requests include those requests from other Azure services, from the
Azure portal, from logging and metrics services, and so on. You can permit
requests from other Azure services by adding an exception to allow trusted
Microsoft services to access the storage account. For more information
about adding an exception for trusted Microsoft services, reference
Configure Azure Storage firewalls and virtual networks.

Enable the Secure

When you enable the Secure transfer required option, all requests made

transfer required
option on all your
storage accounts.

against the storage account must take place over secure connections. Any
requests made over HTTP will fail. For more information, reference Require
secure transfer in Azure Storage.

Limit shared
access signature
(SAS) tokens to

Requiring HTTPS when a client uses a SAS token to access blob data helps to

HTTPS connections

minimize the risk of eavesdropping. For more information, reference Grant
limited access to Azure Storage resources using shared access signatures
(SAS).

only.
Avoid and prevent
using Shared Key
authorization to

It's recommended to use Azure AD to authorize requests to Azure Storage
and to prevent Shared Key Authorization. For scenarios that require Shared
Key authorization, always prefer SAS tokens over distributing the Shared Key.

access storage
accounts.
Regenerate your

Rotating the account keys periodically reduces the risk of exposing your data

account keys
periodically.

to malicious actors.

Recommendation

Description

Create a
revocation plan
and have it in

If a SAS is compromised, you'll want to revoke that SAS immediately. To
revoke a user delegation SAS, revoke the user delegation key to quickly
invalidate all signatures associated with that key. To revoke a service SAS

place for any SAS
that you issue to
clients.

that's associated with a stored access policy, you can delete the stored
access policy, rename the policy, or change its expiry time to a time that is in
the past.

Use near-term

If a SAS is compromised, it's valid only for a short time. This practice is

expiration times
on an impromptu
SAS, service SAS,

especially important if you can't reference a stored access policy. Near-term
expiration times also limit the amount of data that can be written to a blob
by limiting the time available to upload to it. Clients should renew the SAS

or account SAS.

well before the expiration to allow time for retries if the service providing the
SAS is unavailable.

Next step
Disks and cost optimization

Disks and cost optimization
Article • 08/02/2023

Azure managed disks are block-level storage volumes that are managed by Azure and
used with Azure Virtual Machines. Managed disks are like a physical disk in an onpremises server, but these disks are virtualized.
Available disk types include:
Ultra disks
Premium solid-state drives (SSD)
Standard SSDs
Standard hard disk drives (HDD)
For more information about the different types of disks, reference Azure managed disk
types.
To understand how Azure managed disks are cost-effective solutions for your workload,
reference the following articles:
Overview of Azure Disk Backup
Understand how your reservation discount is applied to Azure disk storage
Reduce costs with Azure Disks Reservation
The following sections include design considerations, a configuration checklist, and
recommended configuration options specific to Azure managed disks and cost
optimization.

Design considerations
Azure Disks include the following design considerations:
Use a shared disk for workload, such as SQL server failover cluster instance (FCI),
file server for general use (IW workload), and SAP ASCS/SCS.
Consider selective disk backup and restore for Azure VMs.
Premium storage also features free bursting, combined with an understanding of
workload patterns, offers an effective SKU selection and cost optimization strategy
for IaaS infrastructure, enabling high performance without excessive overprovisioning and minimizing the cost of unused capacity.

Considerations

Description

Use a shared disk for workload, such as
SQL server failover cluster instance (FCI),
file server for general use (IW workload),

You can use shared disks to enable cost-effective
clustering instead of setting up your own shared
disks through S2D (Storage Spaces Direct). Sample

and SAP ASCS/SCS.

workloads that would benefit from shared disks
include:
- SQL Server Failover Cluster Instances (FCI)
- Scale-out File Server (SoFS)
- File Server for General Use (IW workload)
- SAP ASCS/SCS

Checklist
Have you configured your Azure managed disk with cost optimization in mind?
＂ Configure data and log files on different disks for database workloads.
＂ Use bursting for P20 and lower disks for workloads, such as batch jobs, workloads,
which handle traffic spikes, and to improve OS boot time.
＂ Consider using Premium disks (P30 and greater).

Configuration recommendations
Consider the following recommendations to optimize costs when configuring your
Azure managed disk:
Recommendation

Description

Configure data and log files on

You can optimize IaaS DB workload performance by

different disks for database

configuring system, data, and log files to be on different disk

workloads.

SKUs (leveraging Premium Disks for data and Ultra Disks for
logs satisfies most production scenarios). Ultra Disk cost and
performance can be optimized by taking advantage of
configuring capacity, IOPS, and throughput independently.
Also, you can dynamically configure these attributes. Example
workloads include:
- SQL on IaaS
- Cassandra DB
- Maria DB
- MySql and
- Mongo DB on IaaS

Use bursting for P20 and lower

Azure Disks offer various SKUs and sizes to satisfy different

disks for workloads, such as
batch jobs, workloads, which

workload requirements. Some of the more recent features
could help further optimize cost performance of existing disk
use cases. You can use disk bursting for Premium (disks P20

Recommendation

Description

handle traffic spikes, and to

and lower). Example scenarios that could benefit from this

improve OS boot time.

feature include:
- Improving OS boot time
- Handling batch jobs
- Handling traffic spikes

Consider using Premium disks
(P30 and greater).

Premium Disks (P30 and greater) can be reserved (one or three
years) at a discounted price.

Optimize with managed disks.

Determine your performance needs in combination with your
storage capacity needs, accounting for fluctuating workload
patterns. Knowing your needs allows you to determine what
disk type and disk size you need. Some higher performance
disk types offer extra cost optimization features and strategies.

Consider Ephemeral OS disks.

Ephemeral OS disks provide top-tier performance at no extra
cost, but are non-persistent, have limited capacity, and are
restricted to OS and temp disk use only.

Next step
Event Grid and reliability

Event Grid and reliability
Article • 11/30/2022

Azure Event Grid lets you easily build applications with event-based architectures. This
solution has build-in support for events coming from Azure services, like storage blobs
and resource groups. Event Grid also has support for your own events, using custom
topics.
For more information about using Event Grid, reference Create and route custom events
with Azure Event Grid.
To understand how using Event Grid creates a more reliable workload, reference Serverside geo disaster recovery in Azure Event Grid.
The following sections are specific to Azure Event Grid and reliability:
Design considerations
Configuration checklist
Recommended configuration options
Source artifacts

Design considerations
Azure Event Grid provides an uptime SLA. For more information, reference SLA for Event
Grid .

Checklist
Have you configured Azure Event Grid with reliability in mind?
＂ Deploy an Event Grid instance per region, in case of a multi-region Azure solution.
＂ Monitor Event Grid for failed event delivery.
＂ Use batched events.
＂ Event batches can't exceed 1MB in size.
＂ Configure and optimize batch-size selection during load testing.
＂ Ensure Event Grid messages are accepted with HTTP 200-204 responses only if
delivering to an endpoint that holds custom code.
＂ Monitor Event Grid for failed event publishing.

Configuration recommendations

Consider the following recommendations to optimize reliability when configuring Azure
Event Grid:
Recommendation

Description

Monitor Event
Grid for failed

The Delivery Failed metric will increase every time a message can't be

event delivery.

If an event can't be lost, set up a Dead-Letter-Queue (DLQ) storage account.
A DLQ account is where events that can't be delivered after the maximum

delivered to an event handler (timeout or a non- 200-204 HTTP status code).

retry count will be placed. Optionally, implement a notification system on
the DLQ storage account, for example, by handling a new file event through
Event Grid.
Use batched
events in high-

The service will deliver a json array with multiple events to the subscribers,

throughput

to process these arrays.

instead of an array with one event. The consuming application must be able

scenarios.
Event batches

If the message payload is large, only one or a few messages will fit in the

can't exceed 1MB

batch. The consuming service will need to process more event batches. If
your event has a large payload, consider storing it elsewhere, such as in blob

in size.

storage, and passing a reference in the event. When integrating with thirdparty services through the CloudEvents schema, it's not recommended to
exceed 64KB events.
Configure and

Batch size selection depends on the payload size and the message volume.

optimize batchsize selection
during load
testing.
Monitor Event

The Unmatched metric will show messages that are published, but not

Grid for failed
event publishing.

matched to any subscription. Depending on your application architecture,
the latter may be intentional.

Source artifacts
To determine the Input Schema type for all available Event Grid topics, use the following
query:
SQL

Resources
| where type == 'microsoft.eventgrid/topics'
| project name, resourceGroup, location, subscriptionId,
properties['inputSchema']

To retrieve the Resource ID of existing private endpoints for Event Grid domains, use the
following query:
SQL

Resources
| where type == 'microsoft.eventgrid/domains' and
notnull(properties['privateEndpointConnections'])
| mvexpand properties['privateEndpointConnections']
| project-rename privateEndpointConnections =
properties_privateEndpointConnections
| project name, resourceGroup, location, subscriptionId,
privateEndpointConnections['properties']['privateEndpoint']['id']

To identify Public Network Access status for all available Event Grid domains, use the
following query:
SQL

Resources
| where type == 'microsoft.eventgrid/domains'
| project name, resourceGroup, location, subscriptionId,
properties['publicNetworkAccess']

To identify Firewall Rules for all public Event Grid domains, use the following query:
SQL

Resources
| where type == 'microsoft.eventgrid/domains' and
properties['publicNetworkAccess'] == 'Enabled'
| project name, resourceGroup, location, subscriptionId,
properties['inboundIpRules']

To identify Firewall Rules for all public Event Grid topics, use the following query:
SQL

Resources
| where type == 'microsoft.eventgrid/topics' and
properties['publicNetworkAccess'] == 'Enabled'
| project name, resourceGroup, location, subscriptionId,
properties['inboundIpRules']

To retrieve the Resource ID of existing private endpoints for Event Grid topics, use the
following query:

SQL

Resources
| where type == 'microsoft.eventgrid/topics' and
notnull(properties['privateEndpointConnections'])
| mvexpand properties['privateEndpointConnections']
| project-rename privateEndpointConnections =
properties_privateEndpointConnections
| project name, resourceGroup, location, subscriptionId,
privateEndpointConnections['properties']['privateEndpoint']['id']

To determine the Input Schema type for all available Event Grid domains, use the
following schema:
SQL

Resources
| where type == 'microsoft.eventgrid/domains'
| project name, resourceGroup, location, subscriptionId,
properties['inputSchema']

To identify Public Network Access status for all available Event Grid topics, use the
following query:
SQL

Resources
| where type == 'microsoft.eventgrid/topics'
| project name, resourceGroup, location, subscriptionId,
properties['publicNetworkAccess']

Next step
Event Grid and operational excellence

Event Grid and operational excellence
Article • 11/30/2022

Azure Event Grid lets you easily build applications with event-based architectures. This
solution has build-in support for events coming from Azure services, like storage blobs
and resource groups. Event Grid also has support for your own events, using custom
topics.
For more information about using Event Grid, reference Create and route custom events
with Azure Event Grid.
To understand how using Event Grid promotes operational excellence for your workload,
reference Diagnostic logs for Event Grid topics and Event Grid domains.
The following sections are specific to Azure Event Grid and operational excellence:
Design considerations
Configuration checklist
Recommended configuration options
Source artifacts

Design considerations
Azure Event Grid provides an uptime SLA. For more information, reference SLA for Event
Grid .

Checklist
Have you configured Azure Event Grid with operational excellence in mind?
＂ Monitor Event Grid for failed event delivery.
＂ Use batched events.
＂ Event batches can't exceed 1MB in size.
＂ Configure and optimize batch-size selection during load testing.
＂ Ensure Event Grid messages are accepted with HTTP 200-204 responses only if
delivering to an endpoint that holds custom code.
＂ Monitor Event Grid for failed event publishing.

Configuration recommendations

Consider the following recommendations to optimize operational excellence when
configuring Azure Event Grid:
Recommendation

Description

Monitor Event
Grid for failed

The Delivery Failed metric will increase every time a message can't be

event delivery.

If an event can't be lost, set up a Dead-Letter-Queue (DLQ) storage account.
A DLQ account is where events that can't be delivered after the maximum

delivered to an event handler (timeout or a non- 200-204 HTTP status code).

retry count will be placed. Optionally, implement a notification system on
the DLQ storage account, for example, by handling a new file event through
Event Grid.
Use batched
events in high-

The service will deliver a json array with multiple events to the subscribers,

throughput

to process these arrays.

instead of an array with one event. The consuming application must be able

scenarios.
Event batches

If the message payload is large, only one or a few messages will fit in the

can't exceed 1MB

batch. The consuming service will need to process more event batches. If
your event has a large payload, consider storing it elsewhere, such as in blob

in size.

storage, and passing a reference in the event. When integrating with thirdparty services through the CloudEvents schema, it's not recommended to
exceed 64KB events.
Configure and

Batch size selection depends on the payload size and the message volume.

optimize batchsize selection
during load
testing.
Monitor Event

The Unmatched metric will show messages that are published, but not

Grid for failed
event publishing.

matched to any subscription. Depending on your application architecture,
the latter may be intentional.

Source artifacts
To determine the Input Schema type for all available Event Grid topics, use the following
query:
SQL

Resources
| where type == 'microsoft.eventgrid/topics'
| project name, resourceGroup, location, subscriptionId,
properties['inputSchema']

To retrieve the Resource ID of existing private endpoints for Event Grid domains, use the
following query:
SQL

Resources
| where type == 'microsoft.eventgrid/domains' and
notnull(properties['privateEndpointConnections'])
| mvexpand properties['privateEndpointConnections']
| project-rename privateEndpointConnections =
properties_privateEndpointConnections
| project name, resourceGroup, location, subscriptionId,
privateEndpointConnections['properties']['privateEndpoint']['id']

To identify Public Network Access status for all available Event Grid domains, use the
following query:
SQL

Resources
| where type == 'microsoft.eventgrid/domains'
| project name, resourceGroup, location, subscriptionId,
properties['publicNetworkAccess']

To identify Firewall Rules for all public Event Grid domains, use the following query:
SQL

Resources
| where type == 'microsoft.eventgrid/domains' and
properties['publicNetworkAccess'] == 'Enabled'
| project name, resourceGroup, location, subscriptionId,
properties['inboundIpRules']

To identify Firewall Rules for all public Event Grid topics, use the following query:
SQL

Resources
| where type == 'microsoft.eventgrid/topics' and
properties['publicNetworkAccess'] == 'Enabled'
| project name, resourceGroup, location, subscriptionId,
properties['inboundIpRules']

To retrieve the Resource ID of existing private endpoints for Event Grid topics, use the
following query:

SQL

Resources
| where type == 'microsoft.eventgrid/topics' and
notnull(properties['privateEndpointConnections'])
| mvexpand properties['privateEndpointConnections']
| project-rename privateEndpointConnections =
properties_privateEndpointConnections
| project name, resourceGroup, location, subscriptionId,
privateEndpointConnections['properties']['privateEndpoint']['id']

To determine the Input Schema type for all available Event Grid domains, use the
following schema:
SQL

Resources
| where type == 'microsoft.eventgrid/domains'
| project name, resourceGroup, location, subscriptionId,
properties['inputSchema']

To identify Public Network Access status for all available Event Grid topics, use the
following query:
SQL

Resources
| where type == 'microsoft.eventgrid/topics'
| project name, resourceGroup, location, subscriptionId,
properties['publicNetworkAccess']

Next step
Event Hubs and reliability

Event Hubs and reliability
Article • 11/30/2022

Azure Event Hubs is a scalable event processing service that ingests and processes large
volumes of events and data, with low latency and high reliability. It can receive and
process millions of events per second. Data sent to an event hub can be transformed
and stored by using any real-time analytics provider or batching and storage adapters.
For more information about using Event Hubs, reference the Azure Event Hubs
documentation to learn how to use Event Hubs to ingest millions of events per second
from connected devices and applications.
To understand how using Event Hubs creates a more reliable workload, reference Azure
Event Hubs - Geo-disaster recovery.
The following sections are specific to Azure Event Hubs and reliability:
Design considerations
Configuration checklist
Recommended configuration options
Source artifacts

Design considerations
Azure Event Hubs provides an uptime SLA. For more information, reference SLA for
Event Hubs .

Checklist
Have you configured Azure Event Hubs with reliability in mind?
＂ Create SendOnly and ListenOnly policies for the event publisher and consumer,
respectively.
＂ When using the SDK to send events to Event Hubs, ensure the exceptions thrown
by the retry policy ( EventHubsException or OperationCancelledException ) are
properly caught.
＂ In high-throughput scenarios, use batched events.
＂ Every consumer can read events from one to 32 partitions.
＂ When developing new applications, use EventProcessorClient (.NET and Java) or
EventHubConsumerClient (Python and JavaScript) as the client SDK.

＂ As part of your solution-wide availability and disaster recovery strategy, consider
enabling the Event Hubs geo disaster-recovery option.
＂ When a solution has a large number of independent event publishers, consider
using Event Publishers for fine-grained access control.
＂ Don't publish events to a specific partition.
＂ When publishing events frequently, use the AMQP protocol when possible.
＂ The number of partitions reflect the degree of downstream parallelism you can
achieve.
＂ Ensure each consuming application uses a separate consumer group and only one
active receiver per consumer group is in place.
＂ When using the Capture feature, carefully consider the configuration of the time
window and file size, especially with low event volumes.

Configuration recommendations
Consider the following recommendations to optimize reliability when configuring Azure
Event Hubs:
Recommendation

Description

When using the SDK to send

When using HTTPS , ensure a proper retry pattern is implemented.

events to Event Hubs, ensure
the exceptions thrown by the
retry policy
( EventHubsException or
OperationCancelledException )

are properly caught.
In high-throughput scenarios,

The service will deliver a json array with multiple events to the

use batched events.

subscribers, instead of an array with one event. The consuming
application must process these arrays.

Every consumer can read

To achieve maximum scale on the side of the consuming

events from one to 32

application, every consumer should read from a single partition.

partitions.
When developing new
applications, use
EventProcessorClient (.NET

and Java) or
EventHubConsumerClient

(Python and JavaScript) as the
client SDK.

EventProcessorHost has been deprecated.

Recommendation

Description

As part of your solution-wide

This option allows the creation of a secondary namespace in a

availability and disaster
recovery strategy, consider

different region. Only the active namespace receives messages at
any time. Messages and events aren't replicated to the secondary

enabling the Event Hubs geo

region. The RTO for the regional failover is up to 30 minutes.

disaster-recovery option.

Confirm this RTO aligns with the requirements of the customer
and fits in the broader availability strategy. If a higher RTO is
required, consider implementing a client-side failover pattern.

When a solution has a large

Event Publishers automatically set the partition key to the

number of independent event

publisher name, so this feature should only be used if the events

publishers, consider using
Event Publishers for fine-

originate from all publishers evenly.

grained access control.
Don't publish events to a

If ordering events is essential, implement ordering downstream

specific partition.

or use a different messaging service instead.

When publishing events

AMQP has higher network costs when initializing the session, but

frequently, use the AMQP

HTTPS requires TLS overhead for every request. AMQP has higher

protocol when possible.

performance for frequent publishers.

The number of partitions

For maximum throughput, use the maximum number of

reflect the degree of

partitions ( 32 ) when creating the Event Hub. The maximum

downstream parallelism you
can achieve.

number of partitions will allow you to scale up to 32 concurrent

When using the Capture

Data Lake will charge for minimal file size for storage (gen1) or

feature, carefully consider the
configuration of the time

minimal transaction size (gen2). If you set the time window so
low that the file hasn't reached minimum size, you'll incur extra

window and file size,
especially with low event
volumes.

cost.

processing entities and will offer the highest send and receive
availability.

Source artifacts
To find Event Hubs namespaces with Basic SKU, use the following query:
SQL

Resources
| where type == 'microsoft.eventhub/namespaces'
| where sku.name == 'Basic'
| project resourceGroup, name, sku.name

Next step
Event Hubs and operational excellence

Event Hubs and operational excellence
Article • 11/30/2022

Azure Event Hubs is a scalable event processing service that ingests and processes large
volumes of events and data, with low latency and high reliability. It can receive and
process millions of events per second. Data sent to an event hub can be transformed
and stored by using any real-time analytics provider or batching and storage adapters.
For more information about using Event Hubs, reference the Azure Event Hubs
documentation to learn how to use Event Hubs to ingest millions of events per second
from connected devices and applications.
To understand ways using Event Hubs helps you achieve operational excellence for your
workload, reference the following articles:
Monitor Azure Event Hubs
Stream Azure Diagnostics data using Event Hubs
Scaling with Event Hubs
The following sections are specific to Azure Event Hubs and operational excellence:
Design considerations
Configuration checklist
Recommended configuration options
Source artifacts

Design considerations
Azure Event Hubs provides an uptime SLA. For more information, reference SLA for
Event Hubs .

Checklist
Have you configured Azure Event Hubs with operational excellence in mind?
＂ Create SendOnly and ListenOnly policies for the event publisher and consumer,
respectively.
＂ When using the SDK to send events to Event Hubs, ensure the exceptions thrown
by the retry policy ( EventHubsException or OperationCancelledException ) are
properly caught.
＂ In high-throughput scenarios, use batched events.

＂ Every consumer can read events from one to 32 partitions.
＂ When developing new applications, use EventProcessorClient (.NET and Java) or
EventHubConsumerClient (Python and JavaScript) as the client SDK.

＂ As part of your solution-wide availability and disaster recovery strategy, consider
enabling the Event Hubs geo disaster-recovery option.
＂ When a solution has a large number of independent event publishers, consider
using Event Publishers for fine-grained access control.
＂ Don't publish events to a specific partition.
＂ When publishing events frequently, use the AMQP protocol when possible.
＂ The number of partitions reflect the degree of downstream parallelism you can
achieve.
＂ Ensure each consuming application uses a separate consumer group and only one
active receiver per consumer group is in place.
＂ When using the Capture feature, carefully consider the configuration of the time
window and file size, especially with low event volumes.

Configuration recommendations
Consider the following recommendations to optimize reliability when configuring Azure
Event Hubs:
Recommendation

Description

When using the SDK to send

When using HTTPS , ensure a proper retry pattern is implemented.

events to Event Hubs, ensure
the exceptions thrown by the
retry policy
( EventHubsException or
OperationCancelledException )

are properly caught.
In high-throughput scenarios,

The service will deliver a json array with multiple events to the

use batched events.

subscribers, instead of an array with one event. The consuming
application must process these arrays.

Every consumer can read

To achieve maximum scale on the side of the consuming

events from one to 32

application, every consumer should read from a single partition.

partitions.

Recommendation

Description

When developing new

EventProcessorHost has been deprecated.

applications, use
EventProcessorClient (.NET

and Java) or
EventHubConsumerClient

(Python and JavaScript) as the
client SDK.
As part of your solution-wide

This option allows the creation of a secondary namespace in a

availability and disaster
recovery strategy, consider

different region. Only the active namespace receives messages at
any time. Messages and events aren't replicated to the secondary

enabling the Event Hubs geo

region. The RTO for the regional failover is up to 30 minutes.

disaster-recovery option.

Confirm this RTO aligns with the requirements of the customer
and fits in the broader availability strategy. If a higher RTO is
required, consider implementing a client-side failover pattern.

When a solution has a large

Event Publishers automatically set the partition key to the

number of independent event

publisher name, so this feature should only be used if the events

publishers, consider using
Event Publishers for fine-

originate from all publishers evenly.

grained access control.
Don't publish events to a

If ordering events is essential, implement ordering downstream

specific partition.

or use a different messaging service instead.

When publishing events

AMQP has higher network costs when initializing the session, but

frequently, use the AMQP

HTTPS requires TLS overhead for every request. AMQP has higher

protocol when possible.

performance for frequent publishers.

The number of partitions

For maximum throughput, use the maximum number of

reflect the degree of
downstream parallelism you
can achieve.

partitions ( 32 ) when creating the Event Hub. The maximum
number of partitions will allow you to scale up to 32 concurrent

When using the Capture
feature, carefully consider the

Data Lake will charge for minimal file size for storage (gen1) or
minimal transaction size (gen2). If you set the time window so

configuration of the time
window and file size,
especially with low event

low that the file hasn't reached minimum size, you'll incur extra
cost.

processing entities and will offer the highest send and receive
availability.

volumes.

Source artifacts
To find Event Hubs namespaces with Basic SKU, use the following query:

SQL

Resources
| where type == 'microsoft.eventhub/namespaces'
| where sku.name == 'Basic'
| project resourceGroup, name, sku.name

Next step
Service Bus and reliability

Service Bus and reliability
Article • 09/12/2023

Fully manage enterprise message brokering with message queues and publish-subscribe
topics used in Azure Service Bus. This service stores messages in a broker (for example, a
queue) until the consuming party is ready to receive the messages.
Benefits include:
Load-balancing across competing workers.
Safely routing and transferring data and control across service, and application
boundaries.
Coordinating transactional work that requires a high-degree of reliability.
For more information about using Service Bus, reference Azure Service Bus Messaging.
Learn how to set up messaging that connects applications and services across onpremises and cloud environments.
To understand how Service Bus contributes to a reliable workload, reference the
following topics:
Asynchronous messaging patterns and high availability
Azure Service Bus Geo-disaster recovery
Handling outages and disasters
The following sections are specific to Azure Service Bus and reliability:
Design considerations
Configuration checklist
Recommended configuration options
Source artifacts

Design considerations
Maximize reliability with an Azure Service Bus uptime SLA. Properly configured
applications can send or receive messages, or do other operations on a deployed Queue
or Topic. For more information, reference the Service Bus SLA .
Other design considerations include:
Express Entities
Partitioned queues and topics

Besides the documentation on Service Bus Premium and Standard messaging tiers, the
following features are only available on the Premium Stock Keeping Unit (SKU):
Dedicated resources.
Virtual network integration: Limits the networks that can connect to the Service
Bus instance. Requires Service Endpoints to be enabled on the subnet. There are
Trusted Microsoft services that are not supported when implementing Virtual
Networks(for example, integration with Event Grid). For more information,
reference Allow access to Azure Service Bus namespace from specific virtual
networks.
Private endpoints.
IP Filtering/Firewall: Restrict connections to only defined IPv4 addresses or IPv4
address ranges.
Availability zones: Provides enhanced availability by spreading replicas across
availability zones within one region at no extra cost.
Event Grid integration: Available event types.
Scale messaging units.
Geo-Disaster Recovery (paired namespace).
CMK (Customer Managed Key): Azure Service Bus encrypts data at rest and
automatically decrypts it when accessed, but customers can also bring their own
customer-managed key.
When deploying Service Bus with Geo-disaster recovery and in availability zones, the
Service Level Operation (SLO) increases dramatically, but does not change the uptime
SLA.

Checklist
Have you configured Azure Service Bus with reliability in mind?
＂ Evaluate Premium tier benefits of Azure Service Bus.
＂ Ensure that Service Bus Messaging Exceptions are handled properly.
＂ Connect to Service Bus with the Advanced Messaging Queue Protocol (AMQP) and
use Service Endpoints or Private Endpoints when possible.
＂ Review the Best Practices for performance improvements using Service Bus
Messaging.
＂ Implement geo-replication on the sender and receiver side to protect against
outages and disasters.
＂ Configure Geo-Disaster.
＂ If you need mission-critical messaging with queues and topics, Service Bus Premium
is recommended with Geo-Disaster Recovery.

＂ Configure Zone Redundancy in the Service Bus namespace (only available with
Premium tier).
＂ Implement high availability for the Service Bus namespace.
＂ Ensure related messages are delivered in guaranteed order.
＂ Evaluate different Java Messaging Service (JMS) features through the JMS API.
＂ Use .NET Nuget packages to communicate with Service Bus messaging entities.
＂ Implement resilience for transient fault handling when sending or receiving
messages.
＂ Implement auto-scaling of messaging units.

Configuration recommendations
Consider the following recommendations to optimize reliability when configuring Azure
Service Bus:
Recommendation

Description

Evaluate Premium tier benefits

Consider migrating to the Premium tier of Service Bus to take

of Azure Service Bus.

advantage of platform-supported outage and disaster
protection.

Connect to Service Bus with

This recommendation keeps traffic on the Azure Backbone. Note:

the AMQP protocol and use
Service Endpoints or Private

The default connection protocol for Microsoft.Azure.ServiceBus
and Windows.Azure.ServiceBus namespaces is AMQP .

Endpoints when possible.
Implement geo-replication on

Standard tier supports only the implementation of sender and

the sender and receiver side
to protect against outages

receiver-side geo-redundancy. An outage or disaster in an Azure
Region could cause downtime for your solution.

and disasters.
Configure Geo-Disaster.

- Active/Active
- Active/Passive
- Paired Namespace (Active/Passive)
- Note: The secondary region should preferably be an Azure
paired region.

If you need mission-critical

Choosing the pattern is dependent on the business

messaging with queues and
topics, Service Bus Premium is
recommended with Geo-

requirements and the recovery time objective (RTO).

Disaster Recovery.
Configure Zone Redundancy
in the Service Bus namespace

Zone Redundancy includes three copies of the messaging store.
One zone is allocated as the primary messaging store and the

(only available with Premium
tier).

other zones are allocated as secondaries. If the primary zone
becomes unavailable, a secondary is promoted to primary with

Recommendation

Description
no perceivable downtime. Availability Zones are available in a
subset of Azure Regions with new regions added regularly.

Implement high availability for

Premium tier supports Geo-disaster recovery and replication at

the Service Bus namespace.

the namespace level. At this level, Premium tier provides high
availability for metadata disaster recovery using primary and
secondary disaster recovery namespaces.

Ensure related messages are
delivered in guaranteed order.

Be aware of the requirement to set a Partition Key, Session ID, or
Message ID on each message to ensure related messages send
to the same partition in the messaging entity.

Evaluate different JMS

Features available through the JMS 2.0 API (and its Software

features through the JMS API.

Development Kit (SDK)) are not the same as the features
available through the native SDK. For example, Service Bus
Sessions are not available in JMS.

Implement resilience for
transient fault handling when
sending or receiving

It is essential to implement suitable transient fault handling and
error handling for send and receive operations to maintain
throughput and to prevent message loss.

messages.
Implement auto-scaling of
messaging units, to ensure
that you have enough
resources available for your
workloads.

Source artifacts
To identify premium Service Bus Instances that are not using private endpoints, use
the following query:
Kusto

Resources
| where
type == 'microsoft.servicebus/namespaces'
| where
sku.tier == 'Premium'
and isempty(properties.privateEndpointConnections)

To identify Service Bus Instances that are not on the premium tier, use the
following query:
Kusto

Resources
| where
type == 'microsoft.servicebus/namespaces'
| where
sku.tier != 'Premium'

To identify premium Service Bus Instances that are not zone redundant, use the
following query:
Kusto

Resources
| where
type == 'microsoft.servicebus/namespaces'
| where
sku.tier == 'Premium'
and properties.zoneRedundant == 'false'

Next step
Service Bus and operational excellence

Service Bus and operational excellence
Article • 11/30/2022

Fully manage enterprise message brokering with message queues and publish-subscribe
topics using Azure Service Bus. This service stores messages in a broker (for example, a
queue) until the consuming party is ready to receive the messages.
Benefits include:
Load-balancing work across competing workers.
Safely routing and transferring data and control across service, and application
boundaries.
Coordinating transactional work that requires a high-degree of reliability.
For more information about using Service Bus, reference Azure Service Bus Messaging.
Learn how to set up messaging that connects applications and services across onpremises and cloud environments.
To understand how Service Bus promotes operational excellence, reference the following
topics:
Handling outages and disasters
Throttling operations on Azure Service Bus
The following sections are specific to Azure Service Bus and operational excellence:
Design considerations
Configuration checklist
Recommended configuration options
Source artifacts

Design considerations
Maximize reliability with an Azure Service Bus uptime Service Level Agreement (SLA).
Properly configured applications can send or receive messages, or do other operations
on a deployed Queue or Topic. For more information, reference the Service Bus SLA
Other design considerations include:
Express Entities
Partitioned queues and topics

.

Besides the documentation on Service Bus Premium and Standard messaging tiers, the
following features are only available on the Premium Stock Keeping Unit (SKU):
Dedicated resources.
Virtual network integration: Limits the networks that can connect to the Service
Bus instance. Requires Service Endpoints to be enabled on the subnet. There are
Trusted Microsoft services that are not supported when implementing Virtual
Networks (for example, integration with Event Grid). For more information,
reference Allow access to Azure Service Bus namespace from specific virtual
networks.
Private endpoints.
IP Filtering/Firewall: Restrict connections to only defined IPv4 addresses or IPv4
address ranges.
Availability zones: Provides enhanced availability by spreading replicas across
availability zones within one region at no extra cost.
Event Grid integration: Available event types.
Scale messaging units.
Geo-Disaster Recovery (paired namespace).
BYOK (Bring Your Own Key): Azure Service Bus encrypts data at rest and
automatically decrypts it when accessed, but customers can also bring their own
customer-managed key.
When deploying Service Bus with Geo-disaster recovery and in availability zones, the
Service Level Objective (SLO) increases dramatically, but does not change the uptime
SLA.

Checklist
Have you configured Azure Service Bus with operational excellence in mind?
＂ Ensure that Service Bus Messaging Exceptions are handled properly.
＂ Connect to Service Bus with the Advanced Message Queuing Protocol (AMQP) and
use Service Endpoints or Private Endpoints when possible.
＂ Establish a process to actively monitor the dead-letter queue (dlq) messages.
＂ Review the Best Practices for performance improvements using Service Bus
Messaging.
＂ Analyze the differences between Azure Storage Queues and Azure Service Bus
Queues.

Configuration recommendations

Consider the following recommendation to optimize reliability when configuring Azure
Service Bus:
Recommendation

Description

Connect to Service Bus
with the AMQP protocol

This recommendation keeps traffic on the Azure Backbone. Note: The
default connection protocol for Microsoft.Azure.ServiceBus and

and use Service

Windows.Azure.ServiceBus namespaces is AMQP .

Endpoints or Private
Endpoints when possible.
Establish a process to

The dead-letter queue holds messages that cannot be processed or

actively monitor the
dead-letter queue (dlq)

cannot be delivered to any receiver. It is important to monitor this
queue to examine the issue cause, apply required corrections, and to

messages.

resubmit messages.

Analyze the differences

You will find that Azure Service Bus Messaging Entities are more

between Azure Storage

advanced, reliable, and feature-rich than Azure Storage Queues. If

Queues and Azure
Service Bus Queues.

your requirement is for simple queue messaging without
requirements for reliable messaging, then Azure Storage Queues may
be a more suitable option.

Source artifacts
To identify premium Service Bus Instances that aren't using private endpoints, use
the following query:
Kusto

Resources
| where
type == 'microsoft.servicebus/namespaces'
| where
sku.tier == 'Premium'
and isempty(properties.privateEndpointConnections)

To identify Service Bus Instances that are not on the premium tier, use the
following query:
Kusto

Resources
| where
type == 'microsoft.servicebus/namespaces'
| where
sku.tier != 'Premium'

Next step
Queue Storage and reliability

Queue Storage and reliability
Article • 11/30/2022

Azure Queue Storage is a service for storing large numbers of messages that you can
access from anywhere in the world through authenticated calls using HTTP or HTTPS .
Queues are commonly used to create a backlog of work to process asynchronously.
For more information about Queue Storage, reference What is Azure Queue Storage?
To understand how Azure Queue Storage helps maintain a reliable workload, reference
the following topics:
Azure Storage redundancy
Disaster recovery and storage account failover
The following sections are specific to Azure Queue Storage and reliability:
Design considerations
Configuration checklist
Recommended configuration options
Source artifacts

Design considerations
Azure Queue Storage follows the SLA statements of the general Storage Account
service

.

Checklist
Have you configured Azure Queue Storage with reliability in mind?
＂ Since Storage Queues are a part of the Azure Storage service, refer to the Storage
Accounts configuration checklist and recommendations for reliability.
＂ Ensure that for all clients accessing the storage account, implement a proper retry
policy.
＂ Refer to the Storage guidance for specifics on data recovery for storage accounts.
＂ For an SLA increase, use geo-redundant storage.
＂ Use geo-zone-redundant storage (GZRS) or read-access geo-zone-redundant
storage (RA-GZRS) for durability and protection against failover if an entire data
center becomes unavailable.

Configuration recommendations
Consider the following recommendations to optimize reliability when configuring your
Azure Queue Storage:
Recommendation

Description

For an SLA increase, use geo-redundant

Use geo-redundant storage with read access and

storage.

configure the client application to fail over to
secondary read endpoints if the primary endpoints fail
to respond. This consideration should be part of the
overall reliability strategy of your solution.

Use geo-zone-redundant storage (GZRS)

For more information, reference Azure Storage

or read-access geo-zone-redundant

redundancy.

storage (RA-GZRS) for durability and
protection against failover if an entire
data center becomes unavailable.

Source artifacts
To identify storage accounts using locally redundant storage (LRS), use the following
query:
SQL

Resources
| where
type == 'microsoft.storage/storageaccounts'
and sku.name =~ 'Standard_LRS'

To identify storage accounts using V1 storage accounts, use the following query:
SQL

Resources
| where
type == 'microsoft.storage/storageaccounts'
and kind == 'Storage'

Next step
Queue Storage and operational excellence

Queue Storage and operational
excellence
Article • 11/30/2022

Azure Queue Storage is a service for storing large numbers of messages that you can
access from anywhere in the world through authenticated calls using HTTP or HTTPS .
Queues are commonly used to create a backlog of work to process asynchronously.
For more information about Queue Storage, reference What is Azure Queue Storage?
To understand how Azure Queue Storage promotes operational excellence, reference
the following topics:
Monitoring Azure Queue Storage
Best practices for monitoring Azure Queue Storage
The following sections are specific to Azure Queue Storage and operational excellence:
Design considerations
Configuration checklist
Source artifacts

Design considerations
Azure Queue Storage follows the SLA statements of the general Storage Account
service

.

Checklist
Have you configured Azure Queue Storage with operational excellence in mind?
＂ Since Storage Queues are a part of the Azure Storage service, refer to the Storage
Accounts configuration checklist and recommendations for operational excellence.
＂ Ensure that for all clients accessing the storage account, implement a proper retry
policy.
＂ Refer to the Storage guidance for specifics on data recovery for storage accounts.

Source artifacts
To identify storage accounts using V1 storage accounts, use the following query:

SQL

Resources
| where
type == 'microsoft.storage/storageaccounts'
and kind == 'Storage'

Next step
IoT Hub and reliability

IoT Hub and reliability
Article • 11/30/2022

Azure IoT Hub is a managed service hosted in the cloud that acts as a central message
hub for communication between an IoT application and its attached devices. You can
connect millions of devices and their backend solutions reliably and securely. Almost
any device can be connected to an IoT Hub.
IoT Hub supports monitoring to help you track device creation, device connections, and
device failures.
IoT Hub also supports the following messaging patterns:
Device-to-cloud telemetry
Uploading files from devices
Request-reply methods to control your devices from the cloud
For more information about IoT Hub, reference IoT Concepts and Azure IoT Hub.
To understand how IoT Hub supports a reliable workload, reference the following topics:
IoT Hub high availability and disaster recovery
How to achieve cross-region High Availability with IoT Hub
How to clone an Azure IoT Hub to another region
The following sections are specific to Azure IoT Hub and reliability:
Design considerations
Configuration checklist
Recommended configuration options

Design considerations
For more information about the Azure IoT Hub Service Level Agreement, reference SLA
for Azure IoT Hub

.

Checklist
Have you configured Azure IoT Hub with reliability in mind?
＂ Provision a second IoT Hub in another region and have routing logic on the device.
＂ Use the AMQP or MQTT protocol when sending events frequently.

＂ Use only certificates validated by a root CA in the production environment if you're
using X.509 certificates for the device connection.
＂ For maximum throughput, use the maximum number of partitions ( 32 ) when
creating the IoT Hub, if you're planning to use the built-in endpoint.
＂ For scaling, increase the tier and allocated IoT Hub units instead of adding more
than one IoT Hub per region.
＂ In high-throughput scenarios, use batched events.
＂ If you require the minimum possible latency, don't use routing and read the events
from the built-in endpoint.
＂ As part of your solution-wide availability and disaster recovery strategy, consider
using the IoT Hub cross-region Disaster Recovery option.
＂ When reading device telemetry from the built-in Event Hub-compatible endpoint,
refer to the Event Hub consumers recommendation.
＂ When using an SDK to send events to IoT Hubs, ensure the exceptions thrown by
the retry policy ( EventHubsException or OperationCancelledException ) are properly
caught.
＂ To avoid telemetry interruption due to throttling and a fully used quota, consider
adding a custom auto-scaling solution.

Configuration recommendations
Consider the following recommendations to optimize reliability when configuring Azure
IoT Hub:
Recommendation

Description

Provision a second IoT Hub in
another region and have

These configurations can be further enhanced with a Concierge
Service.

routing logic on the device.
Use the AMQP or MQTT

AMQP and MQTT have higher network costs when initializing the

protocol when sending

session, however HTTPS requires extra TLS overhead for every

events frequently.

request. AMQP and MQTT have higher performance for frequent
publishers.

Use only certificates validated

Make sure you have processes in place to update the certificate

by a root CA in the

before they expire.

production environment if
you're using X.509 certificates
for the device connection.

Recommendation

Description

For maximum throughput,
use the maximum number of

The number of device-to-cloud partitions for the Event Hubcompatible endpoint reflect the degree of downstream

partitions ( 32 ) when creating

parallelism you can achieve. This will allow you to scale up to 32

the IoT Hub, if you're

concurrent processing entities and will offer the highest send and

planning to use the built-in
endpoint.

receive availability. This number can't be changed after creation.

For scaling, increase the tier
and allocated IoT Hub units

Adding more than one IoT Hub per region doesn't offer extra
resiliency because all hubs can run on the same underlying

instead of adding more than

cluster.

one IoT Hub per region.
In high-throughput scenarios,

The service will deliver an array with multiple events to the

use batched events.

consumers, instead of an array with one event. The consuming
application must process these arrays.

If you require the minimum
possible latency, don't use

When using message routing in IoT Hub, latency of the message
delivery increases. On average, latency shouldn't exceed 500 ms ,

routing and read the events

but there's no guarantee for the delivery latency.

from the built-in endpoint.
As part of your solution-wide

This option will move the IoT Hub endpoint to the paired Azure

availability and disaster
recovery strategy, consider

region. Only the device registry gets replicated. Events aren't
replicated to the secondary region. The RTO for the customer-

using the IoT Hub cross-

initiated failover is between 10 minutes to a couple of hours. For a

region Disaster Recovery

Microsoft-initiated failover, the RTO is 2-26 hours. Confirm this

option.

RTO aligns with the requirements of the customer and fits in the
broader availability strategy. If a higher RTO is required, consider
implementing a client-side failover pattern.

When using an SDK to send

When using HTTPS , implement a proper retry pattern.

events to IoT Hub, ensure the
exceptions thrown by the
retry policy
( EventHubsException or
OperationCancelledException )

are properly caught.

Next step
IoT Hub and operational excellence

IoT Hub and operational excellence
Article • 11/30/2022

Azure IoT Hub is a managed service hosted in the cloud that acts as a central message
hub for communication between an IoT application and its attached devices. You can
connect millions of devices and their backend solutions reliably and securely. Almost
any device can be connected to an IoT Hub.
IoT Hub supports monitoring to help you track device creation, device connections, and
device failures.
IoT Hub also supports the following messaging patterns:
Device-to-cloud telemetry
Uploading files from devices
Request-reply methods to control your devices from the cloud
For more information about IoT Hub, reference IoT Concepts and Azure IoT Hub.
To understand how IoT Hub promotes operational excellence, reference the following
topics:
Tutorial: Set up and use metrics and logs with an IoT Hub
Monitoring Azure IoT Hub
Trace Azure IoT device-to-cloud messages with distributed tracing (preview)
Check IoT Hub service and resource health
The following sections are specific to Azure IoT Hub and operational excellence:
Design considerations
Configuration checklist
Recommended configuration options

Design considerations
For more information about the Azure IoT Hub Service Level Agreement, reference SLA
for Azure IoT Hub

.

Checklist
Have you configured Azure IoT Hub with operational excellence in mind?

＂ Provision a second IoT Hub in another region and have routing logic on the device.
＂ Use the AMQP or MQTT protocol when sending events frequently.
＂ Use only certificates validated by a root CA in the production environment if you're
using X.509 certificates for the device connection.
＂ For maximum throughput, use the maximum number of partitions ( 32 ) when
creating the IoT Hub, if you're planning to use the built-in endpoint.
＂ For scaling, increase the tier and allocated IoT Hub units instead of adding more
than one IoT Hub per region.
＂ In high-throughput scenarios, use batched events.
＂ If you require the minimum possible latency, don't use routing and read the events
from the built-in endpoint.
＂ As part of your solution-wide availability and disaster recovery strategy, consider
using the IoT Hub cross-region Disaster Recovery option.
＂ When reading device telemetry from the built-in Event Hub-compatible endpoint,
refer to the Event Hub consumers recommendation.
＂ When using an SDK to send events to IoT Hubs, ensure the exceptions thrown by
the retry policy ( EventHubsException or OperationCancelledException ) are properly
caught.
＂ To avoid telemetry interruption due to throttling and a fully used quota, consider
adding a custom auto-scaling solution.

Configuration recommendations
Consider the following recommendations for increasing operational excellence when
configuring Azure IoT Hub:
Recommendation

Description

Provision a second IoT Hub in

These configurations can be further enhanced with a Concierge

another region and have

Service.

routing logic on the device.
Use the AMQP or MQTT

AMQP and MQTT have higher network costs when initializing the

protocol when sending
events frequently.

session, however HTTPS requires extra TLS overhead for every
request. AMQP and MQTT have higher performance for frequent
publishers.

Use only certificates validated
by a root CA in the
production environment if
you're using X.509 certificates
for the device connection.

Make sure you have processes in place to update the certificate
before they expire.

Recommendation

Description

For maximum throughput,

The number of device-to-cloud partitions for the Event Hub-

use the maximum number of
partitions ( 32 ) when creating

compatible endpoint reflect the degree of downstream
parallelism you can achieve. This will allow you to scale up to 32

the IoT Hub, if you're

concurrent processing entities and will offer the highest send and

planning to use the built-in
endpoint.

receive availability. This number can't be changed after creation.

For scaling, increase the tier

Adding more than one IoT Hub per region doesn't offer extra

and allocated IoT Hub units
instead of adding more than

resiliency because all hubs can run on the same underlying
cluster.

one IoT Hub per region.
In high-throughput scenarios,

The service will deliver an array with multiple events to the

use batched events.

consumers, instead of an array with one event. The consuming
application must process these arrays.

If you require the minimum

When using message routing in IoT Hub, latency of the message

possible latency, don't use
routing and read the events

delivery increases. On average, latency shouldn't exceed 500 ms ,
but there's no guarantee for the delivery latency.

from the built-in endpoint.
As part of your solution-wide

This option will move the IoT Hub endpoint to the paired Azure

availability and disaster

region. Only the device registry gets replicated. Events aren't

recovery strategy, consider
using the IoT Hub cross-

replicated to the secondary region. The RTO for the customerinitiated failover is between 10 minutes to a couple of hours. For a

region Disaster Recovery

Microsoft-initiated failover, the RTO is 2-26 hours. Confirm this

option.

RTO aligns with the requirements of the customer and fits in the
broader availability strategy. If a higher RTO is required, consider
implementing a client-side failover pattern.

When using an SDK to send
events to IoT Hub, ensure the

When using HTTPS , implement a proper retry pattern.

exceptions thrown by the
retry policy
( EventHubsException or
OperationCancelledException )

are properly caught.

Next step
IoT Hub Device Provisioning Service and reliability

IoT Hub Device Provisioning Service and
reliability
Article • 11/30/2022

The IoT Hub Device Provisioning Service (DPS) is a helper service for IoT Hub. DPS
enables zero-touch, just-in-time provisioning to the right IoT Hub without requiring
human intervention. IoT Hub DPS allows customers to provision millions of devices in a
secure and scalable manner.
For more information, reference What is Azure IoT Hub Device Provisioning Service?
To understand how IoT Hub DPS can increase workload reliability, reference IoT Hub
DPS supports Availability Zones.

Design considerations
For more information about the Service Level Agreement for Azure IoT Hub DPS,
reference SLA for Azure IoT Hub

.

Next step
IoT Hub Device Provisioning Service and operational excellence

IoT Hub Device Provisioning Service and
operational excellence
Article • 11/30/2022

The IoT Hub Device Provisioning Service (DPS) is a helper service for IoT Hub. DPS
enables zero-touch, just-in-time provisioning to the right IoT Hub without requiring
human intervention. IoT Hub DPS allows customers to provision millions of devices in a
secure and scalable manner.
For more information, reference What is Azure IoT Hub Device Provisioning Service?
To understand how IoT Hub DPS promotes operational excellence, reference How to
manage device enrollments with Azure portal.

Design considerations
For more information about the Service Level Agreement for Azure IoT Hub DPS,
reference SLA for Azure IoT Hub

.

Next step
Application Delivery (General) and reliability

Application Delivery (General) and
reliability
Article • 02/28/2023

Application Delivery (General) explores key recommendations to deliver internal-facing
and external-facing applications in the Azure network through a secure, highly scalable,
and highly available way. General Application Delivery can be handled using a
combination of the following networking services in Azure:
Content Delivery Network (CDN)
Azure Front Door Service
Traffic Manager
Application Gateway
Internet Analyzer
Load Balancer
For more information, reference Azure networking services overview.
The following sections are specific to general Application Delivery and reliability:
Design considerations
Configuration checklist
Recommended configuration options

Design considerations
Application Delivery in Azure includes the following design considerations:
Azure Load Balancer (internal and public) provides high availability for application
delivery at either a regional or global level. (Standard tier only)
Azure Traffic manager allows the delivery of applications through DNS redirection,
including traffic using protocols other than HTTP/S .
Azure Front Door allows the secure delivery of highly available HTTP/S applications
across Azure regions.
Azure Application Gateway allows the secure delivery of HTTP/S applications at a
regional level.

Checklist

Have you configured your Application Delivery networking services with reliability in
mind?
＂ Use Azure Traffic Manager to deliver global applications that span protocols other
than HTTP/S .
＂ When using Azure Front Door and Application Gateway to protect HTTP/S
applications, use Web Application Firewall (WAF) policies in Front Door and lock
down Application Gateway to receive traffic only from Azure Front Door.
＂ Create a separate health endpoint on the backend that the health probe can use.
The health endpoint can aggregate the state of the critical services and
dependencies needed to serve requests.
＂ Enable health probes for backends.
＂ Deploy Application Gateway v2 or third-party NVAs used for inbound HTTP/S
connections together with the applications that they're securing.
＂ When doing global load balancing for HTTP/S applications, use Front Door over
Traffic Manager.
＂ Use a third-party Network Virtual Appliance (NVA) if Application Gateway v2 can't
be used for the security of HTTP/S applications.
＂ For secure delivery of HTTP/S applications, ensure you enable Web Application
Firewall (WAF) protection and policies.
＂ Application delivery for both internal and external facing applications should be
part of the application.
＂ Global HTTP/S applications that span Azure regions should be delivered and
protected using Azure Front Door with Web Application Firewall (WAF) policies.
＂ All public IP addresses in the solution should be protected with a DDoS Standard
protection plan.

Configuration recommendations
Consider the following recommendations to optimize reliability when configuring your
Application Delivery networking services:
Recommendation

Description

Use Azure Traffic Manager to

Traffic manager doesn't forward traffic, but only completes the

deliver global applications that

DNS redirection. The connection from the client is established

span protocols other than
HTTP/S .

directly to the target using any protocol.

Recommendation

Description

When using Azure Front Door

Certain scenarios might force a customer to implement rules

and Application Gateway to
protect HTTP/S applications,

specifically on AppGateway: For example, if ModSec CRS 2.2.9 ,
CRS 3.0 or CRS 3.1 rules are required, rules can be only

use WAF policies in Front Door

implemented on AppGateway. Conversely, rate-limiting and

and lock down Application
Gateway to receive traffic only

geo-filtering are available only on Azure Front Door, not on

from Azure Front Door.

AppGateway. Instructions on how to lock down traffic can be
found at FAQ for Azure Front Door.

Create a separate health

For more information, reference Health Endpoint Monitoring

endpoint on the backend that
the health probe can use. The

pattern.

health endpoint can aggregate
the state of the critical services
and dependencies needed to
serve requests.
Enable health probes for

Health probes are http(s) endpoints that are queried by the

backends.

load balancer (Azure Front Door, Traffic Manager, AppGateway)
service to determine if the backend is healthy enough to handle
requests.

Deploy Application Gateway

Don't centrally manage Application Gateway v2 or third-party

v2 or third-party NVAs used
for inbound HTTP/S

NVAs within the organization and share with other workloads.

connections together with the
applications that they're
securing.
When doing global load
balancing for HTTP/S

- Azure Front Door optimizes the number of TCP connections to
the backend when forwarding traffic.

applications, use Front Door
over Traffic Manager.

- Changes to the routing configuration, based on backend
health, are instantaneous. With Traffic Manager, traffic will point
to the original backend until a new DNS lookup occurs, plus
potential time for DNS propagation.
- Front Door supports caching on global edge nodes, negating
the need for a separate CDN service.
- Front Door supports Web Application Firewall rules, negating
the need for a separate WAF service.

For secure delivery of HTTP/S

Enable WAF protection and policies in either Application

applications, ensure you
enable Web Application
Firewall (WAF) protection and

Gateway or Front Door.

policies.

Recommendation

Description

Application delivery for both
internal and external facing
applications should be part of

Don't centrally manage Application Delivery within an
organization.

the application.

Next step
Application Delivery (General) and operational excellence

Application Delivery (General) and
operational excellence
Article • 11/30/2022

Application Delivery (General) explores key recommendations to deliver internal-facing
and external-facing applications in the Azure network through a secure, highly scalable,
and highly available way. General Application Delivery can be handled using a
combination of the following networking services in Azure:
Content Delivery Network (CDN)
Azure Front Door Service
Traffic Manager
Application Gateway
Internet Analyzer
Load Balancer
For more information, reference Azure networking services overview.
The following sections are specific to general Application Delivery and operational
excellence:
Design considerations
Configuration checklist
Recommended configuration options

Design considerations
Application Delivery in Azure includes the following design considerations:
Azure Load Balancer (internal and public) provides high availability for application
delivery at a regional level. (Standard tier only)
Azure Traffic manager allows the delivery of applications through DNS redirection,
including traffic using protocols other than HTTP/S .
Azure Front Door allows the secure delivery of highly available HTTP/S applications
across Azure regions.
Azure Application Gateway allows the secure delivery of HTTP/S applications at a
regional level.

Checklist

Have you configured your Application Delivery networking services with operational
excellence in mind?
＂ Use Azure Traffic Manager to deliver global applications that span protocols other
than HTTP/S .
＂ When using Azure Front Door and Application Gateway to protect HTTP/S
applications, use Web Application Firewall (WAF) policies in Front Door and lock
down Application Gateway to receive traffic only from Azure Front Door.
＂ Create a separate health endpoint on the backend that the health probe can use.
The health endpoint can aggregate the state of the critical services and
dependencies needed to serve requests.
＂ Enable health probes for backends.
＂ Deploy Application Gateway v2 or third-party NVAs used for inbound HTTP/S
connections together with the applications that they're securing.
＂ When doing global load balancing for HTTP/S applications, use Front Door over
Traffic Manager.
＂ Use a third-party Network Virtual Appliance (NVA) if Application Gateway v2 can't
be used for the security of HTTP/S applications.
＂ For secure delivery of HTTP/S applications, ensure you enable Web Application
Firewall (WAF) protection and policies.
＂ Application delivery for both internal and external facing applications should be
part of the application.
＂ Global HTTP/S applications that span Azure regions should be delivered and
protected using Azure Front Door with Web Application Firewall (WAF) policies.
＂ All public IP addresses in the solution should be protected with a DDoS Standard
protection plan.

Configuration recommendations
Consider the following recommendations for operational excellence when configuring
your Application Delivery networking services:
Recommendation

Description

Use Azure Traffic Manager to

Traffic manager doesn't forward traffic, but only completes the

deliver global applications that

DNS redirection. The connection from the client is established

span protocols other than
HTTP/S .

directly to the target using any protocol.

Recommendation

Description

When using Azure Front Door

Certain scenarios might force a customer to implement rules

and Application Gateway to
protect HTTP/S applications,

specifically on AppGateway: For example, if ModSec CRS 2.2.9 ,
CRS 3.0 or CRS 3.1 rules are required, rules can be only

use WAF policies in Front Door

implemented on AppGateway. Conversely, rate-limiting and

and lock down Application
Gateway to receive traffic only

geo-filtering are available only on Azure Front Door, not on

from Azure Front Door.

AppGateway. Instructions on how to lock down traffic can be
found at FAQ for Azure Front Door.

Create a separate health

For more information, reference Health Endpoint Monitoring

endpoint on the backend that
the health probe can use. The

pattern.

health endpoint can aggregate
the state of the critical services
and dependencies needed to
serve requests.
Enable health probes for

Health probes are http(s) endpoints that are queried by the

backends.

load balancer (Azure Front Door, Traffic Manager, AppGateway)
service to determine if the backend is healthy enough to handle
requests.

Deploy Application Gateway

Don't centrally manage Application Gateway v2 or third-party

v2 or third-party NVAs used
for inbound HTTP/S

NVAs within the organization and share with other workloads.

connections together with the
applications that they're
securing.
When doing global load
balancing for HTTP/S

- Azure Front Door optimizes the number of TCP connections to
the backend when forwarding traffic.

applications, use Front Door
over Traffic Manager.

- Changes to the routing configuration, based on backend
health, are instantaneous. With Traffic Manager, traffic will point
to the original backend until a new DNS lookup occurs, plus
potential time for DNS propagation.
- Front Door supports caching on global edge nodes, negating
the need for a separate CDN service.
- Front Door supports Web Application Firewall rules, negating
the need for a separate WAF service.

For secure delivery of HTTP/S

Enable WAF protection and policies in either Application

applications, ensure you
enable Web Application
Firewall (WAF) protection and

Gateway or Front Door.

policies.

Recommendation

Description

Application delivery for both
internal and external facing
applications should be part of

Don't centrally manage Application Delivery within an
organization.

the application.

Next step
Azure Well-Architected Framework review - Azure Application Gateway v2

Azure Well-Architected Framework
review - Azure Application Gateway v2
Article • 03/20/2023

This article provides architectural best practices for the Azure Application Gateway v2
family of SKUs. The guidance is based on the five pillars of architectural excellence:
Reliability
Security
Cost optimization
Operational excellence
Performance efficiency
We assume that you have a working knowledge of Azure Application Gateway and are
well-versed with v2 SKU features. For more information, see Azure Application Gateway
features.

Prerequisites
Understanding the Well-Architected Framework pillars can help produce a highquality, stable, and efficient cloud architecture. We recommend that you review
your workload by using the Azure Well-Architected Framework Review assessment.
Use a reference architecture to review the considerations based on the guidance
provided in this article. We recommend that you start with Protect APIs with
Application Gateway and API Management and IaaS: Web application with
relational database.

Reliability
In the cloud, we acknowledge that failures happen. Instead of trying to prevent failures
altogether, the goal is to minimize the effects of a single failing component. Use the
following information to minimize failed instances.

Design checklist
As you make design choices for Application Gateway, review the Reliability design
principles.
＂ Deploy the instances in a zone-aware configuration, where available.

＂ Use Application Gateway with Web Application Firewall (WAF) within a virtual
network to protect inbound HTTP/S traffic from the Internet.
＂ In new deployments, use Azure Application Gateway v2 unless there is a compelling
reason to use Azure Application Gateway v1.
＂ Plan for rule updates
＂ Use health probes to detect backend unavailability
＂ Review the impact of the interval and threshold settings on health probes
＂ Verify downstream dependencies through health endpoints

Recommendations
Explore the following table of recommendations to optimize your Application Gateway
configuration for Reliability.
Recommendation

Benefit

Plan for rule updates

Plan enough time for updates before accessing Application
Gateway or making further changes. For example, removing
servers from backend pool might take some time because they
have to drain existing connections.

Use health probes to detect

If Application Gateway is used to load balance incoming traffic

backend unavailability

over multiple backend instances, we recommend the use of
health probes. These will ensure that traffic is not routed to
backends that are unable to handle the traffic.

Review the impact of the
interval and threshold settings

The health probe sends requests to the configured endpoint at
a set interval. Also, there's a threshold of failed requests that

on health probes

will be tolerated before the backend is marked unhealthy.
These numbers present a trade-off.
- Setting a higher interval puts a higher load on your service.
Each Application Gateway instance sends its own health
probes, so 100 instances every 30 seconds means 100 requests
per 30 seconds.
- Setting a lower interval leaves more time before an outage is
detected.
- Setting a low unhealthy threshold may mean that short,
transient failures may take down a backend.
- Setting a high threshold it can take longer to take a backend
out of rotation.

Verify downstream
dependencies through health

Suppose each backend has its own dependencies to ensure
failures are isolated. For example, an application hosted

endpoints

behind Application Gateway may have multiple backends, each
connected to a different database (replica). When such a
dependency fails, the application may be working but won't

Recommendation

Benefit
return valid results. For that reason, the health endpoint
should ideally validate all dependencies. Keep in mind that if
each call to the health endpoint has a direct dependency call,
that database would receive 100 queries every 30 seconds
instead of 1. To avoid this, the health endpoint should cache
the state of the dependencies for a short period of time.

When using Azure Front Door

Certain scenarios can force you to implement rules specifically

and Application Gateway to

on Application Gateway. For example, if ModSec CRS 2.2.9,

protect HTTP/S applications, use
WAF policies in Front Door and

CRS 3.0 or CRS 3.1 rules are required, these rules can be only
implemented on Application Gateway. Conversely, rate-

lock down Application Gateway

limiting and geo-filtering are available only on Azure Front

to receive traffic only from
Azure Front Door.

Door, not on AppGateway.

Azure Advisor helps you ensure and improve continuity of your business-critical
applications. Review the Azure Advisor recommendations.

Security
Security is one of the most important aspects of any architecture. Application Gateway
provides features to employ both the principle of least privilege and defense-in-defense.
We recommend you review the Security design principles.

Design checklist
＂ Set up a TLS policy for enhanced security
＂ Use AppGateway for TLS termination
＂ Use Azure Key Vault to store TLS certificates
＂ When re-encrypting backend traffic, ensure the backend server certificate contains
both the root and intermediate Certificate Authorities (CAs)
＂ Use an appropriate DNS server for backend pool resources
＂ Comply with all NSG restrictions for Application Gateway
＂ Refrain from using UDRs on the Application Gateway subnet
＂ Be aware of Application Gateway capacity changes when enabling WAF

Recommendations
Explore the following table of recommendations to optimize your Application Gateway
configuration for Security.

Recommendation

Benefit

Set up a TLS policy for
enhanced security

Set up a TLS policy for extra security. Ensure you're using the latest
TLS policy version (AppGwSslPolicy20170401S). This enforces TLS
1.2 and stronger ciphers.

Use AppGateway for TLS
termination

There are advantages of using Application Gateway for TLS
termination:
- Performance improves because requests going to different
backends to have to re-authenticate to each backend.
- Better utilization of backend servers because they don't have to
perform TLS processing
- Intelligent routing by accessing the request content.
- Easier certificate management because the certificate only needs
to be installed on Application Gateway.

Use Azure Key Vault to store
TLS certificates

Application Gateway is integrated with Key Vault. This provides
stronger security, easier separation of roles and responsibilities,
support for managed certificates, and an easier certificate renewal
and rotation process.

When re-encrypting

A TLS certificate of the backend server must be issued by a well-

backend traffic, ensure the
backend server certificate
contains both the root and

known CA. If the certificate was not issued by a trusted CA, the
Application Gateway checks if the certificate of the issuing CA was
issued by a trusted CA, and so on until either a trusted CA is found.

intermediate Certificate
Authorities (CAs)

Only then a secure connection is established. Otherwise,
Application Gateway marks the backend as unhealthy.

Use an appropriate DNS
server for backend pool

When the backend pool contains a resolvable FQDN, the DNS
resolution is based on a private DNS zone or custom DNS server (if

resources

configured on the VNet), or it uses the default Azure-provided
DNS.

Comply with all NSG

NSGs are supported on Application Gateway subnet, but there are

restrictions for Application
Gateway

some restrictions. For instance, some communication with certain
port ranges is prohibited. Make sure you understand the
implications of those restrictions. For details, see Network security
groups.

Refrain from using UDRs on
the Application gateway

Using User Defined Routes (UDR) on the Application Gateway
subnet cause some issues. Health status in the back-end might be

subnet

unknown. Application Gateway logs and metrics might not get
generated. We recommend that you don't use UDRs on the
Application Gateway subnet so that you can view the back-end
health, logs, and metrics. If your organizations require to use UDR
in the Application Gateway subnet, please ensure you review the
supported scenarios. For more information, see Supported userdefined routes.

Recommendation

Benefit

Be aware of Application
Gateway capacity changes
when enabling WAF

When WAF is enabled, every request must be buffered by the
Application Gateway until it fully arrives and check if the request
matches with any rule violation in its core rule set and then
forward the packet to the backend instances. For large file uploads
(30MB+ in size), this can result in a significant latency. Because
Application Gateway capacity requirements are different with WAF,
we do not recommend enabling WAF on Application Gateway
without proper testing and validation.

For more suggestions, see Principles of the security pillar.
Azure Advisor helps you ensure and improve continuity of your business-critical
applications. Review the Azure Advisor recommendations.

Policy definitions
Web Application Firewall (WAF) should be enabled for Application Gateway

.

Deploy Azure Web Application Firewall (WAF) in front of public facing web
applications for additional inspection of incoming traffic. Web Application Firewall
(WAF) provides centralized protection of your web applications from common
exploits and vulnerabilities such as SQL injections, Cross-Site Scripting, local and
remote file executions. You can also restrict access to your web applications by
countries/regions, IP address ranges, and other http(s) parameters via custom
rules.
Web Application Firewall (WAF) should use the specified mode for Application
Gateway

. Mandates the use of 'Detection' or 'Prevention' mode to be active on

all Web Application Firewall policies for Application Gateway.
Azure DDoS Protection should be enabled

. DDoS protection should be enabled

for all virtual networks with a subnet that is part of an application gateway with a
public IP.
All built-in policy definitions related to Azure Networking are listed in Built-in policies Network.

Cost optimization
Cost optimization is about looking at ways to reduce unnecessary expenses and
improve operational efficiencies. We recommend you review the Cost optimization
design principles.

Design checklist
＂ Familiarize yourself with Application Gateway pricing
＂ Review underutilized resources
＂ Stop Application Gateway instances that are not in use
＂ Have a scale-in and scale-out policy
＂ Review consumption metrics across different parameters

Recommendations
Explore the following table of recommendations to optimize your Application Gateway
configuration for Cost optimization.
Recommendation

Benefit

Familiarize yourself with
Application Gateway
pricing

For information about Application Gateway pricing, see Understanding
Pricing for Azure Application Gateway and Web Application Firewall.
You can also leverage the Pricing calculator .
Ensure that the options are adequately sized to meet the capacity
demand and deliver expected performance without wasting resources.

Review underutilized
resources

Identify and delete Application Gateway instances with empty backend
pools to avoid unnecessary costs.

Stop Application
Gateway instances
when not in use

You aren't billed when Application Gateway is in the stopped state.
Continuously running Application Gateway instances can incur
extraneous costs. Evaluate usage patterns and stop instances when you
don't need them. For example, usage after business hours in Dev/Test
environments is expected to be low.
See these articles for information about how to stop and start
instances.
- Stop-AzApplicationGateway
- Start-AzApplicationGateway

Have a scale-in and
scale-out policy

A scale-out policy ensures that there will be enough instances to
handle incoming traffic and spikes. Also, have a scale-in policy that
makes sure the number of instances are reduced when demand drops.
Consider the choice of instance size. The size can significantly impact
the cost. Some considerations are described in the Estimate the
Application Gateway instance count.
For more information, see What is Azure Application Gateway v2?

Review consumption
metrics across different
parameters

You're billed based on metered instances of Application Gateway based
on the metrics tracked by Azure. Evaluate the various metrics and
capacity units and determine the cost drivers. For more information,

Recommendation

see Azure Cost Management and Billing
Benefit

.

The following metrics are key for Application Gateway. This information
can be used to validate that the provisioned instance count matches
the amount of incoming traffic.
- Estimated Billed Capacity Units
- Fixed Billable Capacity Units
- Current Capacity Units
For more information, see Application Gateway metrics.
Make sure you account for bandwidth costs. For details, see Traffic
across billing zones and regions.

For more suggestions, see Principles of the cost optimization pillar.
Azure Advisor helps you ensure and improve continuity of your business-critical
applications. Review the Azure Advisor recommendations.

Operational excellence
Monitoring and diagnostics are crucial. Not only can you measure performance statistics
but also use metrics troubleshoot and remediate issues quickly. We recommend you
review the Operational excellence design principles.

Design checklist
＂ Monitor capacity metrics
＂ Enable diagnostics on Application Gateway and Web Application Firewall (WAF)
＂ Use Azure Monitor Network Insights
＂ Match timeout settings with the backend application
＂ Monitor Key Vault configuration issues using Azure Advisor
＂ Configure and monitor SNAT port limitations
＂ Consider SNAT port limitations in your design

Recommendations
Explore the following table of recommendations to optimize your Application Gateway
configuration for Operational excellence.

Recommendation

Benefit

Monitor capacity metrics

Use these metrics as indicators of utilization of the provisioned
Application Gateway capacity. We strongly recommend setting up
alerts on capacity. For details, see Application Gateway high traffic
support.

Troubleshoot using
metrics

There are other metrics that can indicate issues either at Application
Gateway or the backend. We recommend evaluating the following
alerts:
- Unhealthy Host Count
- Response Status (dimension 4xx and 5xx)
- Backend Response Status (dimension 4xx and 5xx)
- Backend Last Byte Response Time
- Application Gateway Total Time
For more information, see Metrics for Application Gateway.

Enable diagnostics on
Application Gateway and
Web Application Firewall
(WAF)

Diagnostic logs allow you to view firewall logs, performance logs, and
access logs. Use these logs to manage and troubleshoot issues with
Application Gateway instances. For more information, see Back-end
health and diagnostic logs for Application Gateway.

Use Azure Monitor
Network Insights

Azure Monitor Network Insights provides a comprehensive view of
health and metrics for network resources, including Application
Gateway. For additional details and supported capabilities for
Application Gateway, see Azure Monitor Network insights.

Match timeout settings
with the backend
application

Ensure you have configured the IdleTimeout settings to match the
listener and traffic characteristics of the backend application. The
default value is set to four minutes and can be configured to a
maximum of 30. For more information, see Load Balancer TCP Reset
and Idle Timeout.
For workload considerations, see Monitoring application health for
reliability.

Monitor Key Vault
configuration issues
using Azure Advisor

Application Gateway checks for the renewed certificate version in the
linked Key Vault at every 4-hour interval. If it is inaccessible due to any
incorrectly modified Key Vault configurations, it logs that error and
pushes a corresponding Advisor recommendation. You must configure
the Advisor alerts to stay updated and fix such issues immediately to
avoid any Control or Data plane related problems. To set an alert for
this specific case, use the Recommendation Type as Resolve Azure
Key Vault issue for your Application Gateway.

Consider SNAT port

SNAT port limitations are important for backend connections on the

limitations in your
design

Application Gateway. There are separate factors that affect how
Application Gateway reaches the SNAT port limit. For example, if the

Recommendation

Benefit
backend is a public IP address, it will require its own SNAT port. In
order to avoid SNAT port limitations, you can increase the number of
instances per Application Gateway, scale out the backends to have
more IP addresses, or move your backends into the same virtual
network and use private IP addresses for the backends.
Requests per second (RPS) on the Application Gateway will be affected
if the SNAT port limit is reached. For example, if an Application
Gateway reaches the SNAT port limit, then it won't be able to open a
new connection to the backend, and the request will fail.

For more suggestions, see Principles of the operational excellence pillar.
Azure Advisor helps you ensure and improve continuity of your business-critical
applications. Review the Azure Advisor recommendations.

Performance efficiency
Performance efficiency is the ability of your workload to scale to meet the demands
placed on it by users in an efficient manner. We recommend you review the
Performance efficiency principles.

Design checklist
＂ Estimate the Application Gateway instance count
＂ Define the maximum instance count
＂ Define the minimum instance count
＂ Define Application Gateway subnet size
＂ Take advantage of Application Gateway V2 features for autoscaling and
performance benefits

Recommendations
Explore the following table of recommendations to optimize your Application Gateway
configuration for Performance efficiency.
Recommendation

Benefit

Estimate the Application
Gateway instance count

Application Gateway v2 scales out based on many aspects, such as
CPU, network throughput, current connections, and more. To
determine the approximate instance count, factor in these metrics:

Recommendation

Benefit
Current compute units — Indicates CPU utilization. 1 Application
Gateway instance is approximately 10 compute units.
Throughput — Application Gateway instance can serve ~500 Mbps of
throughput. This data depends on the type of payload.
Consider this equation when calculating instance counts.
Approximate instance count

=

max

Current compute units

,

Throughput in Mbps

10

500

After you've estimated the instance count, compare that value to the
maximum instance count. This will indicate how close you are to the
maximum available capacity.
Define the minimum

For Application Gateway v2 SKU, autoscaling takes some time

instance count

(approximately six to seven minutes) before the additional set of
instances is ready to serve traffic. During that time, if there are short
spikes in traffic, expect transient latency or loss of traffic.
We recommend that you set your minimum instance count to an
optimal level. After you estimate the average instance count and
determine your Application Gateway autoscaling trends, define the
minimum instance count based on your application patterns. For
information, see Application Gateway high traffic support.
Check the Current Compute Units for the past one month. This metric
represents the gateway's CPU utilization. To define the minimum
instance count, divide the peak usage by 10. For example, if your
average Current Compute Units in the past month is 50, set the
minimum instance count to five.

Define the maximum
instance count

We recommend 125 as the maximum autoscale instance count. Make
sure the subnet that has the Application Gateway has sufficient
available IP addresses to support the scale-up set of instances.
Setting the maximum instance count to 125 has no cost implications
because you're billed only for the consumed capacity.

Define Application
Gateway subnet size

Application Gateway needs a dedicated subnet within a virtual
network. The subnet can have multiple instances of the deployed
Application Gateway resource. You can also deploy other Application
Gateway resources in that subnet, v1 or v2 SKU.
Here are some considerations for defining the subnet size:
- Application Gateway uses one private IP address per instance and
another private IP address if a private front-end IP is configured.
- Azure reserves five IP addresses in each subnet for internal use.

Recommendation

Benefit
- Application Gateway (Standard or WAF SKU) can support up to 32
instances. Taking 32 instance IP addresses + 1 private front-end IP + 5
Azure reserved, a minimum subnet size of /26 is recommended.
Because the Standard_v2 or WAF_v2 SKU can support up to 125
instances, using the same calculation, a subnet size of /24 is
recommended.
- If you want to deploy additional Application Gateway resources in
the same subnet, consider the additional IP addresses that will be
required for their maximum instance count for both, Standard and
Standard v2.

Take advantage of
features for autoscaling
and performance
benefits

The v2 SKU offers autoscaling to ensure that your Application
Gateway can scale up as traffic increases. When compared to v1 SKU,
v2 has capabilities that enhance the performance of the workload. For
example, better TLS offload performance, quicker deployment and
update times, zone redundancy, and more. For more information
about autoscaling features, see Scaling Application Gateway v2 and
WAF v2.
If you are running v1 SKU Application gateway, consider migrating to
the Application gateway v2 SKU. For more information, see Migrate
Azure Application Gateway and Web Application Firewall from v1 to
v2.

Azure Advisor helps you ensure and improve continuity of your business-critical
applications. Review the Azure Advisor recommendations.

Azure Advisor recommendations
Azure Advisor is a personalized cloud consultant that helps you follow best practices to
optimize your Azure deployments. Here are some recommendations that can help you
improve the reliability, security, cost-effectiveness, performance, and operational
excellence of your Application Gateway.

Reliability
Ensure application gateway fault tolerance
Do not override hostname to ensure website integrity

Additional resources
Azure Architecture Center guidance

Using API gateways in microservices
Firewall and Application Gateway for virtual networks
Protect APIs with Application Gateway and API Management
IaaS: Web application with relational database
Securely managed web applications
Zero-trust network for web applications with Azure Firewall and Application
Gateway

Next steps
Deploy an Application Gateway to see how it works: Quickstart: Direct web traffic
with Azure Application Gateway - Azure portal

Azure Well-Architected Framework
review - Azure Firewall
Article • 01/20/2023

This article provides architectural best practices for Azure Firewall. The guidance is based
on the five pillars of architecture excellence:
Reliability
Security
Cost optimization
Operational excellence
Performance efficiency
We assume that you have working knowledge of Azure Firewall and are well versed with
its features. For more information, see Azure Firewall Standard features.

Prerequisites
Understanding the Azure Well-Architected Framework pillars can help produce a
high-quality, stable, and efficient cloud architecture. Review your workload by
using the Well-Architected Framework review assessment.
Use a reference architecture to review the considerations based on the guidance
provided in this article. Start with Network-hardened web application with private
connectivity to PaaS datastores and Implement a secure hybrid network.

Reliability
To learn how Azure Firewall supports a reliable workload, see the following articles:
Introduction to Azure Firewall
Quickstart: Deploy Azure Firewall with availability zones

Design checklist
As you make design choices for Azure Firewall, review the design principles for
reliability.
＂ Deploy by using a secured virtual hub.
＂ Use a global Azure Firewall policy.
＂ Determine if you want to use third-party security as a service (SECaaS) providers.

Recommendations
Explore the following table of recommendations to optimize your Azure Firewall
configuration for reliability.
Recommendation

Benefit

Use Azure Firewall Manager with
Azure Virtual WAN to deploy and
manage instances of Azure Firewall

Easily create hub-and-spoke and transitive architectures
with native security services for traffic governance and
protection.

across Virtual WAN hubs or in hub
virtual networks.
Create a global Azure Firewall policy

Allow for granular policies to meet the requirements of

to govern the security posture across
global network environments. Assign

specific regions. Delegate incremental firewall policies to
local security teams through role-based access control

the policy to all instances of Azure

(RBAC).

Firewall.
Configure supported third-party

You can use your familiar, best-in-breed, third-party

software as a service (SaaS) security
providers within Firewall Manager if

SECaaS offerings to protect internet access for your
users.

you want to use these solutions to
protect outbound connections.
Deploy Azure Firewall across multiple

Azure Firewall provides different SLAs when it's deployed

availability zones for a higher servicelevel agreement (SLA).

in a single availability zone and when it's deployed in
multizones. For more information, see SLA for Azure
Firewall . For information about all Azure SLAs, see SLA
summary for Azure services .

In multi-region environments, deploy

For workloads designed to be resistant to failures and

an instance of Azure Firewall per
region.

fault tolerant, remember to consider that instances of
Azure Firewall and Azure Virtual Network are regional
resources.

Closely monitor Azure Firewall metrics

Closely monitor metrics, especially SNAT port utilization,

to ensure this component of your

firewall health state, and throughput.

solution is healthy.

Azure Advisor helps you ensure and improve the continuity of your business-critical
applications. Review the Azure Advisor recommendations.

Security
Security is one of the most important aspects of any architecture. Azure Firewall is an
intelligent firewall security service that provides threat protection for your cloud

workloads running in Azure.

Design checklist
As you make design choices for Azure Firewall, review the design principles for security.
＂ Use a global Azure Firewall policy.
＂ Use threat intelligence.
＂ Use a DNS proxy.
＂ Direct network traffic through Azure Firewall.
＂ Validate spoke networks.
＂ Determine if you want to use third-party SECaaS providers.
＂ Use just-in-time (JIT) systems.
＂ Protect your hub virtual network with a DDoS protection plan.

Recommendations
Explore the following table of recommendations to optimize your Azure Firewall
configuration for security.
Recommendation

Benefit

Create a global Azure

Allow for granular policies to meet the requirements of specific

Firewall policy to govern

regions. Delegate incremental firewall policies to local security teams

the security posture
across global network

through RBAC.

environments. Assign
the policy to all
instances of Azure
Firewall.
Enable threat
intelligence on Azure
Firewall.

You can enable threat intelligence-based filtering for your firewall to
alert and deny traffic from or to unknown IP addresses and domains.
The IP addresses and domains are sourced from the Microsoft Threat
Intelligence Feed. Intelligent Security Graph powers Microsoft threat
intelligence and is used by multiple services, including Microsoft
Defender for Cloud.

Enable Domain Name
System (DNS) proxy and
point the infrastructure
DNS to Azure Firewall.

By default, Azure Firewall uses Azure DNS. Custom DNS allows you to
configure Azure Firewall to use corporate DNS to resolve external and
internal names.

Recommendation

Benefit

Configure the userdefined routes (UDR) to
force traffic to Azure

Configure UDRs to force traffic to Azure Firewall for SpoketoSpoke ,
SpoketoInternet , and SpoketoHybrid connectivity.

Firewall.
Validate if unnecessary
peering exists between
the hub virtual network

Helps to guarantee that undesired traffic isn't being sent to the Azure
firewall or the hub network where the Azure Firewall is deployed.

where Azure Firewall is
deployed, and other
spoke virtual networks.
Use security partner
providers for third-party
SECaaS offerings.

Security partner providers help filter internet traffic through a virtual
private network or a branch to the internet.

Use JIT systems to

You can use Microsoft Defender for Cloud JIT to control access for

control access to virtual
machines (VMs) from

clients that connect from the internet by using Azure Firewall.

the internet.
Configure Azure Firewall
in the forced tunneling
mode to route all

Azure Firewall must have direct internet connectivity. If your
AzureFirewallSubnet learns a default route to your on-premises
network via the Border Gateway Protocol, you must configure Azure

internet-bound traffic to
a designated next hop
instead of going directly

Firewall in the forced tunneling mode. Using the forced tunneling
feature, you'll need another /26 address space for the Azure Firewall
Management subnet. You're required to name it

to the internet.

AzureFirewallManagementSubnet.
If this is an existing Azure Firewall instance that can't be reconfigured
in the forced tunneling mode, create a UDR with a 0.0.0.0/0 route. Set
the NextHopType value as Internet. Associate it with
AzureFirewallSubnet to maintain internet connectivity.

Set the public IP address
to None to deploy a
fully private data plane

When you deploy a new Azure Firewall instance, if you enable the
forced tunneling mode, you can set the public IP address to None to
deploy a fully private data plane. However, the management plane still

when you configure
Azure Firewall in the
forced tunneling mode.

requires a public IP for management purposes only. The internal traffic
from virtual and on-premises networks won't use that public IP. For
more about forced tunneling, see Azure Firewall forced tunneling.

Use fully qualified

You can use FQDNs based on DNS resolution in Azure Firewall and

domain name (FQDN)
filtering in network rules.

firewall policies. This capability allows you to filter outbound traffic
with any TCP/UDP protocol (including NTP, SSH, RDP, and more). You
must enable the DNS Proxy option to use FQDNs in your network
rules. To learn how it works, see Azure Firewall FQDN filtering in
network rules.

Recommendation

Benefit

Use Azure Firewall

A DDoS protection plan provides enhanced mitigation features to

Manager to create and
associate a DDoS
protection plan with

defend your firewall from DDoS attacks. Azure Firewall Manager is an
integrated tool to create your firewall infrastructure and DDoS
protection plans. For more information, see Configure an Azure DDoS

your hub virtual
network.

Protection Plan using Azure Firewall Manager.

Azure Advisor helps you ensure and improve the continuity of your business-critical
applications. Review the Azure Advisor recommendations.

Policy definitions
All internet traffic should be routed via your Azure Firewall . Protect your subnets from
potential threats by restricting access to them with Azure Firewall or a supported nextgeneration firewall.
All built-in policy definitions related to Azure networking are listed in Built-in policies Network.

Cost optimization
Cost optimization is about looking at ways to reduce unnecessary expenses and
improve operational efficiencies.

Design checklist
As you make design choices for Azure Firewall, review the design principles for cost
optimization.
＂ Determine which firewall SKUs to deploy.
＂ Determine if some resources don't need 100% allocation.
＂ Determine where you can optimize firewall use across workloads.
＂ Monitor firewall usage to determine cost-effectiveness.
＂ Review Firewall Manager capabilities to determine potential operational efficiency.
＂ Determine the number of public IP addresses required.

Recommendations
Explore the following table of recommendations to optimize your Azure Firewall
configuration for cost optimization.

Recommendation

Benefit

Deploy the

The Standard option is usually enough for east-west traffic. Premium has

Standard and
Premium SKUs
where appropriate.

the necessary extra features for north-south traffic, the forced tunneling
feature, and many other features. For more information, see Azure Firewall
Premium Preview features. Deploy mixed scenarios using the Standard and
Premium options according to your needs.

Stop Azure Firewall
deployments that

You might have development environments that are used only during
business hours. For more information, see Deallocate and allocate Azure

don't need to run
for 24 hours.

Firewall.

Share the same
instance of Azure
Firewall across
multiple workloads

You can use a central instance of Azure Firewall in the hub virtual network
and share the same firewall across many spoke virtual networks that are
connected to the same hub from the same region.

and Azure Virtual
Network.

Ensure there's no unexpected cross-region traffic as part of the hub-spoke
topology.

Review
underutilized Azure
Firewall instances.
Identify and delete

To identify unused Azure Firewall deployments, start by analyzing the
monitoring metrics and UDRs associated with subnets pointing to the
firewall's private IP. Combine that information with other validations, such
as if your instance of Azure Firewall has any rules (classic) for NAT, Network

unused Azure
Firewall
deployments.

and Application, or even if the DNS Proxy setting is configured to Disabled,
and with internal documentation about your environment and
deployments.
You can detect deployments that are cost-effective over time.
For more information about monitoring logs and metrics, see Monitor
Azure Firewall logs and metrics and SNAT port utilization.

Use Azure Firewall
Manager and its
policies to reduce
operational costs,
increase efficiency,
and reduce
management
overhead.

Review your Firewall Manager policies, associations, and inheritance
carefully. Policies are billed based on firewall associations. A policy with
zero or one firewall association is free of charge. A policy with multiple
firewall associations is billed at a fixed rate.
For more information, see Pricing - Azure Firewall Manager .

Delete unused
public IP addresses

Validate whether all the associated public IP addresses are in use. If they
aren't in use, disassociate and delete them. Use IP Groups to reduce your

and use IP Groups
to reduce your
management
overhead.

management overhead. Evaluate SNAT port utilization before removing any
IP addresses.
You'll only use the number of public IPs your firewall needs. For more
information, see Monitor Azure Firewall logs and metrics and SNAT port
utilization.

For more suggestions, see Principles of the Cost optimization pillar.
Azure Advisor helps you ensure and improve the continuity of your business-critical
applications. Review the Azure Advisor recommendations.

Operational excellence
Monitoring and diagnostics are crucial. You can measure performance statistics and
metrics to troubleshoot and remediate issues quickly.

Design checklist
As you make design choices for Azure Firewall, review the design principles for
operational excellence.
＂ Use logs for monitoring.
＂ Use tags when possible to allow traffic through the firewall.
＂ Use workbooks.
＂ Use the Azure Firewall connector in Microsoft Sentinel.

Recommendations
Explore the following table of recommendations to optimize your Azure Firewall
configuration for operational excellence.
Recommendation

Benefit

Turn on logs for
Azure Firewall.

You can monitor Azure Firewall by using firewall logs or workbooks. You
can also use activity logs for auditing operations on Azure Firewall
resources.

Use FQDN tags on
Azure Firewall.

FQDN tags make it easy to allow known Azure service network traffic
through your firewall. For example, say you want to allow Windows
Update network traffic through your firewall. You create an application
rule and use the Windows Update tag. Now network traffic from Windows
Update can flow through your firewall.

Use workbooks in
Azure Log Analytics.

Workbooks help visualize firewall logs.

Enable Azure
Firewall connector in
Microsoft Sentinel.

You can use Microsoft Sentinel to create detections and logic apps for
Azure Firewall.

Recommendation

Benefit

Migrate Azure
Firewall rules to
Azure Firewall

For existing deployments, migrate Azure Firewall rules to Azure Firewall
Manager policies. Use Azure Firewall Manager to centrally manage your
firewalls and policies.

Manager policies for
existing
deployments.
Monitoring capacity
metrics are
indicators of the

Set alerts as needed to get notifications after reaching a threshold for any
metric.
For information about monitoring logs and metrics, see Monitor Azure

utilization of
provisioned Azure
Firewall capacity.

Firewall logs and metrics.

Monitor other Azure
Firewall logs and
metrics for
troubleshooting and

Azure Firewall exposes a few other logs and metrics for troubleshooting
that are suitable indicators of issues. Evaluate alerts based on the
following list.

set alerts.

Application Rule log: Each new connection that matches one of your
configured application rules results in a log for the accepted/denied
connection.
Network Rule log: Each new connection that matches one of your
configured network rules results in a log for the accepted/denied
connection.
DNS Proxy log: This log tracks DNS messages to a DNS server
configured using a DNS proxy.

Use diagnostics logs
and policy analytics.

Diagnostic logs allow you to view Azure Firewall logs, performance logs,
and access logs. You can use these logs in Azure to manage and
troubleshoot your Azure Firewall instance.
Policy analytics for Azure Firewall Manager allows you to start seeing rules
and flows that match the rules and hit count for those rules. You can have
full traffic visibility by watching what rule is in use and the traffic being
matched.

Azure Advisor helps you ensure and improve the continuity of your business-critical
applications. Review the Azure Advisor recommendations.

Performance efficiency
Performance efficiency is the ability of your workload to scale to efficiently meet the
demands placed on it by users.

Design checklist
As you make design choices for Azure Firewall, review the design principles for
performance efficiency.
＂ Determine your SNAT port requirements and if you should deploy a NAT gateway.
＂ Plan load tests to test auto-scale performance in your environment.
＂ Plan network rule requirements and opportunities to summarize IP ranges.

Recommendations
Explore the following table of recommendations to optimize your Azure Firewall
configuration for performance efficiency.
Recommendation

Benefit

If you'll need more than 512,000
SNAT ports, deploy a NAT gateway

With a NAT gateway, you can scale up to more than 1
million ports. For more information, see Scale SNAT ports

with Azure Firewall.

with Azure NAT gateway.

Create initial traffic that isn't part of
your load tests 20 minutes before
the test. Use diagnostics settings to
capture scale-up and scale-down
events. You can use the Azure Load

Allows the Azure Firewall instance to scale up its instances
to the maximum.

Testing service to generate the
initial traffic.
Use IP Groups to summarize IP
address ranges.

You can use IP Groups to summarize IP ranges, so you don't
exceed the limit of unique source/destination network rules.
For each rule, Azure multiplies ports by IP addresses. So, if
you have one rule with four IP address ranges and five
ports, you'll consume 20 network rules. The IP Group is
treated as a single address for the purpose of creating
network rules.

Configure an Azure Firewall subnet
(AzureFirewallSubnet) with a /26
address space.

Azure Firewall is a dedicated deployment in your virtual
network. Within your virtual network, a dedicated subnet is
required for the instance of Azure Firewall. Azure Firewall
provisions more capacity as it scales.
A /26 address space for its subnets ensures that the firewall
has enough IP addresses available to accommodate the
scaling. Azure Firewall doesn't need a subnet bigger than
/26. The Azure Firewall subnet name must be
AzureFirewallSubnet.

Azure Advisor helps you ensure and improve the continuity of your business-critical
applications. Review the Azure Advisor recommendations.

Azure Advisor recommendations
Azure Advisor is a personalized cloud consultant that helps you follow best practices to
optimize your Azure deployments. Here are some recommendations that can help you
improve the reliability, security, cost-effectiveness, performance, and operational
excellence of your instance of Azure Firewall.
Create Azure Service Health alerts to be notified when Azure problems affect you
Ensure you have access to Azure cloud experts when you need it
Enable Traffic Analytics to view insights into traffic patterns across Azure resources
Update your outbound connectivity protocol to Service Tags for Azure Site
Recovery
Follow just enough administration (least privilege principle)
Protect your network resources with Microsoft Defender for Cloud

Additional resources
Azure Firewall documentation
Azure Firewall service limits, quotas, and constraints
Azure security baseline for Azure Firewall

Azure Architecture Center guidance
Azure Firewall architecture overview
Use Azure Firewall to help protect an Azure Kubernetes Service (AKS) cluster
Hub-spoke network topology in Azure
Implement a secure hybrid network
Network-hardened web application with private connectivity to PaaS datastores

Next step
Deploy an instance of Azure Firewall to see how it works:
Tutorial: Deploy and configure Azure Firewall and policy by using the Azure portal

Azure Well-Architected Framework
review - Azure ExpressRoute
Article • 11/18/2022

This article provides architectural best practice for Azure ExpressRoute. The guidance is
based on the five pillars of the architecture excellence:
Reliability
Security
Cost optimization
Operational excellence
Performance efficiency
We assume that you have working knowledge of Azure ExpressRoute and are well
versed with all of its features. For more information, see Azure ExpressRoute.

Prerequisites
For context, consider reviewing a reference architecture that reflects these
considerations in its design. We recommend that you start with Cloud Adoption
Framework Ready methodology's guidance Connect to Azure and Architect for hybrid
connectivity with Azure ExpressRoute. For low-code application architectures, we
recommend reviewing Enabling ExpressRoute for Power Platform when planning and
configuring ExpressRoute for use with Microsoft Power Platform.

Reliability
In the cloud, we acknowledge that failures happen. Instead of trying to prevent failures
altogether, the goal is to minimize the effects of a single failing component. Use the
following information to minimize down time to and from Azure when establishing
connectivity using Azure ExpressRoute.
When discussing about reliability with Azure ExpressRoute it's important to taking into
consideration bandwidth usage, physical layout of the network, and disaster recovery if
there's failures. Azure ExpressRoute is capable of achieving these design considerations
and have recommendations for each item in the checklist.
In the design checklist and list of recommendations below, information is presented in
order for you to design a highly available network between your Azure environment and
on-premises network.

Design checklist
As you make design choices for Azure ExpressRoute, review the design principles for
adding reliability to the architecture.
＂ Select between ExpressRoute circuit or ExpressRoute Direct for business
requirements.
＂ Configure a diverse physical layer network to the service provider.
＂ Configure ExpressRoute circuits with different service provider to have diverse
routing paths.
＂ Configure Active-Active ExpressRoute connections between on-premises and Azure.
＂ Set up availability zone aware ExpressRoute Virtual Network Gateways.
＂ Configure ExpressRoute circuits in a different location than the on-premises
network.
＂ Configure ExpressRoute Virtual Network Gateways in different regions.
＂ Configure site-to-site VPN as a backup to ExpressRoute private peering.
＂ Set up monitoring for ExpressRoute circuit and ExpressRoute Virtual Network
Gateway health.
＂ Configure service health to receive ExpressRoute circuit maintenance notification.

Recommendations
Explore the following table of recommendations to optimize your ExpressRoute
configuration for Reliability.
Recommendation

Benefit

Plan for

During the initial planning phase, you want to decide whether you want to

ExpressRoute

configure an ExpressRoute circuit or an ExpressRoute Direct connection. An

circuit or
ExpressRoute

ExpressRoute circuit allows a private dedicated connection into Azure with
the help of a connectivity provider. ExpressRoute Direct allows you to extend

Direct

on-premises network directly into the Microsoft network at a peering
location. You also need to identify the bandwidth requirement and the SKU
type requirement for your business needs.

Physical layer
diversity

For better resiliency, plan to have multiple paths between the on-premises
edge and the peering locations (provider/Microsoft edge locations). This
configuration can be achieved by going through different service provider or
through a different location from the on-premises network.

Plan for geo-

To plan for disaster recovery, set up ExpressRoute circuits in more than one

redundant circuits

peering locations. You can create circuits in peering locations in the same
metro or different metro and choose to work with different service providers
for diverse paths through each circuit. For more information, see Designing
for disaster recovery and Designing for high availability.

Recommendation

Benefit

Plan for ActiveActive connectivity

ExpressRoute dedicated circuits guarantee 99.95% availability when an
active-active connectivity is configured between on-premises and Azure.
This mode provides higher availability of your Expressroute connection. It's
also recommended to configure BFD for faster failover if there's a link failure
on a connection.

Planning for

Create availability zone aware Virtual Network Gateway for higher resiliency

Virtual Network
Gateways

and plan for Virtual Network Gateways in different region for disaster
recovery and high availability.

Monitor circuits
and gateway

Set up monitoring and alerts for ExpressRoute circuits and Virtual Network
Gateway health based on various metrics available.

health
Enable service

ExpressRoute uses service health to notify about planned and unplanned

health

maintenance. Configuring service health will notify you about changes made
to your ExpressRoute circuits.

For more suggestions, see Principles of the reliability pillar.
Azure Advisor provides many recommendations for ExpressRoute circuits as they relate
to reliability. For example, Azure Advisor can detect:
ExpressRoute gateways in which only a single ExpressRoute circuit is deployed,
instead of multiple. Multiple ExpressRoute circuits are recommended for add
resiliency for the peering location.
ExpressRoute circuits that aren't being observed by Connection Monitor, as endto-end monitoring of your ExpressRoute circuit is critical for reliability insights.
Network topologies involving multiple peering locations that would benefit from
ExpressRoute Global Reach to improve disaster recovery designs for on-premises
connectivity to account for unplanned connectivity loss.

Security
Security is one of the most important aspects of any architecture. ExpressRoute provides
features to employ both the principle of least privilege and defense-in-defense. We
recommend you review the Security design principles.

Design checklist
＂ Configure Activity log to send logs to archive.

＂ Maintain an inventory of administrative accounts with access to ExpressRoute
resources.
＂ Configure MD5 hash on ExpressRoute circuit.
＂ Configure MACSec for ExpressRoute Direct resources.
＂ Encrypt traffic over private peering and Microsoft peering for virtual network traffic.

Recommendations
Explore the following table of recommendations to optimize your ExpressRoute
configuration for security.
Recommendation

Benefit

Configure Activity
log to send logs

Activity logs provide insights into operations that were performed at the
subscription level for ExpressRoute resources. With Activity logs, you can

to archive

determine who and when an operation was performed at the control plane.
Data retention is only 90 days and required to be stored in Log Analytics,
Event Hubs or a storage account for archive.

Maintain inventory
of administrative
accounts

Use Azure RBAC to configure roles to limit user accounts that can add,
update, or delete peering configuration on an ExpressRoute circuit.

Configure MD5

During configuration of private peering or Microsoft peering, apply an MD5

hash on
ExpressRoute
circuit

hash to secure messages between the on-premises route and the MSEE
routers.

Configure MACSec
for ExpressRoute
Direct resources

Media Access Control security is a point-to-point security at the data link
layer. ExpressRoute Direct supports configuring MACSec to prevent security
threats to protocols such as ARP, DHCP, LACP not normally secured on the
Ethernet link. For more information on how to configure MACSec, see
MACSec for ExpressRoute Direct ports.

Encrypt traffic

Configure a Site-to-site VPN tunnel over your ExpressRoute circuit to

using IPsec

encrypt data transferring between your on-premises network and Azure
virtual network. You can configure a tunnel using private peering or using
Microsoft peering.

For more suggestions, see Principles of the security pillar.

Cost optimization
Cost optimization is about looking at ways to reduce unnecessary expenses and
improve operational efficiencies. We recommend you review the Cost optimization
design principle and Plan and manage costs for Azure ExpressRoute.

Design checklist
＂ Familiarize yourself with ExpressRoute pricing.
＂ Determine the ExpressRoute circuit SKU and bandwidth required.
＂ Determine the ExpressRoute virtual network gateway size required.
＂ Monitor cost and create budget alerts.
＂ Deprovision ExpressRoute circuits no longer in use.

Recommendations
Explore the following table of recommendations to optimize your ExpressRoute
configuration for Cost optimization.
Recommendation

Benefit

Familiarize
yourself with

For information about ExpressRoute pricing, see Understand pricing for
Azure ExpressRoute . You can also use the Pricing calculator .

ExpressRoute
pricing

Ensure that the options are adequately sized to meet the capacity demand
and deliver expected performance without wasting resources.

Determine SKU

The way you're charged for your ExpressRoute usage varies between the

and bandwidth
required

three different SKU types. With Local SKU, you're automatically charged with
an Unlimited data plan. With Standard and Premium SKU, you can select
between a Metered or an Unlimited data plan. All ingress data are free of
charge except when using the Global Reach add-on. It's important to
understand which SKU types and data plan works best for your workload to
best optimize cost and budget. For more information resizing ExpressRoute
circuit, see upgrading ExpressRoute circuit bandwidth.

Determine the
ExpressRoute

ExpressRoute virtual network gateways are used to pass traffic into a virtual
network over private peering. Review the performance and scale needs of

virtual network
gateway size

your preferred Virtual Network Gateway SKU. Select the appropriate gateway
SKU on your on-premises to Azure workload.

Monitor cost and
create budget

Monitor the cost of your ExpressRoute circuit and create alerts for spending
anomalies and overspending risks. For more information, see Monitoring

alerts

ExpressRoute costs.

Deprovision and
delete

ExpressRoute circuits are charged from the moment they're created. To
reduce unnecessary cost, deprovision the circuit with the service provider

ExpressRoute
circuits no longer
in use.

and delete the ExpressRoute circuit from your subscription. For steps on how
to remove an ExpressRoute circuit, see Deprovisioning an ExpressRoute
circuit.

For more suggestions, see Principles of the cost optimization pillar.

Azure Advisor can detect ExpressRoute circuits that have been deployed for a significant
time but have a provider status of Not Provisioned. Circuits in this state aren't
operational; and removing the unused resource will reduce unnecessary costs.

Operational excellence
Monitoring and diagnostics are crucial. Not only can you measure performance statistics
but also use metrics troubleshoot and remediate issues quickly. We recommend you
review the Operational excellence design principles.

Design checklist
＂ Configure connection monitoring between your on-premises and Azure network.
＂ Configure Service Health for receiving notification.
＂ Review metrics and dashboards available through ExpressRoute Insights using
Network Insights.
＂ Review ExpressRoute resource metrics.

Recommendations
Explore the following table of recommendations to optimize your ExpressRoute
configuration for Operational excellence.
Recommendation

Benefit

Configure
connection
monitoring

Connection monitoring allows you to monitor connectivity between your
on-premises resources and Azure over the ExpressRoute private peering and
Microsoft peering connection. Connection monitor can detect networking
issues by identifying where along the network path the problem is and help
you quickly resolve configuration or hardware failures.

Configure Service

Set up Service Health notifications to alert when planned and upcoming

Health

maintenance is happening to all ExpressRoute circuits in your subscription.
Service Health also displays past maintenance along with RCA if an
unplanned maintenance were to occur.

Recommendation

Benefit

Review metrics
with Network

ExpressRoute Insights with Network Insights allow you to review and analyze
ExpressRoute circuits, gateways, connections metrics and health dashboards.

Insights

ExpressRoute Insights also provide a topology view of your ExpressRoute
connections where you can view details of your peering components all in a
single place.
Metrics available:
- Availability
- Throughput
- Gateway metrics

Review
ExpressRoute
resource metrics

ExpressRoute uses Azure Monitor to collect metrics and create alerts base on
your configuration. Metrics are collected for ExpressRoute circuits,
ExpressRoute gateways, ExpressRoute gateway connections, and
ExpressRoute Direct. These metrics are useful for diagnosing connectivity
problems and understanding the performance of your ExpressRoute
connection.

For more suggestions, see Principles of the operational excellence pillar.

Performance efficiency
Performance efficiency is the ability of your workload to scale to meet the demands
placed on it by users in an efficient manner. We recommend you review the
Performance efficiency principles.

Design checklist
＂ Test ExpressRoute gateway performance to meet work load requirements.
＂ Increase the size of the ExpressRoute gateway.
＂ Upgrade the ExpressRoute circuit bandwidth.
＂ Enable ExpressRoute FastPath for higher throughput.
＂ Monitor the ExpressRoute circuit and gateway metrics.

Recommendations
Explore the following table of recommendations to optimize your ExpressRoute
configuration for performance efficiency.
Recommendation

Benefit

Recommendation

Benefit

Test ExpressRoute
gateway
performance to

Use Azure Connectivity Toolkit to test performance across your ExpressRoute
circuit to understand bandwidth capacity and latency of your network
connection.

meet work load
requirements.
Increase the size
of the
ExpressRoute
gateway.

Upgrade to a higher gateway SKU for improved throughput performance
between on-premises and Azure environment.

Upgrade

Upgrade your circuit bandwidth to meet your work load requirements.

ExpressRoute
circuit bandwidth

Circuit bandwidth is shared between all virtual networks connected to the
ExpressRoute circuit. Depending on your work load, one or more virtual
networks can use up all the bandwidth on the circuit.

Enable
ExpressRoute
FastPath for

If you're using an Ultra performance or an ErGW3AZ virtual network
gateway, you can enable FastPath to improve the data path performance
between your on-premises network and Azure virtual network.

higher throughput
Monitor
ExpressRoute
circuit and
gateway metrics

Set up alerts base on ExpressRoute metrics to proactively notify you when a
certain threshold is met. These metrics are useful to understand anomalies
that can happen with your ExpressRoute connection such as outages and
maintenance happening to your ExpressRoute circuits.

For more suggestions, see Principles of the performance efficiency pillar.
Azure Advisor will offer a recommendation to upgrade your ExpressRoute circuit
bandwidth to accommodate usage when your circuit has recently been consuming over
90% of your procured bandwidth. If your traffic exceeds your allocated bandwidth, you’ll
experience dropped packets, which can lead to significant performance or reliability
impact.

Azure Policy
Azure Policy doesn't provide any built-in policies for ExpressRoute, but custom policies
can be created to help govern how ExpressRoute circuits should match your desired end
state, such as SKU choice, peering type, peering configurations and so on.

Additional resources
Cloud Adoption Framework guidance

Traditional Azure network topology
Virtual WAN network topology (Microsoft-managed)

Next steps
Configure an ExpressRoute circuit or ExpressRoute Direct port to establish
communication between your on-premises network and Azure.

API Management and reliability
Article • 11/30/2022

Learn how to use API Management to publish APIs to external, partner, and employee
developers securely and at scale. This networking service is a hybrid, multicloud
management platform for APIs across all environments.
Components include:
API gateway
Management plane
Developer portal
For more information, reference About API Management.
To understand how API Management can increase reliability for your workload,
reference the following topics:
Availability zone support for Azure API Management
How to deploy an Azure API Management service instance to multiple Azure
regions
How to implement disaster recovery using service backup and restore in Azure API
Management

Checklist
Have you configured API Management with reliability in mind?
＂ Secure the communication between API Management and your backend.
＂ Ensure that each party has its own credential when exposing APIs to third parties.
＂ Ensure you set quotas and rate limits when exposing APIs to third parties.
＂ Evaluate the need for response caching.
＂ Plan a backup and restore process for your API Management instance.
＂ Configure multiple Azure regions in your API Management service.
＂ Implement a strategy to ensure availability during an outage or disaster affecting an
Azure region.

Configuration recommendations
Consider the following recommendations to optimize reliability when configuring your
API Management service:

Recommendation

Description

Ensure you set
quotas and rate
limits when

Protect backend services and reduce the load placed on an API Management
scale unit. Rate limiting policies can be applied at Global, Product, API, and
Operation levels to provide rate limit customization applied to API

exposing APIs to
third parties.

consumers.

Evaluate the need
for response

Response caching can reduce API latency and bandwidth consumption.
Response caching reduces the load placed on the backend APIs leading to

caching.

improved performance, user experience, and reduced solution cost.

Plan a backup and

Consider taking regular backups of your API Management service so that

restore process for
your API
Management

you can easily restore it in another region. Your recovery time objective may
require that a standby is deployed in a secondary region. It is a good
practice to take regular backups to recreate the service due to unforeseen

instance.

loss or misconfiguration of the service. Regular backups allow you to
replicate changes between your primary and standby instances.

Configure multiple

Configure your API Management service with multiple regions to provide

Azure regions in
your API

high-availability support in case an Azure region experiences downtime or a
disaster scenario. Configuring multiple regions also reduces API call latency

Management

because calls can be routed to the nearest region.

service.
Implement a

Consider using Azure Traffic Manager, Azure Front Door, or Azure DNS to

strategy to ensure
availability during

enable access to multiple regional deployments of API Management. Using
these services ensures you can still serve requests due to an outage or

an outage or

disaster. Requirements include syncing configurations between these

disaster affecting
an Azure region.

individual Standard instances.

Next step
API Management and cost optimization

API Management and cost optimization
Article • 11/30/2022

Learn how to use API Management to publish APIs to external, partner, and employee
developers securely and at scale. This networking service is a hybrid, multicloud
management platform for APIs across all environments.
Components include:
API gateway
Management plane
Developer portal
For more information, reference About API Management.
To understand how API Management supports cost optimization for your workload,
reference the following topics:
Automatically scale an Azure API Management instance
Use a virtual network with Azure API Management

Checklist
Have you configured API Management with cost optimization in mind?
＂ Configure autoscaling where appropriate.
＂ Consider which features you need all the time.

Configuration recommendations
Consider the following recommendations to optimize reliability when configuring your
API Management service:
Recommendation

Description

Configure
autoscaling where
appropriate.

Consider scaling your API Management instance up or down to control
costs. You can configure API Management with Autoscale based on a metric
or a specific count. Costs depend upon the number of units, which
determines throughput in requests per seconds (RPS). An autoscaled API
Management instance switches between scale units appropriate for RPS
numbers during a specific time window. Autoscaling helps to achieve
balance between cost optimization and performance.

Recommendation

Description

Consider which

Consider switching between Basic, Standard, and Premium tiers. If a

features you need
all the time.

workload does not need features available in higher tiers, then consider
switching to a lower tier. As an example, a workload may need just 1GB of
cache during off-peak periods compared to 5GB of cache during peak
periods. Costs associated with such a workload can be reduced by switching
from a Premium to Standard tier during off-peak periods and back to a
Premium tier during peak periods. This process can be automated as a job
using Set-AzApiManagement cmdlet. Refer to API Management pricing
about features available in different API Management tiers.

Next step
API Management and operational excellence

API Management and operational
excellence
Article • 11/30/2022

Learn how to use API Management to publish APIs to external, partner, and employee
developers securely and at scale. This networking service is a hybrid, multicloud
management platform for APIs across all environments.
Components include:
API gateway
Management plane
Developer portal
For more information, reference About API Management.
To understand how API Management supports operational excellence, reference the
following topics:
Managing Azure API Management using Azure Automation
Observability in Azure API Management

Checklist
Have you configured API Management with operational excellence in mind?
＂ Secure the communication between API Management and your backend.
＂ Ensure that each party has its own credential when exposing APIs to third parties.
＂ Ensure you set quotas and rate limits when exposing APIs to third parties.
＂ Understand the Microsoft REST API design and architecture guidance.
＂ Enable versioning of APIs to maintain backwards compatibility while adding other
features.
＂ Use the API Management Versioning and Revisions features to implement API
versioning.
＂ Understand the API import restrictions in API Management.
＂ Understand the Event logging feature.
＂ Trace calls in Azure API Management to help with debugging and testing.
＂ Configure logging using Azure Monitor for the API Management service.
＂ Choose the right modes to access private site connections.
＂ Evaluate firewall rules and IP allowlists based on the API Management public IP
address.

Configuration recommendations
Consider the following recommendations for operational excellence when configuring
your API Management service:
Recommendation

Description

Ensure you set

Protect backend services and reduce the load placed on an API

quotas and rate
limits when
exposing APIs to

Management scale unit. Rate limiting policies can be applied at Global,
Product, API, and Operation levels to provide rate limit customization
applied to API consumers.

third parties.
Understand the

Follow standards and best practices when using the REST API. Following

Microsoft REST API

best practices enables maximum compatibility across platforms and

design and
architecture

implementations. Review the REST API Guidelines and API Design guidance.

guidance.
Understand the API

Every effort is made to ensure the API import process runs smoothly, which

import restrictions

includes requiring no customizations. Some scenarios impose restrictions

in API
Management.

that will require modification to the import source. Applies to both REST
and SOAP services. Reference Policy Restrictions for the current API Import
restrictions.

Understand the

Supports event logging to an Azure event hub to perform near real-time

Event logging

analysis. This feature integrates with external logging, security information

feature.

and event management (SIEM) solutions, or analyzing API usage in near
real time.

Trace calls in Azure
API Management

Tracing must be enabled on the subscription used to make the request.
Tracing is enabled on a request-by-request basis using the Ocp-Apim-Trace

to help with

header value. API Tracing is also built into the admin portal and is enabled

debugging and
testing.

by default when testing APIs from the portal.

Configure logging
using Azure

Logs can be sent to a Logs Analytics workspace to enable complex
querying and analysis. Metrics can be ingested for longer term analysis. All

Monitor for the API

data is then surfaced using Azure Monitor. It is possible to integrate

Management

Application Insights for Application Performance Management.

service.
Choose the right
modes to access
private site
connections.

Supports Virtual Network integration in internal and external mode.

Recommendation

Description

Evaluate firewall

A fixed public IP address is available for the lifetime of the service with the

rules and IP
allowlists based on

Basic, Developer, Standard, and Premium plans for API Management.

the API
Management
public IP address.

Next step
Reliability and Azure Firewall

Reliability and Azure Front Door
Article • 08/24/2023

A scalable and secure entry point, Azure Front Door provides fast delivery of your global
web applications. Front Door uses the Microsoft global edge network to create fast,
secure, and widely scalable web applications.
Key features include:
Accelerated application performance by using split TCP-based anycast protocol.
Intelligent health probe monitoring for backend resources.
URL-path based routing for requests.
Enables hosting of multiple websites for efficient application infrastructure.
Cookie-based session affinity.
For more key features and information, reference Why use Azure Front Door?
To understand how Azure Front Door creates a more reliable workload, reference the
following topics:
Selecting the Front Door environment for traffic routing (Anycast)
Front Door routing methods

Checklist
Have you configured Azure Front Door with reliability in mind?
＂ Use WAF policies in Front Door. Lock down Application Gateway to receive traffic
only from Azure Front Door when using Azure Front Door and Application Gateway
to protect HTTP/S applications.
＂ Use Azure Front Door Web Application Firewall (WAF) policies to provide global
protection across Azure regions for inbound HTTP/S connections to a Landing Zone.
＂ Create a rule to block access to the health endpoint from the internet.
＂ Ensure that the connection to the back-end is re-encrypted.
＂ Evaluate the four traffic routing configurations in Azure Front Door.

Configuration recommendations
Consider the following recommendation to optimize reliability when configuring Azure
Front Door:

Recommendation

Description

Use WAF policies in Front Door. Lock
down Application Gateway to receive
traffic only from Azure Front Door

Certain scenarios can force a customer to implement rules
specifically on AppGateway: For example, if ModSec Core
Rule Set (CRS) 2.2.9 , CRS 3.0 , or CRS 3.1 rules are

when using Azure Front Door and
Application Gateway to protect

required, rules can be only implemented on AppGatway.

HTTP/S applications.

Rate-limiting and geo-filtering are available only on Azure
Front Door, not on AppGateway. Instructions to lock
down traffic on Azure Front Door can be found at
Frequently asked questions for Azure Front Door.

Ensure that the connection to the
back-end is re-encrypted.

Front Door doesn't support SSL passthrough. Front Door
must hold the certificate to terminate the encrypted
inbound connection.

Evaluate the four traffic routing

The Front Door service supports various traffic-routing

methods in Azure Front Door.

methods to determine how to route your HTTP/HTTPS
traffic to the various service endpoints. For more
information on traffic routing methods, see Front Door
routing methods.

Next step
Security and Azure Front Door

Security and Azure Front Door
Article • 08/24/2023

A scalable and secure entry point, Azure Front Door provides fast delivery of your global
web applications. Front Door uses the Microsoft global edge network to create fast,
secure, and widely scalable web applications.
Key features include:
Accelerated application performance by using split TCP-based anycast protocol.
Intelligent health probe monitoring for backend resources.
URL-path based routing for requests.
Enables hosting of multiple websites for efficient application infrastructure.
Cookie-based session affinity.
For more key features and information, reference Why use Azure Front Door?
To understand how Azure Front Door creates a more secure workload, reference the
following topics:
Security baseline for Azure Front Door
DDoS protection on Front Door
End-to-end Transport Layer Security (TLS) with Azure Front Door

Checklist
Have you configured Azure Front Door with security in mind?
＂ Consider using geo-filtering in Azure Front Door.

Configuration recommendations
Consider the following recommendation to optimize security when configuring Azure
Front Door:
Recommendation

Description

Consider using geo-

The Front Door service responds to user requests regardless of the

filtering in Azure Front
Door.

location of the user making the request. To receive traffic from specific
countries, use geo-filtering on Web Application Firewall for Azure
Front Door. For more information on geo-filtering see Web
Application Firewall on Front Door geo-filtering.

Next step
Operational excellence and Azure Front Door

Operational excellence and Azure Front
Door
Article • 11/30/2022

A scalable and secure entry point, Azure Front Door provides fast delivery of your global
web applications. Front Door uses the Microsoft global edge network to create fast,
secure, and widely scalable web applications.
Key features include:
Accelerated application performance by using split TCP-based anycast protocol.
Intelligent health probe monitoring for backend resources.
URL-path based routing for requests.
Enables hosting of multiple websites for efficient application infrastructure.
Cookie-based session affinity.
For more key features and information, reference Why use Azure Front Door?
To understand how Azure Front Door supports operational excellence, reference the
following topics:
How Front Door determines backend health
Monitoring metrics and logs in Azure Front Door
Front Door Standard/Premium (Preview) Logging

Checklist
Have you configured Azure Front Door with operational excellence in mind?
＂ Use Web Application Firewall (WAF) policies in Front Door. Lock down Application
Gateway to receive traffic only from Azure Front Door when using Azure Front Door
and Application Gateway to protect HTTP/S applications.
＂ Use Azure Front Door Web Application Firewall (WAF) policies to provide global
protection across Azure regions for inbound HTTP/S connections to a Landing Zone.
＂ Create a rule to block access to the health endpoint from the internet.
＂ Ensure that the connection to the back-end is re-encrypted.

Configuration recommendations

Consider the following recommendation to optimize operational excellence when
configuring Azure Front Door:
Recommendation

Description

Use Web Application Firewall
(WAF) policies in Front Door.

Certain scenarios can force a customer to implement rules
specifically on AppGateway: For example, if ModSec Core Rule

Lock down Application Gateway
to receive traffic only from

Set (CRS) 2.2.9 , CRS 3.0 , or CRS 3.1 rules are required, rules

Azure Front Door when using
Azure Front Door and
Application Gateway to protect

can be only implemented on AppGatway. Rate-limiting and
geo-filtering are available only on Azure Front Door, not on
AppGateway. Instructions on how to lock down traffic can be
found at Frequently asked questions for Azure Front Door

HTTP/S applications.

Ensure that the connection to

Front Door doesn't support SSL passthrough. Front Door must

the back-end is re-encrypted.

hold the certificate to terminate the encrypted inbound
connection.

Next step
Reliability and Network Virtual Appliances

