communication protocols, network types, and messaging patterns helps you design and
optimize a cost effective architecture.
For device connectivity, it's important to specify the network type. If you select a private
LAN or WAN solution, such as WiFi or LoraWAN, consider network TCO as part of overall
costs. If you use carrier networks such as 4G, 5G, or LPWAN, include recurring
connectivity costs.

IoT solution platform
To build an IoT solution for your business, you typically evaluate your solution by using
the managed app platform approach and build your enterprise ready solution by using
the platform services.
Platform services let you fine-tune services and control overall costs. It provides all
the building blocks for customized and flexible IoT applications. You have more
options to choose and code when you connect devices, and ingest, store, and
analyze your data. Azure IoT platform services include the products Azure IoT
Hub

and Azure Digital Twins .

Azure IoT Central

is a managed app platform that lets you quickly evaluate your

IoT solution by reducing the number of decisions needed to achieve results. IoT
Central takes care of most infrastructure elements in your solution, so you can
focus on adding industry knowledge, and evaluating the solution.

IoT Hub tiers
Most IoT solutions require bi-directional communication between devices and the cloud
to be fully functional and secure. The basic IoT Hub tier provides core functionality, but
excludes bi-directional control. For some early solution implementations, you might be
able to reduce costs by using the basic tier. As your solution progresses, you can switch
to a standard tier to optimize a secure communication channel for lower cloud-todevice messaging costs. For more information, see Choose the right IoT Hub tier for
your solution.

IoT Hub message size and frequency
Messaging costs depend greatly on device chattiness and message size. Chatty devices
send many messages to the cloud every minute, while relatively quiet devices only send
data every hour or more. Avoid device-to-cloud interactions that use many small
messages. Clarity about device chattiness and message size helps reduce the likelihood

of over-provisioning, which leads to unused cloud capacity, or under-provisioning,
which leads to scale challenges. Consider the size and frequency of message payloads to
ensure your infrastructure is the correct size and ready to scale.
Avoid cloud-to-device interactions that use many small messages. For example, group
multiple device or module twin updates into a single update, which have their own
throttling. Be aware of the message size used for the daily quota, 4K-byte for non-free
IoT Hub tiers. Sending smaller messages leaves some capacity unused, while larger
messages are charged in 4-KB chunks.
Use a single direct method to get direct feedback. Use a single device or module twin
status update to exchange configuration and status information asynchronously.
 Tip
You can monitor chatty interactions by using Microsoft Defender for IoT on Azure
IoT Hub and the Defender for IoT micro agent. You can create IoT Hub custom
alerts for device-to-cloud or cloud-to-device interactions that exceed a certain
threshold.
If message size is critical to cost management, reducing overhead is especially important
with long device lifecycles or large deployments. Options to reduce this overhead
include:
Use a shorter device ID, module ID, twin name, and message topic to reduce the
payload in MQTT packets. An MQTT payload looks like
devices/{device_id}/modules/{module_id}/messages/events/ .

Abbreviate the fixed length overhead and the message.
Compress the payload, for example by using Gzip.

IoT Hub message quotas and throttling limits
IoT Hub tiers have different sizes with specific quotas and throttling limits for
operations. Understand IoT Hub limits and quotas to optimize costs for device-to-cloud
and cloud-to-device messaging.
For example, the Standard S1 tier has a daily quota of 400,000 messages. Charges
increase in 4-KB chunks based on several factors:
One device-to-cloud (D2C) message can be up to 4-KB.
D2C messages that exceed 4-KB are charged in chunks of 4-KB.

Messages smaller than 4-KB can use the Azure IoT SDK SendEventBatchAsync
method to optimize batching on the device side. For example, bundling up to four
1-KB messages at the edge increases the daily meter by just one message.
Batching is only applicable for AMQP or HTTPS.
Most operations, such as cloud-to-device messages or device twin operations, also
charge messages in 4-KB chunks. All these operations add to the daily throughput
and maximum quota of messages.
Review the Azure IoT Hub pricing information documentation for detailed pricing
examples.
Besides daily message quotas, service operations have throttling limits. A key part of IoT
Hub cost optimization is to optimize both message quotas and operations throttling
limits. Study the differences between the limits in the form of operations per second or
bytes per second. For more information, see IoT Hub quotas and throttling.
Different throttling limits apply to different IoT Hub operations. Device-to-cloud
operations have an operations per second throttle that depends on the tier. In addition
to the message size, which is metered in 4-KB chunks, consider the number of
operations. Batching on the edge lets you send more messages in a single operation.
A single message of 2-KB, a batched message of 10-KB, or a batched message of 256KB only counts as a single operation, letting you send more data to the endpoint
without reaching throttling limits.

IoT Hub autoscaling
Dynamically adjusting the number of IoT Hub units helps optimize costs when message
volume fluctuates. You can implement an autoscale service that automatically monitors
and scales your IoT Hub service. See Auto-scale your Azure IoT Hub for a customizable
sample to implement autoscale capability. You can use your own custom logic to
optimize IoT Hub tier and number of units.

Deployment stamps for scaling
Deployment stamping is a common design pattern for flexible deployment strategies,
predictable scale, and cost. This pattern provides several advantages for IoT solutions,
such as geo-distributing groups of devices, deploying new features to specific stamps,
and observing cost per device. For more information, see Scale IoT solutions with
deployment stamps.

Device management and modeling layer
Managing devices is a task that orchestrates complex processes such as supply chain
management, device inventory, deployment, installation, operational readiness, device
update, bi-directional communication, and provisioning. Device modeling can reduce
management costs and messaging traffic volumes.

IoT Plug and Play
For TCO reduction, consider extended use cases as part of platform selection. IoT Plug
and Play enables solution builders to integrate devices with IoT Hub or Azure Digital
Twins without any manual configuration. IoT Plug and Play uses the Digital Twins
Definition Language (DTDL) V2 . Both are based on open W3C standards such as
JSON-LD and RDF, which enables easier adoption across services and tooling.
There's no extra cost for using IoT Plug and Play and the DTDL. Standard rates for IoT
Hub, Azure Digital Twins and other Azure services remain the same.
For more information, see How to convert an existing device to be an IoT Plug and Play
device.

IoT Hub DPS
IoT Hub DPS is a helper service for IoT Hub that enables low-cost, zero-touch, just-intime provisioning to the correct IoT hub without requiring human intervention. DPS
enables secure and scalable provisioning of millions of devices to reduce error and cost.
DPS enables low or no-touch device provisioning, so you don't have to train and send
people on site. Using DPS reduces the cost for truck rolls and time spent on training and
configuration. DPS also reduces the risk of errors due to manual provisioning.
DPS supports device lifecycle management with IoT Hub through enrollment allocation
policies, zero-touch provisioning, initial configuration setting, reprovisioning, and deprovisioning. For more information, see:
DPS pricing
How to reprovision devices

Asset and device state modeling
Compare cost differences between several device topology and entity stores such as
Azure Cosmos DB, Azure Digital Twins, and Azure SQL Database. Each service has a

different cost structure and delivers different capabilities to your IoT solution.
Depending on required usage, choose the most cost-efficient service.
Azure Digital Twins

can implement a graph-based model of the IoT environment

for asset management, device status, and telemetry data. You can use Azure Digital
Twins as a tool to model entire environments, with real-time IoT data streaming,
and merge business data from non-IoT sources. You can build custom ontologies,
or use standards based ontologies such as RealEstateCore, CIM, or NGSI-LD to
simplify data exchange with third parties. Azure Digital Twins has a pay-per-use
pricing model

with no fixed fee.

Azure Cosmos DB is a globally distributed, multi-model database. Cost is affected
by storage and throughput, with regional or globally distributed and replicated
data options.
Azure SQL Database can be an efficient solution for device and asset modeling.
SQL Database has several pricing models to help you optimize costs.

Asset deployment model
You can deploy edge solutions with different architectures: multiple endpoints, IoT
devices, direct-connected to the cloud, or connected through an edge and/or cloud
gateway. Different options for sourcing edge devices can affect TCO and time to market.
Ongoing maintenance and support of the device fleet also affects the overall solution
cost.
Where data is stored and processed in a given IoT solution affects many factors such as
latency, security, and cost. Analyze each use case and examine where it makes most
sense to use edge processing and data storage, and how it affects costs. Storing and
processing data at the edge can save storage, transportation, and processing costs. But
when you take scale into account, cloud services are often better options because of
cost and development overhead.
The Azure pricing calculator

is a useful tool to compare these options.

Event processing and analytics layer
The purpose of the event processing and analytics layer is to enable data-driven
decisions. Event timing and the purpose of analytics are key factors to consider. The
right service choice increases architectural efficiency and reduces the cost of processing
data and events.

Based on your requirements, implement hot, warm, or cold path processing for IoT data
analytics. The Azure IoT reference architecture helps you understand the difference
between these analytics paths and reviews the available analytics services on each path.
The Cost Optimization pillar in the Azure Well-Architected Framework includes the cost
considerations for data analytics stores, considering data storage, multiple servers to
maximize scalability, and the ability to access large data as external tables.
To get started, determine which types of data go through the hot, warm, or cold path:
Hot path data is kept in memory and analyzed in near real-time, typically using
stream processing. The output may trigger an alert or be written to a structured
format that analytics tools can query immediately.
Warm path data, such as from the last day, week, or month, is kept in a storage
service that can be queried immediately.
Cold path historical data is kept in lower-cost storage to be queried in large
batches.

Storage layer
One of the goals of an IoT solution is to provide data to end users. It's important to
understand storage types, capacity, and pricing to create a strategy for optimizing
storage costs.

Storage types
The choice of a repository for telemetry depends on the use case for your IoT data. If the
purpose is just to monitor IoT data, and volumes are low, you can use a database. If your
scenario includes data analysis, you should save telemetry data to storage. For time
series optimized, append-only storage and querying, consider purpose-designed
solutions such as Azure Data Explorer.
Storage and databases aren't mutually exclusive. Both services can work together,
especially with well-defined hot, warm, and cold analytics paths. Azure Data Explorer
and databases are commonly used for hot and warm path scenarios.
For Azure Storage, it's also important to consider data lifecycle factors like access
frequency, retention requirements, and backups. Azure Storage helps you define the
data lifecycle and automate the process of moving data from the hot tier to other tiers,
which reduces long-term storage costs. For more information, see Configure a lifecycle
management policy.

Database solutions
For database capabilities, it's common to choose between SQL and no-SQL solutions.
SQL databases are best suited for fixed schema telemetry with simple data
transformation or data aggregation requirements. To learn more, see Types of databases
on Azure .
Azure SQL Database and TimescaleDB for PostgreSQL are common choices for SQL
database. For more information, see the following articles:
Plan and manage costs for Azure SQL Database
Azure SQL Database and cost optimization
Azure SQL Database for PostgreSQL Extension
Performance tuning for Azure SQL Databases
If the data is best represented as an object or document without a fixed schema, no-SQL
is a better option. Azure Cosmos DB provides multiple APIs such as SQL or MongoDB.

For any database, partition and index strategies are important for performance
optimization and reducing unnecessary costs. For more information, see:
Partitioning and horizontal scaling in Azure Cosmos DB
Plan and manage costs for Azure Cosmos DB
Azure Synapse Analytics

is a modern Azure data warehouse. Synapse Analytics scales

by Data Warehouse Units (DWU), and you should choose the right capacity to handle
your solution requirements. Depending on use case, you can pause compute when no
job is running to reduce operational costs.

Transport layer
The transport layer transfers and routes data between other layers. As data travels
between layers and services, the choice of protocol affects costs. Use cases such as field
gateways, industry open protocol, and IoT network selection also affect costs in the
transport layer.
To reduce transmission sizes and costs, choose the right protocol for your IoT devices to
send telemetry.
Device clients regularly send keep-alive messages to IoT Hub. According to Charges per
operation, there's no charge for keep-alive messages. But you don't need to add a keepalive property in the telemetry if there's no specific requirement for it. For flexibility,
some Azure IoT Device SDKs provide the option to set a timespan for these messages if
you're using the AMQP or MQTT protocols.
For battery-powered IoT devices, you can choose between keeping connections alive or
reconnecting when the devices wake up. This choice affects power consumption and
network costs.
Reconnecting consumes packets around 6-KB for TLS connection, device authentication,
and retrieving a device twin, but saves battery capacity if the device wakes up only once
or twice per day. You can bundle messages together to decrease TLS overhead. Keeping
alive consumes hundreds of bytes, but keeping the connection alive saves network costs
if the device wakes up every few hours or less.
For high-level guidance about the connectivity and reliable messaging features in Azure
IoT device SDKs, see Manage connectivity and reliable messaging by using Azure IoT
Hub device SDKs. This guidance helps you reduce the costs of handling unexpected
behavior between device and Azure IoT services.

DPS reduces device lifecycle management costs from zero-touch provisioning to
retirement, but connecting to DPS consumes network cost for TLS and authentication.
To reduce network traffic, devices should cache IoT Hub information during
provisioning, and then connect to IoT Hub directly until they need to reprovision. For
more information, see Send a provisioning request from the device.

Interaction and reporting layer
As IoT handles time-series data, there are many interactions from a large number of
devices. Reporting and visualizing realizes the value of this data. Intuitive and simplified
user experiences and well-designed data interactions can be costly to build.
Grafana

is an open-source data visualization tool that provides optimized dashboards

for time-series data. Grafana communities provide examples that you can reuse and
customize in your environment. You can implement metrics and dashboard from timeseries data with little effort. Azure provides a Grafana plug-in for Azure Monitor.
Reporting and dashboard tools like Power BI allow a quick start from unstructured IoT
data. Power BI provides an intuitive user interface and capabilities. You can easily
develop dashboards and reports using time-series data, and get the benefits of security
and deployment at low cost.

Integration layer
Integration with other systems and services can be complex. Many services can help
maximize efficiency to optimize costs in the integration layer.
Azure Digital Twins can integrate various systems and services with IoT data. Azure
Digital Twins transforms all data into its own digital entity, so it's important to
understand its service limits and tuning points for cost reductions. Review Azure Digital
Twins service limits when designing your architecture. Understand functional limitations
to help integrate effectively with business systems.
When you use the query API, Azure Digital Twins charges per Query Unit (QU). You can
trace the number of QUs the query consumed in the response header. Reduce query
complexity and the number of results to optimize costs. For more information, see Find
the QU consumption in Azure Digital Twins.

DevOps layer

Cloud platforms transform capital expenditure (CAPEX) to operational expenditure
(OPEX). While this model provides flexibility and agility, you still need a well-defined
deployment and operational model to take full advantage of the cloud platform. A wellplanned deployment creates repeatable assets to shorten time to market.
A cloud platform provides agility for developers to deploy resources in seconds, but
there's a risk of provisioning resources unintentionally, or over-provisioning. A proper
cloud governance model can minimize such risks and help avoid unwanted costs.

Development environments
Developers can take advantage of the flexibility that Azure provides to optimize
development cost. The IoT Hub free tier, limited to one instance per subscription, offers
standard capabilities but is limited to 8000 messages a day. This tier is sufficient for
early-stage development with a limited number of devices and messages.
For compute environments, you can adopt serverless architecture for cloud-native IoT
solutions. Some popular Azure services for IoT workloads include Azure Functions and
Azure Stream Analytics. The billing mechanism depends on the service. Some services,
like Azure Stream Analytics for real-time processing, let developers pause services
without incurring extra costs. Other services bill by usage. For example, Azure Functions
bills based on number of transactions. Developers can take advantage of these cloudnative capabilities to optimize both development and operational cost.
An integrated development environment (IDE) accelerates development and
deployment. Some open-source IDEs like Visual Studio Code provide Azure IoT
extensions

that let developers develop and deploy code to Azure IoT services at no

cost.
Azure IoT provides free GitHub code samples with guidance. These samples help
developers extend device, IoT Edge, IoT Hub, and Azure Digital Twins applications.
GitHub also has features to implement seamless continuous integration and continuous
deployment (CI/CD) environments with low cost and effort. GitHub Actions are free for
open-source projects. For more information, see GitHub plans and features .

Load testing for cost estimation
You can use load testing to estimate overall costs, including cloud services, for end-toend IoT solutions. Because IoT solutions use large amounts of data, a simulator can help
with load testing. Simulation code samples like the Azure IoT Device Telemetry
Simulator help you test and estimate costs at scale with various parameters.

Deployment environments
It's common to deploy workloads in multiple environments, such as development and
production. Through infrastructure-as-code (IaC), you can accelerate deployment and
reduce time to market by reusing code. IaC can help avoid unintentional deployments
such as incorrect tiers. Azure services like Azure Resource Manager and Azure Bicep, or
third-party services such as Terraform and Pulumi, are common IaC options.
You can apply DevOps deployment practices to IoT solutions by using build and release
pipelines to different environments. For an example, see Use a DevOps pipeline to
deploy a predictive maintenance solution.

Support and maintenance
Long-term support and maintenance of field devices can escalate to become the largest
cost burden for a deployed solution. Careful consideration of system TCO is crucial to
realizing Return on Investment (ROI).
You need to support and maintain IoT devices for the lifetime of the solution. Tasks
include hardware repairs, software upgrades, OS maintenance, and security patching.
Consider ongoing licensing costs for commercial software and proprietary drivers and
protocols. If you can't do remote maintenance, you need to budget for onsite repairs
and updates. For hardware repairs or replacements, you must keep suitable spares in
stock.
For solutions that use cellular or paid connectivity media, select a suitable data plan
based on the number of devices, the size and frequency of data transmissions, and
device deployment location. If you have a service level agreement (SLA), you need a
cost-effective combination of hardware, infrastructure, and trained staff to meet the SLA.

Cloud governance
Cloud governance is essential for compliance, security, and preventing unnecessary
costs.
Cost management APIs let you explore cost and usage data through
multidimensional analysis. You can create customized filters and expressions that
help answer Azure resource consumption-related questions. Cost management
APIs can generate alerts when consumption reaches configured thresholds. Cost
management APIs are available for IoT Central, IoT Hub, and DPS.

Resource tagging applies labels to deployed resources. Along with Azure Cost
Management, tagging provides insights on ongoing costs based on the labels. For
more information, see Common cost analysis uses.
Azure Policy comes with built-in policies to label resources automatically, or flag
resources without tagging. To learn more, see Assign policy definitions for tag
compliance. Another use case for Azure Policy is to prevent provisioning of certain
tiers, which helps prevent over-provisioning in development or production
environments.

Monitoring
Many tools included in your Azure subscription can help your organization implement
financial governance and get more value out of your IoT services. These tools help you
track resource usage and manage costs across all of your clouds with a single, unified
view. You can access rich operational and financial insights to make informed decisions.
Telemetry logging commonly uses Log Analytics workspaces in Azure Monitor

. Log

Analytics includes 5 GB of storage, and the first 30 days of retention are free. Depending
on business needs, you might need a longer retention period. Review and decide the
right retention period to avoid unintentional costs.
Log Analytics provides a workspace environment to query logs interactively. You can
export logs periodically to external locations such as Azure Data Explorer, or archive logs
in a storage account for a less expensive storage option. For more information, see
Monitor usage and estimated costs in Azure Monitor.

Azure Advisor
Azure Advisor is a personalized cloud consultant that helps you follow best practices to
optimize your Azure deployments. Advisor analyzes your resource configuration and
usage telemetry, and recommends solutions that can help you improve cost
effectiveness, performance, reliability, and security.
Advisor helps you optimize and reduce your overall Azure spending by identifying idle
and underutilized resources. You can get cost recommendations from the cost tab on
the Advisor dashboard.
Although Advisor doesn't offer specific recommendations for IoT services, it can provide
useful recommendations for Azure infrastructure, storage, and analytics services. For
more information, see Reduce service costs by using Azure Advisor.

Next steps
Operational excellence in your IoT workload

Related resources
Cost optimization design principles
Capture cost requirements
Develop a cost model
Checklist - Design for cost
Checklist - Optimize cost
Azure IoT reference architecture
Azure IoT documentation

Operational excellence in your IoT
workload
Article • 04/27/2023

Given the complexity of IoT solutions requirements, organization's operational
capabilities are important for driving sustainable business value. This guide focuses on
the operational aspects of IoT devices and services that uniquely address the core
requirements of an IoT solution.
Operational excellence in an IoT workload requires full visibility and control over all
hardware and software components of the solution. Design, development, provisioning,
monitoring, support, and maintenance practices must be agile and deliver business
value without increasing operational risk.
In IoT solutions, the device diversity and scale, different network types, and
geographically distributed locations significantly shift the cloud and hybrid shared
responsibility model away from the cloud provider. Cloud services make it easier for
organizations to operate IoT devices and networks themselves or by using third parties,
but the organizations themselves own the operational responsibility for these key
elements of IoT workloads.
Operational excellence ensures that your IoT solution can successfully:
Support different user roles.
Manage all device lifecycle stages.
Scale efficiently to meet changes on demand.
Use automation for management and monitoring.
Integrate with other back-end systems.

Assess operational excellence in your IoT
workload
To assess your IoT workload through the lenses of the Well-Architected Framework
Operational Excellence pillar, complete the operational excellence questions for IoT
workloads in the Azure Well-Architected Review. After the assessment identifies key
operational excellence recommendations for your IoT solution, use the following
content to help implement the recommendations.

Design Principles

Five pillars of architectural excellence underpin the IoT workload design methodology.
These pillars serve as a compass for subsequent design decisions across the key IoT
design areas. The following design principles extend the quality pillar of the Azure WellArchitected Framework - Operational Excellence.
Design
principle

Considerations

Embrace
continuous

Ensure that the IoT solution can successfully manage automated device
provisioning, integrate with other backend systems, support different roles such as

operations
and scaling

solution developers, solution administrators, and operators, and adapt and scale
efficiently to any changes on demand such as new IoT devices being deployed or
higher ingestion throughput.

Optimize

Any successful enterprise IoT solution requires a strategy to establish and update a

build and
release

device or fleet of device's configuration. A device's configuration includes device
properties, connection settings, relationships, and firmware. IoT operators require

processes

simple and reliable tools that enable them to update a device or fleet of device's
configuration at any point during the device's lifetime.

Understand

Use IoT solution logging, monitoring, and alerting systems to determine whether

operational

the solution is functioning as expected and to help troubleshoot problems

health

throughout the lifecycle of the solution.

Use

An IoT device is fundamentally a small computer with specialized hardware and

automation
and

software. IoT devices are often constrained in hardware, for example having limited
memory or compute capacity. Automation and DevOps are essential to ensure that

DevOps

OS and software for IoT devices and gateways are properly uploaded and deployed
to minimize operational downtime. Automation and DevOps are essential for
monitoring and managing the lifecycle of IoT devices.

IoT architecture layers
Operational Excellence design principles help clarify considerations to ensure your IoT
workload meets requirements across the foundational IoT architecture layers.
The IoT core layers: Device and gateway, device management and modeling, and
ingestion and communication, identify IoT-specific solutions. The other layers and crosscutting activities are also common to, and often shared with, other workloads. DevOps
cross-cutting activities are especially important to support the operational excellence
pillar.

Device management and
modeling
layer

Interac on
and
repor ng
layer

DevOps

Event processing
and analy cs
layer
Device and
gateway
layer

Inges on and
communica on
layer
Storage
layer

Integra on
layer

Transport layer

Core IoT layers

Common layers

Device and gateway layer
This layer represents the physical or virtual device and gateway hardware deployed at
the edge or on premises.
A key factor in IoT operational excellence is an organization's ability to plan, provision,
configure, monitor, and retire IoT devices. Organizations must select IoT hardware that
meets business and technical requirements, and define appropriate testing procedures
to ensure operational reliability.
Greenfield projects that use new hardware usually have more flexibility in device types,
firmware and connectivity features, and technical specifications. You might need to
select devices that comply with regional certification requirements or regulations such
as CE, FCC, UL, PCI, or FDA.
Brownfield projects that already have hardware deployed typically have more hardware
restrictions. You might need to look for other types of hardware, such as protocol or

identity translation devices, or connectivity gateways such as Bluetooth to MQ Telemetry
Transport (MQTT) gateway.
Azure Certified Device Program

certification validates that a device can connect with

Azure IoT Hub and securely provision through the IoT Hub Device Provisioning Service
(DPS). The Azure Certified Device Catalog

can help you find and select certified

partner hardware. The Device Catalog has search and filter capabilities you can use to
find hardware that meets your solution requirements.
An important feature to look for in Azure IoT-certified hardware is Azure Plug-and-Play
and Digital Twins Definition Language (DTDL) compatibility. These features ensure that
devices integrate seamlessly with services such as Azure Digital Twins. For Azure IoT
Edge scenarios, it's important to find catalog devices that have the IoT Edge Managed
certification. This certification guarantees the device can run the IoT Edge runtime, and
enables deployment and management of IoT Edge modules that support edge
processing and analytics workloads.
Device components and spares must be available to cover maintenance and support
contracts for the lifetime of the solution. Ensure a timely and secure equipment supply
at the start of the project, because this requirement can be expensive to introduce later.
Use a trusted vendor chain and consider dual or multiple supply sources.

Ingestion and communication layer
The organization's network operations team typically partners with the
telecommunication operator to handle the communication network technology stack of
an IoT workload. Coordinate with your telecommunication operator to set up and
operate the wired and wireless communication network components of your IoT
solutions and operations.

Capacity scaling
Configure the ingestion and other back-end layers of the IoT cloud solution to be able
to scale to handle expected and unexpected capacity needs. If your solution is tied to a
connected product, you must handle fluctuations in expected load. Load can be
impacted by marketing initiatives such as sales or promotions, or by seasonal events
such as holidays. You should test load variations prior to events, including unexpected
events, to ensure that your IoT solution can scale.
Azure offers several options to meet capacity requirements as your business grows.
Capacity planning and scaling for your IoT solution varies depending on whether you
build an IoT Central

or IoT Hub -based solution.

IoT Central is a managed application platform that you can use to quickly evaluate
your IoT scenario and assess the opportunities for your business. IoT Central takes
care of most infrastructure elements however, it stores only 30 days of data.
Because most IoT solutions export data to other services, you should focus on
making sure those other services can handle expected and unexpected capacity
needs during the evaluation of your solution.
With an IoT Hub-based solution, it's your responsibility to scale up to handle
growth in the number of messages being ingested and to scale out to handle
regional demands. Understanding the number of messages that devices will send
to IoT Hub and the sustained throughput is critical to selecting the correct IoT Hub
tier to support the predicted demand.
If you're approaching the IoT Hub message limit, your system should be able to
automatically scale up IoT Hub to the next unit of capacity. Any back-end services
in the IoT solution, such as Azure Stream Analytics, Azure Cosmos DB, and Azure
Data Explorer must support scalability to ensure there are no bottlenecks anywhere
in the solution's data flow.
You should also plan for edge device capacity needs and requirements. Whether you're
managing real-time operating system (RTOS)-based devices or larger compute devices
with IoT Edge, make sure compute and memory sizing are adequate for your specific
use cases.

Device management and modeling layer
Implement a centralized device management solution to administer, monitor, and
operate the lifecycle of IoT devices, and to manage the overall configuration of the IoT
solution. Consider implementing an integrated UI to assist operation teams with device
fleet management.

Device provisioning
Define a remote device provisioning strategy to enable zero-touch, just-in-time
provisioning of IoT devices in the field without requiring human intervention.
For remote provisioning of IoT devices, Azure IoT Hub Device Provisioning Service (DPS)
enables connecting and configuring remote devices to IoT Hub. DPS enables zero-touch
provisioning without hard-coding information at the factory, and enables loadbalancing of devices across multiple IoT hubs.

Although DPS supports symmetric key attestation, in a production environment you
should use either the X.509 certificate or TPM attestation mechanisms. If you use X.509
certificates, you should deploy the root certificate, or an intermediate certificate signed
by the root certificate to DPS, to allow devices in the field properly authenticate to the
service and be assigned to their correct IoT hub.
Part of an IoT solution lifecycle includes reprovisioning devices in the field or moving
them between IoT hubs. DPS enables the configuration of reprovisioning policies that
determine expected behavior when an IoT device submits a new provisioning request.
Devices should be programmed to send a provisioning request on reboot, and should
implement a method to manually trigger provisioning on demand. This mechanism
ensures that every time a device starts up, it contacts DPS to get redirected to the
appropriate IoT hub.

Device configuration and update management
Establish a strategy to update device or device fleet configuration. A device's
configuration includes device properties, firmware, connection settings, and
relationships. IoT operators need simple and reliable tools that let them update a device
or device fleet's configuration at any point during the device's lifetime.
An IoT solution's scale and specific use of a device's configuration, influences the design
of a configuration management strategy. It's important to automate this strategy as
much as possible, and to ensure that the configuration can be set and updated
efficiently.
A configuration management strategy should support:
Inventory of IoT devices and IoT Edge devices deployed in the field.
Gradual update rollout through device grouping.
Resilient updates to support testing and rollbacks.
Automatic updates for existing or new devices.
Updated status reports and alerts.
Azure features that support these configuration management requirements include IoT
Hub automatic device management, IoT Edge automatic deployments, IoT Hub
scheduled jobs, and Device Update for IoT Hub.
For continuous updates to existing or new devices and IoT Edge device
configurations, such as properties, application specific settings, or relationships,
use either IoT Hub automatic device management or IoT Edge automatic
deployments. Both features offer an efficient, secure, and reliable way to automate
configuration deployments for a fleet or specific group of devices. The services

continuously monitor all new and existing targeted devices and their configuration
based on tags, to ensure the devices always have the specified configuration. The
key difference between these features is that automatic device management
applies only to non-IoT Edge devices, and IoT Edge automatic deployments apply
only to IoT Edge devices.
To update an existing device or IoT Edge device configuration based on a one-time
or recurring schedule, use IoT Hub scheduled jobs. This feature is an efficient,
secure, and reliable way to provide a configuration update for a fleet or specific
group of devices at a scheduled time.
To update existing device or IoT Edge device firmware, application, or package
updates over-the-air (OTA), use Device Update for IoT Hub. This service is a safe,
secure, and reliable way to update a fleet or specific group of devices.
It's a good idea to have a manual update method for IoT devices. Due to root certificate
changes or connectivity issues, you may need to manually update devices by physically
connecting to a local computer or using a local connectivity protocol such as Bluetooth.
To learn more about device management, see:
Azure IoT Hub Automatic Device Management
Azure IoT Edge automatic deployments
Azure IoT Hub scheduled jobs
Device Update for IoT Hub

Management user interface
Solution operators and administrators need an interface to interact with the IoT solution,
for example provision devices, add or remove users, send commands to IoT devices, or
manage device updates.
IoT Central has a built-in, easy-to-use management interface that lets operators and
administrators focus on adding industry knowledge, and evaluating the solution.
When you build your enterprise solution by using the platform services, such as IoT Hub
and Azure Digital Twins you can build a custom management UI by using the REST APIs
exposed in IoT Hub REST APIs and Azure Digital Twins REST APIs.

Integration layer
A typical IoT solution is composed of multiple components such as ingestion, routing,
data storage, and data processing. It's important to document and have a good

understanding of the entire data flow of the IoT solution. Have testing procedures in
place to ensure the different parts of the solution work as expected and meet the
technical and operational requirements of the organization. Implement automation to
identify device capabilities at scale as they connect to your IoT solution and to easily
integrate with back-end services.
Configure and test reliable integration with other Azure and third-party services that
support the back-end and front-end services of the IoT application. A successful IoT
implementation requires integrating IoT services such as IoT Hub and DPS with other
Azure and third-party services.
For example, DPS supports custom allocation policies by using custom code and Azure
Functions, so it's important to confirm that the Azure Function allows traffic coming
from DPS and IoT Hub. Another example is the integration between IoT Hub and
backend services to enable features such as message routing and file upload. IoT Hub
needs to properly authenticate to those Azure services. You should use managed
identities to eliminate the need to manage those credentials manually.

DevOps layer
DevOps includes role and user management, metrics collection, monitoring, and
automation.

Role and user management
A key decision early in a solution design phase is to define the roles that implement and
manage the solution. Determine the roles that are responsible for developing,
managing, and operating the IoT solution at scale, and the users assigned to those roles.
Ideally, the solution should trust a centralized identity provider, such as Azure Active
Directory (Azure AD), and only let the appropriate users in those roles perform
management or operation activities, such as creating and provisioning new devices,
sending commands to hardware in the field, deploying updates, and modifying user
permissions.
In an IoT Hub-based solution, you can use Azure AD to authenticate requests to IoT Hub
service APIs, such as creating device identities or invoking direct methods. You can
develop a custom management UI for solution operators and administrators, that
authenticates users against Azure AD and executes API requests to the IoT solution back
end on behalf of those users.

IoT Edge Metrics Collector
Azure IoT Edge provides the IoT Edge Metrics Collector

ready-to-use IoT Edge

module in the IoT Edge Module Marketplace. Add this module to an IoT Edge
deployment to collect metrics and send them to Azure Monitor. The open-source
module code is a multi-architecture Docker container image that supports Linux x64,
ARM32, and ARM64 version 1809.
The Metrics Collector module can collect logs from all the modules that can emit
metrics by using the Prometheus data model . While built-in metrics enable broad
workload visibility by default, you can also use custom modules to emit scenario-specific
metrics that enhance the monitoring solution.
There are two options to send metrics from the Metrics Collector module to the cloud:
Send the metrics to Log Analytics. The collected metrics are ingested into the
specified Log Analytics workspace using a fixed, native table called
InsightsMetrics .

Send the metrics to IoT Hub. You can configure the collector module to send the
collected metrics as UTF-8 encoded JSON device-to-cloud messages through the
edge hub module. This option unlocks monitoring of locked-down IoT Edge
devices that are only allowed external access to the IoT Hub endpoint.
The AllowedMetrics and BlockedMetrics configuration options take space- or commaseparated lists of metric selectors. A metric is matched to the list and included or
excluded if it matches one or more metrics in either list.
You can visually explore metrics collected from IoT Edge devices by using Azure Monitor
workbooks. Curated workbooks use built-in metrics from the IoT Edge runtime that are
ingested into a Log Analytics workspace. These views don't need any metrics
instrumentation from the workload modules.
The Azure portal provides curated monitoring workbooks for IoT Edge devices as public
templates. To access the workbooks, from your IoT Hub or IoT Central page in the
Azure portal, navigate to the Workbooks page in the Monitoring section.

Monitoring
Use IoT solution logging, monitoring, and alerting systems to determine whether the
solution is functioning as expected and to help troubleshoot and mitigate problems.
Monitoring and logging help determine whether devices or systems are in an error
condition, correctly configured, generating accurate data, and meeting defined service
level objectives.
IoT logging and monitoring systems can be more complicated than in standard line-ofbusiness applications. The complexity arises because IoT solutions often span:
Physical sensors that interact with an environment.
Applications on the edge doing activities like data shaping and protocol
translation.
Infrastructure components such as on-premises gateways, firewalls, and switches.
Ingestion and messaging services.
Persistence mechanisms.
Insight and reporting applications.
Subsystems that operate and scale independently in the cloud.
The following simplified logging and monitoring architecture shows examples of typical
IoT solution components and how they use recommended technologies.


If your critical applications and business processes rely on Azure resources, you should
monitor those resources for availability and performance. You can use Azure Monitor
to carry out the following monitoring activities:
Detect and diagnose issues across applications and dependencies with Application
Insights.
Correlate infrastructure issues with VM Insights and Container Insights.
Drill into your monitoring data with Log Analytics for troubleshooting and deep
diagnostics.
Support operations at scale with smart alerts and automated actions.
Create visualizations with Azure dashboards and workbooks.
Collect data from monitored resources using Azure Monitor Metrics.

Monitor IoT Hub
Azure IoT Hub collects the same types of monitoring data as other Azure resources, as
described in Monitoring data from Azure resources. The Overview page in the Azure
portal for each IoT hub includes charts that provide some usage metrics, such as the
number of messages used and the number of devices connected to the hub. The
information on the Overview page is useful, but represents only a small amount of the
monitoring data available for an IoT hub.
Some monitoring data is collected automatically and is available for analysis as soon as
you create your IoT hub. You can configure other types of data collection. To learn more
about the metrics and logs that IoT Hub creates, see Monitoring Azure IoT Hub data
reference.

Monitor updates

As with any deployment or update, you should monitor the update state of
deployments and devices. DevOps provides a way to consistently deliver fresh software
updates. Device Update for IoT Hub monitors compliance by measuring how many
devices have installed the highest version compatible update. A device is compliant if it
has installed the highest version available compatible update.

Monitor configuration
As with any deployment or update, you should monitor and alert on the status of a
device configuration or update deployment. Each Azure IoT configuration service
collects and stores logs and metrics in Azure Monitor. You can use this data to create
Azure Monitor alerts to send notifications when a configuration deployment or update
is created, completed, or failed.
If the monitoring data provided by each of the Azure IoT configuration services isn't
enough, the Azure IoT Hub service APIs offer a more granular view.

Monitor automation and DevOps
DPS, IoT Hub, and IoT Edge provide continuous metrics and status updates that are key
inputs to monitor continuous integration/continuous deployment (CI/CD) status or
automation script output. You can collect and analyze these metrics in a Log Analytics
workspace and then define alerts.
To learn more about monitoring, see:
Monitor device connectivity using the Azure CLI IoT extension
Monitor, diagnose, and troubleshoot Azure IoT Hub device connectivity
Monitor Azure IoT Hub
Check Azure IoT Hub service and resource health
Tutorial: Set up and use metrics and logs with an Azure IoT hub
Collect and transport metrics

Automation
An IoT device is fundamentally a small computer with specialized hardware and
software. IoT devices are often hardware-constrained, for example have limited memory
or compute capacity. Automation and DevOps ensure that IoT device and gateway
software is properly uploaded and deployed to minimize operational downtime.
Automation and DevOps are essential to monitoring and managing the full lifecycle of
developing, deploying, and operating an IoT solution and devices.

The key benefit of a mature DevOps implementation is agility, the ability to quickly
sense and respond to changes in business needs. To use automation with DevOps for
agile software development, deployment, testing, integration, and operations, follow
these recommendations:
Use CI/CD DevOps principles and processes to boost productivity and create a
seamless rapid development cycle.
Deploy application software changes in an infrastructure-as-code (IaC)
environment to automate and manage the ongoing operation of deployed
software.
Automate the IoT application software lifecycle from development through testing
to deployment to IT operations.
Use DevOps tools and processes in IoT Hub and IoT Edge to automate the edge
software lifecycle. Use IoT Edge to deploy IoT application software on devices.
Provide operators with tools to gain visibility and insights, collaborate, control, and
maintain a reliable IoT solution.
Embrace cross-functional teams to deliver continuously for solutions. Device
vendors and cross-functional solution developers should work together to develop
and deploy IoT solutions.
Evolve business and deployment models to create possibilities for different
business models and pilot validation, deployment, and enhancements.

Automate device lifecycle
Connected IoT Edge devices have a lifecycle that extends beyond deploy, break and fix,
and retire. Connected devices put organizations in the best position to capitalize on
opportunity and continuously add incremental innovation throughout the system
lifecycle.
In IoT solutions, software programs installed on hardware define system functionality.
Thousands of devices might be connected to a single cloud endpoint such as IoT Hub.
Any change in configuration or software must be spread across all the devices. To
change system functionality, update software instead of making hardware changes or
local interventions.
When you implement automation and DevOps in IoT systems, follow specific
automation and DevOps requirements for each device lifecycle phase. The following
tables describe Azure IoT features that support three phases of the device lifecycle.

Beginning of life
Expectations

Platform feature available with code snippets

Non-DPS device registration

Bulk device updates

Device provisioning

DPS configuration required to provide zero touch device
provisioning

Device certificate and token

Control access to IoT Hub using Shared Access Signatures

management

(SAS)

Device certificate lifecycle
management

CA certificate lifecycle management with DPS and DigiCert

Device initial configurations

Device twins and device modules

Midlife
Expectations

Platform feature available with code snippets

Continuous device configuration

Device twins and device modules

management at scale
CI/CD pipeline for IoT Edge modules

Continuous integration and continuous deployment
(CI/CD) to Azure IoT Edge devices

Device reprovisioning

DPS device reprovisioning

SAS key generation for changes or

Control access to IoT Hub using Shared Access Signatures

expiration

(SAS)

Log and device diagnostics

Pre-configured Azure workbooks for IoT Hub

Azure IoT Edge monitoring
diagnostics

Collect and transport IoT Edge device logs and metrics

OTA device updates

Device Update for IoT Hub

End of life
Expectations

Platform feature available with code snippets

Unenroll devices

Disenroll a device from DPS

Remove device-specific configuration

Device twins and device modules

Device replacement

Same as beginning of life

Next steps
Performance efficiency in your IoT workload

Related resources
Automatic IoT device and module management using the Azure CLI
Azure IoT Edge requirements
Azure IoT Edge managed certification requirements
DPS X.509 attestation
Azure IoT Hub scaling
Control access to Azure IoT Hub by using Azure Active Directory
Plan for capacity - Microsoft Azure Well-Architected Framework
Operational excellence design principles
Azure IoT reference architecture
Azure IoT documentation

Performance efficiency in your IoT
workload
Article • 04/27/2023

IoT solutions include device, edge and cloud components, and range from millions of
small devices connected to the cloud to industrial solutions where a few powerful
servers are gateways for cloud connectivity. The number of devices, their physical and
geographical placement, and the number of messages they send or receive are some of
the factors that can define the performance efficiency of an IoT workload.
Performance efficiency also includes an IoT workload's ability to scale efficiently to meet
demands. A benefit of the cloud is geographical availability and the ability to scale
services on demand, with little or no application downtime.
Performance efficiency represents performance relative to resource use under stated
conditions. Performance efficiency measures how well a product or system, when
performing its functions, meets requirements for:
Time behavior, such as response times, processing times, and throughput rates.
Resource utilization, or amounts and types of resources used.
Capacity, or maximum limits.

Assess performance efficiency in your IoT
workload
To assess your IoT workload through the lenses of the Well-Architected Framework
Performance Efficiency pillar, complete the performance efficiency questions for IoT
workloads in the Azure Well-Architected Review. After the assessment identifies key
performance efficiency recommendations for your IoT solution, use the following
content to help implement the recommendations.

Design principles
Five pillars of architectural excellence underpin the IoT workload design methodology.
These pillars serve as a compass for subsequent design decisions across the key IoT
design areas. The following design principles extend the quality pillar of the Azure WellArchitected Framework - Performance Efficiency.

Design
principle

Considerations

Design for
horizontal
scaling

An IoT solution can start with a few hundred devices or messages and grow to
millions of devices and messages per minute. You can easily scale cloud services
to an increase in load, but the situation can be more complex for IoT devices and
gateways. IoT devices can be designed or deployed before the solution is
finalized. Industrial IoT or similar industries can measure device lifespan in
decades. Updating capacity by replacing devices is costly. In these scenarios, it's
especially important to plan ahead.

Shift-left on
performance
testing

Test early and test often to catch issues early. Be aware of the complexity of
having sensors, devices, and gateways in geographically different locations with
different characteristics, speed, and reliability of communication. Plan for this
complexity in your testing, and make sure to test for failure scenarios like network
disconnection. Do stress and load testing of all device, edge, and cloud
components in your IoT solution.

Continuously
monitor for

To monitor different types of devices in multiple geographical regions, use a
distributed monitoring solution. Balance the amount of information monitored

performance

and sent to the cloud against memory and performance costs. Tune transmission

in
production

for diagnostic scenarios, and monitor at multiple levels and layers. Expose
gateway metrics for industrial or gateway-enabled solutions.

IoT architecture layers
Performance efficiency design principles help clarify considerations to ensure your IoT
workload meets requirements across the foundational IoT architecture layers. The
following sections address the layer specifics for the performance efficiency pillar.

Device management and
modeling
layer

Interac on
and
repor ng
layer

DevOps

Event processing
and analy cs
layer
Device and
gateway
layer

Inges on and
communica on
layer
Storage
layer

Integra on
layer

Transport layer

Core IoT layers

Common layers

Device and gateway layer
An IoT device is a computing device that connects to an IoT solution and can collect,
transmit, or receive data. Gateways are connection points between devices and the
cloud, or between IoT and other components.

Optimize hardware capabilities
Upgrading or replacing hardware is costly and time consuming. Size IoT devices for
required capacity and functionality in advance.
To optimize for hardware capabilities:
Run compute and input-output intensive tasks on specific hardware. For example,
run machine learning (ML) algorithms on local graphics processing units (GPUs).

Optimize existing hardware capabilities by using efficient languages and
frameworks like Embedded C

and Rust Embedded

. You can use the Azure IoT

Embedded C SDK when developing for constrained devices, or when most of the
security and communication stack is already available on the device.
Use the Azure IoT device SDK for C for all you need to connect to the cloud
gateway. The Azure IoT Device software development kits (SDKs) manage required
message translation, error handling, and retry mechanisms needed for a resilient
connection.
Scaling is important for the device and gateway layer. To scale this layer:
Use gateways as units of scale. If your solution adds IoT devices or assets (for
example OPC UA

servers) over time, use more edge gateways to ingest data

from those servers.
Conduct a scale assessment for all upstream layers, including cloud gateways and
cloud services. To learn more about using multiple IoT hubs as scale units for an
IoT solution, see How to provision devices across IoT hubs.

Run workloads at the edge
Depending on system constraints such as network throughput or latency, consider
running some workloads at the edge. Separate workloads by time constraint and
required latency and response times. Use local compute for low latency and
intermittently connected scenarios. Run large-scale workloads in the cloud.
At the edge, use priority queues to send different data streams in the required order.
With priority queues messages are sent in order of priority, but Azure IoT Hub still
journals messages based on receipt order.

Optimize device connectivity
Consider the following points to optimize device connectivity:
Use the IoT Hubs that have the lowest latency to your devices. You might need IoT
Hubs in multiple regions when devices need to connect from different
geographical locations.
Use an open stateful connection for bi-directional communications between the
devices and the IoT solution to minimize the overhead of setting up connections.

Don't connect all devices at once, for example after a regional power outage. Use
truncated exponential backoff with introduced jitter when retrying.

Optimize offline scenarios
You can provide devices with enough information and context to work without a cloud
connection and to store data locally, so they can recover from disconnections and
reboots. The following strategies support offline operations:
Ensure the device is capable of storing data locally when the device isn't
connected, including logs and cached telemetry according to priority.
Set a time to live (TTL) on the data, so that expired data is removed automatically.
Discard less important data when the device isn't connected, to reduce local
storage needed and reduce synchronization time when the device reconnects.
If edge device storage reaches capacity, use a cache eviction strategy such as firstin last-out (FIFO), last-in first-out (LIFO), or priority-based.
Consider using a separate disk or disk controller to store data, so the device
runtime or application can continue to work when low on storage.
Use device twins and module twins to asynchronously sync state information between
devices and the cloud, even when devices aren't currently connected to the cloud
gateway. Device and module twins contain only the current state at a point in time, not
any history or removed information.

Ingestion and communication layer
The data ingestion and communication layer sends data from the devices to the IoT
solution. Patterns of communication between devices and the IoT solution include:
Device-to-cloud messages.
Cloud-to-device messages.
File uploads.
Device twins.
Direct methods.

Optimize messaging efficiency
The number and size of device to cloud messages is an important parameter for IoT
solution performance efficiency. Azure IoT services such as IoT Hub

and Azure IoT

Central

define message limits per tier, which affects both solution performance and

cost.
Consider the following messaging recommendations:
IoT Hub and IoT Central calculate daily quota message counts based on a 4-KB
message size. Sending smaller messages leaves some capacity unused. In general,
use message sizes close to the 4-KB boundary. Group smaller device-to-cloud
messages into larger messages to reduce the total number of messages, but
consider the introduced latency when combining messages.
Avoid chatty communication. For device-to-device or module-to-module edge
communication, don't design interactions that send many small messages.
Use built-in Azure IoT Edge SDK message batching for Advanced Message
Queuing Protocol (AMQP) to send multiple telemetry messages to the cloud.
Use application-level batching by combining multiple smaller messages at the
downstream device and sending larger messages to the edge gateway. This
batching limits the message overhead and reduces writes to local edge disk
storage.
Use AMQP connection multiplexing to reduce the dependency on Transmission
Control Protocol (TCP) connections limits per SDK client. With AMQP connection
multiplexing, multiple devices can use a single TCP connection to IoT Hub.
Use direct methods for request-reply interactions that can succeed or fail
immediately, after a user-specified timeout. This approach is useful for scenarios
where the course of action is different depending on whether the device
responded.
Use device twins for device state information, including metadata and
configurations. IoT Hub maintains a device twin for each device that you connect.

Understand messaging quotas and throttling
The IoT Hub tier sets cloud gateway per-unit limits. The messaging quota defines
sustained throughput and sustained send rates for the tier. IoT Hub can handle loads
above these quotas for short durations to resiliently handle bursts or load overshoots.
Another important limit is the hourly or daily service load or throttle limit. Throttle limits
protect an IoT hub from too much load for too long a time.

The following diagrams show the relationship between load, quota, and throttle limits.
The left diagram shows that IoT Hub can handle sustained or constant high load up to
the level of the quota for the IoT Hub tier. The right diagram shows that IoT Hub can
handle load that is changing over time, as long as it doesn't hit the throttle limit and on
average isn't above the quota for the IoT Hub tier.

Optimize message processing
Messages from a device or gateway might need to be translated, processed, or enriched
with more information before storage. This step could be time-consuming, so it's
important to evaluate the effect on performance. Some recommendations conflict, such
as using compression for optimizing data transfer versus avoiding cloud processing in
decrypting messages. These recommendations need to be balanced and evaluated
against other architectural pillars and solution requirements.
To optimize cloud data processing performance:
Optimize the data format used to send data to the cloud. Compare performance
(and cost) of bandwidth vs. performance improvement with less cloud data
processing needed. Consider using IoT Hub message enrichment to add context to
device messages.
Do time-critical event processing on ingested data as it arrives, instead of storing
unprocessed data and requiring complex queries to acquire the data. For timecritical event processing, consider the impacts of late arrival and windowing.
Evaluate depending on use case, for example critical alarm handling versus
message enrichment.
Select the right IoT Hub tier, Basic or Standard, based on solution requirements. Be
aware of features that the Basic tier doesn't support.

Select the right IoT Hub tier size, 1, 2, or 3, and the number of instances based on
data throughput, quotas, and operation throttles. For IoT Central, select the right
tier: Standard 0, Standard 1 or Standard 2, based on the number of messages sent
from devices to the cloud.
Consider using Azure Event Grid for publish-subscribe event routing. For more
information, see React to IoT Hub events by using Event Grid to trigger actions and
Compare message routing and Event Grid for IoT Hub.

Prioritize data
Some data that devices send to the cloud might be more important than other data.
Classifying and handling the data based on priority is a good practice for performance
efficiency.
For example, a thermostat sensor sends temperature, humidity, and other telemetry, but
also sends an alarm when temperature is outside a defined range. The system classifies
the alarm message as higher priority and handles it differently than the temperature
telemetry.
Consider the following recommendations for data classification and handling:
Use IoT Edge priority queues to make sure important data is prioritized while
sending to IoT Hub. IoT Edge buffers messages when there's no connectivity, but
after the connection is restored, sends all buffered messages in priority order first,
followed by new messages.
Use IoT Hub message routing to separate routes for different data priorities
depending on use case. IoT Hub message routing adds some latency.
Save and send low priority data at longer intervals, or by using batch or file
uploads. Malware detection on uploaded files increases latency.
Separate messages based on time constraints. For example, send messages to IoT
Hub directly when there's a time constraint, and utilize file upload via IoT Hub or
batch data transfer like Azure Data Factory if there's no time constraint. You can
use the IoT Edge blob module for file upload.

Device management and modeling layer
Different types of devices can connect to an IoT solution, and an IoT solution can
connect to many devices and gateways at the same time. Besides connecting and

configuring devices and gateways, the IoT solution must understand the data the
devices and gateways capture and ingest, and must transfer and contextualize that data.
IoT components can use different protocols, connectivity, data ingestion frequencies,
and communication patterns. The IoT solution must be able to manage which devices
and gateways are connected and how they're configured.
To manage devices and configurations for performance efficiency:
Optimize sizing based on device and message load.
Know the number of messages the cloud gateway can handle, depending on tier
and number of units.
Account for anomalies in sustained throughput due to data distribution,
seasonality, and bursting.
Use multiple cloud gateways when the IoT solution must manage millions of
devices. Use DPS to assign devices to IoT hubs.

Provision devices with DPS
Use DPS to set up a connection to an IoT hub during provisioning, when the IoT Hub
connection isn't available anymore, or during device reboot.
Use the DPS evenly weighted distribution policy to adjust the weight for
provisioning, based on use case. For more information, see How the allocation
policy assigns devices to IoT Hubs.
Consider provisioning devices to the IoT solution over a period of time, distributed
or in smaller batches, to balance the DPS load and quota. When onboarding in
batches, plan for the batches and overall migration timeline. Account for DPS limits
in number of operations, device registrations, and maximum connections per
minute, including latency and retries.
Use DPS to allocate devices to IoT Hubs in different regions based on latency.
Use a caching strategy for the DPS connection string to reduce DPS reconnect
operations.

Manage downstream devices
An IoT solution is horizontally scalable if it has multiple gateways or edge devices per
site or location and downstream devices that can connect to any of these gateways or

edge devices.
Use multiple gateways and edge devices in translation mode when the number of
downstream devices, their messages and message sizes will change over time, and
their protocol or message must be translated. Gateways and edge devices in
translation mode can translate protocols or messages to and from downstream
devices, however a mapping is needed to find the gateway a downstream device is
connected to. Account for added message translation and buffering overhead at
the gateway or edge device when you use translation mode.
Use multiple gateways and edge devices in transparent mode to connect
downstream Message Queue Telemetry Transport (MQTT) or AMQP devices when
their number can change over time per site or location. Gateways and edge
devices in transparent mode can connect MQTT/AMQP devices for bi-directional
communication. Account for added message buffering, storage, and configuration
overhead at the gateway or edge device when you use transparent mode.

Transport layer
The transport layer handles connections between a device and the IoT solution,
transforming IoT messages to network packages and sending them over the physical
network. IoT solutions commonly use AMQP and MQTT connection protocols.

Optimize resource usage
The connection between a device and the cloud needs to be secure, reliable, and
scalable to handle the targeted number of devices and messages.
Use an open stateful connection from a device to the cloud gateway. IoT Hub is
optimized for managing millions of open stateful connections by using MQTT,
AMQP, or WebSocket protocols. Keep open connections to the devices to
minimize the overhead of security handshakes, authentication, and authorization.
This practice improves performance and greatly reduces required bandwidth.
Use an AMQP protocol that supports multiplexing multiple channels on a single
connection to minimize the number of open connections the cloud gateway
requires. By using multiplexing, a transparent gateway can connect multiple leaf
devices using their own channels over a single connection.
Use the device and module twins cloud gateway patterns to asynchronously
exchange state information between devices and the cloud.

Configure DPS to move the device state when a device connects to another cloud
gateway.

Optimize data communication
The number and size of device to cloud messages affects performance and cost.
Evaluating data communication is key to performance efficiency in your IoT workload.
Use an efficient data format and encoding that doesn't use extensive bandwidth to
send data to the cloud. For low bandwidth networks, consider using a compressed
or binary format, but understand the overhead of uncompressing or converting the
data in the cloud.
Consider storing high-volume data locally and uploading it hourly or daily.
Group many small device-to-cloud messages into fewer larger messages to reduce
the total number. However, don't send only large messages, but balance between
average message size and throughput.

Storage layer
The different types of data collected and referenced in an IoT solution often require
storage types that are specialized and optimized for different scenarios on devices,
gateways, and cloud. Data that must be available in multiple geographical regions
globally or locally, and in some cases replicated to optimize latency, increases IoT
storage complexity.
Use a time-series database for storing time-series data that has timestamps and
values. Enrich time-series data telemetry with columns for filtering, for example
CustomerID, RoomID, or other use-case specific columns.
Use device and gateway storage for caching data, or to keep data when
disconnected. Account for required storage space. Don't keep all data, but use
downsampling, store only aggregates, or store data for limited time periods.
Consider separating data ingestion and event processing storage from reporting
and integration storage needs.
Use the data storage type that fits the need for required throughput, size,
retention period, data volume, CRUD requirements, and regional replication. Some
examples are Azure Data Lake Storage, Azure Data Explorer, Azure SQL, and Azure
Cosmos DB.

Event processing and analytics layer
You can process data that devices generate before sending it to or within the IoT
solution. Data processing can include translation, contextualization, filtering and routing,
or more advanced analytics like trend analysis or anomaly detection.

Optimize edge versus cloud processing
Run real-time and near real-time workloads, or small, optimized, low-latency processing
with time constraints, on devices or at the edge by using local compute. Run larger
workloads, or other workloads that have added or external data, or compute
dependencies, in the cloud.
For example, run a machine learning algorithm at the edge to count people in a video
stream, and send an event containing the count to the cloud. Use the cloud to compare
trends between different factories.
Run analytics workloads at the edge by using the Stream Analytics Edge module. For
example, you can run anomaly detection at the edge and label the events sent to the
cloud with the detected anomaly. When you run analytics at the edge, account for extra
latency, late arrival, and windowing impact.
Be aware of the overhead of an edge workload with many connected downstream
devices. The edge node must forward or process all messages and handle caching all
the data if there's intermittent cloud connectivity. Validate the performance impact on
your solution by testing with the planned maximum of downstream devices and
messages per edge node. Be aware of the performance impact that message translation
or enrichment can have on edge, IoT Hub, or cloud event processing.

Categorize individual workloads
Separate workloads by time constraint and required latency and response times, for
example response within seconds vs. batch per hour. Hybrid hardware systems-on-achip (SoCs) can support workloads on the device level.
At the edge, use priority queues to separate different data streams with different
priorities and TTL. For example, alarms should always be sent first but have a lower TTL
than telemetry.
In the cloud, you can use consumer groups on Azure Event Hubs to separate out
different data streams and handle and scale alarms differently from telemetry. You can
also use IoT Hub routes to separate out different data streams, with filtering and

separate endpoints. IoT Hub message routing adds some latency. Use Event Hubs, Azure
Event Grid, or Azure Service Bus to distribute workloads while protecting against back
pressure in the cloud.
Overly complex IoT Hub routing rules can affect throughput, especially routing rules
with message body JSON filters, where every message needs to be deserialized and
scanned.

Handle high-volume cloud data
To optimize performance efficiency for high-volume cloud data:
Use out-of-the-box service integration between IoT Hub and data destinations like
Azure Data Lake Storage and Azure Data Explorer that are already optimized for
high performance throughput.
Use the Event Hubs SDK to develop custom ingestion from an IoT hub with the
included event processor. The event processor can rebalance devices and hosts.
Use the right number of IoT Hub partitions and consumer groups for the number
of simultaneous data readers and required throughput.
Separate the storage needed for data ingestion and event processing from the
storage needed for reporting and integration.
Use the data storage that fits the needs based on required throughput, size,
retention period, data volume, CRUD requirements, and regional replication.
Examples are Azure Data Lake Storage, Azure Data Explorer, Azure SQL, or Azure
Cosmos DB. For more information, see Select an Azure data store for your
application.

Integration layer
The integration layer connects an IoT solution to other services and business
applications.
Separate the IoT solution ingestion pipeline from integration processing. Make
sure complex queries or loads from the integration layer don't affect data
ingestion performance.
Use well-defined and versioned APIs for access to IoT data and commands.

Avoid tools for end users to create user-defined queries against IoT data storage.
Consider using separate data stores for integration and for reporting.

DevOps layer
Use the following DevOps mechanisms to maximize performance efficiency:
A connected registry for local caching and deployment of container images.
IoT Hub to update deployments to multiple devices at once, including devices and
gateways.
Device twins and module twins to update device configurations in a scalable and
efficient way.
Performance testing, including stress and load tests to replicate the production
environment, such as location and heterogenous devices.

Monitoring
Use Azure Monitor to collect IoT Hub metrics with alerts for critical metrics. Set up Azure
Monitor alerts based on current scale limits, such as device to cloud messages sent per
second. Set the alert to a percentage of the limit, such as 75%, for pre-notification of
upcoming scalability limits. Also set up Azure Monitor alerts for logs and metrics such as
number of throttling errors.
Set Azure Service Health service alerts to trigger notifications when IoT Hub status
changes.

Next steps
Reliability in your IoT workload

Related resources
Performance efficiency principles
Reference: IoT Hub endpoints
IoT Hub message size
Select an Azure data store for your application
Monitoring Azure IoT Hub data reference
Performance efficiency design principles

Azure IoT reference architecture
Azure IoT documentation

Oracle workload best practices
Article • 01/23/2023

Oracle workloads comprise not only Oracle Databases, but also applications such as
Siebel, Peoplesoft, JD Edwards, E-Business Suite or customized WebLogic Server
applications.
Customers around the globe are looking to host Oracle workloads on Azure. For that
reason, Microsoft provides solutions for each workload. This includes guidance around
network and reducing latencies, and also auto-scaling the solutions.
The section about Oracle workloads on Azure provides guidance that applies the Azure
Well-Architected best practices as the technical foundation for building and operating a
highly reliable solution on Azure at-scale.

About Oracle workloads
The term workload refers to a collection of database and application resources that
support a common business goal or the execution of a common business process. These
workloads could be Customer relationship management applications, Human Resources,
customized application that mostly relies on WebLogic Server and others. WebLogic
Server, Siebel, Peoplesoft, JD Edwards and E-Business Suite are Oracle on-premise
applications.
Oracle applications on Azure and its approach are described in Application Design.
An Oracle Workload therefore describes a collection of application resources and
databases, which must be highly available on the platform. The workload must always
be resilient to failures.

What are the common challenges
Microsoft Azure makes it easy to deploy and manage cloud solutions. However, building
and migrating Oracle workloads that are highly available and reliable on the platform
remains a challenge for these main reasons:
Oracle applications architectures are complex. The complexity relies on the
dependencies between the application and database tier, Version upgrades and
patches. Siebel has an architecture change between the version IP16 and IP17. The
architecture change results in adjustments on the application and database tier to
configure application servers on the database layer.

Designing a reliable application at scale requires knowledge about the
application versions and architectures as well as dependencies on each layer. By
providing in-depth knowledge, we can help you to select the right technologies
and guide you through the configuration setup.
Oracle database architectures differ from customer to customer. Oracle RAC,
Exadata features like SmartScan put complexity into the setup. Automatic
Workload Repositories provide a great insight into the actual usage of Exadata
Features or RAC Setup’s. Microsoft Azure provides solutions for every challenge so
that we can address most of your needs.
All Oracle workloads need to be architected to handle failures with correlated or
cascading impact. Reliability Engineering is an important task within the entire
architecture design.

Assess the holistic architecture
Oracle workloads most often require high availability. High Availability is part of
Reliability under Well-Architected Framework. High Availability has impact on the other
pillars as well. If the architecture isn't assessed holistically, you might create unnecessary
latencies. For that reason you should follow the recommendations of all pillars of the
Well-Architected Framework.
Security: The way user access applications and the holistic development of a
workload architecture to mitigate security threats, such as Distributed Denial of
Service (DDoS) attacks, will have a significant bearing on overall reliability.
Operational Excellence: Potentially reached throughput or Memory on the
database respond to operational issues will have a direct impact on application
availability. Latencies should be eliminated to a minimum.
Performance Efficiency: Availability is more than simple uptime, but rather a
consistent level of application service and performance relative to a known healthy
state.
Achieving high reliability imposes significant cost tradeoffs, which may not be justifiable
for every workload scenario. It's therefore recommended that design decisions be driven
by business requirements.

What are the key design areas?
Oracle on Azure guidance within this series is composed of architectural considerations
and recommendations orientated around the below key design areas.

Design

Summary

area
Application

The use of a scale-unit architecture in the context of lift and shift highly reliable

design

Oracle Applications. Also explores the Oracle application design patterns that allow
for scaling, and error handling. Explore Oracle application dependencies between
the web tier and application tier by understanding the shared connection between
storage folders and databases.

Data

Oracle on Azure offer different Virtual Machine sizes. The choice is based on the

Platform

statistics of your Automatic Workload Repository (AWR) report

for analyzing the

current database usage. The AWR should always be handed in on peak-load.
Security

Oracle Applications have attached ports. It also depends on the operating system
the application architecture has. Depending on the protocol, you can use different
options to secure your access. Application Proxy, Azure Firewall, Application
Gateway. Next to this you should take a look on the SSO method the version of the
application has. It's important that we architecture your application according to
best practices.

Networking
&

This section refers a bit to security as well. ExpressRoute helps you to set up a
private connection to properly secure you and your environment. Microsoft Load

Connectivity

Balancer should be configured to IP addresses (if necessary). Make sure that the
network architecture doesn't create unnecessary latency.

Operational

Ansible or other Infrastructure-as-Code possibilities can help you to automate

Procedures

processes for Oracle workloads.

Health

Your Oracle workload environment should be properly maintained. Therefore

Modeling

checking the health status of the virtual machines and the ExpressRoute
Connection should be used. On Oracle databases, you can use the Oracle Cloud
Control.

Deployment
& Testing

Before you upgrade applications, you should test it in your test environment. The
same should be done on the Database side. Even when you use Infrastructure-asCode you should test any deployment before putting in production.

We invite you to explore Oracle workload design best practices and return to this
content regularly throughout the lifecycle of your Oracle workload. The content
highlights critical areas of focus but also refers you to other documentation for deeper
technical insight.

Application design
Oracle applications are complex. Especially the understanding of supported and
unsupported functionalities from version to version make a lift and shift from version to

version introduces difficulties in the migration approach. And if an understanding of
each application version is missing most migration fails.
Moreover companies don't just want to lift and shift, but modernize the architecture and
bind to functional and non-functional requirements. However, these requirements
should be examined alongside key cloud application design patterns to ensure
aspirations are fully achieved.
The design areas below explores both the subscription scale-unit approach and
important application design patterns for building highly reliable Siebel, E-business
Suite, JD Edwards, and Peoplesoft applications on Azure.
） Important
All Oracle applications are legacy systems and possess strong dependencies
between the application tier and the database tier. Separating two tiers across
different cloud vendors introduces latencies. Therefore you should do a proper
technical assessment and decide if you are fine with it.

Oracle application designs
Oracle workloads such as Siebel, E-Business Suite, JD Edwards, and Peoplesoft have
specific application design patterns for Azure. Below are example Azure architecture
diagrams and more product detail of each Oracle workload designed for setting up
internal and external user access. Note the application design considerations and the
Azure services used for each design.

Siebel on Azure
Siebel is an on-premises CRM application that is used in many ways by companies.
Siebel is one of the most complex applications in Oracle’s portfolio.
If you want to migrate your Siebel application, this must be done in the Siebel Tool
subnet. Make sure that the database version matches up with the application version.
Otherwise, this could be a first reason a migration fails.
In version 17 or newer, you need to configure certain servers and utilities on the
application and database tier. As soon as the application tier is set up, all servers must
be configured on the database as well. If all the tasks above haven't been conducted,
either the migration will fail and/or the performance affected heavily.

The following design example provides a first idea of a generic Siebel Architecture on
Azure for IP 16 and earlier:



The following design example provides a first idea of a generic Siebel Architecture on
Azure for IP 17 and earlier:



Refer to the Siebel design considerations:

(1) Network & Security - You should consider establishing an Azure AD for Single-SignOn (SSO). The SSO method used is Security Assertions Markup Language (SAML).
Microsoft allocates an Azure AD Application Proxy. You should consider it especially for
remote users. Internal users should be routed through ExpressRoute. If you desire a
Firewall in front, Azure Firewall can be configured as well.
In cases where external users need to access your application, the Application Gateway
provides a Web Application Firewall, but also a Layer 7 Load Balancing. Note that
Application Gateways can only be used for http/s protocols. The subnets can be secured
by using Network Security Groups (NSG). However if you desire to grant access only to
certain individuals you can also use Role-Based-Access-Control (RBAC).
Because an SSH port is required for Siebel, a Bastion host as a jump box can also
provide another security for an in-depth mature security posture.
(2) Application Web Tier - The web tier load balances the requests and send the
requests accordingly to the application tier, database tier and/or backup.
(3) Application Tier - The application tier contains several tasks and servers. The web
tier directs the requests into the application tier, shared storage system, and the
database. The application tier has strong dependencies between the application server
and the shared file system. The shared file System has a direct connection to the
database. Cutting the dependencies causes latencies. A proper technical architecture
assessment should take place before considering cutting these dependencies to
different cloud vendors.
When you set up a holistic architecture and technical approach for migration you have
the ability to establish it more modern. Microsoft offers various options. Auto-Scaling is
interesting for companies that have events where they need to scale on high demands.
Virtual Machine Scale Sets can provide another value for Siebel. The Siebel Workflow
Servers contain much information and for some customers it scales high and no need to
redo architecture. Virtual Machine Scale Sets lets you create and manage a group of
load-balanced VMs and provides high availability.
(4) Database Tier - The database tier has one primary and replicated to a secondary
using Data Guard. If you stay within one datacenter, the synchronous configuration
should be used. If you install your application across datacenters, you should configure
Data Guard in Asynchronous mode.
(5) Backup - Backups are sent from the application tier and the database tier. It's just
one of many reasons why those two tiers shouldn't be separated into two different

vendors. Thereby Backups of the database are performed by Azure Backup Volume
Snapshot

on Premium Files to the secondary region.

(6) Disaster Recovery - There are different solutions you can choose from. It very much
depends on your requirements. The architecture above is built to be highly available. For
replicating the application tier you can use Azure Site Recovery. Another solution you
can choose is Redundancy options for managed disks. Both solutions replicate your
data. Redundancy options for managed disks are a solution that can simplify the
architecture but also comes with a few limitations.

E-Business Suite on Azure
Oracle E-Business Suite (EBS) is a suite of applications including Supply Chain
Management (SCM) and Customer Relationship Management (CRM). As EBS is a SCM
and CRM system, it usually has many interfaces to third-party systems. The below
architecture is built to be highly available within one region.
We assume that external users don't cross the corporate network in the diagram below:


Refer to the Oracle EBS design considerations:
(1) Network & Security - You should consider establishing an Azure AD for Single-SignOn (SSO). The SSO method used is Security Assertions Markup Language (SAML).
Microsoft allocates an Azure AD Application Proxy. You should consider it especially for

remote users. Internal users should be routed through ExpressRoute. If you desire a
Firewall in front, Azure Firewall can be configured as well.
In cases where external users need to access your application the Application Gateway
provides a Web Application Firewall, but also a Layer 7 Load Balancing. Note that
Application Gateways can only be used for http/s protocols. The subnets can be secured
by using Network Security Groups (NSG). However if you desire to grant access only to
certain individuals you can also use Role-Based-Access-Control (RBAC).
Because an SSH port is required for EBS, a Bastion host as a jump box can also provide
another security for an in-depth mature security posture.
(2) Application Tier - The application tier consists of more than two application servers.
Usually, the rules for the application server are saved on application web servers.
Evaluate the access you need to establish. If users only access the web tier but aren't
allowed to access the application server, consider allocating the tiers into application
web tier and application tier.
However, if the application tier and the database tier will be cut into two different cloud
vendors, it can cause high latencies. We recommend you to do a proper technical
assessment and decide if high latencies will impact your daily business.
As soon as you approach the technical assessment, you should consider modernizing it.
Some customers ask for auto-scaling methods. Auto-Scaling can be achieved through
Virtual Machine Scale Sets (Virtual Machine Scale Sets) for EBS. Some of the servers that
you have in use operate more tasks and create a higher throughput than others. This
should be evaluated during the Design Phase. Virtual Machine Scale Sets don't require a
rearchitecture and let you create and manage a group of load-balanced VMs that
provides high availability.
(3) Database Tier - The database tier has one primary and replicated to a secondary
using Data Guard. If you stay within one datacenter, the synchronous configuration
should be used. If you install your application across datacenters, you should configure
Data Guard in Asynchronous mode.
(4) Backup - Backups are sent from the application tier and the database tier. Thereby
Backups of the database are performed by Azure Backup Volume Snapshot

on

Premium Files to the secondary region.
(5) Disaster Recovery - There are different solutions you can choose from. It very much
depends on your requirements. The architecture above is built to be highly available. For
replicating the application tier you can use Azure Site Recovery. Another solution you
can choose is Redundancy options for managed disks. Both solutions replicate your

data. Redundancy options for managed disks are a solution that can simplify the
architecture but also comes with a few limitations.

JD Edwards on Azure
Oracle's JD Edwards is an integrated applications suite of comprehensive enterprise
resource planning software. We have seen JDE used in Supply chain, Warehouse
Management, Logistics, Manufacturing resource planning and more. Because of the use
of the application, we see that interfaces to other systems are important as well.
The following architecture is built to being highly available. We assumed that external
users aren't accessing over the corporate network. If an external user accesses the
application using corporate network, the architecture can be simplified on networking.


Refer to the JD Edwards design considerations:
(1) Network & Security - You should consider establishing an Azure AD for Single-SignOn (SSO). The SSO method used is Security Assertions Markup Language (SAML).
Microsoft allocates an Azure AD Application Proxy. You should consider it especially for
remote users. JDE does only offer an ssh port. In that case we recommend you to set a
Firewall in front by using Azure Firewall to properly protect your application installation
for external user.

Internal users can access your application through ExpressRoute. If desired, a Web
Application Firewall on Azure Front Door can be configured as well.
The subnets can be secured by using Network Security Groups (NSG). However if you
desire to grant access only to certain individuals you can also use Role-Based-AccessControl (RBAC).
Because an SSH port is required for JDE, a Bastion host as a jump box is recommended
and can provide another security for an in-depth mature security posture.
(2) Application Web Tier - The application web tier consists of more than two
application servers. Usually, the rules for the application server are saved on application
web servers. Within the presentation tier, each instance is associated with storage.
Cutting the dependencies can cause high latencies. Therefore we recommend to do a
proper technical assessment.
As an often requested auto-scaling method you can explore Virtual Machine Scale Sets
for JDE.
Some of the servers that you have in use operate more tasks and create a higher
throughput than others. This throughput should be evaluated during the Design Phase.
Virtual Machine Scale Sets don't require a rearchitecture and let you create and manage
a group of load-balanced VMs which also high availability.
(3) Database Tier - The database tier has one primary and replicated to a secondary
using Data Guard. If you stay within one datacenter, the synchronous configuration
should be used. If you install your application across datacenters, you should configure
Data Guard in Asynchronous mode. Data from the database tier are sent directly to an
Azure Storage. The Storage is dependent on your current architecture setup.
(4) Backup - Backups are sent from the application tier and the database tier. It's just
one of many reasons why those two tiers shouldn't be separated into two different
vendors. Thereby Backups of the database are performed by Azure Backup Volume
Snapshot

on Premium Files to the secondary region.

(5) Disaster Recovery - There are different solutions you can choose from. It very much
depends on your requirements. The architecture above is built to be highly available. For
replicating the application tier you can use Azure Site Recovery. Another solution you
can choose is Redundancy options for managed disks. Both solutions replicate your
data. Redundancy options for managed disks are a solution that can simplify the
architecture but also comes with a few limitations.

Peoplesoft on Azure

Oracle's PeopleSoft application suite contains software for human resources and
financial management. The application suite is multi-tiered, and applications include
human resource management systems (HRMS), customer relationship management
(CRM), financials and supply chain management (FSCM), and enterprise performance
management (EPM).


Refer to the Peoplesoft design considerations:
(1) Network & Security - You should consider establishing an Azure AD for Single-SignOn (SSO). The SSO method used is Security Assertions Markup Language (SAML).
Microsoft allocates a Azure AD Application Proxy. You should consider it especially for
remote users.
Internal users should be routed through ExpressRoute. If you desire a firewall in front,
you configure Azure Firewall.
In cases where external users need to access your application, the Application Gateway
provides a Web Application Firewall, but also a Layer 7 Load Balancing. Note that the
Application Gateway can only be used for http/s protocols.
The subnets can be secured by using Network Security Groups (NSG). However if you
desire to grant access only to certain individuals you can also use Role-Based-AccessControl (RBAC).
Because an SSH port is required for Peoplesoft, a Bastion host as a jump box can
provide extra security for an in-depth mature security posture.

） Important
Check the your operating systems for proper architecture and try to migrate as
much to a Linux OS as possible.
(2) Application Web Tier - Requests entering the web tier are processed and sent to the
application tier, database tier or Backup. The Elastic Search includes the indexes for the
Peoplesoft application.
(3) Application Tier - The application tier contains several tasks and servers. It runs the
business logic and processes but also maintains the connection to the database. As
soon as this dependency is cut, it causes latencies. Therefore, the application and the
database tier shouldn't be separated into two different vendors. The Process Scheduler
is only required for Windows operating systems. For that reason, the architecture should
be evaluated carefully.
Microsoft offers a couple of features for establishing a modern architecture. AutoScaling is interesting for companies that have events where they need to scale on high
demands.
(4) Database Tier - The Database tier has one primary and replicated to a secondary
using Data Guard. If you stay within one datacenter, the synchronous configuration
should be used. If you install your application across datacenters, you should configure
Data Guard in Asynchronous mode.
(5) Backup - Backups are sent from the application tier and the database tier. Thereby
Backups of the database are performed by Azure Backup Volume Snapshot

on

Premium Files to the secondary region.
(6) Disaster Recovery - There are different solutions you can choose from. It very much
depends on your requirements. The earlier mentioned architecture is built to be highly
available. For replicating the application tier you can use Azure Site Recovery. Another
solution you can choose is Redundancy options for managed disks. Both solutions
replicate your data. Redundancy options for managed disks are a solution that can
simplify the architecture but also comes with a few limitations.

Choose the right VM for your workloads
Every database and server is used to different capacities. Therefore, it is important to
extract AWR reports on peak-load.

On the application tier, prepare numbers and statistics from the Web tier and the
application tier. Statistics should include:
Name of the server
Number of CPUs
Average utilization of CPU
Memory size
Average utilization
App/ DB storage size
App and DB version
Operating system
Total IOPS
Total throughput
Backup strategy
The E and M-series Virtual Machines are the right to choose from. Each Virtual Machine
comes with a different size and can be perfectly matched to your needs. Microsoft also
offers constrained VMs. These Virtual Machine are designed for customers not in need
of many CPU but memory.
Recommendations for Oracle on Azure:
Recommendation

Benefit

Define functional and

Includes the access of individuals, your backup strategy, RPO&RTO,

non-functional

availability, storage strategy to cost optimization, data retention, and

requirements

security requirements

Right-Size your

Provide AWRs for your databases on peak-load and an overview about

environment

the statistics of the application server

Provide the version of

Different versions of Oracle Application have different limitations. You can

your application

help us to assess the right migration approach by just providing your
application version

Security

Assess the version of your application for SSO methods. Some versions
come with certain limitations

Availability

Microsoft offer a few availability methods of which you can make use of:
Proximity Placement Groups, HA Storage types

Oracle and Microsoft have partnered to create a number of ready-to-deploy solutions
for Oracle WebLogic Server on Azure IaaS. To get started, see What are solutions for
running Oracle WebLogic Server on Azure Virtual Machines?.

Illustrative Examples
The Oracle workloads guidance provided within this series is based on a solutionorientated approach to illustrate key design considerations and recommendations.
There are several reference implementations and scripts available.
For more information, see the Oracle reference architecture.
We invite you to explore Oracle workload design best practices and return to this
content regularly throughout the lifecycle of your Oracle workload. The content
highlights critical areas of focus but also refers you to other documentation for deeper
technical insight.
For more information, see:
Azure Center for Oracle Solutions
Oracle workload in Azure
Oracle workload architectures

Next Steps
Reliability

Oracle workload reliability
Article • 01/24/2023

In the cloud, we acknowledge that failures happen. Instead of trying to prevent failures
altogether, the goal is to minimize the effects of a single failing component. Use the
following information to minimize down time and ensure that recommended practices
for high availability are built into Azure and Oracle.
When discussing reliability with Oracle in Azure, it’s important to take into consideration
not just the database, the connected tiers on separate VMs, virtual network subnets and
disaster recovery if there's failures. Oracle on Azure IaaS can achieve these design
considerations and have recommendations for each item.

Conduct a reliability assessment
Availability is crucial to Oracle Workloads. To discover the reliability status of your
workload, you should answer some questions that help to identify areas of weaknesses.
This is crucial for the architecture design and configurations.
The assessment provides specific recommendations to focus on. You can start the WAF
assessment when prompted.

Create architecture reliability
Knowing the Architecture of your Oracle on-premises application is crucial. In some
cases, specific versions of applications have a slight difference in the application tiers
which are crucial for your migration phase. Next to it you should establish an API map
pointing out any dependency. A dependency will most definitely occur between the
application and database tier. The same applies to back up and your disaster recovery
strategy.
Make sure to match up to the on-premises application architecture to reach high
availability. It's most important for Siebel.

Make use of Azure Advisor
There are no specific built-in recommendations in Azure Advisor for Oracle on IaaS
solutions in Azure. However, Azure Advisor has broad pillar coverage across the
common resources used in these architectures, including compute (including Azure
VMware), storage, and networking. Reviewing recommendations from Azure Advisor for

these underlying resources can detect configurations & topologies that can lead to
reliability impact, optimize cost from under-utilization of resources, and reveal
opportunities improve user experience through surfacing throttling issues or proximity
placement suggestions. See the related Azure Well-Architected service guide for each
service in your architecture for a list of key Azure Advisor alerts for that service.

Create a fail-over in a multiple availability zone and
second region deployments for disaster recovery
Business-critical Oracle Applications require failure prevention and therefore holistic
architecture. One of these business-critical applications can be Oracle E-Business Suite.
As a given Tier 1 example for Oracle E-Business Suite in a multiple availability zone
deployment and second region deployments for disaster recovery.
First establish a multiple availability zone deployment with separated VNet with
subnets. The Application tier uses Azure Site Recovery with a passive secondary
virtual machine in availability zone three from the availability zone 1 primary.
Use two Oracle Observers as a primary in availability zone one and a secondary in
availability zone two. The observers monitor and direct the whole traffic to the
primary database. Whereas the primary database is deployed in availability zone
one. Oracle Data Guard performs the redo sync to availability zone two and can be
configured for maximum availability. Data Guard can be established as
synchronous or asynchronous. Within one region a synchronous configuration can
be used for reaching a lower latency as in async mode.
A second Data Guard standby configuration in the secondary region is established for
disaster recovery purposes and is configured for maximum protection. Thereby backups
of the database are performed by Azure Backup Volume Snapshot on Premium Files to
the secondary region.
If a primary goes down, Observer(s) will reroute the traffic to the secondary DB2 as it
comes out of standby, becomes primary and takes over all functionality for environment
and sequence to fail over to secondary region standby if regional outage in first region.



Create a failover for business critical Oracle applications
in a two availability zone deployment with manual
failover
The web server tier, application tier and database tier reside in its own virtual network
subnet.
Azure Site Recovery or the manual clone utility can be established to duplicate the
passive secondary in AZ2. The primary will be set up in availability zone one whereas the
database uses Data Guard to replicate it to an active Standby in AZ2.
A failover would require manual intervention from the customer to fail over if there is a
failure of availability zone one. Backups use Active Data Guard standby in AZ2 and
backup to Azure Premium files in AZ2 to remove any additional IO pressure to the
primary database.



Checklist for Reliability
The reliability checklist includes the Recovery Point Objective (RPO), Recovery Time
Objective (RTO) and any business SLAs for the environment. The checklist should include
all of the components for the environment, not just the database and may have different
tiers of HA for different resources depending on their requirement for the business and
system.
Choices for Oracle on Azure should include and be reviewed in the design principles for
adding reliability to the architecture.
To assess the Utilization, extract the AWR or statspack workload data to right-size the
database in Azure (lift and shift the workload, not the on-premises hardware.).
Microsoft offers different sizes of Virtual Machines matching CPU, Memory and
throughput. Based on the data in the AWR or statspack you can choose the correct VM
SKU for Oracle Workload to ensure reliability and sustainability of the Oracle workload.
Some explanations to the different types of Virtual Machines are:
D-series newest version (v5 or higher) for small Oracle databases or nonproduction.
E-series VM skus, newest version, (v5 or higher) whenever available for most
production Oracle database workloads.
M-series for high memory/vCPU use Oracle databases but be cognizant of IO limits
for attached disk. Preference for network attached storage.

Choose a virtual machine (VM) based on the needs of vCPU, memory and IO threshold
for storage attached to VM, dependent on attached managed disk or network attached
storage.
Based on the AWR and statspack data you should also choose a Premium SSD for OS
Disk and place Linux swapfile(s) on VM temp storage.
The appropriate storage for throughput (MBPs) for Oracle workload should be chosen.
Another solution when your workload requires a high throughput is Azure NetApp Files
(ANF). For more product information, see Azure NetApp Files
For any multi-tier systems using E and D series VMs, consider using Proximity Placement
Groups for more consistent performance between VMs.
Calculate the Recovery Point Object (RPO), Recovery Time Objective (RTO) and uptime
SLAs for the system and ensure it matches for both the IT organization and the business.
Consider enabling host level caching on the VM and use readonly caching on premium
SSD P30-P50 for Oracle Datafiles. Performances for read-heavy workloads require
consistency for relational systems. Where bursting may offer some benefits, most often
we rely on host-level caching for best and consistent Oracle workload performance.
Read-only is chosen as Oracle desires all writes to write through to the datafiles to avoid
hindering issues by caching.
Use accelerated networking for VM. To reduce the latency on the network, Azure
ExpressRoute should be established.
The application health should be monitored, not just Oracle, but application and
middleware tier (if existing):
Oracle Enterprise Manager can be deployed on a separate VM to monitor,
maintain, and manage Oracle environments.
Oracle Enterprise Manager text logs can be loaded to Log Analytics and used with
Azure Monitor for a single pane of glass monitoring.

Recommendations for your Oracle workloads on Azure
Recommendation

Benefit

Use Host-level
ReadOnly Caching

P30-P50, (up to 4095G) can offer almost double MBPs on reads for datafiles.
Bursting isn’t consistent or guaranteed, but caching offers better

for Oracle
datafiles

performance and at no extra cost.

Recommendation

Benefit

Use Host-Level

Oracle VMs can benefit with ReadWrite caching for the OS disk only.

ReadWrite caching
on OS Disk
Separate Redo
Logs for Log

Log File Sync and Log File parallel write waits in Oracle can benefit by
separating log files too small ultra disk allocation. If sync waits are shown,

Latency

and requirement to have two members of redo log groups, separate
members to TWO ultra disks with high enough IO set to handle log latency.
Don’t configure any host-level caching if only redo logs on premium disk.

For more suggestions, see Principles of the reliability pillar.

Next step
Security

Oracle workload security
Article • 01/20/2023

Security is one of the most important aspects of any architecture. Azure provides all the
tools needed to secure your Oracle workload. Oracle Applications can contain sensible
data. Peoplesoft as an HR system is one of the examples that the whole architecture
must be secured properly. This can be achieved through secured authentication
methods, hardened networking, and encryption.
Oracle on Azure is delivered in the infrastructure as a service (IaaS) cloud model. We
recommend you regularly evaluate the services and technologies used to ensure your
security posture evolves with the threat landscape. Below are security recommendations
for consideration. We recommend you review the security design principles.

Use identity management
Identity management is a framework that controls access to critical resources. Especially
within Oracle applications lifecycle management is crucial. Part-time workers joining
only during summer season, interns joining companies, or full-time employees. Many of
these are in need of different accesses, which need to be checked and maintained, but
also removed as soon as they leave the company. There are two identity management
use cases to consider for your Oracle workload, and the identity management solution
differs for each.
(1) Operating system - Operating system - Organizations can improve the security of
Windows and Linux virtual machines in Azure by integrating with Azure Active Directory
(Azure AD). Azure AD is a fully managed identity and access management service. For
more information, see:
Sign in to a Windows virtual machine in Azure by using Azure AD
Sign in to a Linux virtual machine in Azure by using Azure AD and OpenSSH
Sign in to a Windows virtual machine in Azure by using Azure AD
(2) Oracle application – Oracle Applications usually require a SSH (Port 22) and/or
http(s) (Port 443) access. We recommend configuring single sign-on (SSO) using Azure
Active Directory). SSO allows end users to connect to the Oracle applications via
browser. For more information, see Azure Active Directory documentation.
The table below provides a summary of the recommended SSO method for the given
Oracle solution.

Oracle solution

SSO methods

Siebel

Security Assertion Markup Language (SAML).
From version IP18.1 and onwards:
OAuth

Peoplesoft

From Version 8.53 and later:
- Kerberos
From Version 8.53 and later:
- SAML
- OAuth2.0
For more information, see Datawiza Azure AD

Hyperion

SAML 2.0

E-business suite (EBS)

SAML

JD Edwards (JDE)

SAML.
For more information, see Datawiza JDE.

Microsoft also offers customers coming from on-premises application to use an
application proxy. The application proxy allows SAML authentication and can be used
for all Oracle applications providing you the opportunity to establish a Single-Sign-On
for external users. For more information, see:
Azure AD Application Proxy documentation.
Tutorial on setting up Azure AD SSO Gateway for Oracle E-Business Suite - EBS,
PeopleSoft, and JDE.

Use role-based access control (RBAC)
Role Based Access Control is a method to grant certain accesses to certain individuals.
Azure RBAC is an authorization system build on the Azure Resource Manager. It
provides a management layer to you that enables you to create, update, and delete
resources according to the need of certain roles and individuals. For more information,
see Azure RBAC documentation.

Enforce network and application security
Network and application security is crucial. Especially in regard to potential latencies,
but also internet facing applications. Network security should be the baseline of every
architecture.

(1) Azure Network Design - The first security option every customer has is a private
connection to the cloud installation. In this case it's an MPLS (any-to-any networks)
connection that is ExpressRoute. We recommend keeping the workload specific
resources in one virtual network.
For Oracle-native setups, you should use Oracle Cloud Connector and Oracle Private
Link for Azure as part of the hub-spoke setup. These technologies support the Oracle
extension and innovation architecture for the Oracle Business Technology Platform
(BTP). Azure native integrations fully integrated with Azure virtual networks and APIs and
don’t require these components.
(2) Virtual network security - You can use Network Security Groups (NSG) to filter
network traffic between Azure resources in your Azure virtual network. The NSG rules
can be defined to allow or deny access to your Oracle application. It can also be
dropped down to ports from on-premises IP address ranges. For more information, see
network security groups.
(3) Application security - This is one of the most complex parts when it comes to Oracle
applications. Determine where are users accessing the application and if they're only
coming from the corporate network or also from the Internet. Take a look on the
operating systems currently used whether Linux or Windows. Linux systems usually
require access from SSH whereas Windows require an RDP protocol. Most customers
desire to properly secure these protocols by installing a Bastion host in front. It's highly
based on the customer requirements and also on where the application will be accessed.
Next to this it's also recommended to secure these accesses through a Web application
Firewall. In case everyone logs in from the corporate network, this is only based on your
security requirements and optional.
In case a user accesses the application from the internet, consider an Application
Gateway. Azure Application Gateway provides two built-in functionalities. At first it
operates as a Web Application Firewall, but also has a built-in Layer7 Load Balancer. It is
only supported for access at Port 443 (http/s). For more information, see Azure
Application Gateway
Another option to secure your network is the Azure Firewall. This component defends
the web services against common exploits and vulnerabilities. It keeps the Oracle
Application highly available and helps you meet compliance requirements.
Another possibility to configure a mature security posture are Application Security
Groups (ASG). An ASG is an easier possibility to establish network security of the
dedicated workload. For more information, see Azure application security groups.

Make use of Azure Policy
There are no specific built-in Azure Policy definitions for Oracle on IaaS in Azure. Azure
Policy has broad coverage over the core resources that make up any Oracle solution on
Azure. Primary resources are virtual machines, storage, and networking. Always enforce
architectural choices with Azure Policy to prevent accidental drift from desired state.
There are policies for these resources that span all five pillars of the Well-Architected
Framework. If built-in policies for your architecture’s components or configurations do
not exist, you can create custom policies to cover any gaps.
Examples of key policies that are built-in would be Audit virtual machines without
disaster recovery, virtual machines should use Secure Boot, and any policies that limit
SKU choices to ensure you’re meeting reliability, cost optimization, and performance
efficiency targets. See the related Azure Well-Architected service guide for each service
for a list of recommended Azure Policies for that service.

Recommendations
Explore the following table of recommendations to optimize your Oracle on Azure IaaS
environment for security:
Recommendation

Benefit

Send STIG security
alerts from Oracle

Oracle Cloud Control STIG alerts and logs can be imported into Log
Analytics to grant a single pane of glass for Cloud Management, while

Cloud Control to
Activity Logs

retaining Oracle tools for database specialists.

Use Listener Services

Follow recommended practices for the Oracle Net Listener

to enforce

local operating system authentication and manage incoming client
connection requests to the database server.
Consider using the
DBSAT to evaluate

Oracle provides a stand-alone command line tool called the Oracle
Database Security Assessment Tool (DBSAT) to assess and check

security state of
database

regulatory compliance, including relevant configuration and configuration
information.

Virtual Machine

Follow the recommended practices for Virtual Machine Security in Azure,

Security in Azure

including the use of compute, data security, ports and network.

Next Steps
Cost Optimization

Oracle workload cost optimization
Article • 01/24/2023

Cost optimization is about looking at ways to reduce unnecessary expenses and
improve operational efficiencies. We recommend you review the Cost optimization
design principle.

Optimize workload compute costs
AWR and statspack statistics show your actual utilization. Based on your utilization, we
help you to choose the right SKU to right-size according to your individual setup. Virtual
Machines provide the computer power for your Oracle workload and have a cost effect
that we can easily address. Below we provide some guidance to optimize your costs by
choosing the right virtual machine type.

Choose the right VM type
Oracle workloads tend to be low utilized on the CPU but high on the memory. Next to
the utilization of compute power and memory, it's important that the throughput fit into
the VM as well. Addressing the fact that very low compute power is used, Microsoft
offers you constrained VM sizes.
To match the Oracle workload into a Virtual Machine, we recommend to either use the E
series or M series. Both E and M series sizes are memory optimized and able to handle a
high throughput.

Optimize workload storage
All Oracle applications have a Shared File Storage. Data from the web tier but also from
the database tier regularly sends the updated data into the File Storage. From there, the
data is sent to back up storage. Storage can also have an effect of the performance,
availability, and recoverability of your Oracle workload.
Set up a storage architecture that meets your requirements and allocating cost savings
accordingly.
The following provides some guidance to set up a well-architected storage solution:
(1) Use reserved capacity storage type - There are several types of storage to choose
from based on the requirements. Managed Disks, Blob Storage, and Azure Backup

Storage will support you in various combinations. As every application has a file storage
in the application tier, a cost optimization can be reached by having a File Storage in
Place. Network attached storage offers an opportunity for workloads with high
throughputs. In this case it's Azure NetApp Files (ANF).
The above storage options come with storage reservation options that lower overall
costs on the persistent data layer. For more information, please visit:
Azure disk reserved capacity
Azure NetApp Files
Azure Backup Storage reserved capacity
About Azure VM Backup
(2) Use lifecycle management policies - Next to reserved capacity you should define a
data retention period. An Oracle database backup can be large and add cost to the
storage costs if it isn't optimized. We recommend creating a lifecycle policy that meets
the recovery time objective (RTO) and the recovery point objective (RPO) of your Oracle
workload.

Recommendations
Explore the following table of recommendations to optimize your Oracle on Azure IaaS
for Cost optimization:
Recommendation

Benefit

Familiarize yourself with

Based on our experiences most Oracle environments are over-

right-sizing of Oracle
databases

provisioned. Learn how to take AWR or Oracle Statspack data
and provide a right-size of the database(s) environment. Deliver
expected performance without wasting resources.

Determine the most optimal

Define the lifecycle management policy according to your

pricing on storage that

requirements to the RTO and RPO. If the data reaches an age

meets the workload
requirements

consider that the policy should move into Premium, Standard,
Cold, Archive storage based on its age and business requirements.

Determine the IO and
backup demands when

Some intense IO workloads might require an NFS. Other workloads
might not require an NFS. There are situations where sizing and IO

using network attached

will result with higher tiers of storage having lower cost.

storage
Monitor costs and create

The Azure portal equips you with various options and possibilities

budget alerts

to monitor the costs. Alerts will help you.

Recommendation

Benefit

Before scaling up hardware,

Optimizing workloads can save a considerable amount over time

ensure you understand what
is causing performance

and potentially also CPUs that you actually don't need. Make sure
to regularly take a look on the AWR reports. When there are

bottlenecks and if it’s at the

performance issues, it can also be caused on a storage level. Make

database or hardware level

sure to understand issues first before scaling up.

Familiarize yourself with the

Be aware of what products are supported in Azure and how

Oracle licensing FAQ

licensing works in Azure as a supported cloud for Oracle.

Next Steps
Operational Excellence

Oracle workload operational excellence
Article • 03/10/2023

Operational excellence is about creating efficient processes to support your Oracle
workload. Operations will be the longest phase of the Oracle workload lifecycle, and
teams must be equipped with operational best practices to manage the day-today tasks.
Failure in operations will affect the other design areas and the overall success of the
Oracle workload. It’s critical to tailor your operations to support an Oracle workload in
operations. Below are recommendations to drive operational excellence.

Monitor the workload
Monitoring and diagnostics are crucial for Oracle on Azure IaaS. As Oracle is a nonnative solution running in Azure, Oracle Cloud Control offers the ability to monitor,
manage and automate much of Oracle with little additional cost. Oracle Cloud Control
comes with a Limited Use Enterprise Edition License, so the database repository does
NOT require additional licensing, only the management packs are licensed to each
target database. This ensures the same or similar tools that Oracle technologists have
used on-premises are available in the cloud. We recommend you review the Operational
excellence design principles.
Oracle Cloud Control has text logs with a clear format that can be exported and loaded
into Azure Log Analytics to offer a single pane of glass when monitoring Oracle
database information. Cloud Control can be used with management packs to add more
functionality, including “simulating” a PaaS experience for IaaS solutions such as Oracle
in Azure. When using the Cloud and Lifecycle Management Packs for Oracle Cloud
Control, full cycle management can be added to the system- automating patching of
both database and OS, along with cloning and deployments.

Azure policy and operational excellence
Many built-in Azure Policy definitions come in Deploy if Not Exists (DINE) versions for
the resources that commonly make up Oracle solutions on Azure. Infrastructure as code
(IaC) is the gold standard for resource deployment in business-critical applications, such
as Oracle workloads. DINE policies perform imperative operations on your infrastructure
and happen outside of the declarative model of IaC. Consider their usage carefully,
opting for IaC-based deployments of infrastructure and architecture decisions, leaving
Azure Policy for governance, not workload deployment/configuration.

Recommendations
Explore the following table of recommendations to optimize your ExpressRoute
configuration for Operational excellence:
Recommendation

Benefit

Use Perf Insights

Use Perf Insights to monitor the overall cloud landscape.

Configure
ExpressRoute

In case of failures or performance issues, it provides a first view into the
network.

connection
monitoring
between your onpremises and Azure
network.
Consider Oracle

Oracle is a non-native product and Oracle provides an infrastructure

Cloud Control for
Oracle

monitoring, management and automation tool that can be deployed on a
VM with little to no cost to the customer, as it’s most likely already used
on-premises. Deploy to the cloud to eliminate egress to an on-premises
version and evolve to automate with:
- Monitoring templates
- Metric Extensions (self-service metrics)
- Corrective Actions
- OS and database patch automation
Oracle Cloud Control will “simulate” a PaaS like solution for IaaS when
using it to manage, monitor and automate Oracle.

Next Steps
Performance Efficiency

Oracle workload performance efficiency
Article • 03/10/2023

Performance efficiency is the ability of your workload to scale to meet the demands
placed on it by users in an efficient manner. We recommend you review the
Performance efficiency principles.
Oracle on Azure IaaS has components that are distributed across various Azure services.
These components are the capacity planning targets for your application servers and
database sizing choices. This includes load balancing configurations for even traffic
distribution and Oracle-native solutions, like Oracle Data Guard for fast-start failover
database setups.

Optimize workload compute
Compute includes the hardware, number of cores, and memory but also the throughput.
It’s important to know the demands of your workload. Therefore, regularly look on the
AWR reports and statistics. It shows the actual needs of your workload so that you can
right-size your environment. Where possible and required you can add auto-scaling on
the VMs. It can potentially be achieved through Virtual Machine Scale Sets.

Optimize workload storage
By having the correct solution, you gain the ability to improve the performance of the
existing capabilities and allow yourself to add new features. In general the storage
should meet the input output operation per second (IOPS) but also the functionalities.
Microsoft offers different solutions that can simplify the architecture.

Optimize workload networking
Oracle applications usually have a high number of interfaces to other systems. Common
communication paths are local storage, external storage, VMs in the network, and thirdparty applications. Optimizing the workload network with Proximity Placement Groups
can bring higher performance.

Understanding Proximity Placement Groups
A proximity placement group is a logical grouping. It makes sure that Azure compute
resources are physically located close to each other. Proximity placement groups are

useful for workloads where low latency is a requirement, which is typical for Oracle
Workloads.
Proximity placement groups reduce the distance between Oracle workloads. They can
group different VM types under a single network spine. As the Azure footprint grows, a
single availability zone may span multiple physical data centers. The distribution across
data centers can create network latency impacting your Oracle application performance.
The proximity of the VMs provides lower network latency.
The capabilities are ideal, but there are drawbacks to be aware of. Proximity placement
groups often limit your VM choices and make resizing VMs more difficult. Proximity
placement groups bind VMs to a specific network spine. This binding limits the possible
combinations of different VM types. The host hardware that is needed to run a certain
VM type might not be present in the data center or under the network spine to which
the proximity placement group was assigned. The availability of VM types can be
severely restricted.
We recommend using proximity placement groups in two scenarios:
1. Use proximity placement groups in Azure regions where latency across zones is
higher than recommended for the Oracle workload.
2. Use proximity placement groups for application volume group. The Application
Volume Group feature of Azure NetApp Files (ANF) uses PPG to deploy ANF
volumes close to the VM/compute cluster. We recommend using this feature as
designed.
For more information, see:
Overview of proximity placement groups

Recommendations
Explore the following table of recommendations to optimize your Oracle database
environments for performance efficiency:
Recommendation

Benefit

Move from RMAN backups to Volume

Databases larger than 1 TB can benefit from removal of

Snapshots

streaming backup utilities, such as RMAN or Datapump
(exports) and can save 20-40% IO used by these
utilities.

Recommendation

Benefit

Collect size of database, redo
generation, and backup retention/size

AWR reports provide an insight into it. The numbers
will help you to right-size your environment.

to determine the target minimal load
on resources and the network.
Determine if using premium SSD is best

If using premium, enable host level read-only caching

for the OS disk with the earlier
mentioned sizing assessment in mind.

for datafiles.

Ensure host level caching is disabled for
redo logs.

Higher Performance.

Test the VM chosen that the workload it
was sized to support meets the needs

Include implementing load balancing and
autodetection so that as services are added or moved,

once running in Azure.

the application can perform the necessary routing – it
prevents you reaching high latencies.

Increase the size of the ExpressRoute

Upgrade to a higher gateway SKU for improved

gateway.

throughput performance between on-premises and
Azure environment.

Move the right database files to higher
IO storage

Use the AWR/Statspack report on IO Summary by file
type to ensure that what you offer more IO to, is what
will benefit from faster storage.

Next Steps
Oracle Reference Architecture

SAP workload documentation
Learn how to build an SAP workload on Azure

Get started

ｅ

OVERVIEW

SAP workload
Design principles

Design areas

ｐ

CONCEPT

Application design
Application platform
Data platform
Networking and connectivity
Security
Operational procedures

Reference examples

Ｙ

ARCHITECTURE

SAP on Azure landing zone accelerator
Start small and expand with SAP HANA

Reference implementations

｀

DEPLOY

SAP on Azure Deployment Automation Framework

Learn

ｄ

TRAINING

How to use SAP on Azure Solutions

Assessment

ｃ

HOW-TO GUIDE

Azure Well-Architected Review (SAP on Azure)

SAP workload
Article • 01/09/2023

SAP is one of the world’s leading producers of software solutions for business
management and customer operations. SAP provides a suite of powerful applications
that you can configure to meet specific environment and organizational needs. These
applications facilitate data processing and information flow across organizations and
provide critical capabilities that drive key organizational functions.
SAP applications thrive on infrastructure that is tailored to maximize their capabilities
and with cloud services designed to optimize SAP workload functionality. Microsoft has
hosted SAP instances in its data centers for decades and has custom built infrastructure
and services to run SAP and its applications as they were designed. We’ve used this SAP
experience to create a concise set of best practices for evaluating, designing, and
optimizing an SAP workload from premigration to operations. The goal of this guidance
is to help you get the most benefits from each SAP workload.


Figure 1: Using SAP workload guidance throughout the lifecycle of an SAP workload.
The guidance is designed for one SAP workload at a time. Anytime you want to optimize
a specific SAP application (S4/HANA, NetWeaver, etc.) for Azure or in Azure, you should
use this guidance. Work through the guidance as many times as you need to derive the
benefits you expect. In operations, this guidance should be paired with the WellArchitected Review assessments and health checks. We address these tools in our
guidance.
Start with SAP platform landing zone. Before using this content, you should have an
SAP platform landing zone in Azure. The platform landing zone provides shared services
to one or more of your SAP workloads. If you don’t have a platform landing zone, you
should use the SAP cloud adoption framework and deploy the SAP landing zone
accelerator. The landing zone accelerator establishes the required foundation for your
SAP workload.
For more information, see:
SAP landing zone accelerator

SAP cloud adoption framework
Azure landing zone overview
We invite you to explore SAP workload design best practices and return to this content
regularly throughout the lifecycle of your SAP workload. The content highlights critical
areas of focus but also refers you to other documentation for deeper technical insight.
For more information, see:
Azure Center for SAP Solutions
SAP workload in Azure
SAP workload architectures

Next steps
Our guidance adheres to five pillars of the Well-Architected Framework. It's important to
understand what those pillars mean for an SAP workload and how they interact at a high
level.
Design principles

Design principles of an SAP workload
Article • 01/09/2023

We built this guidance around the Azure Well-Architected Framework and its five pillars
of architectural excellence. The table below lists each pillar and provides a general
summary of the articles in this set.
Wellarchitected
framework
pillar

Summary

Reliability

An SAP workload requires resiliency at the architecture layer. You’ll learn how to
create an SAP application with high availability to process critical business data.

Security

An SAP workload contains critical business data. You’ll learn to secure your SAP
applications with multiple security layers, including identity, access, input
validation, data sovereignty, and encryption.

Cost
Optimization

An SAP workload has several architecture layers and numerous resources
supporting it. You’ll learn how to make sure your SAP application deployment
meets performance expectations while reducing the total cost of ownership.

Performance
Efficiency

An SAP workload needs to be high performing resources to meet productivity
requirements. You’ll learn how to make sure that your SAP workload meets user
demands while managing costs.

Operational
Excellence

An SAP workload spends most of its lifecycle in operations. You’ll learn how to
manage an SAP workload and to keep it running.

Reliability
A reliable SAP workload is both resilient and available. Resiliency is the ability to recover
from failures and continue to function. Availability is uptime. High availability reduces
SAP application downtime during critical maintenance and improves recovery from
failures such as VM crashes, backend updates, major downtime, or ransomware
incidents. Failures happen on-premises and in the cloud, so it’s important to design your
SAP workload for resiliency and availability.
Conduct a reliability assessment. Before you can standardize the reliability of an SAP
workload and improve areas of weakness, you need to assess its reliability. It’s critical to
know how reliable an SAP workload is so steps can be taken to fix issues or solidify
those configurations. We recommend conducting a reliability assessment on your SAP
workload. The assessment asks you questions about your workload and provides

specific recommendations to focus on. The assessment builds on itself, so you can track
your progress without restarting every time.
For the assessment, start an Azure Well-Architected Review. Select "Start Assessment"
and “SAP on Azure” when prompted.

Security
SAP on Azure is delivered in the infrastructure as a service (IaaS) cloud model. Microsoft
builds security protections into the service at the levels of the physical data center,
physical network, physical host, and hypervisor. But you're responsible for areas above
the hypervisor, such as the guest operating system for SAP. We recommend you
regularly evaluate the services and technologies used to ensure your security posture
evolves with the threat landscape.

Cost optimization
Microsoft makes significant investments in the fast evolution of its SAP hardware and
services to provide more value for less. The frequent increase in Azure hardware
capability provides regular opportunity for an SAP workload to optimize costs, eliminate
waste, and improve technology. To align Azure and your SAP workload, we recommend
creating a plan for each SAP workload. The plan should contain the objectives and
motivations for the workload. Organizational objectives and investment priorities should
drive cost optimization initiatives for your application, application platform, and data
platform.

Performance efficiency
Performance efficiency is about accelerating digital transformation with less. The goal is
to get the most out of your SAP workload and meet user demand without over or under
provisioning resources. Inefficient performance can degrade user experience and inflate
costs. Performance affects productivity for internal applications. It determines growth for
public facing applications. Designing an SAP workload that can't meet user demand will
slow the application. Overcompensating with too much compute power will drive up
cost needlessly. These scenarios are avoidable with the right compute, data, and
networking design.

Operational excellence

Operational excellence is about creating efficient processes to support your SAP
workload. Operations will be the longest phase of the SAP workload lifecycle, and teams
must be equipped with operational best practices to manage the day-today tasks.
Failure in operations will affect the other design areas and the overall success of the SAP
workload. It’s critical to tailor your operations to support an SAP workload in operations.
Regular assessments, monitoring, and automation are central to improving SAP
operational excellence.

Next steps
We've woven these design principles throughout our guidance in specific design areas.
The design areas provide targeted guidance. We want you to find what you need fast so
you can be more productive with less time. Use the headings as a compass to find
appropriate direction in each design area.
Application design
Application platform
Data platform
Networking and connectivity
Security
Operational procedures

SAP workload application design
Article • 01/09/2023

SAP applications should adhere to the design principles. The guidance here focuses on
cost optimization and reliability.

SAP application cost optimization
Optimizing your SAP application can lower the total cost of ownership without reducing
capabilities. The goal is to generate the maximum return on investment (ROI). Here are
ways to optimize an SAP application.
Identify application responsibility. Optimizing an SAP Application should be the
responsibility of the customer business application team. Having someone or a group
responsible for costs will help drive decisions that optimize costs over the lifecycle of the
SAP workload.
Rationalize and rearchitect. You should consider rationalizing or rearchitecting the SAP
application, especially during migrations. S4 HANA often replaces older SAP applications
that can be added as a legacy system. The SAP WAF assessment can help validate
rearchitecting efforts and should be conducted on a periodic basis. For more
information, see Azure Well-Architected Review.
Minimize investment in legacy systems. You should host a legacy SAP application on
minimum-supported architecture to help reduce cost. A legacy application is slower and
less performant. Any legacy systems that remain after rationalizing and rearchitecting
should receive the minimum spend possible and be retired when appropriate. For more
information, see Azure Cost Management.

SAP application reliability
Use a multi-tier architecture. Creating a multi-tier architecture to support an SAP
workload is essential for reliability. The number of tiers and architecture varies for each
SAP application. Make sure to isolate application components from each other and
create redundancy to achieve high availability. Where applicable, you should isolate the
SAP Web Dispatcher, SAP Central Services, SAP App Server, SAPMNT Share and
database. We have sample architectures for several different SAP applications you can
use to inform your design.
For more information, see:

SAP S/4HANA in Linux
SAP BW/4HANA
SAP NetWeaver
Configure SAP central services reliability. SAP central services (SCS) or ABAP SAP
central services (ASCS) is the basis of SAP application communication. It consists of the
message server and enqueue server. The central services layer is often a single point of
failure and must be set up for high availability to achieve SAP application resiliency. To
add redundancy, create a cluster of SAP central services with compatible shared storage
technology supporting the cluster. Depending on the operating system and available
shared storage technology in general availability or private/public preview, various
options are available. Availability zones provide an opportunity to create a highly
available ASCS architecture.
For more information, see:
SAP workload configurations with Azure Availability Zones
High-availability architecture for an SAP ASCS/SCS instance on Windows
High-availability architecture for an SAP ASCS/SCS instance on Linux

Next steps
Application platform
Data platform
Networking and connectivity
Security
Operational procedures

SAP workload application platform
Article • 01/09/2023

The application platform refers to the hosting environment, application dependencies,
frameworks, and libraries. For an SAP workload, the Azure platform provides
opportunities to optimize cost and performance, allowing you to do more with less.

Optimize compute costs
Compute cost optimization is achieved through planning, monitoring, and resizing VMs
throughout the SAP workload lifecycle. VMs provide the compute power for the SAP
application and have a direct effect on cost and performance. We recommend
monitoring the compute costs of an SAP workload to ensure the dollars spent are
helping you meet organizational goals. Here are cost-optimization recommendations for
SAP workload compute.

Choose the right VM type
Azure has SAP-certified VMs for your workload. The wrong VM type will require larger
sizes to get the performance need, increasing cost without benefit. A smaller VM of the
correct type can give you equal or better performance than a large instance of the
wrong type. Azure offers a list of SAP-certified configurations to help you understand
what VMs work well with your business needs.
For more information, see SAP certified infrastructure .
Memory-optimized VMs can meet the requirements of most SAP applications. An SAP
online analytical processing (OLAP) workload and an online transactional processing
(OLTP) workload should use M-series VMs. Examples of an OLTP workload include SAP
HANA, SAP Business Suite on HANA, and SAP S/4HANA. Examples of OLAP workloads
include SAP BW on HANA BW/4HANA. SAP Business One on HANA pairs with M-series
VMs.
SAP NetWeaver, Business All-in-One, Business Suite Software, and BusinessObjects BI
have broader alignment with different VM types. They can run on VMs in the D, G, E,
and M-series.

Optimize compute cost during migration

Many SAP journeys start on-premises, so it’s important to plan for compute
optimization throughout the migration of a workload. Make sure to follow best practices
across every SAP migration. You can find process guidance in our CAF SAP
documentation. With the broader process guidance in place, you’ll still need to
customize your compute optimization for each SAP workload. We want you to consider
pre-migration and post-migration milestones.
Optimize pre-migration. Pre-migration optimization ensures you have sufficient cloud
resources provisioned to support the expected migration runtime of the SAP workload.
You need to verify that the Azure VM meets the technical requirements of the onpremises workload. Planning will shorten the migration time of a workload and minimize
the time of migration will keep costs lower.
Optimize post-migration. Post-migration optimization focuses on the end-user
experience. This step coincides with the hypercare period, a time of elevated customer
service to make sure that the workload is performing. You should monitor the workload
as users begin to interact with it. The performance metrics might indicate that you need
to downsize the VM or switch to a different VM type.

Improve application platform operational
excellence
It’s important to optimize VMs in operations for the most cost-savings. By VM
operations, we're referring to the daily management of an SAP workload. This phase of a
workload brings the ability to predict the compute needs. It’s important to see how user
demand affects compute needs over time. The VM choice should change along with the
SAP workload’s requirements. Here are cost-saving recommendations for operations.
Use Azure Advisor. We recommend you use Azure Advisor to identify VM usage that
needs optimization. For more information, see Azure Advisor cost optimization.
Enforce VM governance. You should enforce VM governance at VM creation as a cost
and security best practice. Every VM deployment increases the operational cost and
attack surface of the SAP workload. VMs created outside of the governance process
tend to create unneeded expense and have more vulnerabilities. We recommend using
Azure Policy to enforce VM governance for your SAP workload. For more information,
see Azure Policy for SAP.
Stop non-critical workloads. Each SAP workload has different levels of criticality. Some
workloads aren’t needed on nights and weekends. A sandbox environment is a good
example of low criticality. We recommend stopping VMs that support non-critical

workload environment to reduce costs. You can automate this process for the SAP
workload in Azure. For more information, see automate VM start and stop.
Use Reserved Instances. Any SAP workload that needs to run continuously should use
reserved instances to optimize cost. For budget predictability, you can make an
advanced purchase for one or three years in a specified region. For more information,
see Azure Reservations.
Use the Azure Hybrid Benefit. Azure lets you use on-premises Software Assuranceenabled Windows Server and SQL Server licenses. The benefit applies to Red Hat and
SUSE Linux subscriptions. This benefit can generate significant savings for a hybrid SAP
workload. For more information, see hybrid licensing benefit .
For more information, see:
SAP on Azure
SAP NetWeaver
SAP HANA install
SAP HANA configuration

Configure application sever reliability
The goal of application server reliability is to have multiple application servers load
balance traffic and failover when needed. Resiliency for the SAP application server layer
can be achieved through redundancy. You can configure multiple dialog instances on
different instances of Azure virtual machines with a minimum of two application servers.
Here are application server resiliency recommendations.
Use Availability Sets / Availability Zones. An SAP application server can be deployed in
an availability set or across availability zones. The decision you make needs to be based
on workload requirements. We recommend you choose one method to improve
resiliency, but we don’t recommend scale sets. For more information, see availability
zones for SAP.
Use multiple application servers. Using multiple smaller application servers instead of
one larger application server is recommended. This setup avoids a single point of failure.
It’s a best practice to configure SAP Logon Group (SMLG) and Batch Server Group
(RZ12) for better load balancing between end-user & batch processing.
For more information, see:
Azure Virtual Machines high availability for SAP NetWeaver
SAP HANA high availability for Azure virtual machines

SAP workload configurations with Azure Availability Zones

Improve compute performance efficiency
Compute is the core that powers an SAP application. Compute includes the hardware,
number of cores, and memory. These features are foundational to organizations. If you
don’t optimize your compute configuration, an SAP workload will be unable to meet
spikes in user demand or stay withing predefined budgets. It’s important to know the
demands on your workload and match those demands with the compute you use for
your SAP workload. Here are some compute performance considerations.
Conduct reference sizing for on-premises workload. Reference sizing is the process of
checking the configurations and resource utilization data of an SAP workload onpremises. Reference sizing data shows the current compute needs of the workload, and
these needs should be matched in Azure. To find this information, use the SAP OS
Collector. SAP OS Collector retrieves system utilization information that can be reported
via SAP transaction OS07N and the EarlyWatch Alert. Any system performance and
statistics gathering tools can collect similar information.
Use SAP Quick Sizer for a new workload. SAP Quick Sizer is a free web-based tool
developed by SAP that translates business requirements into technical requirements.
Use this tool when you build a new SAP workload to find the Azure VM with the correct
network and storage throughput. For more information, see SAP quick sizer .

Next steps
Application design
Data platform
Networking and connectivity
Security
Operational procedures

SAP workload data platform
Article • 01/09/2023

The data platform refers to the data store technologies that support an SAP workload.
SAP workloads place high demands on the data platform. We outline best practices for
optimizing cost while maintaining performance.

Optimize data costs
We recommend optimizing the storage cost for your SAP workload. Storage is an
essential component of an SAP workload. Storage contains active data and backup data
that is critical to your organization. Storage affects the performance, availability, and
recoverability of an SAP workload. It's important to have the right performance at the
right cost. Here are recommendations to help you reach this goal.
Use reserved capacity storage type. There are several storage options available to
choose from based on the workload requirement. Managed disks, blog storage, and
backup storage can support an SAP workload in various combinations. Each of these
options comes with storage reservation options that lower overall costs for persistent
data.
For more information, see:
Azure disk reserved capacity
Blob storage reserved capacity
Azure Backup Storage reserved capacity
Use lifecycle management policies. Other than reserved capacity, you need to ensure
the data-retention period is right for the SAP workload. An SAP database backup can be
large and add to the storage cost if not optimized. We recommend that you create a
lifecycle policy that meets the recovery time objective (RTO) and recovery point
objective (RPO) of your SAP workload. The policy should move into Premium, Standard,
Cold, Archive storage based on its age and business requirements.

Improve data reliability
Data reliability is essential for ensuring continuity of operations. We provide reliability
recommendations for configuring database reliability, creating SAPMNT share reliability,
using backups, and implementing a disaster recovery solution.

Configure database reliability
An SAP application feeds data to multiple enterprise systems, making database
resiliency a key workload consideration. We recommend replicating production data for
the highest resiliency. Cross-region replication is the preferred disaster recovery
solution. But for a more affordable option, you should configure zone redundancy at a
minimum. The methods you choose depends on the database management system
(DBMS) and required business service-level agreement (SLA). Below are
recommendations for the database layer.
Define RPO and RTO. Creating database resiliency requires a plan to recover data loss. A
logical error on the SAP database, a large-scale disaster, or a system outage can cause
data loss in an SAP workload. Your recovery plan should identify how much data you’re
willing to lose and how fast you need to recover. The amount of data loss you’re willing
to lose is your recovery point objective (RPO). How fast you need to recover is your
recovery time objective (RTO). When you design for recoverability, you need to
understand the desired and actual RPO and RTO of your SAP application.
Use synchronous replication for no data loss. In some scenarios, there’s no tolerance
for data loss. The recovery point objective is 0. To achieve this RPO, you need use
synchronous replication on the database layer. Synchronous replication commits
database transactions to database instances in two separate zones or regions. You
should measure the latency between the two instances to ensure it meets workload
needs, and you can do it with the SAP niping measuring tool. Higher network latency
will slow down the scalability of your workload, and physical distance between the
instances adds network latency. As a result, replication across regions will have higher
latency than across availability zones because there's more distance between the
instances. Database replication between different regions should be asynchronous and
replication between availability zones should be synchronous. It’s important to balance
resiliency and latency in SAP workload design.
For more information, see:
General Azure Virtual Machines DBMS deployment for SAP workload
High-availability architecture and scenarios for SAP NetWeaver
Network latency between and within zones

Create SAPMNT share reliability
SAPMNT hosts the physical kernel files for SAP application and can be a single point of
failure. Several options are available on Azure to created redundancy and architect a
highly available SAPMNT share. We recommend using Azure Premium Files or Azure

NetApp Files for Linux and Azure Premium Files. For Windows-based deployments, you
should use Azure NetApp Files or Azure Shared Disk.
There are also a few application specific configurations you should address for SAPMNT
reliability. You need shared directories in the environment ( /sapmnt/SID and
/usr/sap/trans ) to deploy the SAP NetWeaver application layer. We recommend

creating highly available file systems and ensuring they're resilient. The /sapmnt/SID and
/usr/sap/SID/ASCS directories are important. You should place these file systems on NFS

on Azure Files to achieve the maximum reliability.
For more information see, NFS on Azure Files.
Table 1 - SAPMNT guidance for each operating system.
OS

SAPMNT Guidance

Windows

Cluster an SAP ASCS/SCS instance on a Windows failover cluster by using a
cluster shared disk in Azure
Cluster an SAP ASCS/SCS instance on a Windows failover cluster by using a
file share in Azure
High availability for SAP NetWeaver on Azure VMs on Windows with Azure
Files Premium SMB for SAP applications
High availability for SAP NetWeaver on Azure VMs on Windows with Azure
NetApp Files(SMB) for SAP applications

Red Hat Enterprise

High availability for SAP NetWeaver on Azure VMs on Red Hat Enterprise

Linux (RHEL)

Linux with NFS on Azure Files
Azure Virtual Machines high availability for SAP NetWeaver on Red Hat
Enterprise Linux with Azure NetApp Files for SAP applications

SUSE Linux
Enterprise Server

High-availability SAP NetWeaver with simple mount and NFS on SLES for
SAP Applications VMs

(SLES)
High availability for SAP NetWeaver on Azure VMs on SUSE Linux Enterprise
Server with NFS on Azure Files

Use data backups
The SAP workload should implement a regular backup solution. Backups are the
backbone of disaster recovery and help ensure continuity of operations. We have a few
recommendations for backup reliability.

Start with Azure Backup
We recommend you use Azure Backup as the foundational backup strategy for an SAP
workload. Azure Backup is the native backup solution in Azure, and it provides multiple
capabilities to help streamline your SAP backups. With Azure Backup, we want to point
out a few features.
Table 2 - Azure Backup features
Feature

Description

Native

Azure Backup provides native backups through the Backint connector for SAP

database
backup
compatibility

HANA, SQL Server, and Oracle databases used by SAP Applications. Azure backup
for SAP offers an API called Backint. Backint allows backup solutions to create
backups directly on the database layer. Azure backup also supports the database
backup capability for HANA & SQL Server databases today.

Storage
backup

The storage backup feature can help optimize the backup strategy by using disk
snapshots of Azure Premium storage for selective disks. For more information on
application-consistent backups, see snapshot consistency.

Virtual
machine
backup

Back up and restore Azure VM data through the Azure portal. Cross-region
restoration lets you restore Azure VMs that were to a paired secondary region.

Long-term
retention

Azure Backup allows you to retain SAP backups years for compliance and audit
needs.

Backup
management

Azure Backup enables you to manage backups from the Azure portal with an easy
user interface.

For more information, see:
Azure Backup documentation
SAP HANA backup overview
Backup guide for SAP HANA on Azure Virtual Machines
Backup guide for SQL Server on Azure Virtual Machines

Find marketplace backup solutions
Several certified third-party backup solutions exist in the Azure Marketplace . These
solutions offer vendor backup capabilities and SAP-certified backup capabilities. You
should consider layering these solutions on top of Azure Backup to generate custom
solutions with foundational support.

Microsoft partners provide solutions that are integrated with Azure Storage for archive,
backup, and for business continuity and disaster recovery (BCDR) workloads. The partner
solutions take advantage of the scale and cost benefits of Azure Storage. You can use
the solutions to help solve backup challenges, create a disaster recovery site, or archive
unused content for long-term retention. They can replace tape-based backups and offer
an on-demand economic recovery site with all the compliance standards and storage
features such as immutable storage and lifecycle management.

Use snapshots
A snapshot is a point-in-time, copy of your data. The speed and reliability of snapshots
can help manage large databases and protect the primary database against corruption
or failure. These features make snapshots critical for disaster recovery. We have a few
options to create and store backups for your SAP workload.
Azure Backup can take database backups for HANA and SQL Server, for example. The
Backup vault feature of Azure Shared Disk can serve as your database storage solution.
Azure NetApp Files (ANF) can also back up critical data by using snapshots, such as ANF
volumes Snapshot. ANF Cross Region Replication uses ANF snapshots to replicate data
from one region to another.
The right solution depends on your desired cost and availability levels. In some
scenarios, you might want to replicate your SAP on Azure data to other Azure regions
for disaster recovery. However, you can achieve the same capabilities with Azure Storage
replication, such as Geo-redundant storage (GRS) or Azure Site Recovery.
For more information, see:
SAP workload configurations with Azure Availability Zones
SAP NetWeaver disaster recovery
Azure Site Recovery for SAP workloads
Azure Storage redundancy
Back up SAP HANA databases' instance snapshots in Azure VMs

Implement a disaster recovery plan
We recommend you invest in disaster recovery (DR) to improve the reliability of the SAP
workload. Disaster recovery is achieved by replicating primary data to a secondary
location. Several tools & methodology can be used to the achieve goal. Disaster
Recovery is required when the primary location isn't accessible due to technical or
natural disaster. Disaster Recovery solutions can be across zones within region or across

regions based on your business requirements, but we recommended DR across region
for better resiliency.
For more information, see:
Azure Site Recovery
Cross-region replication of Azure NetApp Files volumes
Cross-region snapshot copy for Azure Disk Storage
Backup and Disaster Recovery

Improve storage performance
It’s important to choose the appropriate storage solutions to support the data needs of
the SAP workload. The correct solution can improve the performance of existing
capabilities and allow you to add new features. In general, storage needs to meet the
input/output operations per second (IOPS) requirements and throughput needs of the
SAP database.
For more information, see storage types for an SAP workload.
Use storage that supports performance requirement. Microsoft supports different
storage technology to meet your performance requirement. For SAP workload, you can
use Azure Managed Disk (for example, Premium SSD, Premium SSD v2, Standard SSD)
and Azure NetApp Files.
Configure storage for performance. We've published a storage configuration guideline
for SAP HANA databases. It covers production scenarios and a cost-conscious nonproduction variant. Following the recommended storage configurations will ensure the
storage passes all SAP hardware and cloud measurement tool (HCMT) KPIs. For more
information, see SAP HANA Azure virtual machine storage configurations.
Enable write accelerator. Write accelerator is a capability for M-Series VMs on Premium
Storage with Azure Managed Disks exclusively. It’s imperative to enable write accelerator
on the disks associated with the /hana/log volume. This configuration facilitates sub
millisecond writes latency for 4 KB and 16-KB blocks sizes. For more information, see
Azure Write Accelerator.
Choose the right VM. Choosing the right VM has cost and performance implications.
The goal is to pick a storage VM that supports the IOPS and throughput requirements of
the SAP workload. There are three critical areas to focus while selecting a VM
Table 3 - Compute features that affect performance

Compute
features

Description

Number of

The number of CPUs has a direct effect on the licenses in the database node. Most

vCPUs

of the databases follow a core-based licensing model. Use the amount that meets
your needs and adjust licensing agreements as necessary.

Memory

Memory is critical to application performance, and your SAP application can have
high memory demands. In general, higher memory provides more memory-reads,
less paging, and higher VM cost.

Throughput

Throughput is important for an application hosted on one of the VMs to
communicate with outside the VM by using its network interface cards (NICs).

Next steps
Application design
Application platform
Networking and connectivity
Security
Operational procedures

SAP workload networking and
connectivity
Article • 01/09/2023

Networking for an SAP workload has many facets, but we want to focus on the
performance affects of networking. The goal is to help you make the right networking
decisions to ensure peak SAP workload performance.

Networking performance
An SAP workload needs to communicate with other workloads. Common
communication paths are to local storage, external storage, NICs, VMs in the network,
VMs in other networks, and third-party applications. Optimize workload networking to
improve these communication channels to meet workload and application demand. If
SAP network performance isn't considered, it will cause application performance issues.
Understand proximity placement groups. Proximity placement groups reduce the
distance between SAP workloads. They can group different VM types under a single
network spine. As the Azure footprint grows, a single availability zone may span multiple
physical data centers. The distribution across data centers can create network latency
impacting your SAP application performance. The proximity of the VMs provides lower
network latency.
The capabilities are ideal, but there are drawbacks to be aware of. Proximity placement
groups often limit your VM choices and make resizing VMs more difficult. Proximity
placement groups bind VMs to a specific network spine. This binding limits the possible
combinations of different VM types. The host hardware that is needed to run a certain
VM type might not be present in the data center or under the network spine to which
the proximity placement group was assigned. The availability of VM types can be
severely restricted.
We recommend using proximity placement groups in two scenarios. (1) Use proximity
placement groups in Azure regions where latency across zones is higher than
recommended for the SAP workload. (2) Use proximity placement groups for application
volume group. The Application Volume Group feature of Azure NetApp Files (ANF) uses
PPG to deploy ANF volumes close to the VM/compute cluster. We recommend using
this feature as designed.
For more information, see:

Overview of proximity placement groups
SAP and proximity placement groups
Use accelerated networking. Accelerated Network is default for most of the VM
deployments and is recommended for every VM hosting an SAP workload. Accelerated
Network improves the network performance by bypassing the physical switch. We
recommend you enable Accelerated Networking on the Azure VMs running your SAP
Application and Database. Accelerated networking provides improved latency, jitter, and
CPU utilization. You should test the latency between the SAP application server and
database with the SAP ABAP report /SSA/CAT. It's an Inventory Check for the SAP Azure
Workbook. For more information, see accelerated networking overview.

On-premises connectivity
Use ExpressRoute GlobalReach. ExpressRoute is a private and resilient way to connect
your on-premises networks to different Azure regions. This feature allows you to link
ExpressRoute circuits to make a private network between your on-premises networks.
Global Reach should be used for SAP HANA Large Instance deployments to enable
direct access from on-premises to your HANA Large Instance units deployed in different
regions. For more information, see ExpressRoute Global Reach.

Next steps
Application design
Application platform
Data platform
Security
Operational procedures

SAP workload security
Article • 01/09/2023

Azure provides all the tools needed to secure your SAP workload. SAP applications can
contain sensitive data about your organization. You must protect your SAP architecture
with secure authentication methods, hardened networking, and encryption.

Configure identity management
Identity management is a framework to enforce the policies that control access to
critical resources. Identity management controls access your SAP workload within or
outside its virtual network. There are three identity management use cases to consider
for your SAP workload, and the identity management solution differs for each.

Use Azure Active Directory
Organizations can improve the security of Windows and Linux virtual machines in Azure
by integrating with Azure Active Directory (Azure AD). Azure AD is a fully managed
identity and access management service. Azure AD can authenticate and authorize end
user’s access to the SAP operating system. You can use Azure AD to create domains that
exist on Azure, or use it integrate with your on-premises Active Directory identities.
Azure AD also integrates with Microsoft 365, Dynamics CRM Online, and many
Software-as-a-Service (SaaS) applications from partners. We recommend using System
for Cross-Domain Identity Management (SCIM) for identity propagation. This pattern
enables optimal user life cycle.
For more information, see:
SCIM synchronization with Azure Active Directory
Configure SAP Cloud Platform Identity Authentication for automatic user
provisioning
Azure Active Directory Single sign-on (SSO) integration with SAP NetWeaver
Sign in to a Linux virtual machine in Azure by using Azure AD and OpenSSH
Sign in to a Windows virtual machine in Azure by using Azure AD

Configure single sign-on
You can access the SAP application with the SAP frontend software (SAP GUI) or a
browser with HTTP/S. We recommend configuring single sign-on (SSO) using Azure

Active Directory or Active Directory Federation Services (AD FS). SSO allows end users to
connect to SAP applications via browser where possible.
For more information, see:
SAP HANA SSO
SAP NetWeaver SSO
SAP Fiori SSO
SAP Cloud Platform SSO
SuccessFactors SSO
Azure Active Directory overview

Use application-specific guidance
We recommend consulting the SAP Identity Authentication Service for SAP Analytics
Cloud, SuccessFactors, and SAP Business Technology Platform. You can also integrate
services from the SAP Business Technology Platform with Microsoft Graph using Azure
AD and the SAP Identity Authentication Service.
For more information, see:
Using Azure Active Directory to secure access to SAP platforms and applications.
SAP Identity Authentication Service
SAP Identity Provisioning Service
A common customer scenario is deploying SAP application into Microsoft Teams. This
solution requires SSO with Azure AD. We recommend browsing the Microsoft
commercial marketplace to see which SAP apps are available in Microsoft Teams. For
more information, see the Microsoft commercial marketplace .
Table 1 - Summary of the recommended SSO methods
SAP solution

SSO method

SAP NetWeaver based-web applications such as
Fiori, WebGui

Security Assertion Markup Language (SAML)

SAP GUI

Kerberos with windows active directory or
AAD-Domain services or third party solution

SAP PaaS and SaaS applications such as SAP
Business Technology Platform (BTP), Analytics

SAML / OAuth / JSON Web Tokens (JWT) and
pre-configured authentication flows with Azure

Cloud, Cloud Identity Services ,

AD directly or by proxy with the SAP Identity

SuccessFactors, Cloud for Customer, Ariba

Authentication Service

Use role-based access control (RBAC)
It’s important to control access to the SAP workload resources you deploy. Every Azure
subscription has a trust relationship with an Azure AD tenant. We recommend you use
Azure role-based access control (Azure RBAC) to grant users within your organization
access the SAP application. Grant access by assigning Azure roles to users or groups at a
certain scope. The scope can be a subscription, a resource group, or a single resource.
The scope depends on the user and how you’ve grouped your SAP workload resources.
For more information, see:
Azure AD trust relationship
Azure RBAC

Enforce network and application security
Network and application security controls are baseline security measures for every SAP
workload. Their importance bears repeating to enforce the idea that the SAP network
and application requires rigorous security review and baseline controls.
Use hub-spoke architecture. It’s critical to differentiate between shared services and
SAP application services. A hub-spoke architecture is a good approach to security. You
should keep workload specific resources in its own virtual network separate from the
shared services in hub such as management services and DNS.
For SAP-native setups, you should use SAP Cloud Connector and SAP Private Link for
Azure as part of the hub-spoke setup. These technologies support the SAP extension
and innovation architecture for the SAP Business Technology Platform (BTP). Azure
native integrations fully integrated with Azure virtual networks and APIs and don’t
require these components.
Use network security groups. Network security groups (NSGs) allow you to filter
network traffic to and from your SAP workload. You can define NSG rules to allow or
deny access to your SAP application. You can allow access to the SAP application ports
from on-premises IP addresses ranges and denying public internet access. For more
information, see network security groups
Use application security groups. In general, the security best practices for application
development also apply in the cloud. These include things like protecting against crosssite request forgery, thwarting cross-site scripting (XSS) attacks, and preventing SQL
injection attacks.

Application security groups (ASGs) make it easier to configure the network security of a
workload. The ASG can be used in security rules instead of explicit IPs for VMs. The VMs
are then assigned to ASG. This configuration supports the reuse of the same policy over
different application landscapes, because of this abstraction layer. Cloud applications
often use managed services that have access keys. Never check access keys into source
control. Instead, store application secrets in Azure Key Vault. For more information, see
application security groups.
Filter web traffic. An internet facing workload must be protected using services like
Azure Firewall, Web Application Firewall, Application Gateway to create separation
between endpoints. For more information, see inbound and outbound internet
connections for SAP on Azure.

Encrypt data
Azure includes tools to safeguard data according to your organization's security and
compliance needs. It's essential that you encrypt SAP workload data at rest and in
transit.

Encrypt data at rest
Encrypting data at rest is a common security requirement. Azure Storage service-side
encryption is enabled by default for all managed disks, snapshots, and images. Serviceside encryption uses service-managed keys by default, and these keys are transparent to
the application.
We recommend you review and understand service/server-side encryption (SSE) with
customer-managed keys (CMKs). The combination of server-side encryption and a
customer-managed key allows you to encrypt data at rest in the operating system (OS)
and data disks for available SAP OS combinations. Azure Disk Encryption doesn’t
support all SAP operating systems. The customer-managed key should be stored in Key
Vault to help ensure the integrity of the operating system. We also recommend
encrypting your SAP databases. Azure Key Vault supports database encryption for SQL
Server from the database management system (DBMS) and other storage needs. The
following image shows the encryption process.

When you use client-side encryption, you encrypt the data and upload the data as an
encrypted blob. Key management is done by the customer. For more information, see:
Server-side encryption for managed disks
Azure Storage service-side encryption
Service-side encryption using customer-managed key in Azure Key Vault
Client-side encryption

Encrypt data in transit
Encryption in transit applies to the state of data moving from one location to another.
Data in transit can be encrypted in several ways, depending on the nature of the
connection. For more information, see encryption of data in transit.

Collect and analyze SAP application logs
Application log monitoring is essential for detecting security threats at the application
level. We recommend using the Microsoft Sentinel Solution for SAP. It’s a cloud-native
security information and event management (SIEM) solution built for your SAP workload
running on a VM. For more information, see Microsoft Sentinel Solution for SAP.
For general security information, see:
Azure security documentation
Trusted Cloud eBook

Next steps
Application design
Application platform
Data platform
Networking and connectivity
Operational procedures

SAP workload operational procedures
Article • 01/09/2023

Standard operating procedures (SOPs) are documented processes for managing a
workload. Each SAP workload should have SOPs to govern operations. Without SOPs,
teams drift from management best practices, so we recommend a continuous cycle of
assessment and health checks for your SAP workload.

Use health checks and assessments
Run health checks. We have four Azure SAP (AzSAP) health checks: (1) deployment
checklist, (2) inventory checklist, (3) quality checks, and (4) Linux VM OS analyzer. The
image below shows how they share a cycle with our Azure SAP assessments. For more
information on the health checks, see SAP quality checks.


Figure 1: The cycle of SAP health checks and assessments throughout th journey.
Conduct assessments. We have three SAP assessments: (1) landing zone accelerator
(LZA), (2) Azure SAP (AzSAP) deployment management assessment, and (3) the AzSAP
Well-architected framework assessment. These assessments are designed for different
stages in the SAP workload lifecycle.
The AzSAP Well-architected framework assessment is for operations. It compares your
SAP operations against SAP workload best practices. The assessment encourages
continuous improvement by building on each previous assessment.


Figure 2: How the Well-architected assessment creates milestones and builds on these
milestones over time.

The initial assessment creates a baseline, and the next iteration of assessment uses the
previous assessment as the starting point. It will maintain the selections from the last
assessment to track and review the design principle. Because the assessment builds on
itself, you can track improvements overtime. The assessment is designed for an existing
SAP workload in Azure and can assess one or more of the WAF pillars.
We recommend using this SAP assessment to develop and realign the SOPs for your
SAP workload. The assessment identifies areas of strength and weakness that allow you
to build better SOPs. For more information, see Azure Well-Architected Review.

Monitor the workload
Monitoring is the process of collecting, analyzing, and acting on data gathered from an
SAP workload. Monitoring provides insights of the health of the workload to compare
with an expected baseline. It allows you to know when, where, and why failures occur. A
monitoring best practice is to use a common and consistent logging schema that lets
you correlate events across systems. The monitoring and diagnostics process has several
distinct phases.
Table 1 - Phases of monitoring and diagnostic process
Phases

Process description

Instrumentation

Generating the raw data from application logs, web server logs, the diagnostics
built into the Azure platform, and other sources.

Collection and

Consolidating the data into one place.

storage
Analysis and

Troubleshooting issues and seeing the overall health.

diagnosis
Visualization

Using data to spot trends or alert your operations team.

and alerts

We recommend using Azure Monitor for SAP solutions to drive these processes. Azure
Monitor for SAP is an Azure-native monitoring product for SAP landscapes that run on
Azure. Azure Monitor for SAP solutions uses specific parts of the Azure Monitor
infrastructure to provide insights into the monitoring of SAP Netweaver, SAP HANA, SQL
Server & Pacemaker High-Availability deployments on Azure. For more information, see
Azure Monitor for SAP Solutions.

Automate workload infrastructure

You should use infrastructure as code (IaC) to automate SAP workload deployments with
minimal human intervention and build a scalable and consistent SAP workload on Azure.
The manual process of creating the required SAP workload resources is slow and allows
for errors. Microsoft has a repository of SAP deployment templates that you should use.
It’s called the SAP on Azure Deployment Automate Framework. The templates support
SAP HANA and NetWeaver with any database on any SAP-supported operating systems.
For more information, see:
SAP deployment automation framework
SAP automate repository
Azure Monitor for SAP solutions
Table 2 - Benefits of automated deployments with IaC
Benefit

Automate deployment

domain

benefits

Knowledge

Works immediately after some

Requires specialized knowledge in many

initial preparation time. Requires
little domain knowledge.

domains outside of SAP.

Consumes predictable time from
30 minutes to a couple of hours.

Can take much more time depending on
the size of the SAP landscape, depending

Time

Manual deployment disadvantages

on the size of the SAP landscape.
Cost

Makes automated deployments

Expensive due to more time spent.

cheap due to less time spent.
Testing

Provides templates that include
test instrumentation during
deployment and migration.

Allows for limited testing. Requires more
work to inject tests in the process.

Scaling

Allows you to easily scale up,
down, and out. Provides new
deployment templates.

Takes more time to scale and customize the
environment.

Standardization

Applies your defined standards

Sometimes leads to unwanted variations in

with each deployment.

design.

Next steps
Application design
Application platform

Data platform
Networking and connectivity
Security

Sustainability workload documentation
In partnership with the Green Software Foundation, we've developed this set of
recommendations for optimizing Azure workloads. This documentation helps you plan
your path forward, improve your sustainability posture, and create new business value
while reducing your operational footprint.

Get started

ｅ

OVERVIEW

What is sustainability?
Design methodology
Design principles

Design areas

ｐ

CONCEPT

Application design
Application platform
Testing
Operational procedures
Networking and connectivity
Storage
Security

Reference examples

Ｙ

ARCHITECTURE

Example scenario - Measure Azure app sustainability by using the SCI score

Learn

Learn

ｄ

TRAINING

The Principles of Sustainable Software Engineering

Assessment

ｃ

HOW-TO GUIDE

Sustainability assessment tool

Sustainable workloads
Article • 10/12/2022

This section of the Microsoft Azure Well-Architected Framework aims to address the
challenges of building sustainable workloads on Azure. Review the provided guidance
that applies Well-Architected best practices as a technical foundation for building and
operating sustainable solutions on Azure.
We encourage you to also read more about the Microsoft Cloud for Sustainability

for

opportunities to leverage the capabilities of that platform as part of your solution
architecture. However, guidance found in this article series is focused on any solutions
you're building or operating on Azure.
Additionally, read about The Carbon Benefits of Cloud Computing: a Study of the
Microsoft Cloud

to learn more about how Azure is more energy efficient and carbon

efficient than on-premises solutions.

What is a sustainable workload?
The term workload refers to a collection of application resources that support a common
business goal or the execution of a common business process, with multiple services,
such as APIs and data stores, working together to deliver specific end-to-end
functionality.
With sustainability, we refer to the environmental impact of our workloads.
A sustainable workload therefore describes the practice of designing solutions that
maximize utilization while minimizing waste, ultimately reducing the footprint on the
environment.

Cloud efficiency overview
Making workloads more cloud efficient requires combining efforts around cost
optimization, reducing carbon emissions, and optimizing energy consumption.
Optimizing the application's cost is the initial step in making workloads more
sustainable.
Here's a conceptual overview of cloud efficiency in this context:

Scoring and measuring the cloud efficiency is essential to understand whether changes
tracked over time have any impact.
Learn about building more sustainable and efficient workloads by starting with the
design area for sustainable Application Design.

What are the common challenges?
Building and designing sustainable workloads on Microsoft Azure can be challenging for
these main reasons:
Understanding if your workloads are in alignment with sustainability targets. It
requires assessments of current workloads to determine if they're designed in a
sustainable way.
Designing workloads that are natively environmentally friendly and optimized.
Measuring and tracking the emissions of your workloads.

Is sustainability only about performance and
cost?
While performance efficiency and cost optimization are areas of strong focus for
designing sustainable workloads, the other pillars of the Well-Architected Framework
are equally important when building long-term sustainable workloads on Azure.
Security: how the security appliances in a workload are optimized and designed to
auto-scale will have an impact on the environment.
Reliability: designing reliable workloads that meet sustainability guidelines from
the Green Software Foundation can greatly reduce the workloads' carbon and
electricity footprint.
Operational Excellence: how a workload is able to effectively respond to
operational issues can ultimately reduce carbon emissions.

What are the key design areas?
Sustainable guidance within this series is composed of architectural considerations and
recommendations oriented around these key design areas.
Decisions made in one design area can impact or influence decisions across the entire
design. The focus is ultimately on building a sustainable solution to minimize the
footprint and impact on the environment.
Design area

Description

Application

Cloud application patterns that allow for designing sustainable workloads.

design
Application

Choices around hosting environment, dependencies, frameworks, and libraries.

platform
Testing

Strategies for CI/CD pipelines and automation, and how to deliver more
sustainable software testing.

Operational

Processes related to sustainable operations.

procedures
Storage

Design choices for making the data storage options more sustainable.

Network and
connectivity

Networking considerations that can help reduce traffic and amount of data
transmitted to and from the application.

Security

Relevant recommendations to design more efficient security solutions on
Azure.

We recommend that readers familiarize themselves with these design areas, reviewing
provided considerations and recommendations to better understand the consequences
of encompassed decisions.

Next step
Review the sustainability design methodology.
Design methodology

Design methodology for sustainable
workloads on Azure
Article • 10/21/2022

Building a sustainable application on any cloud platform requires technical expertise and
an understanding of sustainability guidelines in general and for your specific cloud
platform.
This design methodology aims to help establish an understanding about producing
more carbon efficient solutions, measuring your carbon impact, and ultimately reducing
unnecessary energy usage and emissions.

1—Design for business requirements
Businesses globally have different requirements. Expect that the review considerations
and design recommendations provided by this design methodology will yield different
design decisions and trade-offs for different scenarios and organizations.
Establish your business requirements and priorities, then review the design
methodologies in alignment with those requirements.

2—Evaluate the design areas using the design
principles
Refer to the sustainability design principles and the design areas below for your
sustainability workloads.
Decisions made within each design area will echo across other design areas. Review the
considerations and recommendations in each design area to understand the
consequences and impact and any known trade-offs.
Design areas:
Application design
Application platform
Deployment and testing
Operational procedures
Storage
Network and connectivity
Security

3—Understanding your emissions
To lower your emissions, you need to understand how to measure your sustainability
efforts.

Briefly about emission scopes
At Microsoft, we segment our greenhouse gas (GHG) emissions into three categories,
consistent with the Greenhouse Gas Protocol .
Scope 1 emissions: direct emissions that your activities create.
Scope 2 emissions: indirect emissions that result from the production of the
electricity or heat you use.
Scope 3 emissions: indirect emissions from all other activities you're engaged in.
For a business, these Scope 3 emissions can be extensive. They must be accounted
for across its supply chain, materials in its buildings, employee business travel, and
the life cycle of its products (including the electricity customers consume when
using the products). A company's Scope 3 emissions are often far more significant
than its Scope 1 and 2 emissions combined.
As a customer, the context of Scope 3 emissions can be network configuration and
delivery, power consumption, and devices outside the data center. If an application uses
excess bandwidth or packet size, it will impact from when the traffic leaves the data
center, through the various hops on the internet, down to the end-user device. Reducing
network bandwidth, therefore, can have a significant impact throughout the delivery
chain. The same considerations apply to compute resources, data storage, application
platform decisions, application design, and more.
Find more in-depth details and definitions in Azure's Scope 3 Methodology White
Paper

, published in 2021.

Measure and track carbon impact
Microsoft aligns with the Green Software Foundation , responsible for creating the
Software Carbon Intensity

(SCI) specification.

To measure the carbon impact of an application, the GSF provided a scoring
methodology called SCI, calculated as follows:
SCI = ((E*I)+M) per R

Where:

E = Energy consumed by a software system. Measured in kWh.
I = Location-based marginal carbon emissions. Carbon emitted per kWh of

energy, gCO2/kWh.
M = Embodied emissions of a software system. Carbon that is emitted through the

hardware on which the software is running.
R = Functional unit, which is how the application scales; per extra user, per API call,

per service, etc.
With this knowledge, it's essential to consider not only the application infrastructure and
hardware but also the user devices and application scalability, as it can alter the
environmental footprint considerably.
Read the full SCI specification on GitHub .

Carbon tracking and reporting with the Emissions Impact
Dashboard
Microsoft offers the Emissions Impact Dashboard

for Azure and Microsoft 365, which

helps you measure your cloud-based emissions and carbon savings potential.
We recommend you use this tool to get the insights and transparency you need to
understand your carbon footprint and to measure and track emissions over time.
Download the Emissions Impact Dashboard Power BI app for Azure

to get started.

Leverage the Microsoft Sustainability Manager
Customers using Microsoft Cloud for Sustainability can leverage Microsoft Sustainability
Manager. This extensible solution unifies data intelligence and provides comprehensive,
integrated, and automated sustainability management for organizations at any stage of
their sustainability journey. It automates manual processes, enabling organizations to
record, report, and reduce their emissions more efficiently.

Use a proxy solution to measure emissions
One way of estimating the carbon emissions from workloads is to design a proxy
solution architecture based on the SCI model as described above.
Defining the proxies for applications can be done in different ways. For example, using
these variables:
Any known carbon emission of the infrastructure

The cost of the infrastructure
Edge services and infrastructure carbon emissions
The number of users that are concurrently using the application
Metrics of the application to inform us about the performance over time
By designing an equation using the above variables, you can estimate the carbon score
(an approximation), helping you understand if you're building sustainable solutions.
There's also the aspect of application performance. You can link performance to cost
and carbon and assume this relationship yields a value. With this relation, you can
simplify the view like this:
Application

Application

Likely outcome

performance

cost

High

Unchanged

Optimized app

High

Lower

Optimized app

Unchanged/Lower

Higher

According to the green principles, a higher energy cost can
cause higher carbon emissions. Therefore, you can assume
that the app produces unnecessary carbon emissions.

High

High

The app may be producing unnecessary carbon

Therefore, building a carbon score dashboard can make use of the following proxies:
Cost
Performance
Carbon emissions of the infrastructure (if known/available)
Usage over time (requests, users, API calls, etc.)
Any extra measurement that is relevant to the application

4—The shared responsibility model for
sustainability
Reducing emissions is a shared responsibility between the cloud provider and the
customer designing and deploying applications on the platform.

Ways to reduce emissions
Reducing carbon emissions can happen with three possible solutions:
Carbon neutralization; compensating carbon emissions

Carbon avoidance; not emitting carbon in the first place
Carbon removal; subtract carbon from the atmosphere
The goal of green software is to avoid unnecessary emissions in the first place, hence
actively working toward a more sustainable future. Further, carbon removal is the
preferred goal for removing emissions from our atmosphere.
Microsoft is committed to being carbon negative by 2030 , and by 2050 to have
removed all the carbon

the company has emitted since it was founded in 1975.

A shared responsibility
As a cloud provider, Microsoft is responsible for the data centers hosting your
applications.
However, deploying an application in the Microsoft cloud doesn't automatically make it
sustainable, even if the data centers are optimized for sustainability. Applications that
aren't optimized may still emit more carbon than necessary.
Let's take an example.
You deploy an app to an Azure service, but you only utilize 10% of the allocated
resources. The provisioned resources are underutilized, ultimately leading to
unnecessary emissions.
It would help if you considered scaling to an appropriate tier of the resource
(rightsizing) or deploying more apps to the same provisioned resources.
We recommend making applications more efficient to utilize the data center capacity in
the best way possible. Sustainability is a shared responsibility goal that must combine
the efforts of the cloud provider and the customers in designing and implementing
applications.

Next steps
Review the design principles for sustainability.
Design principles

Design principles of a sustainable
workload
Article • 10/12/2022

The sustainability design methodology provides a framework to record, report, and
reduce or optimize the environmental impact of your workloads.
To achieve an increase in carbon efficiency, consider how your workload, directly and
indirectly, can reduce carbon emissions through:
Using less physical and virtual resources
Using less energy
Using energy and resources more intelligently
Supporting older devices
It's important to effectively record, report, and reduce carbon emissions through
actionable insights.
Gain transparency into your current carbon impact
Estimate savings
Take action to accelerate progress
These critical design principles for sustainability resonate and extend the quality pillars
of the Azure Well-Architected Framework—Reliability, Security, Cost Optimization,
Operational Excellence, and Performance Efficiency.

Principles of green software
Microsoft is actively working toward sustainability targets, and empowers every
organization to help reduce emissions and improve our environmental health. The Azure
Well-Architected Framework workload for sustainability aligns with the Green Software
Principles

from the Green Software Foundation .

The principles of green software are the starting point to understand the SCI model and
how this will be included in our framework.

Carbon efficiency
Principle: Emit the least amount of carbon possible.

The application or software must emit the least amount of carbon possible. A carbon
efficient cloud application is one that is optimized, and the starting point is the cost –
streamlining the application infrastructure and cost will ensure that no unnecessary
resources are wasted in the cloud to run the software. But this isn't enough, as you
might have cost-optimized your application but still waste tons of resources that emit
carbon for no reason.
Read more about the Carbon Efficiency principle

from the Green Software

Foundation.

Energy efficiency
Principle: Use the least amount of energy possible.
The goal of this principle is that you build applications that are energy-efficient. This is a
common pattern for mobile applications, since they must rely on a battery powered
device and are optimizing its consumption. It's less common, however, for desktop or
web applications, since until now, developers have never been asked to optimize the
electricity consumption of their software.
Read more about the Energy Efficiency principle

from the Green Software

Foundation

Carbon awareness
Principle: Do more when the electricity is cleaner and do less when the electricity is
dirtier.
We need to make the application aware of how much carbon it's emitting. This way, we
can react to specific conditions of energy supply using demand shifting and demand
shaping techniques:
Technique

Description

Demand

Demand shifting means moving the workloads and resources to regions or data

shifting

centers, or a time in the data center where the energy supply is high and the
demand is lower and can be met by renewable energy. Delaying running apps to a
time when there's less demand should result in lower carbon intensity.

Demand

Demand shaping means changing the application's behavior and appearance to

shaping

match the energy supply in real-time. A good practice is to build an eco-version of
the app and keep it as a benchmark for demand shaping and carbon optimization.

Read more about the Carbon Awareness principle

from the Green Software

Foundation.

Hardware efficiency
Principle: Use the least amount of embodied carbon possible.
Embodied carbon is the carbon that was emitted to build a device. Therefore, a
sustainable application will make sure older devices are supported and will maximize the
efficiency of each device. The goal is to build hardware-efficient applications.
Consider the tradeoff that older devices can have power inefficiencies, and may not
always be suitable.
Read more about the Hardware Efficiency principle

from the Green Software

Foundation.

Measuring sustainability
Principle: What you can't measure, you can't improve.
Measuring carbon emissions of a cloud application is a complex task, as it involves the
whole ecosystem of the software: from the cloud infrastructure (where we have the
emissions dashboards to help us out), to the network path that is crossed, to the edge
technology and user devices. With the SCI, we aren't targeting a discrete measurement
of carbon emissions, but a score that will change over time and with our optimization
techniques.
Read more about the Measurement

from the Green Software Foundation.

Climate commitments
Principle: Understand the exact mechanism of reduction.
Many corporations and groups have made commitments to the climate. They actively
work toward new sustainability goals with a primary objective to remove, reduce and
prevent carbon emissions.
There are several options for reducing the carbon footprint of any organization or entity.
However, and aligned with the goal of the Green Software Foundation, our main
direction should always be to avoid emitting carbon in the first place. This is what we
call Abatement, or Carbon Elimination.

Once we've pursued this goal, there will still be emissions that can't be avoided. All the
remaining carbon reduction methodologies will help us do so, offsetting (either
compensating or neutralizing carbon).
Your company's strategy can be a mix of all the possible methodologies and, depending
on the final result, can reach a Net Zero target when carbon emissions are eliminated
where possible and the residual emissions compensated.
The SCI equation aims to eliminate emissions, which should always be the primary goal
of a sustainable workload, and the score can only be reduced with abatement.
Read more about the Climate Commitments
Foundation.

Next steps
Review the considerations for application design.
Application design

from the Green Software

Application design of sustainable
workloads on Azure
Article • 10/12/2022

When building new or updating existing applications, it's crucial to consider how the
solution will impact the climate and if there are ways to improve and optimize. Learn
about considerations and recommendations to optimize your code and applications for
a more sustainable application design.
） Important
This article is part of the Azure Well-Architected sustainable workload series. If
you aren't familiar with this series, we recommend you start with what is a
sustainable workload?

Code efficiency
Demands on applications can vary, and it's essential to consider ways to stabilize the
utilization to prevent over- or underutilization of resources, which can lead to
unnecessary energy spills.

Evaluate moving monoliths to a microservice architecture
Monolithic applications usually scale as a unit, leaving little room to scale only the
individual components that may need it.
Green Software Foundation alignment: Energy efficiency, Hardware efficiency
Recommendation:
Evaluate the microservice architecture guidance.
A microservice architecture allows for scaling of only the necessary components
during peak load; ensuring idle components are scaled down or in. Additionally, it
may reduce the overhead and resources required for deploying monolithic
applications.
Consider this tradeoff: While reducing the compute resources required, you may
increase the amount of traffic on the network, and the complexity of the
application may increase significantly.

Consider this other tradeoff: Moving to microservices can result in extra
deployment overhead with numerous similarities in deployment pipelines.
Carefully consider the required deployment resources for monolithic versus
microservice architectures.
Additionally, read about containerizing monolithic applications.

Improve API efficiency
Many modern cloud applications are designed to transact many messages between
services and components asynchronously. Consider the format used to encode the
payload data. How much information does your application need to communicate, and
is there room to reduce the chattiness?
Green Software Foundation alignment: Energy efficiency
Recommendation:
Learn about the chatty I/O antipattern to better understand how a large number of
requests can impact performance and responsiveness.
Improve the reliability and reduce unnecessary load to your systems. Implement
advanced request throttling with API Management.
Minimize the amount of data the application returns from requests by being
selective and encoding the messages. See message encoding considerations.
Cache responses to avoid reprocessing the same type of information from the
backend system unless necessary. See caching in Azure API Management.

Ensure backward software compatibility to ensure it
works on legacy hardware
Consider how applications render information. Does the application need to critically
serve everything in the highest quality, resulting in higher bandwidth and processing? Is
there room for reducing the quality of components in the UI to serve sustainability goals
better?
Green Software Foundation alignment: Hardware efficiency
Recommendation:
Support more end-user consumer devices, like older browsers and operating
systems. This backward compatibility improves hardware efficiency by reusing
existing hardware instead of requiring a hardware upgrade for the solution to
work.

Consider this tradeoff: If the most recent software updates have significant
performance improvements, using older software versions may not be more
efficient.

Leverage cloud native design patterns
Learning about cloud-native design patterns is helpful for building applications, whether
they're hosted on Azure or running elsewhere. Optimizing the performance and cost of
your cloud application will also reduce its resource utilization, hence its carbon
emissions.
Green Software Foundation alignment: Energy efficiency, Hardware efficiency
Recommendation:
Leverage cloud-native design patterns when writing or updating applications.

Consider using circuit breaker patterns
Consider evaluating and preventing applications from performing operations that are
likely to fail. Repeated failures can lead to overhead and unnecessary processing that
you can avoid with proper design patterns.
Green Software Foundation alignment: Energy efficiency
Recommendation:
A circuit breaker can act as a proxy for operations that might fail and should
monitor the number of recent failures that have occurred and use that information
to decide whether to proceed.
Study the Circuit Breaker pattern, and then consider how you can implement the
Circuit Breaker patterns to your applications.
Consider using Azure Monitor to monitor failures and set up alerts.

Optimize code for efficient resource usage
Applications deployed using inefficient code may result in an inherent impact on
sustainability.
Green Software Foundation alignment: Energy efficiency, Hardware efficiency
Recommendation:
Reduce CPU cycles and the number of resources you need for your application.

Use optimized and efficient algorithms and design patterns.
Consider the Don't repeat yourself (DRY) principle.

Optimize for async access patterns
Demands on applications can vary, and it's essential to consider ways to stabilize the
utilization to prevent over- or underutilization of resources, which can lead to
unnecessary energy spills.
Green Software Foundation alignment: Energy efficiency
Recommendation:
Queue and buffer requests that don't require immediate processing, then process
in batch. Designing your applications in this way helps achieve a stable utilization
and helps flatten consumption to avoid spiky requests.
Read about optimizing for async access patterns.

Evaluate server-side vs. client-side rendering
Determine whether to render on the server-side or client-side when building
applications with a UI.
Green Software Foundation alignment: Energy efficiency, Hardware efficiency
Recommendation:
Consider these benefits of server-side rendering:
When the server's power comes from less-polluting alternatives than the client's
locale.
When the hardware on the server has better processing-energy ratios.
Can use centralized caching to reduce multiple unnecessary renders.
Reducing the number of browser-to-server round-trips can be particularly
important when the client's device has a lossy link.
When the client devices are older and have slower CPUs. Users don't need to
upgrade their devices to support a modern browser.
Consider these benefits of client-side rendering:
When the end-user devices are more suitable, pushing the responsibility of
rendering to the clients.
It's more efficient only to render what's needed and as requested, as opposed
to rendering everything at least once.
There's no need for a server, as you can rely on static storage.

Browser caching is used on the clients.

Be aware of UX design for sustainability
Consider how the UX design of a workload impacts sustainability and determine what
options exist for improving energy efficiency and reducing unnecessary network load,
data processing, and compute resources.
Green Software Foundation alignment: Energy efficiency
Recommendation:
Consider reducing the number of components to load and render on pages.
Determine whether the application can render lower-resolution images and videos.
Don't render full-size images as thumbnails where the browser is doing the
resizing.
Using full-size images as thumbnails or resized images will transfer more data,
unnecessary network traffic, and additional client-side CPU usage due to image
resizing and pre-rendering.
Ensuring there are no unused pages will help minimize the UX design.
Consider search and findability. Making it easier for users to find what they're
looking for helps lower the amount of data stored and retrieved.
Consider providing a lighter UI, using fewer resources and with a lower impact on
sustainability, and provide users with an informed choice.
Save energy by offering your apps and websites in dark mode, with dark
backgrounds.
Opt for using system fonts when possible to avoid forcing clients to download
additional fonts, which causes more network load.

Update legacy code
Consider upgrading or deprecating legacy code if it's not running on modern cloud
infrastructure or with the latest updates.
Green Software Foundation alignment: Hardware efficiency
Recommendation:
Identify inefficient legacy code suited for modernization.
Review if there are options to move to serverless or any of the optimized PaaS
options.
Consider this tradeoff: Updating old code that might end up being deprecated can
consume valuable time.

Next step
Review the design considerations for the application platform.
Application platform

Application platform considerations for
sustainable workloads on Azure
Article • 02/21/2023

Designing and building sustainable workloads requires understanding the platform
where you're deploying the applications. Review the considerations and
recommendations in this section to know how to make better informed platform-related
decisions around sustainability.
） Important
This article is part of the Azure Well-Architected sustainable workload series. If
you aren't familiar with this series, we recommend you start with what is a
sustainable workload?

Platform and service updates
Keep platform and services up to date to leverage the latest performance improvements
and energy optimizations.

Review platform and service updates regularly
Platform updates enable you to use the latest functionality and features to help increase
efficiency. Running on outdated software can result in running a suboptimal workload
with unnecessary performance issues. New software tends to be more efficient in
general.
Green Software Foundation alignment: Energy efficiency
Recommendation:
Upgrade to newer and more efficient services as they become available.
Consider backward compatibility and hardware reusability. An upgrade may not be
the most efficient solution if the hardware or the OS isn't supported.
Make use of Azure Automation Update Management to ensure software updates
are deployed to Azure VMs.

Regional differences

The Microsoft Azure data centers are geographically spread across the planet and
powered using different energy sources. Making decisions around where to deploy your
workloads can significantly impact the emissions your solutions produce.
Learn more about sustainability from the data center to the cloud with Azure . See
region-specific sustainability information in the Microsoft data center sustainability fact
sheets .

Deploy to low-carbon regions
Learn about what Azure regions have a lower carbon footprint than others to make
better-informed decisions about where and how our workloads process data.
Green Software Foundation alignment: Carbon efficiency
Recommendation:
Use less carbon because the data centers where you deploy the workload are more
likely to be powered by renewable and low-carbon energy sources.
Consider these potential tradeoffs:
The effort and time it takes to move to a low-carbon region.
Migrating data between data centers may not be carbon efficient.
Consider the cost for new regions, including low-carbon regions, which may be
more expensive.
If the workloads are latency sensitive, moving to a lower carbon region may not
be an option.

Process when the carbon intensity is low
Some regions on the planet are more carbon intense than others. Therefore it's essential
to consider where we deploy our workloads and combine this with other business
requirements.
Green Software Foundation alignment: Carbon efficiency, Carbon awareness
Recommendation:
Where you have the data available, consider optimizing workloads when knowing
that the energy mix comes mostly from renewable energy sources.
If your application(s) allow it, consider moving workloads dynamically when the
energy conditions change.
For example, running specific workloads at night may be more beneficial when
renewable sources are at their peak.

Choose data centers close to the customer
Deploying cloud workloads to data centers is easy. However, consider the distance from
a data center to the customer. Network traversal increases if the data center is a greater
distance from the consumer.
Green Software Foundation alignment: Energy efficiency
Recommendation:
Consider deploying to data centers close to the consumer.

Run batch workloads during low-carbon intensity periods
Proactively designing batch processing of workloads can help with scheduling intensive
work during low-carbon periods.
Green Software Foundation alignment: Carbon awareness
Recommendation:
Where you have the data available to you, plan your deployments to maximize
compute utilization for running batch workloads during low-carbon intensity
periods.
Potential tradeoffs may include the effort and time it takes to move to a lowcarbon region. Additionally, migrating data between data centers may not be
carbon efficient, and the cost for new regions-including low—carbon regions—
may be more expensive.

Modernization
Consider these platform design decisions when choosing how to operate workloads.
Leveraging managed services and highly optimized platforms in Azure helps build
cloud-native applications that inherently contribute to a better sustainability posture.

Containerize workloads where applicable
Consider options for containerizing workloads to reduce unnecessary resource
allocation and to utilize the deployed resources better.
Green Software Foundation alignment: Hardware efficiency
Recommendation:

Deploying apps as containers allows for bin packing and getting more out of a VM,
ultimately reducing the need for duplication of libraries on the host OS.
Removes the overhead of managing an entire VM, and allows deploying more
apps per physical machine. Containerization also optimizes server utilization rates
and improves service reliability, lowering operational costs. Fewer servers are
needed, and the existing servers can be better utilized.
Consider these tradeoffs: The benefit of containerization will only realize if the
utilization is high. Additionally, provisioning an orchestrator such as Azure
Kubernetes Services (AKS) or Azure Red Had OpenShift (ARO) for only a few
containers would likely lead to higher emissions overall.

Evaluate moving to PaaS and serverless workloads
Managed services are highly optimized and operate on more efficient hardware than
other options, contributing to a lower carbon impact.
Green Software Foundation alignment: Hardware efficiency, Energy efficiency
Recommendation:
Build a cloud-native app without managing the infrastructure, using a fully
managed and inherently optimized platform. The platform handles scaling,
availability, and performance, ultimately optimizing the hardware efficiency.
Review design principles for Platform as a Service (PaaS) workloads.

Use Spot VMs where possible
Think about the unused capacity in Azure data centers. Utilizing the otherwise wasted
capacity—at significantly reduced prices—the workload contributes to a more
sustainable platform design.
Green Software Foundation alignment: Hardware efficiency
Recommendation:
By utilizing Spot VMs, you take advantage of unused capacity in Azure data centers
while getting a significant discount on the VM.
Consider the tradeoff: When Azure needs the capacity back, the VMs get evicted.
Learn more about the Spot VM eviction policy.

Right sizing

Ensuring workloads use all the allocated resources helps deliver a more sustainable
workload. Oversized services are a common cause of more carbon emissions.

Turn off workloads outside of business hours
Operating idle workloads wastes energy and contributes to added carbon emissions.
Green Software Foundation alignment: Energy efficiency, Hardware efficiency
Recommendation:
Dev and testing workloads should be turned off or downsized when not used.
Instead of leaving them running, consider shutting them off outside regular
business hours.
Learn more about starting/stopping VMs during off-hours.

Utilize auto-scaling and bursting capabilities
It's not uncommon with oversized compute workloads where much of the capacity is
never utilized, ultimately leading to a waste of energy.
Green Software Foundation alignment: Hardware efficiency
Recommendation:
Review auto-scaling guidance for Azure workloads.
Review the B-series burstable virtual machine sizes.
Consider that it may require tuning to prevent unnecessary scaling during short
bursts of high demand, as opposed to a static increase in demand.
Consider the application architecture as part of scaling considerations. For
example, logical components should scale independently to match the demand of
that component, as opposed to scaling the entire application if only a portion of
the components needs scaling.

Match the scalability needs
Consider the platform and whether it meets the scalability needs of the solution. For
example, having provisioned resources with a dedicated allocation may lead to unused
or underutilized compute resources.
Examples:

Provisioning an Azure App Service Environment (ASE) over an App Service plan
may lead to having provisioned compute, whether utilized or not.
Choosing the Azure API Management Premium tier instead of the consumption
tier leads to unused resources if you aren't utilizing it fully.
Green Software Foundation alignment: Hardware efficiency
Recommendation:
Review the platform design decisions regarding scalability, and ensure the
workload utilizes as much of the provisioned resources as possible.
Consider this tradeoff: Some services require a higher tier to access certain features
and capabilities regardless of resource utilization.
Consider and prefer services that allow dynamic tier scaling where possible.

Evaluate Ampere Altra Arm-based processors for Virtual
Machines
The Arm-based VMs represent a cost-effective and power-efficient option that doesn't
compromise on the required performance.
Green Software Foundation alignment: Energy efficiency
Recommendation:
Evaluate if the Ampere Altra Arm-based VMs is a good option for your workloads.
Read more about Azure Virtual Machines with Ampere Altra Arm–based
processors

on Azure.

Delete zombie workloads
Consider discovering unutilized workloads and resources and if there are any orphaned
resources in your subscriptions.
Green Software Foundation alignment: Hardware efficiency, Energy efficiency
Recommendation:
Delete any orphaned workloads or resources if they're no longer necessary.

Next step
Review the design considerations for deployment and testing.

Deployment and testing

Testing considerations for sustainable
workloads on Azure
Article • 10/28/2022

Organizations developing and deploying solutions to the cloud also need reliable
testing. Learn about the considerations and recommendations for running workload
tests and how to optimize for a more sustainable testing model.
） Important
This article is part of the Azure Well-Architected sustainable workload series. If
you aren't familiar with this series, we recommend you start with what is a
sustainable workload?

Testing efficiency
Run integration, performance, load, or any other intense
testing during low-carbon periods
Running integration, performance, load, or any other intense testing capability may
result in much processing. A well-crafted design for testing the deployed workloads can
help ensure full utilization of the available resources, reducing carbon emissions.
Green Software Foundation alignment: Carbon awareness
Recommendation:
Where you have the data available to you, plan for running testing when the data
center's energy mix primarily uses renewable energy. It may, for example, be more
beneficial to run testing during the night in some regions.

Automate CI/CD to scale worker agents as needed
Running underutilized or inactive CI/CD agents results in more emissions.
Green Software Foundation alignment: Hardware efficiency
Recommendation:

Keeps the compute utilization high, based on the current demand, avoiding
unnecessary capacity allocation.
Only scale out when necessary, and when not testing, scale in. Ultimately this
ensures there's no idle compute resources in test environments.
Consider optimized platform services like containers over testing in a VM, utilizing
the platform to reduce maintenance.

Consider caching when using CI/CD agents
Using caching mechanisms during CI/CD can reduce compute time and, thus, carbon
emissions.
Green Software Foundation alignment: Energy Efficiency
Recommendation:
Store results from steps in a cache and re-use them between different CI/CD runs
when possible: when there are steps that take CPU time to produce an artifact that
does not often change between different runs, it is wise to save it for future usage
so that CPU time is not wasted on every run producing the same artifact, over and
over.
If the CI/CD agent is self-hosted, use a cache local to the agent to further reduce
data transfers and emissions. This ensures that the cache is not transferred over
the network, which can be a significant source of emissions.

Split large code repositories
Splitting large repositories can help the CI/CD phases, where only the parts of the code
that have changed are compiled. This reduces compute time, which ultimately lowers
carbon emissions.
Green Software Foundation alignment: Energy Efficiency
Recommendation:
Split large code repositories, separating main code from libraries and
dependencies.
Publish and re-use artifacts and libraries of code that are common across multiple
repositories.
Recommendation:

Split large repositories of code into smaller ones, separating main code from
libraries and dependencies.
Publish and re-use artifacts and libraries of code that are common across multiple
repositories.

Profiling and measuring
Measuring, profiling, and testing workloads are imperative to understanding how to
best use allocated resources.

Assess where parallelization is possible
Without properly profiling and testing workloads, it's difficult to know if it's making the
best use of the underlying platform and deployed resources.
Green Software Foundation alignment: Measuring sustainability
Recommendation:
Test your applications to understand concurrent requests, simultaneous
processing, and more.
If you're running Machine Learning (ML) for tests, consider machines with a GPU
for better efficiency gains.
Identify if the workload is performance intensive and work toward optimization.
Consider this tradeoff: Running GPU-based machines for ML tests may increase the
cost.

Assess with chaos engineering
Running integration, performance and load tests increase the reliability of a workload.
However, the introduction of chaos engineering can significantly help improve reliability
and resilience and how the applications react to failures. In doing so, the workload can
be optimized to handle failures gracefully and with less wasted resources.
Green Software Foundation alignment: Measuring sustainability
Recommendation:
Use load testing or chaos engineering to assess how the workload handles
platform outages and traffic spikes or dips. This helps increase service resilience
and the ability to react to failures, allowing for a more optimized fault handling.

Consider this tradeoff: Injecting fault during chaos engineering and increasing the
load on any system also increases the emissions used for the testing resources.
Evaluate how and when you can utilize chaos engineering to increase the workload
reliability while considering the climate impact of running unnecessary testing
sessions.
Another angle to this is using chaos engineering to test energy faults or moments
with higher carbon emissions: consider setting up tests that will challenge your
application to consume the minimum possible energy. Define how the application
will react to such conditions with a specific "eco" version informing users that
they're emitting the minimum possible carbon by sacrificing some features and
possibly some performance. This can also be your benchmark application for
scoring its sustainability.

Establish CPU and Memory thresholds in testing
Help build tests for testing sustainability in your application. Consider having a baseline
CPU utilization measurement, and detect abnormal changes to the CPU utilization
baseline when tests run. With a baseline, suboptimal decisions made in recent code
changes can be discovered earlier.
Adding tests and quality gates into the deployment and testing pipeline helps avoid
deploying non-sustainable solutions, contributing to lowered emissions.
Green Software Foundation alignment: Energy efficiency
Recommendation:
Monitor CPU and memory allocations when running integration tests or unit tests.
Find abnormally high resource consumption areas in the application code and
focus on mitigating those first.
Configure alerts or test failures if surpassing the established baseline values,
helping avoid deploying non-sustainable workloads.
Consider this tradeoff: As applications grow, the baseline may need to shift
accordingly to avoid failing the tests when introducing new features.

Next step
Review the design considerations for operational procedures.
Operational procedures

Operational procedure considerations
for sustainable workloads on Azure
Article • 10/12/2022

The discipline of green software and its implementation within cloud efficiency patterns
is relatively recent, and no specific and universal standards have been agreed upon yet.
The Green Software Foundation

works on creating and standardizing ways of making

green software. However, it's vital that everyone considers this aspect in their daily work
and that when designing, planning, and deploying Azure workloads, we consider the
best practices that are already available and prepare our environment to incorporate
new standards when ready.
This document will guide you through setting up an environment for measuring and
continuously improving your Azure workloads' cost and carbon efficiency.
） Important
This article is part of the Azure Well-Architected sustainable workload series. If
you aren't familiar with this series, we recommend you start with what is a
sustainable workload?

Measure and track carbon impact
To optimize or improve something, we first must decide what we want to change and
how to measure it. In this section, you'll learn about best practices and guidelines to
measure and track the sustainability impact of your workloads.

The Emissions Impact Dashboard
An essential aspect of working toward any sustainability goal is tracking and quantifying
progress. If you can't track and measure the impact, you'll never be sure if the efforts are
worthwhile. The Emissions Impact Dashboard is a Power BI dashboard that will give you
a measure of the carbon impact of all your services and resource groups in your Azure
subscription(s).
The Emissions Impact Dashboards produce insights in various forms, and allows for a
wide range of reporting capabilities:

Series of visual representations in the dashboard itself.
Snapshot export to Excel, Power Point and PDF.
Continuous export to Microsoft Sustainability Manager and Dataverse.
Green Software Foundation alignment: Measuring sustainability
Recommendation:
Use the Emissions Impact Dashboard

to record current and future environmental

impact.
Identify and track metrics to quantify the achievement of technical, business, and
sustainability outcomes.
Rely on tooling to help measure the impact, and record any changes made to your
workload.
Learn more about the Sustainability and Dataverse API access in the Microsoft
Learn module Access Microsoft Sustainability Manager data.

Define emissions target
The Software Carbon Intensity (SCI) is the score you're looking for to measure the
carbon impact of your application(s) by adding the scalability and cost metrics to any
carbon emissions measurement.
If you aren't using the Emissions Impact Dashboard, there are still ways of building
carbon proxies that allow you to measure your application's impact on emissions.
It can be a challenge to build carbon proxies for existing applications. Therefore, we
recommend planning for efficiency targets during the design phase of every workload.
When adding new workloads to Azure, you should consider planning for costs and
emissions that will add to your existing footprint. The main goal should always be not to
emit carbon, so ideally, you should immediately find an optimization pattern to make up
for the new emissions.
The next step is to define your target emissions, either for a single application or for
your entire set of cloud workloads. The target can also include cost constraints, making
it even easier to build upon since shrinking costs will give you some budget to optimize
emissions. Once you know your target, the cloud efficiency continuous optimization
process can start.
Green Software Foundation alignment: Measuring sustainability
Recommendations:

Calculate your new workload's minimum cost and carbon emissions (where
applicable).
Track progress with Service Level Objectives (SLO), Service Level Agreements (SLA),
or other performance metrics.
Provide optimization patterns to accommodate the new application to your overall
cloud efficiency score.

Identify the metrics and set improvement goals
Once you've defined your target, you'll need to identify a few metrics that you can
measure to prove your changes had a positive effect on efficiency.
The metrics can, as an example, be derived from these categories:
Application performance metrics.
Cost optimization metrics.
Carbon emissions metrics (or proxies).
Green Software Foundation alignment: Measuring sustainability
Recommendation:
Discuss with every application owner since the impact of optimizing can vary and
might affect many users.
Make sure that any plan that impacts performance is agreed upon and
communicated clearly to the app users so that they know that a lower performance
may be necessary for the greater good of fewer carbon emissions.
If you've connected the Microsoft Emissions Impact Dashboard (EID) to your
Microsoft Sustainability Manager (MSM) instance, you can use the Goal Tracking
feature in MSM to define and track your goals by linking them to live data from
EID.

Cost optimization as a proxy
Sometimes the ease of deploying cloud resources makes us forget what is useful and
what is simply a waste of resources, money, and carbon. The message here's that
experiments in the cloud can sometimes be costly in terms of overall cloud efficiency,
not purely cost, while bringing no innovation.
Use cloud resources wisely, considering any extra workload's carbon footprint.
When defining your SCI, you can use carbon proxies to compensate for the lack of
specific standards and measurements. One of the safest and most potent proxies for

carbon emissions are your application(s) cost. Reducing unnecessary spending lowers
the number of excessive emissions from deployed workloads as you're using fewer
cloud resources.
Linking cost performance metrics to carbon efficiency can be a sound strategy because
you won't necessarily need to compromise on your defined workload Key Performance
Indicators (KPI) by optimizing cost and reducing carbon emissions. However, you might
decide that you're prepared to sacrifice a KPI towards your carbon goal, which can also
be part of your strategy.
Green Software Foundation alignment: Measuring sustainability
Recommendation:
Review the concept of using a proxy solution to measure emissions.
Leverage the guidance in the Azure Well-Architected Framework Cost Optimization
pillar.

Defining policies
Azure Policy is a powerful tool that can make some decisions for your cloud efficiency
easier to implement. Consider defining one of more policies to keep your Azure virtual
data center continuously optimized.
Green Software Foundation alignment: Climate commitments
Recommendation:
Incorporate and use the cost policies available in the Cloud Adoption Framework.
Leverage built-in policies relevant to cost in Azure Policy, as they're technically
closely tied to sustainability.
Customize Azure Policy policies according to green software principles. For
example, create a new Azure Policy initiative for "Sustainability".
Consider this tradeoff: Enforcement of new policies must not impact any
unplanned operational performance metric.

Community and knowledge sharing
Teams needs to be constantly aware of new advancements in sustainability, so they
leverage these learnings when implementing workloads.
Building a community around cloud efficiency and green software is a good starting
point to foster cloud efficiency awareness and culture across your organization.

Create a sustainability community
Creating a sustainability community doesn't have to be a tedious task. Start with a small
team that will invest some time in learning the sustainability status and the relevant
information on green software. This team can also join the Green Software
Foundation

and be part of the teams that create rules, standards, and more.

The Core cloud Efficiency team will have to be up to date with all the innovative tools
and principles that drive your Azure workload's cost and carbon footprint.
Green Software Foundation alignment: Climate commitments
Recommendation:
Define policies and targets, and communicate their efforts and goals with the rest
of the organization.
Learn more by reading how do I start a sustainability community in my
organization?

Plan for learning
Make time for the core team to learn about advancements in sustainable operations.
Meanwhile, ensure that your entire organization starts thinking about green software
and how to contribute to the sustainability picture with their daily choices.
Green Software Foundation alignment: Climate commitments
Recommendation:
Review these popular training and learning resources:
Use the self-paced learning module to Learn about The Principles of Sustainable
Software Engineering.
Use the self-paced learning path to Get started with Microsoft Cloud for
Sustainability.
Find more resources in the Microsoft Sustainability Learning Center

.

Share best practices across teams
Driving adoption of sustainability efforts requires input and work from across the
organization.
Green Software Foundation alignment: Climate commitments

Recommendation:
Let team members share their workload and company-specific best practices for
sustainable operations.
Set up a shared repository of best practices and guidance that have been tested in
your environment with tangible results.
Consider frequent knowledge-sharing sessions or internal webinars for getting
everyone up to speed.

Plan for incentives
The quickest way of enforcing policies and creating the right culture is by setting
incentives for improving the environmental sustainability of a workload by either putting
sustainability as a core KPI or adding it to the overall efficiency of the applications.
Many software partners already include green software in their best practices. Therefore,
ensure that your efficiency targets are defined and accepted when discussing the
workload.
Green Software Foundation alignment: Climate commitments
Recommendations:
Promote carbon-aware applications. Reward application owners if the measured
carbon footprint meets the KPI.
Introduce gamification by creating a friendly culture of sustainability competition
—track records to promote green workloads, SCI scoring, and any optimization or
improvement on the score.
Consider introducing loyalty programs, where participants get incentives when
they can prove the cloud efficiency of their applications.
Explore the opportunity to introduce badges like "Carbon Aware" and "Carbon
Optimized".

Next step
Review the design considerations for networking and connectivity.
Networking and connectivity

Networking considerations for
sustainable workloads on Azure
Article • 10/12/2022

Most workloads in the cloud rely heavily on networking to operate. Whether internal
networking or public-facing workloads, the components and services used in
provisioned solutions must consider the impact of carbon emissions. Consider that
network equipment consumes electricity, including traffic between the data centers and
end consumers. Learn about considerations and recommendations to enhance and
optimize network efficiency to reduce unnecessary carbon emissions.
Internet traversal between data centers and end consumers is a significant Scope 3
emission. Therefore, recommendations in this section are aligned with the Principles of
Green Software Networking

area to improve networking efficiency.

） Important
This article is part of the Azure Well-Architected sustainable workload series. If
you aren't familiar with this series, we recommend you start with what is a
sustainable workload?

Network efficiency
Reduce unnecessary network traffic and lower bandwidth requirements where possible,
allowing for a more optimized network efficiency with less carbon emission.

Make use of a CDN
Unnecessary traffic on the network should be avoided, as it's a cause for extra carbon
emissions.
Green Software Foundation alignment: Energy efficiency
Recommendation:
A CDN helps minimize latency through storing frequently read static data closer to
consumers, and helps reduce the network traversal and server load.
Ensure to follow best practices for CDN.

Follow caching best practices
Minimizing the amount of data transferred is crucial.
Green Software Foundation alignment: Energy efficiency, Hardware efficiency
Recommendation:
Caching is a well-understood design technique to improve performance and
efficiency.
A caching solution helps reduce network traversal and reduces the server load.
Consider that it may require tuning of parameters to maximize the benefit and
minimize the carbon drawbacks. For example, setting a Time to Live (TTL).
Adding in-memory caching can help use idle compute resources, increasing the
compute density of resources that are already allocated.
Read caching best practices.

Select Azure regions based on where the customer
resides
The location of an application's consumers can be disparate, and it can be challenging
to serve requests with good performance and energy efficiency if the distance is too
great.
Green Software Foundation alignment: Energy efficiency
Recommendation:
Deploy or move Azure resources across regions to better serve the applications
from where most consumers reside.

Use managed audio and video streaming services with
built-in compression
Applications making use of a media streaming service may have high requirements for
bandwidth and compression, and can have a substantial carbon footprint if not
designed carefully.
Green Software Foundation alignment: Hardware efficiency
Recommendation:

By making use of a managed service for audio and video, applications can leverage
built-in optimizations like encoding, compressions, and more.
Read about managed audio and video streaming services.

Enable network file compression
Networks sending uncompressed data can have a higher requirement on bandwidth, the
allocated resources, and the solution in general. Consider compressing data to optimize
the workload and design for a more network efficient solution.
Green Software Foundation alignment: Energy efficiency
Recommendation:
Reduce the network payload by improving CDN performance.

Maximize network utilization within the same cloud and
region
Operating solutions in multiple regions have a networking impact. Network traversals
between components in Azure are optimized to stay within the Azure infrastructure.
However, any network traffic destined for the internet or a component in another cloud
involves the public internet's router resources, which you have no control over regarding
resource impact measurement or utilization.
Green Software Foundation alignment: Energy efficiency
Recommendation:
Keeping resources in a single cloud gives you maximum control and allows the
cloud provider to optimize the network routing.
Maximize network utilization within the same cloud and, if possible, within the
same region.
Since the cost can be a proxy for sustainability, review the Azure regions
documentation in the Cost Optimization pillar of the Azure Well-Architected
Framework.

Next step
Review the design considerations for storage.
Storage

Data and storage design considerations
for sustainable workloads on Azure
Article • 10/12/2022

Data storage in Azure is a crucial component of most provisioned workloads. Learn how
to design for a more sustainable data storage architecture and optimize existing
deployments.
） Important
This article is part of the Azure Well-Architected sustainable workload series. If
you aren't familiar with this series, we recommend you start with what is a
sustainable workload?

Storage efficiency
Build solutions with efficient storage to increase performance, lower the required
bandwidth, and minimize unnecessary storage design climate impact.

Enable storage compression
Storing much uncompressed data can result in unnecessary bandwidth waste and
increase the storage capacity requirements.
Green Software Foundation alignment: Hardware efficiency
Recommendation:
A solution to reduce the storage requirements, including both capacity and
required bandwidth to write or retrieve data. For example, compressing files in
Azure Front Door and compressing files in Azure CDN.
Compression is a well-known design technique to improve network performance.
Consider the tradeoff of compression: Does the benefit of compression outweigh
the increased carbon cost in the resources (CPU, RAM) needed to perform the
compression/decompression?

Optimize database query performance

Querying extensive databases or retrieving much information simultaneously can have a
performance penalty. Ideally, apps should optimize for query performance.
Green Software Foundation alignment: Energy efficiency
Recommendation:
Reduces the latency of data retrieval while also reducing the load on the database.
Understand the query performance for Azure SQL Databases
There are many well-known ways to optimize data query performance, for example
tuning apps and databases for performance in an Azure SQL database.
Consider that it may require fine-tuning to achieve optimal results.

Use the best suited storage access tier
The carbon impact of data retrieved from hot storage can be higher than data from
cold- or archive storage. Designing solutions with the correct data access pattern can
enhance the application's carbon efficiency.
Green Software Foundation alignment: Energy efficiency
Recommendation:
Use storage best suited for the application's data access patterns.
Make sure your most frequent data is stored in hot storage, making it easy to
retrieve and doesn't require more processing to access.
Infrequently used data should be stored in cold or offline archive storage, using
less energy.

Only store what is relevant
Backup is a crucial part of reliability. However, storing backups indefinitely can quickly
allocate much unnecessary disk space. Consider how you plan backup storage retention.
Green Software Foundation alignment: Hardware efficiency
Recommendation:
Implement policies to streamline the process of storing and keeping relevant
information. Microsoft Purview can help label data and add time-based purging to
delete it after a retention period automatically. Additionally, this lets you stay in
control of your data and reduces the amount of data to process and transfer.
Workloads integrated with Azure Monitor can rely on Data Collection Rules (DCR)
to specify what data should be collected, how to transform that data, and where to

send the data.

Determine the most suitable access tier for blob data
Consider whether to store data in an online tier or an offline tier. Online tiers are
optimized for storing data that is accessed or modified frequently. Offline tiers are
optimized for storing data that is rarely accessed.
Green Software Foundation alignment: Energy efficiency
Recommendation:
Read Hot, Cool, and Archive access tiers for blob data.

Reduce the number of recovery points for VM backups
Recovery points aren't automatically cleaned up. Therefore, consider where soft delete is
enabled for Azure Backup. The expired recovery points aren't cleaned up automatically.
Green Software Foundation alignment: Hardware efficiency
Recommendation:
Read more about the impact of expired recovery points for items in soft deleted
state.

Revise backup and retention policies
Consider reviewing backup policies and retention periods for backups to avoid storing
unnecessary data.
Green Software Foundation alignment: Hardware efficiency
Recommendation:
Review and revise backup and retention policies to minimize storage overhead.
Actively review and delete backups that are no longer needed.

Optimize the collection of logs
Continuously collecting logs across workloads can quickly aggregate and store lots of
unused data.
Green Software Foundation alignment: Energy efficiency

Recommendation:
Make sure you are logging and retaining only data that is relevant to your needs.
Read more about the Cost optimization and Log Analytics.

Next step
Review the design considerations for security.
Security

Security considerations for sustainable
workloads on Azure
Article • 10/12/2022

Designing sustainable workloads on Azure must encompass security, which is a
foundational principle through all phases of a project. Learn about considerations and
recommendations leading to a more sustainable security posture.
） Important
This article is part of the Azure Well-Architected sustainable workload series. If
you aren't familiar with this series, we recommend you start with what is a
sustainable workload?

Security monitoring
Use cloud native security monitoring solutions to optimize for sustainability.

Use cloud native log collection methods where applicable
Traditionally, log collection methods for ingestion to a Security Information and Event
Management (SIEM) solution required the use of an intermediary resource to collect,
parse, filter and transmit logs onward to the central collection system. Using this design
can carry an overhead with more infrastructure and associated financial and carbonrelated costs.
Green Software Foundation alignment: Hardware efficiency, Energy efficiency
Recommendation:
Using cloud native service-to-service connectors simplify the integration between
the services and the SIEM, and removes the overhead of extra infrastructure.
It's possible to ingest log data from existing compute resources using previously
deployed agents such as the Azure Monitor Analytics agent. Review how to
migrate to Azure Monitor agent from Log Analytics agent.
Consider this tradeoff: Deploying more monitoring agents will increase the
overhead in processing as it needs more compute resources. Carefully design and
plan for how much information is needed to cover the security requirements of the
solution and find a suitable level of information to store and keep.

A possible solution to reduce unnecessary data collection is to rely on the Azure
Monitor Data Collection Rules (DCR).

Avoid transferring large unfiltered data sets from one
cloud service provider to another
Conventional SIEM solutions required all log data to be ingested and stored in a
centralized location. In a multicloud environment, this solution can lead to a large
amount of data being transferred out of a cloud service provide and into another,
causing increased burden on the network and storage infrastructure.
Green Software Foundation alignment: Carbon efficiency, Energy efficiency
Recommendation:
Cloud native security services can perform localized analysis on relevant security
data source. This analysis allows the bulk of log data to remain within the source
cloud service provider environment. Cloud native SIEM solutions can be connected
via an API or connector to these security services to transmit only the relevant
security incident or event data. This solution can greatly reduce the amount of data
transferred while maintaining a high level of security information to respond to an
incident.
In time, using the described approach helps reduce data egress and storage costs, which
inherently help reduce emissions.

Filter or exclude log sources before transmission or
ingestion into a SIEM
Consider the complexity and cost of storing all logs from all possible sources. For
instance, applications, servers, diagnostics and platform activity.
Green Software Foundation alignment: Carbon efficiency, Energy efficiency
Recommendation:
When designing a log collection strategy for cloud native SIEM solutions, consider
the use cases based on the Microsoft Sentinel analytics rules required for your
environment and match up the required log sources to support those rules.
This option can help remove the unnecessary transmission and storage of log data,
reducing the carbon emissions on the environment.

Archive log data to long-term storage
Many customers have a requirement to store log data for an extended period due to
regulatory compliance reasons. In these cases, storing log data in the primary storage
location of the SIEM system is a costly solution.
Green Software Foundation alignment: Energy efficiency
Recommendation:
Log data can be moved out to a cheaper long-term storage option

which

respects the retention policies of the customer, but lowers the cost by utilizing
separate storage locations.

Network architecture
Increase the efficiency and avoid unnecessary traffic by following good practices for
network security architectures.

Use cloud native network security controls to eliminate
unnecessary network traffic
When you use a centralized routing- and firewall design, all network traffic is sent to the
hub for inspection, filtering, and onward routing. While this approach centralizes policy
enforcement, it can create an overhead on the network of unnecessary traffic from the
source resources.
Green Software Foundation alignment: Hardware efficiency, Energy efficiency
Recommendation:
Use Network security groups and Application security groups to help filter traffic at
the source, and to remove the unnecessary data transmission. Using these
capabilities can help reduce the burden on the cloud infrastructure, with lower
bandwidth requirements and less infrastructure to own and manage.

Minimize routing from endpoints to the destination
In many customer environments, especially in hybrid deployments, all end user device
network traffic is routed through on-premises systems before being allowed to reach
the internet. Usually, this happens due to the requirement to inspect all internet traffic.

Often, this requires higher capacity network security appliances within the on-premises
environment, or more appliances within the cloud environment.
Green Software Foundation alignment: Energy efficiency
Recommendation:
Minimize routing from endpoints to the destination.
Where possible, end user devices should be optimized to split out known traffic
directly to cloud services while continuing to route and inspect traffic for all
other destinations. Bringing these capabilities and policies closer to the end
user device prevents unnecessary network traffic and its associated overhead.

Use network security tools with auto-scaling capabilities
Based on network traffic, there will be times when demand of the security appliance will
be high, and other times where it will be lower. Many network security appliances are
deployed to a scale to cope with the highest expected demand, leading to inefficiencies.
Additionally, reconfiguration of these tools often requires a reboot leading to
unacceptable downtime and management overhead.
Green Software Foundation alignment: Hardware efficiency
Recommendation:
Making use of auto-scaling allows the rightsizing of the backend resources to meet
demand without manual intervention.
This approach will vastly reduce the time to react to network traffic changes,
resulting in a reduced waste of unnecessary resources, and increases your
sustainability effect.
Learn more about relevant services by reading how to enable a Web Application
Firewall (WAF) on an Application Gateway, and deploy and configure Azure Firewall
Premium.

Evaluate whether to use TLS termination
Terminating and re-establishing TLS is CPU consumption that might be unnecessary in
certain architectures.
Green Software Foundation alignment: Energy efficiency
Recommendation:

Consider if you can terminate TLS at your border gateway and continue with nonTLS to your workload load balancer and onwards to your workload.
Review the information on TLS termination to better understand the performance
and utilization impact it offers.
Consider the tradeoff: A balanced level of security can offer a more sustainable and
energy efficient workload while a higher level of security may increase the
requirements on compute resources.

Use DDoS protection
Distributed Denial of Service (DDoS) attacks aim to disrupt operational systems by
overwhelming them, creating a significant impact on the resources in the cloud.
Successful attacks flood network and compute resources, leading to an unnecessary
spike in usage and cost.
Green Software Foundation alignment: Energy efficiency, Hardware efficiency
Recommendation:
DDoS protection seeks to mitigate attacks at an abstracted layer, so the attack is
mitigated before reaching any customer operated services.
Mitigating any malicious usage of compute and network services will ultimately
help reduce unnecessary carbon emissions.

Endpoint security
It's imperative that we secure our workloads and solutions in the cloud. Understanding
how we can optimize our mitigation tactics all the way down to the client devices can
have a positive outcome for reducing emissions.

Integrate Microsoft Defender for Endpoint
Many attacks on cloud infrastructure seek to misuse deployed resources for the
attacker's direct gain. Two such misuse cases are botnets and crypto mining.
Both of these cases involve taking control of customer-operated compute resources and
use them to either create new cryptocurrency coins, or as a network of resources from
which to launch a secondary action like a DDoS attack, or mass e-mail spam campaigns.
Green Software Foundation alignment: Hardware efficiency
Recommendations:

Integrate Microsoft Defender for Endpoint with Defender for Cloud to identify and
shut down crypto mining and botnets.
The EDR capabilities provide advanced attack detections and are able to take
response actions to remediate those threats. The unnecessary resource usage
created by these common attacks can quickly be discovered and remediated,
often without the intervention of a security analyst.

Reporting
Getting the right information and insights at the right time is important for producing
reports around emissions from your security appliances.

Tag security resources
It can be a challenge to quickly find and report on all security appliances in your tenant.
Identifying the security resources can help when designing a strategy for a more
sustainable operating model for your business.
Green Software Foundation alignment: Measuring sustainability
Recommendation:
Tag security resources to record emissions impact of security resources.

Next step
Review the design principles for sustainability.
Design principles

Azure Well-Architected Framework
review - Azure Service Fabric
Article • 01/11/2023

Azure Service Fabric is a distributed systems platform that makes it easy to package,
deploy, and manage scalable and reliable microservices and containers. These resources
are deployed onto a network-connected set of virtual or physical machines, which is
called a cluster.
There are two clusters models in Azure Service Fabric: standard clusters and managed
clusters.
Standard clusters require you to define a cluster resource alongside a number of
supporting resources. These resources must be set up correctly upon deployment and
maintained correctly throughout the lifecycle of the cluster. Otherwise, the cluster and
your services will not function properly.
Managed clusters simplify your deployment and management operations. The
managed cluster model consists of a single Service Fabric managed cluster resource that
encapsulates and abstracts away the underlying resources.
This article primarily discusses the managed cluster model for simplicity. However, callouts are made for any special considerations that apply to the standard cluster model.
In this article, you learn architectural best practices for Azure Service Fabric. The
guidance is based on the five pillars of architectural excellence:
Reliability
Security
Cost optimization
Operational excellence
Performance efficiency

Prerequisites
Understanding the Well-Architected Framework pillars can help produce a high
quality, stable, and efficient cloud architecture. Check out the Azure WellArchitected Framework overview page to review the five pillars of architectural
excellence.

Reviewing the core concepts of Azure Service Fabric and microservice architecture
can help you understand the context of the best practices provided in this article.

Reliability
The following sections cover design considerations and configuration recommendations,
specific to Azure Service Fabric and reliability.
When discussing reliability with Azure Service Fabric, it's important to distinguish
between cluster reliability and workload reliability. Cluster reliability is a shared
responsibility between the Service Fabric cluster admin and their resource provider,
while workload reliability is the domain of a developer. Azure Service Fabric has
considerations and recommendations for both of these roles.
In the design checklist and list of recommendations below, call-outs are made to
indicate whether each choice is applicable to cluster architecture, workload architecture,
or both.
For more information about Azure Service Fabric cluster reliability, check out the
capacity planning documentation.
For more information about Azure Service Fabric workload reliability, reference the
Reliability subsystem included in the Service Fabric architecture.

Design checklist
As you make design choices for Azure Service Fabric, review the design principles for
adding reliability to the architecture.
＂ Cluster architecture: Use Standard SKU for production scenarios. Standard cluster:
Use durability level Silver (5 VMs) or greater for production scenarios.
＂ Cluster architecture: For critical workloads, consider using Availability Zones for
your Service Fabric clusters.
＂ Cluster architecture: For production scenarios, use the Standard tier load balancer.
Managed clusters create an Azure public Standard Load Balancer and fully qualified
domain name with a static public IP for both the primary and secondary node types.
You can also bring your own load balancer, which supports both Basic and Standard
SKU load balancers.
＂ Cluster architecture: Create additional, secondary node types for your workloads.

Recommendations

Explore the following table of recommendations to optimize your Azure Service Fabric
configuration for service reliability:
Azure Service Fabric

Benefit

Recommendation
Cluster architecture: Use

This level ensures the resource provider maintains cluster

Standard SKU for production

reliability. Standard cluster: A Standard SKU managed cluster

scenarios.

provides the equivalent of durability level Silver. To achieve this
using the standard cluster model, you will need to use 5 VMs (or
more).

Cluster architecture:
Consider using Availability

Service Fabric managed cluster supports deployments that span
across multiple Availability Zones to provide zone resiliency. This

Zones for your Service Fabric

configuration will ensure high-availability of the critical system

clusters.

services and your applications to protect from single-points-offailure.

Cluster architecture:
Consider using Azure API

API Management can integrate with Service Fabric directly.

Management to expose and
offload cross-cutting
functionality for APIs hosted
on the cluster.
Workload architecture: For

The Reliable Services model allows your services to stay up even in

stateful workload scenarios,

unreliable environments where your machines fail or hit network

consider using Reliable
Services.

issues, or in cases where the services themselves encounter errors
and crash or fail. For stateful services, your state is preserved even
in the presence of network or other failures.

For more suggestions, see Principles of the reliability pillar.

Security
The following sections cover design considerations and configuration recommendations,
specific to Azure Service Fabric and security.
When discussing security with Azure Service Fabric, it's important to distinguish between
cluster security and workload security. Cluster security is a shared responsibility between
the Service Fabric cluster admin and their resource provider, while workload security is
the domain of a developer. Azure Service Fabric has considerations and
recommendations for both of these roles.
In the design checklist and list of recommendations below, call-outs are made to
indicate whether each choice is applicable to cluster architecture, workload architecture,

or both.
For more information about Azure Service Fabric cluster security, check out Service
Fabric cluster security scenarios.
For more information about Azure Service Fabric workload security, reference Service
Fabric application and service security.

Design checklist
As you make design choices for Azure Service Fabric, review the design principles for
adding security to the architecture.
＂ Cluster architecture: Ensure Network Security Groups (NSG) are configured to
restrict traffic flow between subnets and node types. Ensure that the correct ports
are opened for application deployment and workloads.
＂ Cluster architecture: When using the Service Fabric Secret Store to distribute
secrets, use a separate data encipherment certificate to encrypt the values.
＂ Cluster architecture: Deploy client certificates by adding them to Azure Key Vault
and referencing the URI in your deployment.
＂ Cluster architecture: Enable Azure Active Directory integration for your cluster to
ensure users can access Service Fabric Explorer using their Azure Active Directory
(AAD) credentials. Don't distribute the cluster client certificates among users to
access Explorer.
＂ Cluster architecture: For client authentication, use admin and read-only client
certificates and/or AAD authentication.
＂ Cluster and workload architectures: Create a process for monitoring the expiration
date of client certificates.
＂ Cluster and workload architectures: Maintain separate clusters for development,
staging, and production.

Recommendations
Consider the following recommendations to optimize your Azure Service Fabric
configuration for security:
Azure Service Fabric

Benefit

Recommendation
Cluster architecture: Ensure Network
Security Groups (NSG) are configured

For example, you may have an API Management instance
(one subnet), a frontend subnet (exposing a website

to restrict traffic flow between
subnets and node types.

directly), and a backend subnet (accessible only to
frontend).

Azure Service Fabric

Benefit

Recommendation
Cluster architecture: Deploy Key
Vault certificates to Service Fabric

Centralizing storage of application secrets in Azure Key
Vault allows you to control their distribution. Key Vault

cluster virtual machine scale sets.

greatly reduces the chances that secrets may be
accidentally leaked.

Cluster architecture: Apply an Access
Control List (ACL) to your client

Using an ACL provides an additional level of
authentication.

certificate for your Service Fabric
cluster.
Cluster architecture: Use resource

Enforcing resource limits helps ensure that one service

requests and limits to govern
resource usage across the nodes in
your cluster.

doesn't consume too many resources and starve other
services.

Workload architecture: Encrypt

Encryption on your secret values provides an additional

Service Fabric package secret values.

level of security.

Workload architecture: Include client
certificates in Service Fabric

Having your applications use client certificates for
authentication provides opportunities for security at both

applications.

the cluster and workload level.

Workload architecture: Authenticate
Service Fabric applications to Azure

Using Managed Identity allow you to securely manage
the credentials in your code for authenticating to various

Resources using Managed Identity.

services without saving them locally on a developer
workstation or in source control.

Cluster and workload architectures:
Follow Service Fabric best practices

Following the best practices provides a security standard
to follow.

when hosting untrusted applications.

For more suggestions, see Principles of the security pillar.
Azure Advisor helps you ensure and improve the security of Azure Service Fabric. You
can review the recommendations in the Azure Advisor section of this article.

Policy definitions
Azure Policy helps maintain organizational standards and assess compliance across your
resources. Keep the following built-in policies in mind as you configure Azure Service
Fabric:
Service Fabric clusters should have the ClusterProtectionLevel property set to
EncryptAndSign . This is the default value for managed clusters and isn't

changeable. Standard cluster: Ensure you set ClusterProtectionLevel to
EncryptAndSign .

Service Fabric clusters should only use Azure Active Directory for client
authentication.
All built-in policy definitions related to Azure Service Fabric are listed in Built-in policies
- Service Fabric.

Cost optimization
The following sections cover design considerations and configuration recommendations,
specific to Azure Service Fabric and cost optimization.
When discussing cost optimization with Azure Service Fabric, it's important to
distinguish between cost of cluster resources and cost of workload resources. Cluster
resources are a shared responsibility between the Service Fabric cluster admin and their
resource provider, while workload resources are the domain of a developer. Azure
Service Fabric has considerations and recommendations for both of these roles.
In the design checklist and list of recommendations below, call-outs are made to
indicate whether each choice is applicable to cluster architecture, workload architecture,
or both.
For cluster cost optimization, go to the Azure pricing calculator

and select Azure

Service Fabric from the available products. You can test different configuration and
payment plans in the calculator.
For more information about Azure Service Fabric workload pricing, check out the
example cost calculation process for application planning.

Design checklist
As you make design choices for Azure Service Fabric, review the design principles for
optimizing the cost of your architecture.
＂ Cluster architecture: Select appropriate VM SKU.
＂ Cluster architecture: Use appropriate node type and size.
＂ Cluster and workload architectures: Use appropriate managed disk tier and size.

Recommendations

Explore the following table of recommendations to optimize your Azure Service Fabric
configuration for cost:
Azure Service Fabric Recommendation

Benefit

Cluster architecture: Avoid VM SKUs with temp disk
offerings.

Service Fabric uses managed disks by
default, so avoiding temp disk offerings
ensures you don't pay for unneeded
resources.

Cluster architecture: If you need to select a certain
VM SKU for capacity reasons and it happens to offer
temp disk, consider using temporary disk support for
your stateless workloads.

Make the most of the resources you're
paying for. Using a temporary disk
instead of a managed disk can reduce
costs for stateless workloads.

Cluster and workload architectures: Align SKU

Matching your selection to your

selection and managed disk size with workload
requirements.

workload demands ensures you don't
pay for unneeded resources.

For more suggestions, see Principles of the cost optimization pillar.

Operational excellence
The following sections cover design considerations and configuration recommendations,
specific to Azure Service Fabric and operational excellence.
When discussing security with Azure Service Fabric, it's important to distinguish between
cluster operation and workload operation. Cluster operation is a shared responsibility
between the Service Fabric cluster admin and their resource provider, while workload
operation is the domain of a developer. Azure Service Fabric has considerations and
recommendations for both of these roles.
In the design checklist and list of recommendations below, call-outs are made to
indicate whether each choice is applicable to cluster architecture, workload architecture,
or both.

Design checklist
As you make design choices for Azure Service Fabric, review the design principles for
operational excellence.
＂ Cluster architecture: Prepare a cluster monitoring solution.
＂ Cluster architecture: Review the cluster health policies in the Service Fabric health
model.

＂ Workload architecture: Prepare an application monitoring solution.
＂ Workload architecture: Review the application and service type health policies in
the Service Fabric health model.
＂ Cluster and workload architectures: Prepare an infrastructure monitoring solution.
＂ Cluster and workload architectures: Design your cluster with build and release
pipelines for continuous integration and deployment.

Recommendations
Explore the following table of recommendations to optimize your Azure Service Fabric
configuration for operational excellence:
Azure Service Fabric Recommendation

Benefit

Workload architecture: Use Application Insights
to monitor your workloads.

Application Insights integrates with the Azure
platform, including Service Fabric.

Cluster and workload architectures: Create a
process for monitoring the expiration date of
client certificates.

For example, Key Vault offers a feature that
sends an email when x% of the certificate's
lifespan has elapsed.

Cluster and workload architectures: For preproduction clusters use Azure Chaos Studio to
drill service disruption on a Virtual Machine Scale

Practicing service disruption scenarios will
help you understand what is at-risk in your
infrastructure and how to best mitigate the

Set instance failure.

issues if they arise.

Cluster and workload architectures: Use Azure
Monitor to monitor cluster and container
infrastructure events.

Azure Monitor integrates well with the Azure
platform, including Service Fabric.

Cluster and workload architectures: Use Azure
Pipelines for your continuous integration and
deployment solution.

Azure Pipelines integrates well with the Azure
platform, including Service Fabric.

For more suggestions, see Principles of the operational excellence pillar.

Performance efficiency
The following section covers configuration recommendations, specific to Azure Service
Fabric and performance efficiency.
When discussing security with Azure Service Fabric, it's important to distinguish between
cluster operation and workload operation. Cluster performance is a shared responsibility
between the Service Fabric cluster admin and their resource provider, while workload

performance is the domain of a developer. Azure Service Fabric has considerations and
recommendations for both of these roles.
In the design checklist and list of recommendations below, call-outs are made to
indicate whether each choice is applicable to cluster architecture, workload architecture,
or both.
For more information about how Azure Service Fabric can reduce performance issues for
your workload with Service Fabric performance counters, reference Monitoring and
diagnostic best practices for Azure Service Fabric.

Design checklist
＂ Cluster architecture: Exclude the Service Fabric processes from Windows Defender
to improve performance.
＂ Cluster architecture: Select appropriate VM SKU.
＂ Workload architecture: Decide what programming model you will use for your
services.
＂ Cluster and workload architectures: Use appropriate managed disk tier and size.

Recommendations
Consider the following recommendations to optimize your Azure Service Fabric
configuration for performance efficiency:
Azure Service Fabric
Recommendation

Benefit

Cluster architecture:
Exclude the Service Fabric

By default, Windows Defender antivirus is installed on Windows
Server 2016 and 2019. To reduce any performance impact and

processes from Windows
Defender to improve
performance.

resource consumption overhead incurred by Windows Defender, and
if your security policies allow you to exclude processes and paths for
open-source software, you can exclude.

Cluster architecture:
Consider using
Autoscaling for your
cluster.

Autoscaling gives great elasticity and enables addition or reduction
of nodes on demand on a secondary node type. This automated and
elastic behavior reduces the management overhead and potential
business impact by monitoring and optimizing the amount of nodes
servicing your workload.

Cluster architecture:
Consider using
Accelerated Networking.

Accelerated networking enables a high-performance path that
bypasses the host from the data path, which reduces latency, jitter,
and CPU utilization for the most demanding network workloads.

Azure Service Fabric
Recommendation

Benefit

Cluster architecture:
Considering using
encryption at host instead

This encryption method improves on ADE by supporting all OS types
and images, including custom images, for your VMs by encrypting
data in the Azure Storage service.

of Azure Disk Encryption
(ADE).
Workload architecture:
Review the Service Fabric
programming models to
decide what model would

Service Fabric supports several programming models. Each come
with their own advantages and disadvantages. Knowing about the
available programming models can help you make the best choices
for designing your services.

best suit your services.
Workload architecture:
Leverage loosely-coupled
microservices for your
workloads where
appropriate.

Using microservices allows you to get the most out of Service
Fabric's features.

Workload architecture:

Using event-driven architecture allows you to get the most out of

Leverage event-driven
architecture for your
workloads where
appropriate.

Service Fabric's features.

Workload architecture:
Leverage background
processing for your

Using background processing allows you to get the most out of
Service Fabric's features.

workloads where
appropriate.
Cluster and workload
architectures: Review the
different ways you can
scale your solution in

You can use scaling to enable maximum resource utilization for your
solution.

Service Fabric.

For more suggestions, see Principles of the performance efficiency pillar.

Azure Advisor recommendations
Azure Advisor is a personalized cloud consultant that helps you follow best practices to
optimize your Azure deployments. Here are some recommendations that can help you
improve the reliability, security, cost effectiveness, performance, and operational
excellence when using Azure Service Fabric.

Security
Service Fabric clusters should have the ClusterProtectionLevel property set to
EncryptAndSign . This is the default value for managed clusters and isn't

changeable. Standard cluster: Ensure you set ClusterProtectionLevel to
EncryptAndSign .

Service Fabric clusters should only use Azure Active Directory for client
authentication.

Additional resources
Check out the Azure Service Fabric managed cluster configuration options article for a
list of all the options you have while creating and maintaining your cluster.
Review the Azure application architecture fundamentals for guidance on how to develop
your workloads. While Service Fabric can be used solely as a container hosting platform,
using well-architected workloads leverages Service Fabric's full functionality.

Next steps
Use these recommendations as you create your Service Fabric managed cluster using an
ARM template or through the Azure portal:
Quickstart: Deploy a Service Fabric managed cluster with an Azure Resource
Manager template
Quickstart: Deploy a Service Fabric managed cluster using the Azure portal

Azure App Service and reliability
Article • 11/30/2022

Azure App Service is an HTTP-based service for hosting web applications, REST APIs, and
mobile back ends. This service adds the power of Microsoft Azure to your application,
such as:
Security
Load balancing
Autoscaling
Automated management
To explore how Azure App Service can bolster the resiliency of your application
workload, reference key features in Why use App Service?
The following sections include design considerations, a configuration checklist, and
recommended configuration options specific to Azure App Service.

Design considerations
Microsoft guarantees that Azure App Service will be available 99.95% of the time.
However, no SLA is provided using either the Free or Shared tiers.
For more information, reference the SLA for App Service .

Checklist
Have you configured Azure App Service with resiliency in mind?
＂ Consider disabling ARR Affinity for your App Service.
＂ Use a different store for session state.
＂ Use Web Jobs.
＂ Enable Always On to ensure Web Jobs run reliably.
＂ Access the on-prem database using private connections like Azure VPN or Express
Route.
＂ Set up backup and restore.
＂ Understand IP Address deprecation impact.
＂ Ensure App Service Environments (ASE) are deployed in highly available
configurations across Availability Zones.
＂ Ensure the ASE Network is configured correctly.
＂ Consider configuring Upgrade preference if multiple environments are used.

＂ Plan for scaling out the ASE cluster.
＂ Use Deployment slots for resilient code deployments.
＂ Avoid unnecessary worker restarts.
＂ Use Run From Package to avoid deployment conflicts.
＂ Use Basic or higher plans with two or more worker instances for high availability.
＂ Evaluate the use of TCP and SNAT ports to avoid outbound connection errors.
＂ Enable Health check to identify non-responsive workers.
＂ Enable Autoscale to ensure adequate resources are available to service requests.
＂ Enable Local Cache to reduce dependencies on cluster file servers.
＂ Enable Diagnostic Logging to provide insight into application behavior.
＂ Enable Application Insights Alerts to signal fault conditions.
＂ Review Azure App Service diagnostics to ensure common problems are addressed.
＂ Evaluate per-app scaling for high density hosting on Azure App Service.

Configuration recommendations
Explore the following table of recommendations to optimize your App Service
configuration for service reliability:
ASE

Description

Recommendation
Consider disabling

ARR Affinity (Application Request Routing) sets an affinity cookie, which is

ARR Affinity for

used to redirect users to the same node that handled their previous

your App Service.

requests.

Use a different

Storing session state in memory can result in losing session state when

store for session

there's a problem with the application or App Service. It also limits the

state.

possibility of spreading the load over other instances.

Enable Always On

A web app can time out after 20 minutes of inactivity. Only requests to the

to ensure Web
Jobs run reliably.

actual web app reset the timer. If your app runs continuously or if you
schedule Timer trigger Web Jobs, enable Always On. Only available in the
Basic, Standard, and Premium pricing tiers.

Access the on-

Access the on-premises database through a private connection so that the

prem database

connection is secure and predictable.

using private
connections like
Azure VPN or
Express Route.
Set up backup and

Backup and restore lets you manually create or schedule app backups. You

restore.

can retain backups for an indefinite amount of time.

ASE

Description

Recommendation
Understand IP

Floating addresses aren't guaranteed to remain on the resource. It's essential

Address

to check for deprecated IP addresses.

deprecation
impact.
Deploy in highly
available

Ensures applications can continue to operate even if there's a datacenterlevel failure. This provides excellent redundancy without requiring multiple

configuration

deployments in different Azure regions.

across Availability
Zones.
Configure ASE
Network correctly.

A common ASE pitfall occurs when ASE is deployed into a subnet with an IP
address space that is too small to support future expansion. In such cases,
ASE can be left unable to scale without redeploying the entire environment
into a larger subnet. We highly recommend that adequate IP addresses be
used to support either the maximum number of workers or the largest
number considered workloads will need. A single ASE cluster can scale to
201 instances, which would require a /24 subnet.

Configure

If lower environments are used for staging or testing, consider configuring

Upgrade

these environments to receive updates sooner than the production

preference if

environment. This will help to identify any conflicts or problems with an

multiple
environments are

update, and provides a window to mitigate issues before they reach the
production environment. If multiple load balanced (zonal) production

used.

deployments are used, Upgrade preference can be used to protect the
broader environment against issues from platform upgrades.

Scale out the ASE

Scaling ASE instances vertically or horizontally takes 30 to 60 minutes as

cluster.

new private instances need to be provisioned. We highly recommend
investing in up-front planning for scaling during spikes in load or transient
failure scenarios.

Use Deployment

Deployment slots allow for code to be deployed to instances that are

slots for resilient
code
deployments.

warmed-up before serving production traffic. For more information,
reference Testing in production with Azure App Service.

Avoid unnecessary

Many events can lead App Service workers to restart, such as content

worker restarts.

deployment, App Settings changes, and VNet integration configuration
changes. A best practice is to make changes in a deployment slot other than
the slot currently configured to accept production traffic. After workers are
recycled and warmed up, a swap can be performed without unnecessary
down time.

ASE
Recommendation

Description

Run From Package

Run from Package provides several advantages:

to avoid

- Eliminates file lock conflicts between deployment and runtime.

deployment
conflicts

- Ensures only fully deployed apps are running at any time.
- May reduce cold-start times, particularly for JavaScript functions with large
npm package trees.

Use Basic or
higher plans with

Azure App Service provides many configuration options that aren't enabled
by default.

two or more
worker instances
for high
availability.
Evaluate the use
of TCP and SNAT

TCP connections are used for all outbound connections; but, SNAT ports are
used when making outbound connections to public IP addresses. SNAT port

ports.

exhaustion is a common failure scenario that can be predicted by load
testing while monitoring ports using Azure Diagnostics. For more
information, reference TCP and SNAT ports.

Enable Health
check to identify
non-responsive

Any health check is better than none at all. The logic behind endpoint tests
should assess all critical downstream dependencies to ensure overall health.
As a best practice, we highly recommend tracking application health and

workers.

cache status in real time as this removes unnecessary delays before action
can be taken.

Enable Autoscale
to ensure

The default limit of App Service workers is 30 . If the App Service routinely

adequate
resources are
available to

maximum number of workers to 2x the instance count required to serve

uses 15 or more instances, consider opening a support ticket to increase the
normal peak load.

service requests.
Enable
Local_Cache to

Enabling local cache is always appropriate because it can lead to slower
worker startup times. When coupled with Deployment slots, it can improve

dependencies on
cluster file servers.

resiliency by removing dependencies on file servers and also reduces
storage-related recycle events. Don't use local cache with a single worker
instance or when shared storage is required.

Enable Diagnostic
Logging to

Diagnostic logging provides the ability to ingest rich application and
platform-level logs through Log Analytics, Azure Storage, or a third-party

provide insight
into application
behavior.

tool using Event Hub.

reduce

ASE

Description

Recommendation
Enable
Application

Application performance monitoring with Application Insights provides deep
analyses into application performance. For Windows Plans, a codeless

Insights alerts to
make you aware
of fault conditions.

deployment approach is possible to quickly get a performance analysis
without changing any code.

Review Azure App

It's a good practice to regularly review service-related diagnostics and

Service
diagnostics to
ensure common

recommendations, and take action as appropriate.

problems are
addressed.
Evaluate per-app

Per-app scaling can be enabled at the App Service plan level to allow for

scaling for high
density hosting on
Azure App Service.

scaling an app independently from the App Service plan that hosts it. This
way, an App Service plan can be scaled to 10 instances, but an app can be
set to use only five. Apps are allocated within the available App Service plan
using a best effort approach for even distribution across instances. While an
even distribution isn't guaranteed, the platform will make sure that two
instances of the same app won't be hosted on the same App Service plan
instance.

TCP and SNAT ports
If a load test results in SNAT errors, it's necessary to either scale across more or larger
workers, or implement coding practices to help preserve and reuse SNAT ports, such as
connection pooling and the lazy loading of resources. We don't recommend exceeding
100 simultaneous outbound connections to a public IP address per worker, and to avoid

communicating with downstream services through public IP addresses when a private
address (Private Endpoint) or Service Endpoint through vNet Integration could be used.
TCP port exhaustion happens when the sum of connection from a given worker exceeds
the capacity. The number of available TCP ports depend on the size of the worker.
The following table lists the current limits:
TCP ports

Small (B1, S1, P1, I1)

Medium (B2, S2, P2, I2)

Large (B3, S3, P3, I3)

TCP ports

1920

3968

8064

Applications with many longstanding connections require ports to be left open for long
periods of time, which can lead to TCP Connection exhaustion. TCP Connection limits are
fixed based on instance size, so it's necessary to scale up to a larger worker size to

increase the allotment of TCP connections, or implement code level mitigations to
govern connection usage. Similar to SNAT port exhaustion, you can use Azure
Diagnostics to identify a problem exists with TCP port limits.

Source artifacts
To identify App Service Plans with only one instance, use the following query:
SQL

Resources
| where type == "microsoft.web/serverfarms" and properties.computeMode ==
`Dedicated`
| where sku.capacity == 1

Learn more
The Ultimate Guide to Running Healthy Apps in the Cloud

Next step
Azure App Service and cost optimization

Azure App Service and cost
optimization
Article • 03/06/2023

Azure App Service is an HTTP-based service for hosting web applications, REST APIs, and
mobile back ends. This service adds the power of Microsoft Azure to your application,
such as:
Security
Load balancing
Autoscaling
Automated management
To explore how to optimize costs for Azure App Service in your workload, reference key
features in Why use App Service?
The following sections include a checklist and recommended configuration options
specific to Azure App Service.

Checklist
Have you configured Azure App Service while considering cost optimization?
＂ Ensure the ASE subnet is appropriately sized.
＂ Consider cost savings by using the App Service Premium v3 plan over the Premium
v2 plan.
＂ Always use a scale-out and scale-in rule combination.
＂ Understand the behavior of multiple scaling rules in a profile.
＂ Consider Basic or Free tier for non-production usage.

Configuration recommendations
Explore the following table of recommendations to optimize your App Service
configuration for service cost:
ASE
Recommendation

Description

ASE
Recommendation

Description

Ensure the ASE
subnet is
appropriately

The size of the subnet used to host an ASE directly affects maximum scale.
An ASE with no App Service plans will use 12 to 13 addresses before you
create an app. It's recommended that you deploy ASEs into a /24 subnet.

sized.

The maximum number of nodes in an ASE is 100 . During a scale-up event,
the new machines are provisioned and placed into the subnet before the
applications are migrated to the new machines, and the old machines are
removed. The subnet must allow for at least 200 machines to handle the
maximum deployment size, which requires a /24 subnet. If you plan for
insufficient capacity, scale-out operations will be limited.

Use App Service

The App Service Premium (v3) Plan has a 20% discount versus comparable

Premium v3 plan

Pv2 configurations. Reserved Instance commitment (1Y, 3Y, Dev/Test)

over the Premium
v2 plan

discounts are available for App Services running in the Premium v3 plan.
Consider adding an Azure savings plan for compute and get significant
savings on compute services with a one or three year commitment.

Use a scale-out
and scale-in rule

If you use only one part of the combination, autoscale will only take action in
a single direction (scale out, or in) until it reaches the maximum, or minimum

combination

instance counts defined in the profile. This scaling behavior isn't optimal,
ideally you want your resource to scale up at times of high usage to ensure
availability. Similarly, at times of low usage, you want your resource to scale
down, so you can realize cost savings.

Understand the

There are cases where you may have to set multiple rules in a profile. On

behavior of

scale-out, autoscale runs if any rule is met. On scale-in, autoscale requires

multiple scaling
rules in a profile.

all rules to be met.

Consider Basic or
Free tier for non-

For non-prod App Service plans, consider scaling to Basic or Free Tier and
scale up, as needed, and scale down when not in use – for example, during a

production usage.

Load Test exercise or based on the capabilities provided (such as custom
domain, SSL, and more).

Next step
Azure App Service and operational excellence

Azure App Service and operational
excellence
Article • 11/30/2022

Azure App Service is an HTTP-based service for hosting web applications, REST APIs, and
mobile back ends. This service adds the power of Microsoft Azure to your application,
such as:
Security
Load balancing
Autoscaling
Automated management
To explore how Azure App Service can benefit the operational excellence of your
application workload, reference key features in Why use App Service?
The following sections include design considerations, a configuration checklist, and
recommended configuration options specific to Azure App Service.

Design considerations
Microsoft guarantees that Azure App Service will be available 99.95% of the time.
However, no SLA is provided using either the Free or Shared tiers.
For more information, reference the SLA for App Service .

Checklist
Have you configured Azure App Service while considering operational excellence?
＂ Create a deployment plan because redeploying the app service can reset the scaled
units.
＂ Review the App Service Advisor recommendations.
＂ Ensure you configure the App Service Environments (ASE) Network correctly.
＂ Consider configuring Upgrade Preference if you're using multiple environments.
＂ Plan for scaling out the ASE cluster.
＂ Use Deployment Slots for resilient code deployments.
＂ Avoid unnecessary worker restarts when deploying application code or
configuration.
＂ Use Run From Package to avoid deployment conflicts.

＂ Use Basic or higher plans with two or more worker instances for high availability.
＂ Evaluate the use of TCP and SNAT ports to avoid outbound connection errors.
＂ Enable Health check to identify non-responsive workers.
＂ Enable Autoscale to ensure adequate resources are available to service requests.
＂ Enable Local Cache to reduce dependencies on cluster file servers.
＂ Enable Diagnostic Logging to provide insight into application behavior.
＂ Enable Application Insights Alerts to signal fault conditions.
＂ Review Azure App Service diagnostics to ensure common problems are addressed.
＂ Evaluate per-app scaling for high density hosting on Azure App Service.
ASE

Description

Recommendation
Create a
deployment plan

Automatic scaling rules apply during operation of the environment, but
redeploying the app service may cause the plan to reset to the default

because

number of units. Customers should be aware of this behavior and plan for it

redeploying the
app service can

during deployments. Deploy only during off-peak times or deploy maximum
units with automatic scaling enabled to scale in and out to prevent website

reset the scaled

performance implications.

units.
Review the App

App Service Advisor gives you real-time recommendations in the portal on

Service Advisor

resource exhaustion and conditions related to CPU, memory, and

recommendations.

connections.

Ensure you

One common ASE pitfall occurs when ASE is deployed into a subnet with an

configure the App
Service

IP address space that is too small to support future expansion. In such cases,
ASE can be left unable to scale without redeploying the entire environment

Environments

into a larger subnet. We highly recommended that adequate IP addresses be

(ASE) Network
correctly.

used to support either the maximum number of workers or the largest
number considered workloads will need. A single ASE cluster can scale to
201 instance, which would require a /24 subnet.

Configure
Upgrade

If lower environments are used for staging or testing, consider configuring
these environments to receive updates sooner than the production

preference if

environment. This will help to identify any conflicts or problems with an

you're using
multiple

update, and provides a window to mitigate issues before they reach the
production environment. If multiple load balanced (zonal) production

environments.

deployments are used, Upgrade preference can be used to protect the
broader environment against issues from platform upgrades.

Scale out the ASE

Scaling ASE instances vertically or horizontally takes 30 to 60 minutes as

cluster.

new private instances need to be provisioned. We highly recommend
investing in up-front planning for scaling during spikes in load or transient
failure scenarios.

ASE

Description

Recommendation
Use Deployment

Deployment slots allow for code to be deployed to instances that are

slots for resilient

warmed-up before serving production traffic. For more information,

code
deployments.

reference Testing in production with Azure App Service.

Avoid unnecessary
worker restarts.

Many events can lead App Service workers to restart, such as content
deployment, App Settings changes, and VNet integration configuration
changes. A best practice is to make changes in a deployment slot other than
the slot currently configured to accept production traffic. After workers are
recycled and warmed up, a swap can be performed without unnecessary
down time.

Run From Package

Run from Package provides several advantages:

to avoid

- Eliminates file lock conflicts between deployment and runtime.

deployment

- Ensures only fully deployed apps are running at any time.

conflicts

- May reduce cold-start times, particularly for JavaScript functions with large
npm package trees.

Use Basic or

Azure App Service provides many configuration options that aren't enabled

higher plans with
two or more

by default.

worker instances
for high
availability.
Evaluate the use
of TCP and SNAT

TCP connections are used for all outbound connections, but SNAT ports are
used when making outbound connections to public IP addresses. SNAT port

ports.

exhaustion is a common failure scenario that can be predicted by load
testing while monitoring ports using Azure Diagnostics. For more
information, reference TCP and SNAT ports.

Enable Health
check to identify

Any health check is better than none at all. The logic behind endpoint tests
should assess all critical downstream dependencies to ensure overall health.

non-responsive
workers.

As a best practice, we highly recommend tracking application health and
cache status in real time as this removes unnecessary delays before action
can be taken.

Enable Autoscale

The default limit of App Service workers is 30 . If the App Service routinely

to ensure
adequate
resources are

uses 15 or more instances, consider opening a support ticket to increase the

available to
service requests.

maximum number of workers to 2x the instance count required to serve
normal peak load.

ASE
Recommendation

Description

Enable

Enabling local cache is always appropriate because it can lead to slower

Local_Cache to

worker startup times. When coupled with Deployment slots, it can improve
resiliency by removing dependencies on file servers and also reduces
storage-related recycle events. Don't use local cache with a single worker

reduce
dependencies on
cluster file servers.

instance or when shared storage is required.

Enable Diagnostic

Diagnostic logging provides the ability to ingest rich application and

Logging to
provide insight
into application

platform-level logs through Log Analytics, Azure Storage, or a third-party
tool using Event Hub.

behavior.
Enable
Application

Application performance monitoring with Application Insights provides deep
analyses into application performance. For Windows Plans, a codeless

Insights alerts to
make you aware
of fault conditions.

deployment approach is possible to quickly get a performance analysis
without changing any code.

Review Azure App
Service
diagnostics to

It's a good practice to regularly review service-related diagnostics and
recommendations, and take action as appropriate.

ensure common
problems are
addressed.
Evaluate per-app

Per-app scaling can be enabled at the App Service plan level to allow for

scaling for high
density hosting on
Azure App Service.

scaling an app independently from the App Service plan that hosts it. This
way, an App Service plan can be scaled to 10 instances, but an app can be
set to use only five. Apps are allocated to available App Service plan using a
best effort approach for an even distribution across instances. While an even
distribution isn't guaranteed, the platform will make sure that two instances
of the same app won't be hosted on the same App Service plan instance.

TCP and SNAT ports
If a load test results in SNAT errors, it's necessary to either scale across more or larger
workers, or implement coding practices to help preserve and reuse SNAT ports, such as
connection pooling and the lazy loading of resources. We don't recommend exceeding
100 simultaneous outbound connections to a public IP address per worker, and to avoid

communicating with downstream services through public IP addresses when a private
address (Private Endpoint) or Service Endpoint through vNet Integration could be used.
TCP port exhaustion happens when the sum of connection from a given worker exceeds
the capacity. The number of available TCP ports depend on the size of the worker.

The following table lists the current limits:
TCP ports

Small (B1, S1, P1, I1)

Medium (B2, S2, P2, I2)

Large (B3, S3, P3, I3)

TCP ports

1920

3968

8064

Applications with many longstanding connections require ports to be left open for long
periods of time, which can lead to TCP Connection exhaustion. TCP Connection limits are
fixed based on instance size, so it's necessary to scale up to a larger worker size to
increase the allotment of TCP connections, or implement code level mitigations to
govern connection usage. Similar to SNAT port exhaustion, you can use Azure
Diagnostics to identify if a problem exists with TCP port limits.

Source artifacts
To identify App Service plans with only one instance, use the following query:
SQL

Resources
| where type == "microsoft.web/serverfarms" and properties.computeMode ==
`Dedicated`
| where sku.capacity == 1

Learn more
The Ultimate Guide to Running Healthy Apps in the Cloud

Next step
Azure Batch and reliability

Azure Batch and reliability
Article • 11/30/2022

Azure Batch allows you to run large-scale parallel and high-performance computing
(HPC) batch jobs efficiently in Azure.
Use Azure Batch to:
Create and manage a pool of compute nodes (virtual machines).
Install applications you want to run.
Schedule jobs to run on the compute nodes.
The following sections include a design and configuration checklist, recommended
design, and configuration options specific to Azure Batch.

Design and configuration checklist
Have you designed your workload and configured Azure Batch with resiliency in
mind?
＂ Keep application binaries and reference data up to date in all regions.
＂ Use fewer jobs and more tasks.
＂ Use multiple Batch accounts in various regions to allow your application to continue
running, if an Azure Batch account in one region becomes unavailable.
＂ Build durable tasks.
＂ Pre-create all required services in each region, such as the Batch account and
storage account.
＂ Make sure the appropriate quotas are set on all subscriptions ahead of time, so you
can allocate the required number of cores using the Batch account.

Design and configuration recommendations
Explore the following table of recommendations to optimize your workload design and
Azure Batch configuration for service reliability:
Recommendation

Description

Keep application binaries
and reference data up to

Staying up to date will ensure the region can be brought online
quickly without waiting for file upload and deployment.

date in all regions.

Recommendation

Description

Use fewer jobs and more
tasks.

Using a job to run a single task is inefficient. For example, it's more
efficient to use a single job containing 1000 tasks rather than
creating 100 jobs that contain 10 tasks each. Running 1000 jobs,
each with a single task, would be the least efficient, slowest, and
most expensive approach.

Use multiple Batch
accounts in various

It's crucial to have multiple accounts for a highly available
application.

regions to allow your
application to continue
running, if an Azure Batch
account in one region
becomes unavailable.
Build durable tasks.

Tasks should be designed to withstand failure and accommodate
retry, especially for long running tasks. Ensure tasks generate the
same, single result even if they're run more than once. One way to
achieve the same result is to make your tasks goal seeking. Another
way is to make sure your tasks are idempotent (tasks will have the
same outcome no matter how many times they're run).

Pre-create all required

There's often no charge for creating accounts and charges accrue

services in each region,

only when you use the account, or when you store data.

such as the Batch account
and storage account.

Next step
Azure Batch and operational excellence

Azure Batch and operational excellence
Article • 11/30/2022

Azure Batch allows you to run large-scale parallel and high-performance computing
(HPC) batch jobs efficiently in Azure.
Use Azure Batch to:
Create and manage a pool of compute nodes (virtual machines).
Install applications you want to run.
Schedule jobs to run on the compute nodes.
The following sections include a design and configuration checklist, recommended
design, and configuration options specific to Azure Batch.

Design and configuration checklist
Have you designed your workload and configured Azure Batch with operational
excellence in mind?
＂ Keep application binaries and reference data up to date in all regions.
＂ Use fewer jobs and more tasks.
＂ Pre-create all required services in each region, such as the Batch account and
storage account.
＂ Make sure the appropriate quotas are set on all subscriptions ahead of time, so you
can allocate the required number of cores using the Batch account.

Design and configuration recommendations
Explore the following table of recommendations to optimize your workload design and
Azure Batch configuration for operational excellence:
Recommendation

Description

Keep application

Staying up to date will ensure the region can be brought online quickly

binaries and reference
data up to date in all
regions.

without waiting for file upload and deployment.

Recommendation

Description

Use fewer jobs and
more tasks.

Using a job to run a single task is inefficient. For example, it's more
efficient to use a single job containing 1000 tasks rather than creating
100 jobs that contain 10 tasks each. Running 1000 jobs, each with a

single task, would be the least efficient, slowest, and most expensive
approach.
Pre-create all required
services in each

There's often no charge for creating accounts and charges accrue only
when you use the account, or when you store data.

region, such as the
Batch account and
storage account.

Next step
Azure Batch and performance efficiency

Azure Batch and performance efficiency
Article • 11/30/2022

Azure Batch allows you to run large-scale parallel and high-performance computing
(HPC) batch jobs efficiently in Azure.
Use Azure Batch to:
Create and manage a pool of compute nodes (virtual machines).
Install applications you want to run.
Schedule jobs to run on the compute nodes.
The following sections include a design checklist and recommended design options
specific to Azure Batch.

Design checklist
Have you designed your workload and configured Azure Batch with performance
efficiency in mind?
＂ Use fewer jobs and more tasks.

Design and configuration recommendations
Consider the following recommendation to optimize your workload design and Azure
Batch configuration for performance efficiency:
Recommendation

Description

Use fewer jobs
and more tasks.

Using a job to run a single task is inefficient. For example, it's more efficient
to use a single job containing 1000 tasks rather than creating 100 jobs that
contain 10 tasks each. Running 1000 jobs, each with a single task, would be
the least efficient, slowest, and most expensive approach.

Next step
AKS and reliability

Azure Well-Architected Framework
review - Azure Kubernetes Service (AKS)
Article • 04/17/2023

This article provides architectural best practices for Azure Kubernetes Service (AKS). The
guidance is based on the five pillars of architecture excellence:
Reliability
Security
Cost optimization
Operational excellence
Performance efficiency
We assume that you understand system design principles, have working knowledge of
Azure Kubernetes Service, and are well versed with its features. For more information,
see Azure Kubernetes Service.

Prerequisites
Understanding the Well-Architected Framework pillars can help produce a high-quality,
stable, and efficient cloud architecture. We recommend that you review your workload
by using the Azure Well-Architected Framework Review assessment.
For context, consider reviewing a reference architecture that reflects these
considerations in its design. We recommend that you start with the baseline architecture
for an Azure Kubernetes Service (AKS) cluster and Microservices architecture on Azure
Kubernetes Service. Also review the AKS landing zone accelerator, which provides an
architectural approach and reference implementation to prepare landing zone
subscriptions for a scalable Azure Kubernetes Service (AKS) cluster.

Reliability
In the cloud, we acknowledge that failures happen. Instead of trying to prevent failures
altogether, the goal is to minimize the effects of a single failing component. Use the
following information to minimize failed instances.
When discussing reliability with Azure Kubernetes Service, it's important to distinguish
between cluster reliability and workload reliability. Cluster reliability is a shared
responsibility between the cluster admin and their resource provider, while workload

reliability is the domain of a developer. Azure Kubernetes Service has considerations and
recommendations for both of these roles.
In the design checklist and list of recommendations below, call-outs are made to
indicate whether each choice is applicable to cluster architecture, workload architecture,
or both.

Design checklist
＂ Cluster architecture: For critical workloads, use availability zones for your AKS
clusters.
＂ Cluster architecture: Plan the IP address space to ensure your cluster can reliably
scale, including handling of failover traffic in multi-cluster topologies.
＂ Cluster architecture: Enable Container insights to monitor your cluster and
configure alerts for reliability-impacting events.
＂ Workload architecture: Ensure workloads are built to support horizontal scaling
and report application readiness and health.
＂ Cluster and workload architectures: Ensure your workload is running on user node
pools and chose the right size SKU. At a minimum, include two nodes for user node
pools and three nodes for the system node pool.
＂ Cluster architecture: Use the AKS Uptime SLA to meet availability targets for
production workloads.

AKS configuration recommendations
Explore the following table of recommendations to optimize your AKS configuration for
Reliability.
Recommendation

Benefit

Cluster and workload
architectures: Control

Allows the Kubernetes scheduler to logically isolate workloads by
hardware in the node. Unlike tolerations , pods without a matching

pod scheduling using

node selector can be scheduled on labeled nodes, which allows

node selectors and
affinity.

unused resources on the nodes to consume, but gives priority to
pods that define the matching node selector. Use node affinity for
more flexibility, which allows you to define what happens if the pod
can't be matched with a node.

Cluster architecture:

Azure CNI is required for specific scenarios, for example, Windows-

Ensure proper selection of
network plugin based on

based node pools, specific networking requirements and Kubernetes
Network Policies. Reference Kubenet versus Azure CNI for more

network requirements and

information.

cluster sizing.

Recommendation

Benefit

Cluster and workload

The AKS Uptime SLA guarantees:

architectures: Use the
AKS Uptime SLA for

- 99.95% availability of the Kubernetes API server endpoint for AKS
Clusters that use Azure Availability Zones, or

production grade clusters.

- 99.9% availability for AKS Clusters that don't use Azure Availability
Zones.

Cluster and workload

Container insights help monitor the health and performance of

architectures: Configure

controllers, nodes, and containers that are available in Kubernetes

monitoring of cluster with

through the Metrics API. Integration with Prometheus enables

Container insights.

collection of application and workload metrics.

Cluster architecture: Use

By spreading node pools across multiple zones, nodes in one node

availability zones to
maximize resilience within

pool will continue running even if another zone has gone down. If
colocality requirements exist, either a regular VMSS-based AKS

an Azure region by

deployment into a single zone or proximity placement groups can be

distributing AKS agent
nodes across physically

used to minimize internode latency.

separate data centers.
Cluster architecture:

Internet facing workloads should leverage Azure Front Door or Azure

Adopt a multiregion

Traffic Manager to route traffic globally across AKS clusters.

strategy by deploying AKS
clusters deployed across
different Azure regions to
maximize availability and
provide business
continuity.
Cluster and workload
architectures: Define Pod
resource requests and

Container CPU and memory resource limits are necessary to prevent
resource exhaustion in your Kubernetes cluster.

limits in application
deployment manifests,
and enforce with Azure
Policy.
Cluster and workload
architectures: Keep the

System node pools require a VM SKU of at least 2 vCPUs and 4 GB
memory, but 4 vCPU or more is recommended. Reference System

System node pool
isolated from application
workloads.

and user node pools for detailed requirements.

Cluster and workload

Applications may share the same configuration and need GPU-

architectures: Separate
applications to dedicated

enabled VMs, CPU or memory optimized VMs, or the ability to scaleto-zero. Avoid large number of node pools to reduce extra

node pools based on
specific requirements.

management overhead.

Recommendation

Benefit

Cluster architecture: Use
a NAT gateway for
clusters that run

To avoid reliability issues with Azure Load Balancer limitations with
high concurrent outbound traffic, us a NAT Gateway instead to
support reliable egress traffic at scale.

workloads that make
many concurrent
outbound connections.

For more suggestions, see Principles of the reliability pillar.

Azure Policy
Azure Kubernetes Service offers a wide variety of built-in Azure Policies that apply to
both the Azure resource like typical Azure Policies and, using the Azure Policy add-on
for Kubernetes, also within the cluster. There are a numerous number of policies, and
key policies related to this pillar are summarized here. For a more detailed view, see
built-in policy definitions for Kubernetes.

Cluster and workload architecture
Clusters have readiness or liveness health probes configured for your pod spec.
In addition to the built-in Azure Policy definitions, custom policies can be created for
both the AKS resource and for the Azure Policy add-on for Kubernetes. This allows you
to add additional reliability constraints you'd like to enforce in your cluster and
workload architecture.

Security
Security is one of the most important aspects of any architecture. To explore how AKS
can bolster the security of your application workload, we recommend you review the
Security design principles. If your Azure Kubernetes Service cluster needs to be designed
to run a sensitive workload that meets the regulatory requirements of the Payment Card
Industry Data Security Standard (PCI-DSS 3.2.1), review AKS regulated cluster for PCIDSS 3.2.1.
To learn about DoD Impact Level 5 (IL5) support and requirements with AKS, review
Azure Government IL5 isolation requirements.
When discussing security with Azure Kubernetes Service, it's important to distinguish
between cluster security and workload security. Cluster security is a shared responsibility

