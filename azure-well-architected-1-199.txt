Tell us about your PDF experience.

Microsoft Azure Well-Architected
Framework
Article • 03/28/2023

The Azure Well-Architected Framework is a set of guiding tenets that you can use to
improve the quality of a workload. The framework consists of five pillars of architectural
excellence:
Reliability
Security
Cost optimization
Operational excellence
Performance efficiency
Incorporating these pillars helps produce a high quality, stable, and efficient cloud
architecture:
Pillar

Description

Reliability

The ability of a system to recover from failures and continue to function.

Security

Protecting applications and data from threats.

Cost optimization

Managing costs to maximize the value delivered.

Operational excellence

Operations processes that keep a system running in production.

Performance efficiency

The ability of a system to adapt to changes in load.

To learn about how to architect successful workloads on Azure by using the WellArchitected Framework, watch this video:
https://learn.microsoft.com/shows/azure-enablement/architect-successful-workloadson-azure--introduction-ep-1-well-architected-series/player

Overview
The following diagram is a high-level overview of the Azure Well-Architected
Framework:

In the center is the Well-Architected Framework, which includes the five pillars of
architectural excellence. Surrounding the Well-Architected Framework are six supporting
elements:
Azure Well-Architected Review
Azure Advisor
Documentation
Partners

, Support , and Services Offers

Reference architectures
Design principles

Assess your workload
To assess your workload using the tenets found in the Microsoft Azure Well-Architected
Framework, see the Microsoft Azure Well-Architected Review.


We also recommend that you use Azure Advisor and Advisor Score to identify and
prioritize opportunities to improve the posture of your workloads. Both services are free
to all Azure users and align to the five pillars of the Well-Architected Framework:
Azure Advisor is a personalized cloud consultant that helps you follow best
practices to optimize your Azure deployments. It analyzes your resource
configuration and usage telemetry. It recommends solutions that can help you
improve the reliability, security, cost effectiveness, performance, and operational
excellence of your Azure resources. Learn more about Azure Advisor.
Advisor Score is a core feature of Azure Advisor that aggregates Advisor
recommendations into a simple, actionable score. This score enables you to tell at
a glance if you're taking the necessary steps to build reliable, secure, and costefficient solutions. It helps to prioritize the actions that yield the biggest
improvement to the posture of your workloads. The Advisor Score consists of an
overall score, which can be further broken down into five category scores
corresponding to each of the Well-Architected pillars. Learn more about Advisor
Score.

Reliability
A reliable workload is both resilient and available. Resiliency is the ability of the system
to recover from failures and continue to function. The goal of resiliency is to return the
application to a fully functioning state after a failure occurs. Availability is whether your
users can access your workload when they need to.

For more information about resiliency, watch the following video that shows you how to
start improving the reliability of your Azure workloads:
https://learn.microsoft.com/shows/azure-enablement/start-improving-the-reliability-ofyour-azure-workloads--reliability-ep-1--well-architected-series/player

Reliability guidance
The following resources offer guidance on designing and improving reliable Azure
applications:
Reliability design principles
Design patterns for resiliency
Best practices:
Transient fault handling
Retry guidance for specific services
For an overview of reliability principles, see Reliability design principles.

Security
Think about security throughout the entire lifecycle of an application, from design and
implementation to deployment and operations. The Azure platform provides protections
against various threats, such as network intrusion and DDoS attacks. You still need to
build security into your application and into your DevOps processes.
Learn to ask the right questions about secure application development on Azure by
watching the following video:
https://learn.microsoft.com/shows/azure-enablement/ask-the-right-questions-aboutsecure-application-development-on-azure/player

Security guidance
Consider the following broad security areas:
Identity management
Protect your infrastructure
Application security
Data sovereignty and encryption
Security resources
For more information, see Overview of the security pillar.

Cost optimization
When you design a cloud solution, focus on generating incremental value early. Apply
the principles of Build-Measure-Learn to accelerate your time to market while avoiding
capital-intensive solutions. See What is the build-measure-learn feedback loop.
For more information, see Cost optimization and watch the following video on how to
start optimizing your Azure costs:
https://learn.microsoft.com/shows/azure-enablement/start-optimizing-your-azurecosts--cost-optimization-ep-1--well-architected-series/player

Cost guidance
The following resources offer cost optimization guidance as you develop the WellArchitected Framework for your workload:
Review cost principles
Develop a cost model
Create budgets and alerts
Review the cost optimization checklist
For a high-level overview, see Overview of the cost optimization pillar.

Operational excellence
Operational excellence covers the operations and processes that keep an application
running in production. Deployments must be reliable and predictable. Automate
deployments to reduce the chance of human error. Fast and routine deployment
processes don't slow down the release of new features or bug fixes. Equally important,
you must be able to quickly roll back or roll forward if an update has problems.
For more information, watch the following video about bringing security into your
DevOps practice on Azure:
https://learn.microsoft.com/shows/azure-enablement/devsecops-bringing-security-intoyour-devops-practice-on-azure/player

Operational excellence guidance
The following resources provide guidance on designing and implementing DevOps
practices for your Azure workload:
Operational excellence patterns

Best practices: Monitoring and diagnostics guidance
For a high-level summary, see Overview of the operational excellence pillar.

Performance efficiency
Performance efficiency is the ability of your workload to scale to meet the demands
placed on it by users in an efficient manner. The main ways to achieve performance
efficiency include using scaling appropriately and implementing PaaS offerings that have
scaling built in.
For more information, watch Performance Efficiency: Fast & Furious: Optimizing for
Quick and Reliable VM Deployments.

Performance efficiency guidance
The following resources offer guidance on how to design and improve the performance
efficiency posture of your Azure workload:
Performance efficiency patterns
Best practices:
Autoscaling
Background jobs
Caching
CDN
Data partitioning
For a high-level overview, see Overview of the performance efficiency pillar.

Next steps
Learn more about:
Azure Well-Architected Review
Well-Architected Series
Introduction to the Microsoft Azure Well-Architected Framework
Microsoft Defender for Cloud
Cloud Adoption Framework
Azure Deployment Environments
Microsoft Dev Box

Microsoft Azure Well-Architected
Framework
Article • 03/28/2023

The Azure Well-Architected Framework is a set of guiding tenets that you can use to
improve the quality of a workload. The framework consists of five pillars of architectural
excellence:
Reliability
Security
Cost optimization
Operational excellence
Performance efficiency
Incorporating these pillars helps produce a high quality, stable, and efficient cloud
architecture:
Pillar

Description

Reliability

The ability of a system to recover from failures and continue to function.

Security

Protecting applications and data from threats.

Cost optimization

Managing costs to maximize the value delivered.

Operational excellence

Operations processes that keep a system running in production.

Performance efficiency

The ability of a system to adapt to changes in load.

To learn about how to architect successful workloads on Azure by using the WellArchitected Framework, watch this video:
https://learn.microsoft.com/shows/azure-enablement/architect-successful-workloadson-azure--introduction-ep-1-well-architected-series/player

Overview
The following diagram is a high-level overview of the Azure Well-Architected
Framework:

In the center is the Well-Architected Framework, which includes the five pillars of
architectural excellence. Surrounding the Well-Architected Framework are six supporting
elements:
Azure Well-Architected Review
Azure Advisor
Documentation
Partners

, Support , and Services Offers

Reference architectures
Design principles

Assess your workload
To assess your workload using the tenets found in the Microsoft Azure Well-Architected
Framework, see the Microsoft Azure Well-Architected Review.


We also recommend that you use Azure Advisor and Advisor Score to identify and
prioritize opportunities to improve the posture of your workloads. Both services are free
to all Azure users and align to the five pillars of the Well-Architected Framework:
Azure Advisor is a personalized cloud consultant that helps you follow best
practices to optimize your Azure deployments. It analyzes your resource
configuration and usage telemetry. It recommends solutions that can help you
improve the reliability, security, cost effectiveness, performance, and operational
excellence of your Azure resources. Learn more about Azure Advisor.
Advisor Score is a core feature of Azure Advisor that aggregates Advisor
recommendations into a simple, actionable score. This score enables you to tell at
a glance if you're taking the necessary steps to build reliable, secure, and costefficient solutions. It helps to prioritize the actions that yield the biggest
improvement to the posture of your workloads. The Advisor Score consists of an
overall score, which can be further broken down into five category scores
corresponding to each of the Well-Architected pillars. Learn more about Advisor
Score.

Reliability
A reliable workload is both resilient and available. Resiliency is the ability of the system
to recover from failures and continue to function. The goal of resiliency is to return the
application to a fully functioning state after a failure occurs. Availability is whether your
users can access your workload when they need to.

For more information about resiliency, watch the following video that shows you how to
start improving the reliability of your Azure workloads:
https://learn.microsoft.com/shows/azure-enablement/start-improving-the-reliability-ofyour-azure-workloads--reliability-ep-1--well-architected-series/player

Reliability guidance
The following resources offer guidance on designing and improving reliable Azure
applications:
Reliability design principles
Design patterns for resiliency
Best practices:
Transient fault handling
Retry guidance for specific services
For an overview of reliability principles, see Reliability design principles.

Security
Think about security throughout the entire lifecycle of an application, from design and
implementation to deployment and operations. The Azure platform provides protections
against various threats, such as network intrusion and DDoS attacks. You still need to
build security into your application and into your DevOps processes.
Learn to ask the right questions about secure application development on Azure by
watching the following video:
https://learn.microsoft.com/shows/azure-enablement/ask-the-right-questions-aboutsecure-application-development-on-azure/player

Security guidance
Consider the following broad security areas:
Identity management
Protect your infrastructure
Application security
Data sovereignty and encryption
Security resources
For more information, see Overview of the security pillar.

Cost optimization
When you design a cloud solution, focus on generating incremental value early. Apply
the principles of Build-Measure-Learn to accelerate your time to market while avoiding
capital-intensive solutions. See What is the build-measure-learn feedback loop.
For more information, see Cost optimization and watch the following video on how to
start optimizing your Azure costs:
https://learn.microsoft.com/shows/azure-enablement/start-optimizing-your-azurecosts--cost-optimization-ep-1--well-architected-series/player

Cost guidance
The following resources offer cost optimization guidance as you develop the WellArchitected Framework for your workload:
Review cost principles
Develop a cost model
Create budgets and alerts
Review the cost optimization checklist
For a high-level overview, see Overview of the cost optimization pillar.

Operational excellence
Operational excellence covers the operations and processes that keep an application
running in production. Deployments must be reliable and predictable. Automate
deployments to reduce the chance of human error. Fast and routine deployment
processes don't slow down the release of new features or bug fixes. Equally important,
you must be able to quickly roll back or roll forward if an update has problems.
For more information, watch the following video about bringing security into your
DevOps practice on Azure:
https://learn.microsoft.com/shows/azure-enablement/devsecops-bringing-security-intoyour-devops-practice-on-azure/player

Operational excellence guidance
The following resources provide guidance on designing and implementing DevOps
practices for your Azure workload:
Operational excellence patterns

Best practices: Monitoring and diagnostics guidance
For a high-level summary, see Overview of the operational excellence pillar.

Performance efficiency
Performance efficiency is the ability of your workload to scale to meet the demands
placed on it by users in an efficient manner. The main ways to achieve performance
efficiency include using scaling appropriately and implementing PaaS offerings that have
scaling built in.
For more information, watch Performance Efficiency: Fast & Furious: Optimizing for
Quick and Reliable VM Deployments.

Performance efficiency guidance
The following resources offer guidance on how to design and improve the performance
efficiency posture of your Azure workload:
Performance efficiency patterns
Best practices:
Autoscaling
Background jobs
Caching
CDN
Data partitioning
For a high-level overview, see Overview of the performance efficiency pillar.

Next steps
Learn more about:
Azure Well-Architected Review
Well-Architected Series
Introduction to the Microsoft Azure Well-Architected Framework
Microsoft Defender for Cloud
Cloud Adoption Framework
Azure Deployment Environments
Microsoft Dev Box

Reliability documentation
Apply resiliency principles to your architecture to ensure an application returns to a fully
functioning state after a failure occurs. A reliable workload is both resilient and available.

Key points

ｆ

QUICKSTART

Principles
Design checklist
Testing checklist
Monitoring checklist
Reliability patterns
Take the Azure Well-Architected Review

ｄ

TRAINING

Reliability
Resilience in Azure whitepaper

ｑ

VIDEO

Inside Azure Datacenter Architecture with Mark Russinovich

Region and availability zone fundamentals

ｐ

CONCEPT

Explore business continuity management in Azure
Achieve reliability through regions and availability zones
Understand Azure service offerings across region types
Consider Azure services that support availability zones
Understand region and availability zone terminology

Design for availability and resiliency

ｂ

GET STARTED

Consider target and non-functional requirements
Use availability zones within a region
Respond to failure
Build resiliency with failure mode analysis
Understand the impact of dependencies

ｐ

CONCEPT

Understand design best practices
Ensure connectivity
Use zone-aware services
Design for scalability

ｄ

TRAINING

Design a geographically distributed application

ｑ

VIDEO

Zone to zone disaster recovery with Azure Site Recovery

Test for availability and resiliency

ｅ

OVERVIEW

Resiliency testing
Backup and disaster recovery
Error handling
Chaos engineering

ｐ

CONCEPT

Understand testing best practices

Verify workload performance under failure
Design a backup strategy
Design a disaster recovery strategy

ｑ

VIDEO

Using availability zones for Kubernetes cluster

Monitor reliability

ｅ

OVERVIEW

Diagnose application health
Use health models for reliability

ｐ

CONCEPT

Understand monitoring best practices
Implement health probes and check functions
Check long-running workflows
Maintain application logs

ｑ

VIDEO

SQL high availability by service tier

Reliability tools and services

ｉ

REFERENCE

Azure Advisor
Advisor Score
Azure Kubernetes Service (AKS)
Azure Virtual Machines
Azure SQL Database

Azure API Management
Application Gateway (V2)
Key Vault
Azure Backup
Azure Site Recovery

Reliability APIs

ｉ

REFERENCE

API Management
Recovery Services vault
Backup REST API
Site Recovery REST API

Overview of the reliability pillar
Article • 05/30/2023

Reliability ensures that your application can meet the commitments you make to your
customers. Architecting reliability into your application framework ensures that your
workloads are available and can recover from failures at any scale.
Building for reliability includes:
Ensuring a highly available architecture
Recovering from failures such as data loss, major downtime, or ransomware
incidents
To assess the reliability of your workload using the tenets found in the Microsoft Azure
Well-Architected Framework, take the Microsoft Azure Well-Architected Review.
For more information, explore the following video on diving deeper into Azure workload
reliability:
https://learn.microsoft.com/_themes/docs.theme/master/en-us/_themes/global/videoembed.html?show=azure-enablement&ep=diving-deeper-into-azure-workloadreliability-part-2--reliability-ep-2--well-architected&locale=enus&embedUrl=%2Fazure%2Fwell-architected%2Fresiliency%2Foverview
In traditional application development, there has been a focus on increasing the mean
time between failures (MTBF). Effort was spent trying to prevent the system from failing.
In cloud computing, a different mindset is required because of several factors:
Distributed systems are complex. A failure at one point can potentially cascade
throughout the system.
Costs for cloud environments are kept low through commodity hardware.
Occasional hardware failures must be expected.
Applications often depend on external services. Those services might be
temporarily unavailable or throttle high-volume users.
Today's users expect an application to be available 24/7 without ever going offline.
All of these factors mean that cloud applications must be designed to expect occasional
failures and recover from them. Azure has many resiliency features already built into the
platform, such as these examples:
Azure Storage, Azure SQL Database, and Azure Cosmos DB provide built-in data
replication across availability zones and regions.

Azure managed disks are automatically placed in different storage scale units to
limit the effects of hardware failures.
Virtual machines in an availability set are spread across several fault domains. A
fault domain is a group of virtual machines that share a common power source
and network switch. Spreading virtual machines across fault domains limits the
effect of physical hardware failures, network outages, or power interruptions.
Availability zones are physically separate locations within an Azure region. Each
zone is composed of one or more datacenters equipped with independent power,
cooling, and networking infrastructure. With availability zones, you can design and
operate applications and databases that automatically transition between zones
without interruption. This approach ensures reliability if one zone is affected. For
more information, reference Azure regions and availability zones.
Even with these features, you still need to build resiliency into your application.
Resiliency strategies can be applied at all levels of the architecture. Some mitigations are
more tactical in nature, for example, retrying a remote call after a transient network
failure. Other mitigations are more strategic, such as failing over the entire application
to a secondary region.
Tactical mitigations can make a large difference. While it's rare for an entire region to
experience a disruption, transient problems such as network congestion are more
common. Target these issues first. Having the right monitoring and diagnostics is also
important, both to detect failures when they happen, and to find the root causes.
When designing an application to be resilient, you must understand your availability
requirements. How much downtime is acceptable? The amount of downtime is partly a
function of cost. How much does potential downtime cost your business? How much
should you invest in making the application highly available?

Topics and best practices
The reliability pillar covers the following topics and best practices to help you build a
resilient workload:
Reliability

Description

article
Reliability

These critical principles are used as lenses to assess the reliability of an

design
principles

application deployed on Azure.

Design for
reliability

Consider how systems use availability zones, perform scalability, respond to
failure, and other strategies that optimize reliability in application design.

Reliability

Description

article
Resiliency
checklist for

Every technology has its own particular failure modes, which you must consider
when designing and implementing your application. Use this checklist to review

specific Azure

the resiliency considerations for specific Azure services.

services
Target

Target functional and nonfunctional requirements, such as availability targets and

functional and
nonfunctional

recovery targets, allow you to measure the uptime and downtime of your
workloads. Having clearly defined targets is crucial to have a goal to work and

requirements

measure against.

Resiliency and

Building failure recovery into the system should be part of the architecture and

dependencies

design phases from the beginning to avoid the risk of failure. Dependencies are
required for the application to fully operate.

High

Availability zones can be used to spread a solution across multiple zones within a

availability
using

region, allowing for an application to continue functioning when one zone fails.

availability
zones
Available

Availability of services across Azure regions depends on a region's type. Azure's

services

general policy on deploying services into any given region is primarily driven by
region type, service categories, and customer demand.

Availability
zone

To better understand regions and availability zones in Azure, it helps to
understand key terms or concepts.

terminology
Best practices
for reliability
in

During the architectural phase, focus on implementing practices that meet your
business requirements, identify failure points, and minimize the scope of failures.

applications
Testing for
reliability

Regular testing should be performed as part of each major change to validate
existing thresholds, targets, and assumptions.

Monitoring

Get an overall picture of application health. If something fails, you need to know

for reliability

that it failed, when it failed, and why.

Reliability
patterns

Applications must be designed and implemented to maximize availability.

Next steps
Reliability design principles

Reliability design principles
Article • 11/30/2022

Building a reliable application in the cloud is different from traditional application
development. Historically, you may have purchased levels of redundant higher-end
hardware to minimize the chance of an entire application platform failing.
In the cloud, we acknowledge that failures happen. Instead of trying to prevent failures
altogether, the goal is to minimize the effects of a single failing component.
To assess your workload using the tenets found in the Azure Well-Architected
Framework, reference the Microsoft Azure Well-Architected Review.
The following design principles provide:
Context for questions
Why a certain aspect is important
How an aspect is applicable to Reliability
These critical design principles are used as lenses to assess the Reliability of an
application deployed on Azure. These lenses provide a framework for the application
assessment questions.

Design for business requirements
Reliability is a subjective concept. For an application to be appropriately reliable, it must
reflect the business requirements surrounding it.
For example, a mission-critical application with a 99.999% service level agreement (SLA)
requires a higher level of reliability than another application with an SLA of 95% .
Cost implications are inevitable when introducing greater reliability and high availability.
This trade-off should be carefully considered.

Design for failure
Failure is impossible to avoid in a highly distributed and multi-tenant environment like
Azure.
By anticipating failures, from individual components to entire Azure regions, you can
develop a solution in a resilient way to increase reliability.

Observe application health
Before mitigating issues that impact application reliability, you must first detect these
issues.
By monitoring the operation of an application relative to a healthy state, you can detect
and predict reliability issues.
Monitoring allows you to take swift and remedial action.

Drive automation
One of the leading causes of application downtime is human error due to the
deployment of insufficiently tested software or through misconfiguration.
To minimize the possibility and consequence of human errors, it's vital to strive for
automation in all aspects of a cloud solution.
Automation improves:
Reliability
Automated testing
Deployment
Management

Design for self-healing
Self-healing describes the ability of a system to deal with failures automatically.
Handling failures happens through pre-defined remediation protocols. These protocols
connect to failure modes within the solution.
It's an advanced concept that requires a high level of system maturity with monitoring
and automation.
From inception, self-healing should be an aspiration to maximize reliability.

Design for scale-out
Scale-out is a concept that focuses on the ability of a system to respond to demand
through horizontal growth. As traffic grows, more resource units are added in parallel,
instead of increasing the size of the existing resources.

Through scale units, a system can handle expected and unexpected traffic increases,
essential to overall reliability.
Scale units further reduce the effects of a single resource failure.

Next step
Design

Design for reliability
Article • 05/30/2023

Reliable applications should maintain a predefined percentage of uptime, or availability.
They should also balance between high resiliency, low latency, and cost, which is high
availability. As important, applications should be able to recover from failures, which is
resiliency.

Checklist
How have you designed your applications with reliability in mind?
＂ Define availability and recovery targets to meet business requirements.
＂ Build reliability and availability into your apps by gathering requirements.
＂ Ensure that application and data platforms meet your reliability requirements.
＂ Configure connection paths to promote availability.
＂ Use Azure availability zones where applicable to improve reliability and optimize
costs.
＂ Ensure that your application architecture is resilient to failures.
＂ Know what happens if the requirements of service-level agreements (SLAs) are not
met.
＂ Identify possible failure points in the system to build reliability.
＂ Ensure that applications can operate in the absence of their dependencies.

Azure services
Azure Front Door
Azure Traffic Manager
Azure Load Balancer
Azure NAT Gateway
Azure Service Fabric
Azure Kubernetes Service (AKS)
Azure Site Recovery

Reference architecture
Deploy highly available network virtual appliances
Failure mode analysis for Azure applications
Minimize coordination

Related Links
Use platform as a service (PaaS) options
Design to scale out
Workload availability targets
Building solutions for high availability using availability zones
Make all things redundant

Next steps
Target functional and nonfunctional requirements

Target functional and nonfunctional
requirements
Article • 08/08/2023

Target functional and nonfunctional requirements include availability targets and
recovery targets. These requirements allow you to measure the uptime and downtime of
your workloads. Having clearly defined targets is crucial so that you have a goal to work
and measure against. There are many other requirements that you should consider that
improve reliability requirements and meet business expectations.
Resiliency means the ability to recover from failures. Availability means to run in a
healthy state without significant downtime. Building resiliency and availability into your
apps begins with gathering requirements. For example, how much downtime is
acceptable and how much does potential downtime cost your business?

Key points
Determine the acceptable level of uptime for your workloads.
Determine how long workloads can be unavailable and how much data is
acceptable to lose during a disaster.
Consider application and data platform requirements to improve resiliency and
availability.
Ensure connection availability and improve reliability with Azure services.
Assess overall application health of workloads.

Availability targets
A service-level agreement (SLA) is an availability target that represents a commitment
around performance and availability of the application. Understanding the SLA of
individual components within the system is essential to define reliability targets.
Knowing the SLA of dependencies also provides a justification for extra spending when
making the dependencies highly available and with proper support contracts.
Availability targets for any dependencies used by the application should be understood
and ideally align with application targets should also be considered.
Understanding your availability expectations is vital to reviewing overall operations for
the application. If you want to achieve an application service-level objective (SLO) of
99.999%, the level of inherent operational action required by the application is going to
be far greater than if an SLO of 99.9% is the goal.

Monitoring and measuring application availability is vital to qualifying overall
application health and progress towards defined targets. Make sure you measure and
monitor key targets such as:
Mean Time Between Failures (MTBF). The average time between failures of a
particular component.
Mean Time To Recover (MTTR). The average time it takes to restore a component
after a failure.

Considerations for availability targets
Keep the following questions in mind.

Are SLAs/SLOs/SLIs for all applied dependencies understood?
Availability targets for any dependencies used by the application should be understood
and ideally align with application targets. Make sure SLAs/SLOs/service level indicators
(SLIs) for all applied dependencies are understood.

Has a composite SLA been calculated for the application and key
scenarios using Azure SLAs?
A composite SLA captures the end-to-end SLA across all application components and
dependencies. It's calculated using the individual SLAs of Azure services hosting
application components. A composite SLA provides an important indicator of designed
availability in relation to customer expectations and targets. Make sure that the
composite SLA of all components and dependencies on the critical paths are
understood. For more information, see Composite SLAs.
７ Note
If you have contractual commitments to an SLA for your Azure solution, allowances
on top of the Azure composite SLA must be made to accommodate outages
caused by code-level issues and deployments. This fact is often overlooked. You
might directly put the composite SLA forward to your customers.

Are availability targets considered while the system runs in disaster
recovery mode?

Availability targets might or might not be applied when the system runs in disaster
recovery mode. It depends on the application. If targets must also apply in a failure
state, an N+1 model should be used to achieve greater availability and resiliency. In this
scenario, N is the capacity needed to deliver required availability. There's also a cost
implication. More resilient infrastructure is usually more expensive.

What are the consequences if availability targets aren't satisfied?
Are there any penalties, such as financial charges, associated with failing to meet SLA
commitments? Other measures can be used to prevent penalties, but that also brings
extra cost to operate the infrastructure. This fact has to be factored in and evaluated.
The consequences if availability targets aren't satisfied should be fully understood. This
approach also informs when to initiate a failover case.

Recovery targets
Recovery targets identify how long the workload can be unavailable and how much data
is acceptable to lose during a disaster. Define target reports for the application and key
scenarios. Target reports needed are:
Recovery Time Objective (RTO). The maximum acceptable time an application is
unavailable after an incident.
Recovery Point Objective (RPO). The maximum duration of data loss that is
acceptable during a disaster.
Recovery targets are nonfunctional requirements of a system and should be dictated by
business requirements. Recovery targets should be defined in accordance to the
required RTO and RPO targets for the workloads.

Meet application platform requirements
Azure application platform services offer resiliency features to support application
reliability. They might only apply for a certain SKU and configuration or deployment. For
example, they might apply if an SLA is dependent on the number of instances deployed
or a certain feature enabled.
We recommend that you review the SLA for services used. For example, the Service Bus
Premium SKU provides predictable latency and throughput to mitigate noisy neighbor
scenarios. It also lets you automatically scale and replicate metadata to another Service
Bus instance for failover purposes.

For more information, see Service Bus Premium and Standard messaging tiers.

Use availability zones
Many Azure regions provide availability zones, which are separated groups of data
centers. Within a region, each availability zone is close enough together to have very
low-latency connections to other availability zones, but they're far enough apart to
ensure that they have independent power, cooling, and networking infrastructure.
Availability zones are designed so that if one zone has an outage, then regional services,
capacity, and high availability are supported by the remaining zones.
If you deploy into an Azure region that contains availability zones, then you can use
multiple availability zones together. By using multiple availability zones, you can keep
separate copies of your application and data within separate physical data centers in a
wide metropolitan area.
There are two ways to use availability zones within a solution:
Zonal resources are pinned to a specific availability zone. You can combine
multiple zonal deployments across different zones to achieve high reliability
requirements. You're responsible for managing data replication and distributing
requests across zones. If an outage occurs in a single availability zone, you're
responsible for failover to another availability zone.
Zone-redundant resources are spread across multiple availability zones. Microsoft
manages spreading requests across zones, and the replication of data across
zones, for you. If an outage occurs in a single availability zone, Microsoft manages
failover automatically.
Different Azure services support one or both of these approaches. In general, PaaS
services typically support zone-redundant deployments, and IaaS services typically
support zonal deployments. For more information about how Azure services work with
availability zones, see Azure services with availability zone support.
There are performance and cost considerations where applications are extremely chatty
across zones given the physical separation and inter-zone bandwidth charges.
For more information about designing for availability zones and other ways to achieve
resiliency in Azure, see Building solutions for high availability using availability zones
and Business continuity with data resiliency .

Use multiple Azure regions

The ability to respond to disaster scenarios for overall compute platform availability and
application reliability depends on the use of multiple availability zones or regions. If you
have a mission-critical solution, you might consider deploying it across multiple Azure
regions. However, if you don't explicitly need a multi-region design, then it's cheaper
and less complex to use availability zones instead.
 Tip
For most workloads, an architecture based around availability zones provide the
best balance of tradeoffs between resiliency, performance, cost, and complexity.
Consider a multi-region deployments if one of these situations applies to your
workload:
The SLAs given by a single-region multi-zone configuration are insufficient.
Your users are geographically spread out and it makes sense to have instances
of your workload near your user bases. For example, you might follow the
Deployment Stamps pattern or the Geode pattern.
Many regions also have a paired region. Paired regions support certain types of multiregion deployment approaches, such as native replication features like geo-redundant
storage (GRS) asynchronous replication. Some newer regions have multiple availability
zones and don't have a paired region. You can still deploy multi-region solutions into
these regions, but the approaches you use might be different.
If you plan maintenance, updates to a region are performed sequentially. For more
information, see Cross-region replication in Azure.

Considerations for availability
There are several considerations for availability.

Is the application hosted across two or more application platform
nodes?
To ensure application platform reliability, it's vital that the application is hosted across at
least two nodes. This approach ensures that there are no single points of failure. Ideally
an N+1 model should be applied for compute availability where N is the number of
instances required to support application availability and performance requirements.

７ Note
Higher SLAs provided for virtual machines and associated related platform services
require at least two replica nodes deployed to either an availability set or across
two or more availability zones. For more information, see SLA for Virtual
Machines

.

How is the client traffic routed to the application for region,
availability zone, or network outage?
If there's a major outage, client traffic should be routable to application deployments
that remain available across other regions or availability zones. This situation is
ultimately where cross-premises connectivity and global load balancing should be used,
depending on whether the application is internal or external facing. Services such as
Azure Front Door, Azure Traffic Manager, or third-party content delivery networks can
route traffic across regions based on application health discovered by using health
probes. For more information, see Traffic Manager endpoint monitoring.

Meet data platform requirements
Data and storage services should be running in a highly available configuration or SKU.
Azure data platform services offer reliability features to support application reliability.
They might only be applicable at a certain SKU. Examples are Azure SQL Database
Business Critical SKUs and Azure Storage Zone Redundant Storage (ZRS) with three
synchronous replicas spread across availability zones.

Data consistency
Data types should be categorized by data consistency requirements. Data consistency
requirements, such as strong or eventual consistency, should be understood for all data
types and used to inform data grouping and categorization. Consistency requirements
should inform what data replication and synchronization strategies can be considered to
meet application reliability targets.
CAP theorem proves that it's impossible for a distributed data store to simultaneously
provide more than two guarantees across the following measures:
Consistency. Every read receives the most recent write or an error.
Availability. Every request receives a nonerror response, without the guarantee that
it contains the most recent write.

Partition tolerance. A system continues to operate despite an arbitrary number of
transactions being dropped or delayed by the network between nodes.
Determining which of these guarantees are most important in the context of application
requirements is critical.

Replication and redundancy
Replicating data across availability zones or regions supports application availability
objectives to limit the effect of failure scenarios. The ability to restore data from a
backup is essential when recovering from data corruption situations and failure
scenarios. To ensure sufficient redundancy and availability during availability zone and
regional failure scenarios, backups should be stored across availability zones or regions.
Define and test a data restore process to ensure a consistent application state. Regular
testing of the data restore process promotes operational excellence and confidence in
the ability to recover data in alignment with defined recovery objectives for the
application.
Consider how your application traffic is routed to data sources when there's a region,
availability zone, or network outage. Understanding the method used to route
application traffic to data sources if there's a major failure event is critical to identify
whether failover processes meet recovery objectives. Many Azure data platform services
offer native reliability capabilities to handle major failures, such as Azure Cosmos DB
Automatic Failover and Azure SQL Database active geo-replication.
７ Note
Some capabilities, such as Azure Storage read-access geo-redundant storage and
Azure SQL DB active geo-replication, require application-side failover to alternate
endpoints in some failure scenarios. Application logic should be developed to
handle these scenarios.

Networking and connectivity requirements
Consider these guidelines to ensure connection availability and improve reliability with
Azure services.

Connectivity
Use a global load balancer to distribute traffic and failover across regions.

Azure Front Door, Azure Traffic Manager, or third-party content delivery network
services can be used to direct inbound requests to external-facing application
endpoints deployed across multiple regions. Traffic Manager is a DNS-based load
balancer, so failover must wait for DNS propagation to occur. A sufficiently low
time-to-live (TTL) value should be used for DNS records, though not all ISPs honor
this setting. For application scenarios that require transparent failover, Azure Front
Door should be used. For more information, see Disaster Recovery using Azure
Traffic Manager and Routing architecture overview.
For cross-premises connectivity, by using Azure ExpressRoute or VPN, ensure that
there are redundant connections from different locations.
At least two redundant connections should be established across two or more
Azure regions and peering locations to ensure there are no single points of failure.
An active/active load-shared configuration provides path diversity and promotes
availability of network connection paths. For more information, see Cross-network
connectivity.
Simulate a failure path to ensure that connectivity is available over alternative
paths.
The failure of a connection path onto other connection paths should be tested to
validate connectivity and operational effectiveness. Using site-to-site VPN
connectivity as a backup path for ExpressRoute provides an extra layer of network
resiliency for cross-premises connectivity. For more information, see Using site-tosite VPN as a backup for ExpressRoute private peering.
Eliminate all single points of failure from the data path, both on-premises and
hosted on Azure.
Single-instance Network Virtual Appliances (NVAs) introduce significant
connectivity risk, whether deployed in Azure or within an on-premises datacenter.
For more information, see Deploy highly available network virtual appliances.

Zone-aware services
Use ExpressRoute or VPN zone-redundant virtual network gateways.
Zone-redundant virtual network gateways distribute gateway instances across
availability zones to improve reliability and ensure availability during failure
scenarios that affect a datacenter in a region. For more information, see About
zone-redundant virtual network gateway in Azure availability zones.

If used, deploy Azure Application Gateway v2 in a zone-redundant configuration.
Azure Application Gateway v2 can be deployed in a zone-redundant configuration
to deploy gateway instances across zones for improved reliability and availability
during failure scenarios that affect a datacenter in a region. For more information,
see Scaling Application Gateway v2 and WAF v2.
Use Azure Load Balancer Standard to load-balance traffic across availability zones.
Azure Load Balancer Standard is zone-aware to distribute traffic across availability
zones. It can also be configured in a zone-redundant configuration to improve
reliability and ensure availability during failure scenarios that affect a datacenter
within a region. For more information, see Load Balancer and availability zones.
Configure health probes for Azure Load Balancer and Azure Application Gateways.
Health probes allow Azure Load Balancer to assess the health of backend
endpoints to prevent traffic from being sent to unhealthy instances. For more
information, see Azure Load Balancer health probes.
Assess critical application dependencies with health probes.
Custom health probes should be used to assess overall application health
including downstream components and dependent services, such as APIs and
datastores. In this approach, traffic isn't sent to backend instances that can't
successfully process requests due to dependency failures. For more information,
see Health Endpoint Monitoring pattern.

Related links
To understand business metrics to design resilient Azure applications, see Using
business metrics to design resilient Azure applications.
For information on availability zones, see Build solutions for high availability using
availability zones.
For information on health probes, see Azure Load Balancer health probes and
Health Endpoint Monitoring pattern.
To learn about connectivity risk, see Deploy highly available network virtual
appliances.

Next steps
Design reliable Azure applications

Go back to the main article: Design for reliability

Design reliable Azure applications
Article • 08/08/2023

Building a reliable application in the cloud differs from traditional application
development. In the past, you might have purchased redundant higher-end hardware to
minimize the chance of platform failure. However, for applications that run in the cloud,
it's important to acknowledge up front that failures happen. Instead of trying to prevent
failures altogether, the goal is to minimize the effects of a single failing component. The
kinds of failures that you can expect in the cloud are inherent to all highly distributed
systems.

Key points
Use availability zones, where applicable, to improve reliability and optimize costs.
Design applications to operate when impacted by failures.
Use the native resiliency capabilities of platform as a service (PaaS) to support
overall application reliability.
Design to scale out and also scale in.
Validate that required capacity is within Azure service scale limits and quotas.

Use availability zones within a region
Design your application architecture to use availability zones within a region. Availability
zones can be used to optimize application availability within a region by providing
datacenter-level fault tolerance. However, the application architecture must not share
dependencies between zones to use them effectively.
Many Azure services provide a zone-redundant configuration. Zone redundancy
distributes multiple replicas of the service across availability zones. Your workload can
take advantage of these benefits offered by Azure as part of the feature:
Multiple instances of the service are spread across availability zones.
Incoming requests are automatically distributed across the instances.
Changes in your data and configuration are automatically replicated across
instances in each zone.
If a datacenter or availability zone outage occurs, during the failover, traffic is
automatically sent to instances in the surviving availability zones.
Consider if component proximity is required for application performance reasons. If the
application is highly "chatty", it might be sensitive to extra latency. When traffic goes

between availability zones that are geographically separated, extra latency is introduced.
While the amount of latency is very small, chatty applications might make many
requests, so the total latency is much higher. In this scenario, consider whether you
should co-locate your resources. Some Azure services enable zonal deployments, which
are sometimes called zone-pinned deployments. When you use a zonal deployment
approach, the resource is deployed to a specific zone. Multiple components can be
deployed to the same zone to reduce the communication latency.
You should also consider whether the use of multiple availability zones could increase
your costs. For example, inter-zone bandwidth charges might be incurred when your
resources synchronize data.
If you have business requirements that require mitigating the risk of an outage of an
entire region, consider deploying to multiple regions. Multiple regions can be used for
failover purposes in a disaster state. A multi-region solution is often more complicated
to deploy and operate. Other cost needs should be considered, including the extra data
and networking charges, and for services such as Azure Site Recovery.

Respond to failure
The possibility of failure is unavoidable in public cloud environments. As a result,
applications require resilience to respond to outages and deliver reliability. The
application should therefore be designed to operate even when impacted by regional,
zonal, service, or component failures across critical application scenarios and
functionality. Application operations might experience reduced functionality or
degraded performance during an outage.
Define an availability strategy to capture how the application remains available during a
failure state. The strategy should apply across all application components and the
application deployment stamp as a whole, such as via multi-geo scale-unit deployment
approach. There are cost implications as well. More resources need to be provisioned in
advance to provide high availability. Active-active setup, while more expensive than
single deployment, can balance cost by lowering load on one stamp and reducing the
total amount of resources needed.
In addition to an availability strategy, define a Business Continuity Disaster Recovery
(BCDR) strategy for the application and/or its key scenarios. A BCDR strategy should
capture how the application responds to a disaster situation, such as a regional outage
or the loss of a critical platform service, using either a redeployment, warm-spare activepassive, or hot-spare active-active approach.

To reduce costs, consider splitting application components and data into groups. For
example:
Must protect
Nice to protect
Ephemeral, can be rebuilt or lost instead of protected by the same policy

Considerations to improve reliability
Is the application designed to use managed services?
Azure-managed services provide native resiliency capabilities to support overall
application reliability. PaaS offerings should be used to leverage these capabilities. PaaS
options are easier to configure and administer. You don't need to provision VMs, set up
VNets, manage patches and updates, or do all of the other overhead associated with
running software on a VM. To learn more, see Use managed services.

Has the application been designed to scale out?
Azure provides elastic scalability and you should design to scale out. However,
applications must leverage a scale-unit approach to navigate service and subscription
limits to ensure that individual components and the application as a whole can scale
horizontally. Don't forget about scale in, which is important to reduce cost. For example,
scale in and out for App Service is done via rules. Often customers write scale out rules
and never write scale in rules, which leaves the App Service more expensive.

Is the application deployed across multiple Azure
subscriptions?
Understand the subscription landscape of the application and how components are
organized within or across subscriptions when you analyze if relevant subscription limits
or quotas can be navigated. Review Azure subscription and service limits to validate that
required capacity is within Azure service scale limits and quotas. To learn more, see
Azure subscription and service limits.

Related links
To learn how to minimize dependencies, see Minimize coordination.

For more information on fault-points and fault-modes, see Failure mode analysis
for Azure applications.
For information on managed services, see Use platform as a service (PaaS) options.
Go back to the main article: Design for reliability

Next steps
Resiliency and dependencies

Resiliency and dependencies
Article • 05/30/2023

To avoid the risk of failure, building failure recovery into the system should be part of
the architecture and design phases from the beginning. Dependencies are required for
the application to fully operate.

Key points
Identify possible failure points in the system with failure mode analysis.
Eliminate all single points of failure.
Maintain a complete list of application dependencies.
Ensure that applications can operate in the absence of their dependencies.
Understand the service-level agreements (SLAs) of individual components in the
system to define reliability targets.

Build resiliency with failure mode analysis
Failure mode analysis (FMA) is a process for building resiliency into a system by
identifying possible failure points in the system. FMA should be part of the architecture
and design phases. Build failure recovery into the system from the beginning.
Fault points describe the elements in an application architecture that are capable of
failing. Fault modes capture the various ways by which a fault point might fail. Identify all
fault points and fault modes. To ensure that an application is resilient to end-to-end
failures, it's essential that all fault points and fault modes are understood and
operationalized. For more information, see Failure mode analysis for Azure applications.
Eliminate all single points of failure. A single point of failure describes a specific fault
point that, if it were to fail, would bring down the entire application. Single points of
failure introduce significant risk since any failure of such a component causes an
application outage. For more information, see Make all things redundant.
７ Note
Eliminate all singletons. A singleton describes a logical component in an application
for which there can only be a single instance. This definition can apply to stateful
architectural components or application code constructs.

Singletons introduce a significant risk by creating single points of failure in the
application design.

Understand the impact of dependencies
Internal dependencies describe components in the application scope that are required
for the application to fully operate. External dependencies capture required components
outside the scope of the application, such as another application or third-party service.
Dependencies might be categorized as either strong or weak based on whether the
application is able to continue operating in a degraded fashion in their absence. For
more information, see Twelve-Factor App: Dependencies .
You should maintain a complete list of application dependencies. Examples of typical
dependencies include platform dependencies outside the scope of the application, such
as Azure Active Directory, Azure ExpressRoute, or a central Network Virtual Appliance
(NVA), and application dependencies such as APIs. For cost purposes, it's important to
understand the price for these services and how the services are being charged. For
more information, see Develop a cost model.
You can map application dependencies either as a simple list or a document. Usually this
decision is part of a design document or reference architecture.
Understand the effect of an outage with each dependency.
Strong dependencies play a critical role in application function and availability.
Their absence has a significant effect. The absence of weak dependencies might
only affect specific features and not affect overall availability. This distinction
reflects the cost that is needed to maintain the high availability relationship
between the service and its dependencies. Classifying dependencies as either
strong or weak helps you identify which components are essential to the
application.
Maintain SLAs and support agreements for critical dependencies.
A service-level agreement (SLA) represents a commitment around performance
and availability of the application. Understanding the SLA of individual
components in the system is essential to define reliability targets. Knowing the SLA
of dependencies also provides a justification for more spending when making the
dependencies highly available and with proper support contracts. The operational
commitments of all external and internal dependencies should be understood to
inform the broader application operations and health model.

The usage of platform level dependencies, such as Azure Active Directory, must
also be understood to ensure that the availability and recovery targets align with
the targets of the application.
Ensure that applications can operate in the absence of their dependencies.
If the application has strong dependencies that it can't operate without, the
availability and recovery targets of these dependencies should align with the
targets of the application itself. Make an effort to minimize dependencies to
achieve control over application reliability. For more information, see Minimize
coordination.
Ensure that the lifecycle of the application is decoupled from its dependencies.
If the application lifecycle is closely coupled with the lifecycle of its dependencies,
it can limit the operational agility of the application. This fact is true particularly for
new releases.

Related links
For information on fault points and fault modes, see Failure mode analysis for
Azure applications.
For information on single points of failure, see Make all things redundant.
For information on minimizing dependencies, see Minimize coordination.

Next steps
Best practices for designing reliability
Go back to the main article: Design for reliability

Data management for reliability
Article • 08/08/2023

This article describes database resiliency and database recovery by using geo-restore
and active geo-replication. Use the samples described here to understand storage
resiliency.

Database resiliency
Azure services offer resiliency, including Azure SQL Database, SQL Server on virtual
machines, and Azure Cosmos DB.

Azure SQL Database
SQL Database automatically performs a combination of full database backups weekly,
differential database backups hourly, and transaction log backups every five to ten
minutes. These backups help protect your business from data loss. Use point-in-time
restore to restore a database to an earlier time. For more information, see:
Restore a database from a backup in Azure SQL Database
Overview of business continuity with Azure SQL Database

SQL Server on virtual machines
For SQL Server running on virtual machines, there are two options: traditional backups
and log shipping. Traditional backups enable you to restore to a specific point in time,
but the recovery process is slow. Restoring traditional backups requires starting with an
initial full backup, and then applying any backups taken after that backup.
The second option is to configure a log shipping session to delay the restore of log
backups, for example, by two hours. This approach provides a window to recover from
errors made on the primary.

Azure Cosmos DB
Azure Cosmos DB automatically makes backups at regular intervals. Backups are stored
separately in another storage service. Those backups are globally replicated for
resiliency against regional disasters. If you accidentally delete your database or
collection, you can file a support ticket or call Azure support to restore the data from the

last automatic backup. For more information, see Online backup and on-demand data
restore in Azure Cosmos DB.

Azure Database for MySQL, Azure Database for
PostgreSQL
When you use Azure Database for MySQL or Azure Database for PostgreSQL, the
database service automatically makes a backup of the service every five minutes. Using
this automatic backup feature, you can restore the server and all its databases into a
new server to an earlier point-in-time. For more information, see:
How to back up and restore a server in Azure Database for MySQL using the Azure
portal
How to backup and restore a server in Azure Database for PostgreSQL using the
Azure portal

Distribute data geographically
Azure services support geographically distributed data, such as Azure SQL Database and
SQL Server on virtual machines.
７ Note
For many situations, you should consider using availability zones to replicate your
data between multiple physical locations. Many of Azure's storage and data
services support zone-redundant deployments. In a zone-redundant deployment,
Microsoft manages synchronous data replication across availability zones,
automatically distributes traffic between the availability zones, and handles failover
if an availability zone has an outage.

SQL Database
Azure SQL Database provides two types of recovery: geo-restore and active georeplication.

Geo-restore
Geo-restore provides the default recovery option when the database is unavailable
because of an incident in the region where your database is hosted. It's also available

with Basic, Standard, and Premium databases.
Similar to point-in-time restore, geo-restore relies on database backups in georedundant Azure storage. It restores from the geo-replicated backup copy, and
therefore is resilient to the storage outages in the primary region. For more information,
see Azure SQL Database disaster recovery guidance.

Active geo-replication
Active geo-replication is available for all database tiers. It's designed for applications
that have more aggressive recovery requirements than geo-restore can offer. Using
active geo-replication, you can create up to four readable secondaries on servers in
different regions. You can initiate failover to any of the secondaries.
Active geo-replication can be used to support the application upgrade or relocation
scenarios and load balancing for read-only workloads. For more information, see
Configure active geo-replication and failover.
For information on how to design and implement applications and applications upgrade
without downtime, see Designing globally available services using Azure SQL Database
and Managing rolling upgrades of cloud applications by using SQL Database active georeplication.

SQL Server on Azure Virtual Machines
Various options are available for recovery and high availability for SQL Server 2012 and
later that run in Azure Virtual Machines. For more information, see Business continuity
and HADR for SQL Server on Azure Virtual Machines.

SQL Server Always On availability groups across regions
You can use SQL Always On availability groups for high availability by creating a single
availability group that includes the SQL Server instances in both regions.
As an example, the Multi-region N-tier application reference architecture shows
practices for running an N-tier application in multiple Azure regions to achieve
availability and a robust disaster recovery infrastructure. It uses a SQL Server Always On
availability group and Azure Traffic Manager.

Storage resiliency

Azure Storage provides data resiliency through automated replicas. However, this ability
doesn't prevent application code or users from corrupting data, whether accidentally or
maliciously. Maintaining data fidelity in the face of application or user error requires
more advanced techniques, such as copying the data to a secondary storage location
with an audit log.
Block blobs. Create a point-in-time snapshot of each block blob. For more
information, see Create a snapshot of a blob.
For each snapshot, you're only charged for the storage required to store the
differences within the blob since the last snapshot state. The snapshots are
dependent on the existence of the original blob that they're based on. We
recommend a copy operation to another blob or even another storage account.
This approach ensures that backup data is properly protected against accidental
deletion.
You can use AzCopy or Azure PowerShell to copy the blobs to another storage
account.
Files. Use share snapshots, or use AzCopy or PowerShell, to copy your files to
another storage account.
Tables. Use AzCopy to export the table data into another storage account in
another region.
For samples related to storage resiliency, see Storage resiliency code samples

.

The scripts demonstrate these tasks:
Deploy storage accounts, blob containers, and a file share with an Azure Resource
Manager template.
Copy a local file into a blob container.
Create a blob snapshot.
Copy a local file into a file share.
Create a share snapshot.
Use AzCopy to copy a blob container from one storage account to another.

Design reliable Azure applications
Article • 08/08/2023

Building a reliable application in the cloud differs from traditional application
development. In the past, you might have purchased redundant higher-end hardware to
minimize the chance of platform failure. However, for applications that run in the cloud,
it's important to acknowledge up front that failures happen. Instead of trying to prevent
failures altogether, the goal is to minimize the effects of a single failing component. The
kinds of failures that you can expect in the cloud are inherent to all highly distributed
systems.

Key points
Use availability zones, where applicable, to improve reliability and optimize costs.
Design applications to operate when impacted by failures.
Use the native resiliency capabilities of platform as a service (PaaS) to support
overall application reliability.
Design to scale out and also scale in.
Validate that required capacity is within Azure service scale limits and quotas.

Use availability zones within a region
Design your application architecture to use availability zones within a region. Availability
zones can be used to optimize application availability within a region by providing
datacenter-level fault tolerance. However, the application architecture must not share
dependencies between zones to use them effectively.
Many Azure services provide a zone-redundant configuration. Zone redundancy
distributes multiple replicas of the service across availability zones. Your workload can
take advantage of these benefits offered by Azure as part of the feature:
Multiple instances of the service are spread across availability zones.
Incoming requests are automatically distributed across the instances.
Changes in your data and configuration are automatically replicated across
instances in each zone.
If a datacenter or availability zone outage occurs, during the failover, traffic is
automatically sent to instances in the surviving availability zones.
Consider if component proximity is required for application performance reasons. If the
application is highly "chatty", it might be sensitive to extra latency. When traffic goes

between availability zones that are geographically separated, extra latency is introduced.
While the amount of latency is very small, chatty applications might make many
requests, so the total latency is much higher. In this scenario, consider whether you
should co-locate your resources. Some Azure services enable zonal deployments, which
are sometimes called zone-pinned deployments. When you use a zonal deployment
approach, the resource is deployed to a specific zone. Multiple components can be
deployed to the same zone to reduce the communication latency.
You should also consider whether the use of multiple availability zones could increase
your costs. For example, inter-zone bandwidth charges might be incurred when your
resources synchronize data.
If you have business requirements that require mitigating the risk of an outage of an
entire region, consider deploying to multiple regions. Multiple regions can be used for
failover purposes in a disaster state. A multi-region solution is often more complicated
to deploy and operate. Other cost needs should be considered, including the extra data
and networking charges, and for services such as Azure Site Recovery.

Respond to failure
The possibility of failure is unavoidable in public cloud environments. As a result,
applications require resilience to respond to outages and deliver reliability. The
application should therefore be designed to operate even when impacted by regional,
zonal, service, or component failures across critical application scenarios and
functionality. Application operations might experience reduced functionality or
degraded performance during an outage.
Define an availability strategy to capture how the application remains available during a
failure state. The strategy should apply across all application components and the
application deployment stamp as a whole, such as via multi-geo scale-unit deployment
approach. There are cost implications as well. More resources need to be provisioned in
advance to provide high availability. Active-active setup, while more expensive than
single deployment, can balance cost by lowering load on one stamp and reducing the
total amount of resources needed.
In addition to an availability strategy, define a Business Continuity Disaster Recovery
(BCDR) strategy for the application and/or its key scenarios. A BCDR strategy should
capture how the application responds to a disaster situation, such as a regional outage
or the loss of a critical platform service, using either a redeployment, warm-spare activepassive, or hot-spare active-active approach.

To reduce costs, consider splitting application components and data into groups. For
example:
Must protect
Nice to protect
Ephemeral, can be rebuilt or lost instead of protected by the same policy

Considerations to improve reliability
Is the application designed to use managed services?
Azure-managed services provide native resiliency capabilities to support overall
application reliability. PaaS offerings should be used to leverage these capabilities. PaaS
options are easier to configure and administer. You don't need to provision VMs, set up
VNets, manage patches and updates, or do all of the other overhead associated with
running software on a VM. To learn more, see Use managed services.

Has the application been designed to scale out?
Azure provides elastic scalability and you should design to scale out. However,
applications must leverage a scale-unit approach to navigate service and subscription
limits to ensure that individual components and the application as a whole can scale
horizontally. Don't forget about scale in, which is important to reduce cost. For example,
scale in and out for App Service is done via rules. Often customers write scale out rules
and never write scale in rules, which leaves the App Service more expensive.

Is the application deployed across multiple Azure
subscriptions?
Understand the subscription landscape of the application and how components are
organized within or across subscriptions when you analyze if relevant subscription limits
or quotas can be navigated. Review Azure subscription and service limits to validate that
required capacity is within Azure service scale limits and quotas. To learn more, see
Azure subscription and service limits.

Related links
To learn how to minimize dependencies, see Minimize coordination.

For more information on fault-points and fault-modes, see Failure mode analysis
for Azure applications.
For information on managed services, see Use platform as a service (PaaS) options.
Go back to the main article: Design for reliability

Next steps
Resiliency and dependencies

Recommendations for using availability
zones and regions
Article • 09/20/2023

This guide describes the recommendations for determining when to deploy workloads
across availability zones or regions.
When you design a solution for Azure, you need to decide whether you'll deploy across
multiple availability zones in a region or deploy into multiple regions. This decision
affects your solution's reliability, cost, and performance, and your team's ability to
operate the solution. This guide provides information about the key business
requirements that influence your decision, the approaches you can consider, the
tradeoffs involved in each approach, and the effect of each approach on the core pillars
of the Azure Well-Architected Framework.
Your choice of how you use regions and availability zones affects several of the pillars of
the Well-Architected Framework:
Reliability: Your choice of deployment approach can help you to mitigate various
types of risks. In general, by spreading your workload across a more geographically
distributed area, you can achieve higher resiliency.
Cost Optimization: Some architectural approaches require deploying more
resources than others, which can increase your resource costs. Other approaches
involve sending data across geographically separated availability zones or regions,
which might incur network traffic charges. It's also important to consider the
ongoing cost of managing your resources, which is usually higher when you have a
more complex architecture.
Performance Efficiency: Most workloads aren't highly sensitive to network latency,
but occasionally they can be. If latency is an issue, you need to physically locate the
components close together to minimize latency when they communicate, which
typically means deploying them into a single availability zone.
Operational Excellence: A complex architecture takes more effort to deploy,
configure, and manage. Additionally, for a highly available solution, you might
need to plan how to fail over to a secondary set of resources. Failover, failback, and
transparently redirecting your traffic can be complex, especially when manual steps
are required.
However you design your solution, the Security pillar applies. Usually, decisions about
whether and how you use availability zones and regions doesn't change your security
posture. Azure applies the same security rigor to every region and availability zone.

 Tip
For many production workloads, a zone-redundant deployment provides the best
balance of tradeoffs. You can extend this approach with asynchronous data backup
to another region. If you aren't sure which approach to select, start with this type
of deployment.
Consider other workload approaches when you need the specific benefits that
those approaches provide, but be aware of the tradeoffs involved.
Definitions
Term

Definition

Region

A geographic perimeter that contains a set of datacenters.

Datacenter

A facility that contains servers, networking equipment, and other hardware
to support Azure resources and workloads.

Availability zone

A separated group of datacenters within a region. Each availability zone is
independent of the others, with its own power, cooling, and networking
infrastructure. Many regions support availability zones.

Paired regions

A relationship between two Azure regions. Some Azure regions are
connected to another defined region to enable specific types of multi-region
solutions. Newer Azure regions aren't paired.

Region

The specific configuration of the Azure region, including the number of

architecture

availability zones and whether the region is paired with another region.

Locally redundant

A deployment model in which a resource is deployed into a single region

deployment

without reference to an availability zone. In a region that supports
availability zones, the resource might be deployed in any of the region's
availability zones.

Zonal (pinned)

A deployment model in which a resource is deployed into a specific

deployment

availability zone.

Zone-redundant

A deployment model in which a resource is deployed across multiple

deployment

availability zones. Microsoft manages data synchronization, traffic
distribution, and failover if a zone experiences an outage.

Multi-region

A deployment model in which resources are deployed into multiple Azure

deployment

regions.

Asynchronous

A data replication approach in which data is written and committed to one

replication

location. At a later time, the changes are replicated to another location.

Term

Definition

Synchronous
replication

A data replication approach in which data is written and committed to
multiple locations. Each location must acknowledge completion of the write
operation before the overall write operation is considered complete.

Active-active

An architecture in which multiple instances of a solution actively process
requests at the same time.

Active-passive

An architecture in which one instance of a solution is designated as the
primary and processes traffic, and one or more secondary instances are
deployed to serve traffic if the primary is unavailable.

Key design strategies
Azure has a large global footprint. An Azure region is a geographic perimeter that
contains a set of datacenters. You need to have a complete understanding of Azure
regions and availability zones.
Azure regions have a variety of configurations, which are also called region architectures.
Many Azure regions provide availability zones, which are separated groups of
datacenters. Within a region, availability zones are close enough to have low-latency
connections to other availability zones, but they're far enough apart to reduce the
likelihood that more than one will be affected by local outages or weather. Availability
zones have independent power, cooling, and networking infrastructure. They're
designed so that if one zone experiences an outage, then regional services, capacity,
and high availability are supported by the remaining zones.
The following diagram shows several example Azure regions. Regions 1 and 2 support
availability zones.

If you deploy into an Azure region that contains availability zones, you can use multiple
availability zones together. By using multiple availability zones, you can keep separate
copies of your application and data within separate physical datacenters in a large
metropolitan area.
There are two ways to use availability zones in a solution:
Zonal resources are pinned to a specific availability zone. You can combine
multiple zonal deployments across different zones to meet high reliability
requirements. You're responsible for managing data replication and distributing
requests across zones. If an outage occurs in a single availability zone, you're
responsible for failover to another availability zone.
Zone-redundant resources are spread across multiple availability zones. Microsoft
manages spreading requests across zones and the replication of data across zones.
If an outage occurs in a single availability zone, Microsoft manages failover
automatically.
Azure services support one or both of these approaches. Platform as a service (PaaS)
services typically support zone-redundant deployments. Infrastructure as a service (IaaS)
services typically support zonal deployments. For more information about how Azure
services work with availability zones, see Azure services with availability zone support.
Microsoft aims to deploy updates to Azure services to a single availability zone at a
time. This approach reduces the impact that updates might have on an active workload,
because the workload can continue to run in other zones while the update is in process.
For more information about how Azure deploys updates, see Advancing safe
deployment practices

.

Many regions also have a paired region. Paired regions support certain types of multiregion deployment approaches. Some newer regions have multiple availability zones
and don't have a paired region. You can still deploy multi-region solutions into these
regions, but the approaches you use might be different.
For more information about how Azure uses regions and availability zones, see What are
Azure regions and availability zones?

Understand shared responsibilities
The shared responsibility principle describes how responsibilities are divided between
the cloud provider (Microsoft) and you. Depending on the type of services you use, you
might take on more or less responsibility for operating the service.

Microsoft provides availability zones and regions to give you flexibility in how you
design your solution to meet your requirements. When you use managed services,
Microsoft takes on more of the management responsibilities for your resources, which
might even include data replication, failover, failback, and other tasks related to
operating a distributed system.
Regardless of the approach you use, your own code needs to follow recommended
practices for handling transient failures. These practices are even more important in a
multi-zone or multi-region solution, because failover between zones or regions usually
requires that your application retry connections to services.

Identify key business and workload requirements
To make an informed decision about how to use availability zones and regions in your
solution, you need to understand your requirements. These requirements should be
driven by discussions between solution designers and business stakeholders.

Risk tolerance
Different organizations have different degrees of risk tolerance. Even within an
organization, risk tolerance is often different for each workload. Most workloads don't
need extremely high availability. However, some workloads are so important that it's
even worth mitigating risks that are unlikely to occur, like major natural disasters that
affect a wide geographic area.
This table lists a few of the common risks that you should consider in a cloud
environment:
Risk

Examples

Likelihood

Hardware

Problem with hard disk or networking

High. Any resiliency strategy

outage

equipment.

should account for these risks.

Host reboots.
Datacenter
outage

Power, cooling, or network failure across an
entire datacenter.

Medium

Natural disaster in one part of a metropolitan
area.
Region

Major natural disaster that affects a wide

outage

geographical area.
Network or service problem that makes one or

Low

Risk

Examples

Likelihood

more Azure services unavailable in an entire
region.

It would be ideal to mitigate every possible risk for every workload, but it's not practical
or cost effective to do so. It's important to have an open discussion with business
stakeholders so you can make informed decisions about the risks that you should
mitigate.
 Tip
Generally, it's only worth mitigating the low-likelihood risks for mission-critical
workloads. For example, banks, governments, and healthcare workloads often need
to remain operational in all situations. For other workloads, the organization's risk
tolerance is usually higher.

Resiliency requirements
It's important to understand the resiliency requirements for your workload, including the
recovery time objective (RTO) and recovery point objective (RPO). These objectives help
you decide which approaches to rule out. If you don't have clear requirements, you can't
make an informed decision about which approach to follow. For more information, see
Use business metrics to design resilient Azure applications.

Service-level agreements
You should understand your solution's expected uptime service-level agreement (SLA).
For example, you might have a business requirement that your solution needs to meet
99.9% uptime.
Azure provides SLAs for each service. An SLA indicates the level of uptime you should
expect from the service and the conditions you need to meet to achieve that expected
SLA.
Your architectural decisions affect your solution's composite SLA. In general, the more
redundancy you build into your solution, the higher your SLA is likely to be. Many Azure
services provide higher SLAs when you deploy services in a zone-redundant or multiregion configuration. Review the SLAs for each of the Azure services you use to ensure
that you understand how to maximize the resiliency and SLA of the service.

Data residency
Some organizations place restrictions on the physical locations into which their data can
be stored and processed. Sometimes these requirements are based on legal or
regulatory standards. In other situations, an organization might decide to adopt a data
residency policy to avoid customer concerns. If you have strict data residency
requirements, you might need to use a single-region deployment or use a subset of
Azure regions and services.
７ Note
Avoid making unfounded assumptions about your data residency requirements. If
you need to comply with specific regulatory standards, verify what those standards
actually specify.

User location
If your users are geographically dispersed, it might make sense to deploy your workload
across multiple regions. If your users are in one area, a single-region deployment can
simplify your operational requirements and reduce your costs.
Even if your users are in different geographical areas, you might not need a multi-region
deployment. Consider whether you can achieve your requirements within a single region
by using global traffic acceleration, like the acceleration provided by Azure Front Door.

Budget
If you operate under a constrained budget, it's important to consider the costs involved
in deploying redundant workload components. These costs can include additional
resource charges, networking costs, and the operational costs of managing more
resources and a more complex environment.

Complexity
It's a good practice to avoid unnecessary complexity in your solution architecture. The
more complexity you introduce, the harder it becomes to make decisions about your
architecture. Complex architectures are harder to operate, harder to secure, and often
less performant.

Azure facilitation

By providing regions and availability zones, Azure enables you to select a deployment
approach that fits your needs. There are many approaches that you can choose from,
each of which provides benefits and incurs costs.
７ Note
It's important to understand the specific details of the Azure services that you use.
For example, some Azure services require that you configure their availability zone
configuration when you first deploy the resource, while others support changing
the deployment approach later. Similarly, some service features might not be
available with every deployment approach.
To illustrate the deployment approaches that you can use, consider an example scenario.
Suppose you're thinking about deploying a new solution that includes an application
that writes data to some sort of storage:

This example isn't specific to any particular Azure services. It's intended to provide a
simple example for illustrating fundamental concepts.
There are multiple ways to deploy this solution. Each approach provides a different set
of benefits and incurs different costs. At a high level, you can consider a locally
redundant, zonal (pinned), zone-redundant, or multi-region deployment. This table
summarizes some of the pillar concerns:
Pillar

Locally redundant

Zonal (pinned)

Zone-redundant

Multi-region

Reliability

Low reliability

Depends on

High or very high

High or very

approach

reliability

high reliability

Cost
Optimization

Low cost

Depends on
approach

Moderate cost

High cost

Performance
Efficiency

Acceptable
performance (for
most workloads)

High
performance

Acceptable
performance (for
most workloads)

Depends on
approach

Operational

Low operational

High

Low operational

High

Excellence

requirements

operational
requirements

requirements

operational
requirements

This table summarizes some of the approaches you can use and how they affect your
architecture:
Architectural
concern

Locally
redundant

Zonal (pinned)

Zone-redundant

Multiregion

Compliance with
data residency

High

High

High

Depends on
region

Regional availability

All regions

Regions with
availability zones

Regions with
availability zones

Depends on
region

The rest of this article describes each of the approaches listed in the preceding table.
The list of approaches isn't exhaustive. You might decide to combine multiple
approaches or use different approaches in different parts of your solution.

Deployment approach 1: Locally redundant deployments
If you don't specify multiple availability zones or regions when you deploy your
resources, Azure doesn't make any guarantees about whether the resources are
deployed into a single datacenter or split across multiple datacenters in the region. In
some situations, Azure might also move your resource between availability zones.

Most Azure resources are highly available by default, with high SLAs and built-in
redundancy within a datacenter that's managed by the platform. However, from a
reliability perspective, if any part of the region experiences an outage, there's a chance
that your workload might be affected. If it is, your solution might be unavailable, or your
data could be lost.
For highly latency-sensitive workloads, this approach might also result in lower
performance. Your workload components might not be colocated in the same
datacenter, so you might observe some latency for intra-region traffic. Azure might also
transparently move your service instances between availability zones, which might
slightly affect performance. However, this isn't a concern for most workloads.
This table summarizes some of the pillar concerns:

Pillar

Impact

Reliability

Low reliability. Services are subject to outages if a datacenter fails. You can,
however, build an application to be resilient to other types of failures.

Cost
Optimization

Lowest cost. You only need to have a single instance of each resource, and you
don't incur any inter-zone or inter-region bandwidth costs.

Performance

For most workloads: Acceptable performance. This approach is likely to

Efficiency

provide satisfactory performance.
For highly latency-sensitive workloads: Low performance. Components aren't
guaranteed to be located in the same availability zone, so you might see lower
performance for highly latency-sensitive components.

Operational
Excellence

High operational efficiency. You only need to deploy and manage a single
instance of each resource.

This table summarizes some of the concerns from an architectural perspective:
Architectural concern

Impact

Compliance with data
residency

High. When you deploy a solution that uses this approach, data is
stored in the Azure region that you select.

Regional availability

High. This approach can be used in any Azure region.

Locally redundant deployments with backup across regions
You can extend a locally redundant deployment by performing regular backups of your
infrastructure and data to a secondary region. This approach adds an extra layer of
protection to mitigate against an outage in your primary region. Here's what it looks
like:

When you implement this approach, you need to carefully consider your RTO and RPO:
Recovery time: If a regional outage occurs, you might need to rebuild your
solution in another Azure region, which affects your recovery time. Consider
building your solution by using an infrastructure-as-code (IaC) approach so that

you can quickly redeploy into another region if a major disaster occurs. Ensure that
your deployment tools and processes are just as resilient as your applications so
that you can use them to redeploy your solution even if there's an outage. Plan for
and rehearse the steps that are required to restore your solution back to a working
state.
Recovery point: Your backup frequency determines the amount of data loss that
you might experience (your recovery point). You can typically control the frequency
of backups so that you can meet your RPO.
This table summarizes some of the pillar concerns:
Pillar

Impact

Reliability

Moderate reliability. Services are subject to outages if a datacenter fails. Data is
backed up asynchronously to a geographically separated region, which reduces
the effect of a full region outage by minimizing data loss. In a full region outage,
you can manually restore operations into another region. However, recovery
processes can be complex, and it can take time to manually restore into the
other region.

Cost

Low cost. Typically, adding a backup to another region costs only slightly more

Optimization

than deploying a locally redundant resource.

Performance
Efficiency

For most workloads: Acceptable performance. This approach is likely to provide
satisfactory performance.
For highly latency-sensitive workloads: Low performance. Components aren't
guaranteed to be located in the same availability zone, so you might see lower
performance for highly latency-sensitive components.

Operational

During any outage within a region: Low operational efficiency. Failover is your

Excellence

responsibility and might require manual operations and redeployments.

This table summarizes some of the concerns from an architectural perspective:
Architectural

Impact

concern
Compliance with

Depends on region selection. Data is primarily stored in the Azure region

data residency

that you specify. However, you need to select another region to store your
backups, so it's important that you select a region that's compatible with
your data residency requirements.

Regional
availability

High. You can use this approach in any Azure region.

Deployment approach 2: Zonal (pinned) deployments

In a zonal deployment, you specify that your resources should be deployed to a specific
availability zone. This approach is sometimes called a zone-pinned deployment.

A zonal approach reduces the latency between your components. However, by itself, it
doesn't increase the resiliency of your solution. To increase your resiliency, you need to
deploy multiple instances of your components into multiple availability zones and
decide how to route traffic between each instance. This example shows an active-passive
traffic routing approach:

In the previous example, a load balancer is deployed across multiple availability zones.
It's important to consider how you route traffic between instances in different
availability zones, because a zone outage might also affect the networking resources
deployed into that zone. You might also consider using a global load balancer, like
Azure Front Door or Azure Traffic Manager, which isn't deployed into a region at all.
When you use a zonal deployment model, you take on many responsibilities:
You need to deploy resources to each availability zone, and configure and manage
those resources individually.
You need to decide how and when to replicate data between the availability zones,
and then configure and manage the replication.
You're responsible for distributing the requests to the correct resources, by using,
for example, a load balancer. You need to ensure that the load balancer meets your
resiliency requirements. You also need to decide whether to use an active-passive
or an active-active request distribution model.

If an availability zone experiences an outage, you need to handle the failover to
send traffic to resources in another availability zone.
An active-passive deployment across multiple availability zones is sometimes called inregion DR or Metro DR.
This table summarizes some of the pillar concerns:
Pillar

Impact

Reliability

When deployed in a single availability zone: Low reliability. A zonal deployment
doesn't provide any resiliency to an outage in a datacenter or availability zone.
You must deploy redundant resources across multiple availability zones to
achieve high resiliency.
When deployed in multiple availability zones: High reliability. Services can be
made resilient to a datacenter or availability zone outage.

Cost
Optimization

When deployed in a single availability zone: Low cost. A single-zone
deployment requires only a single instance of each resource.
When deployed in multiple availability zones: High cost. You deploy multiple
instances of the resources, each of which are billed separately. You also need to
pay for inter-zone traffic for data replication.

Performance

High performance. Latency can be very low when the components that serve a

Efficiency

request are located in the same availability zone.

Operational

Low operational efficiency. You need to configure and manage multiple

Excellence

instances of your service. You need to replicate data between availability zones.
During an availability zone outage, failover is your responsibility.

This table summarizes some of the concerns from an architectural perspective:
Architectural concern

Impact

Compliance with data
residency

High. When you deploy a solution that uses this approach, data is
stored in the Azure region that you select.

Regional availability

Regions with availability zones. This approach is available in any
region that supports availability zones.

This approach is typically used for workloads that are based on virtual machines. For a
complete list of services that support zonal deployments, see Availability zone service
and regional support.
When you plan a zonal deployment, verify that the Azure services you use are supported
in the availability zones you plan to use. For example, to list which virtual machine SKUs

are available in each availability zone, see Check VM SKU availability.
 Tip
When you deploy a resource into a specific availability zone, you select the zone
number. The sequence of zone numbers is different for each Azure subscription. If
you deploy resources across multiple Azure subscriptions, verify the zone numbers
that you should use in each subscription. For more information, see What are
Azure regions and availability zones?.

Deployment approach 3: Zone-redundant deployments
When you use this approach, your application tier is spread across multiple availability
zones. When requests arrive, a load balancer that's built into the service (which itself
spans availability zones) disperses the requests across the instances in each availability
zone. If an availability zone experiences an outage, the load balancer directs traffic to
instances in the healthy availability zones.
Your storage tier is also spread across multiple availability zones. Copies of your
application's data are distributed across multiple availability zones via synchronous
replication. When the application makes a change to data, the storage service writes the
change to multiple availability zones, and the transaction is considered complete only
when all of these changes are complete. This process ensures that each availability zone
always has an up-to-date copy of the data. If an availability zone experiences an outage,
another availability zone can be used to access the same data.

A zone-redundant approach increases your solution's resiliency to issues like datacenter
outages. Because data is replicated synchronously, however, your application has to wait

for the data to be written across multiple separate locations that might be in different
parts of a metropolitan area. For most applications, the latency involved in inter-zone
communication is negligible. However, for some highly latency-sensitive workloads,
synchronous replication across availability zones might affect the application's
performance.
This table summarizes some of the pillar concerns:
Pillar

Impact

Reliability

High reliability. Services are resilient to an outage of a datacenter or availability
zone. Data is synchronously replicated across availability zones and with no
delay.

Cost

Moderate cost. Depending on the services you use, you might incur some

Optimization

costs for higher service tiers to enable zone redundancy, or some inter-zone
networking costs.

Performance
Efficiency

For most workloads: Acceptable performance. This approach is likely to provide
satisfactory performance.
For highly latency-sensitive workloads: Low performance. Some components
might be sensitive to latency due to inter-zone traffic or data replication time.

Operational
Excellence

High operational efficiency. You typically need to manage only a single logical
instance of each resource. For most services, during an availability zone outage,
failover is the responsibility of Microsoft and happens automatically.

This table summarizes some of the concerns from an architectural perspective:
Architectural concern

Impact

Compliance with data
residency

High. When you deploy a solution that uses this approach, data is
stored in the Azure region that you select.

Regional availability

Regions with availability zones. This approach is available in any
region that supports availability zones.

This approach is possible with many Azure services, including Azure Virtual Machine
Scale Sets, Azure App Service, Azure Functions, Azure Kubernetes Service, Azure Storage,
Azure SQL, Azure Service Bus, and many others. For a complete list of services that
support zone redundancy, see Availability zone service and regional support.

Zone-redundant deployments with backup across regions

You can extend a zone-redundant deployment by performing regular backups of your
infrastructure and data to a secondary region. This approach gives you the benefits of a
zone-redundant approach and adds a layer of protection to mitigate the extremely
unlikely event of a full region outage.

When you implement this approach, you need to carefully consider your RTO and RPO:
Recovery time: If a regional outage does occur, you might need to rebuild your
solution in another Azure region, which affects your recovery time. Consider
building your solution by using an IaC approach so that you can quickly redeploy
into another region during a major disaster. Ensure that your deployment tools
and processes are just as resilient as your applications so that you can use them to
redeploy your solution even if an outage occurs. Plan for and rehearse the steps
required to restore your solution back to a working state.
Recovery point: Your backup frequency determines the amount of data loss that
you might experience (your recovery point). You can typically control the frequency
of backups to meet your RPO.
 Tip
This approach often provides a good balance for all architectural concerns. If you
aren't sure which approach to use, start with this type of deployment.
This table summarizes some of the pillar concerns:
Pillar

Impact

Reliability

Very high reliability. Services are resilient to an outage of a datacenter or
availability zone. For most services, data is replicated across zones automatically
and with no delay. Data is backed up asynchronously to a geographically
separated region. This backup reduces the effect of a full region outage by

Pillar

Impact
minimizing data loss. After a full region outage, you can manually restore
operations into another region. However, recovery processes can be complex,
and it can take time to manually restore into the other region.

Cost
Optimization

Moderate cost. Typically, adding a backup to another region costs only slightly
more than implementing zone redundancy.

Performance
Efficiency

For most workloads: Acceptable performance. This approach is likely to provide
satisfactory performance.
For highly latency-sensitive workloads: Low performance. Some components
might be sensitive to latency due to inter-zone traffic or data replication time.

Operational
Excellence

During an availability zone outage: High operational efficiency. Failover is the
responsibility of Microsoft and happens automatically.
During a regional outage: Low operational efficiency. Failover is your
responsibility and might require manual operations and redeployments.

This table summarizes some of the concerns from an architectural perspective:
Architectural

Impact

concern
Compliance with

Depends on region selection. Data is stored primarily in the Azure region

data residency

that you specify, but you need to select another region to store your
backups. Select a region that's compatible with your data residency
requirements.

Regional
availability

Regions with availability zones. This approach is available in any region that
supports availability zones.

Deployment approach 4: Multi-region deployments
You can use multiple Azure regions together to distribute your solution across a wide
geographical area. You can use this multi-region approach to improve your solution's
reliability or to support geographically distributed users. If data residency is an
important concern for your solution, carefully consider which regions you use to ensure
that your data is stored only in locations that meet your requirements.

Active and passive regions
Multi-region architectures are complex, and there are many ways to design a multiregion solution. For some workloads, it makes sense to have multiple regions actively

processing requests simultaneously (active-active deployments). For other workloads,
it's better to designate one primary region and use one or more secondary regions for
failover (active-passive deployments). This section focuses on the second scenario, in
which one region is active and another is passive. For information about active-active
multi-region solutions, see Deployment Stamps pattern and Geode pattern.

Data replication
Communicating across regions is much slower than communicating within a region. In
general, a larger geographic distance between two regions incurs more network latency.
See Azure network round-trip latency statistics for the expected network latency when
you connect between two regions.
Cross-region network latency can significantly affect your solution design because you
need to carefully consider how the extra latency affects data replication and other
transactions. For many solutions, a cross-region architecture requires asynchronous
replication to minimize the effect of cross-region traffic on performance.

Asynchronous data replication
When you implement asynchronous replication across regions, your application doesn't
wait for all regions to acknowledge a change. After the change is committed in the
primary region, the transaction is considered complete. The change is replicated to the
secondary regions at a later time. This approach ensures that inter-region connection
latency doesn't directly affect application performance. However, because of the delay in
replication, a region-wide outage might result in some data loss. This data loss can
occur because a region might experience an outage after a write is completed in the
primary region but before the change could be replicated to another region.

This table summarizes some of the pillar concerns:
Pillar

Impact

Reliability

High reliability. The solution is resilient to an outage of a datacenter, an
availability zone, or an entire region. Data is replicated but might not be
synchronous, so some data loss is possible in a failover scenario.

Cost

High cost. You need to deploy separate resources in each region, and each

Optimization

resource incurs deployment and maintainenance costs. Data replication across
regions might also incur significant costs.

Performance
Efficiency

High performance. Application requests don't require cross-region traffic, so
traffic is typically low latency.

Operational
Excellence

Low operational efficiency. You need to deploy and manage resources across
multiple regions. You're also responsible for failover between regions during a
regional outage.

This table summarizes some of the concerns from an architectural perspective:
Architectural

Impact

concern
Compliance with

Depends on region selection. This approach requires you to select multiple

data residency

regions for your workload to run in. Choose regions that are compatible
with your data residency requirements.

Regional

Many Azure regions are paired. Some Azure services use paired regions to

availability

replicate data automatically. If you run your workload in a region that
doesn't have a pair, you might need to use a different approach to replicate
your data.

Synchronous data replication
If you implement a synchronous multi-region solution, your application needs to wait
for write operations to complete in each Azure region before the transaction is
considered complete. The latency incurred by waiting for write operations depends on
the distance between the regions. For many workloads, inter-region latency can make
synchronous replication too slow to be useful.

This table summarizes some of the pillar concerns:
Pillar

Impact

Reliability

Very high reliability. The solution is resilient to an outage of a datacenter, an
availability zone, or an entire region. Data is always in sync across regions, so,
even if a complete region loss occurs, your data is available and complete in
another region.

Cost

High cost. You need to deploy separate resources in each region, and each

Optimization

resource incurs deployment and maintainenance costs. Data replication across
regions might also incur significant costs.

Performance
Efficiency

Low performance. Application requests require cross-region traffic. Depending
on the distance between the regions, synchronous replication might add
significant latency to requests.

Operational

Low operational efficiency. You need to deploy and manage resources across

Excellence

multiple regions. You're also responsible for failover between regions during a
regional outage.

This table summarizes some of the concerns from an architectural perspective:
Architectural

Impact

concern
Compliance with
data residency

Depends on region selection. This approach requires you to select multiple
regions for your workload to run in. Select regions that are compatible with
your data residency requirements.

Regional
availability

Many Azure regions are paired. Some Azure services use paired regions to
replicate data automatically. If you run your workload in a region that

Architectural
concern

Impact
doesn't have a pair, you might need to use a different approach to replicate
your data.

Region architectures
When you design a multi-region solution, consider whether the Azure regions you plan
to use are paired.
You can create a multi-region solution even when the regions aren't paired. However,
the approaches that you use to implement a multi-region architecture might be
different. For example, in Azure Storage, you can use geo-redundant storage (GRS) with
paired regions. If GRS isn't available, consider using features like Azure Storage object
replication, or design your application to write to multiple regions.

Combine multi-zone and multi-region approaches
You can also combine multi-zone and multi-region approaches. For example, you might
deploy zone-redundant components into each region and also configure replication
between the regions. Configuring this type of approach can be complicated, and this
approach can be expensive, but for some solutions it provides a very high degree of
reliability.
） Important
Mission-critical workloads should use both multiple availability zones and multiple
regions. For more information about the considerations that you should give when
designing mission-critical workloads, see Mission-critical workload
documentation.

Examples
This section describes some common use cases and the key requirements that you
typically need to consider for each workload. For each workload, a suggested
deployment approach is provided, based on the requirements and approaches
described in this article.

Line-of-business application for an enterprise

Contoso, Ltd., is a large manufacturing company. The company is implementing a lineof-business application to manage some components of its financial processes.
Business requirements: The information that the system manages is difficult to replace,
so data needs to be persisted reliably. The architects say that the system needs to incur
as little downtime and as little data loss as possible. Contoso's employees use the
system throughout the workday, so high performance is important to avoid keeping
team members waiting. Cost is also a concern, because the finance team has to pay for
the solution.
Suggested approach: Zone-redundant deployment or zone-redundant deployment with
backup across regions.

Internal application
Fourth Coffee is a small business. The company is developing a new internal application
that employees can use to submit timesheets.
Business requirements: For this workload, cost efficiency is a primary concern. Fourth
Coffee evaluated the business impact of downtime and decided that the application
doesn't need to prioritize resiliency or performance. The company accepts the risk that
an outage in an Azure availability zone or region might make the application
temporarily unavailable.
Suggested approach: Locally redundant deployment.

Legacy application migration
Fabrikam, Inc., is migrating a legacy application from an on-premises datacenter to
Azure. The implementation will use an IaaS approach that's based on virtual machines.
The application wasn't designed for a cloud environment, and communication between
the application tier and the database is very chatty.
Business requirements: Performance is a priority for this application. Resiliency is also
important, and the application must continue to work even if an Azure datacenter
experiences an outage.
Suggested approach: Zonal (pinned) deployment, with passive deployments across
multiple availability zones (in-region DR).

Healthcare application

Lamna Healthcare Company is implementing a new electronic health record system on
Azure.
Business requirements: Because of the nature of the data that this solution stores, data
residency is critically important. Lamna operates under a strict regulatory framework
that mandates that data must remain in a specific location.
Suggested approach: Lamna might consider a zone-redundant deployment or a zoneredundant deployment with backup across regions. The company could also consider a
multi-region deployment if there are multiple regions that fit Lamna's data residency
requirements.

Banking system
Woodgrove Bank runs its core banking operations from a large solution that's deployed
to Azure.
Business requirements: This is a mission-critical system. Any outages can cause major
financial impact for customers. As a result, Woodgrove Bank has very low risk tolerance.
The system needs the highest level of reliability possible, and the architecture needs to
mitigate the risk of any failures that can be mitigated.
Suggested approach: Multi-region deployment. The architecture must use regions that
fit the company's data residency requirements.

Software as a service (SaaS)
Proseware, Inc., builds software that's used by companies across the world. The
company's user base is widely distributed geographically.
Business requirements: Proseware needs to enable each of its customers to choose a
deployment region that's close to the customer. Enabling this choice is important for
latency and for the customers' data residency requirements.
Suggested approach: Multi-region deployment. Alternatively, Proseware could consider
using a single-region deployment with a global traffic acceleration solution, like Azure
Front Door.

Related links
Following are some reference architectures and example scenarios for multi-zone and
multi-region solutions:

Baseline highly available zone-redundant web application
Highly available multi-region web application
Multi-region N-tier application
Multi-tier web application built for HA/DR
Many Azure services support provide guidance about how to use multiple availability
zones, including the following examples:
Azure Site Recovery: Enable Azure VM disaster recovery between availability zones
Azure NetApp Files: Understand cross-zone replication of Azure NetApp Files
Azure Storage redundancy

Use business metrics to design resilient
Azure applications
Article • 05/30/2023

You can use business metrics to design resilient applications in Azure. You need to
understand workload availability targets, recovery metrics, and availability metrics.

Workload availability targets
Are availability targets, such as service-level agreements (SLAs), service-level indicators
(SLIs), and service-level objectives (SLOs), defined for the application or key scenarios?
Understanding customer availability expectations is vital to reviewing overall operations
for the application. For instance, if a customer wants an application SLO of 99.999% , the
level of inherent operational activity required by the application is going to be far
greater than if an SLO of 99.9% is the goal.
Define your own target SLAs for each workload in your solution so you can determine
whether the architecture meets the business requirements.

Consider cost and complexity
Everything else being equal, higher availability is better. But as you strive for more nines,
the cost and complexity grow. An uptime of 99.99% translates to about five minutes of
total downtime per month. Is it worth the extra complexity and cost to reach five nines?
The answer depends on your business requirements.
Here are some other considerations when defining an SLA:
To achieve four nines ( 99.99% ), you can't rely on manual intervention to recover
from failures. The application must be self-diagnosing and self-healing.
Beyond four nines, it's challenging to detect outages quickly enough to meet the
SLA.
Think about the time window that your SLA is measured against. The smaller the
window, the tighter the tolerances. It doesn't make sense to define your SLA in
terms of hourly or daily uptime.
Consider the mean time to recover (MTTR) and mean time between failures (MTBF)
measurements. The higher your SLA, the less frequently the service can go down
and the quicker the service must recover.

Get agreement from your customers for the availability targets of each piece of
your application, and document it. Otherwise, your design might not meet your
customers' expectations.

Identify dependencies
Perform dependency-mapping exercises to identify internal and external dependencies.
Examples include dependencies relating to security or identity, such as Active Directory
or third-party services. Third-party services might include a payment provider or email
messaging service.
Pay particular attention to external dependencies that might be a single point of failure
or cause bottlenecks. If a workload requires 99.99% uptime but depends on a service
with a 99.9% SLA, that service can't be a single point of failure in the system. One
remedy is to have a fallback path in case the service fails. Alternatively, take other
measures to recover from a failure in that service.
The following table shows the potential cumulative downtime for various SLA levels.
SLA

Downtime per week

Downtime per month

Downtime per year

99%

1.68 hours

7.2 hours

3.65 days

99.9%

10.1 minutes

43.2 minutes

8.76 hours

99.95%

5 minutes

21.6 minutes

4.38 hours

99.99%

1.01 minutes

4.32 minutes

52.56 minutes

99.999%

6 seconds

25.9 seconds

5.26 minutes

Identify critical system flows
Understanding critical system flows is vital to assessing overall operational effectiveness
and should be used to inform a health model for the application. It can also tell if areas
of the application are over or underutilized and should be adjusted to better meet
business needs and cost goals.
Critical subsystems or paths through the application might have higher expectations
around availability, recovery, and performance due to the criticality of associated
business scenarios and functionality. This fact also helps to understand if cost might be
affected due to these higher needs.

Identify less critical components
Some less critical components or paths through the application might have lower
expectations around availability, recovery, and performance. Less critical components
can result in cost reduction by choosing lower SKUs with less performance and
availability.

Recovery metrics
Derive these values by conducting a risk assessment, and make sure that you
understand the cost and risk of downtime and data loss. These nonfunctional
requirements of a system should be dictated by business requirements.
Recovery time objective (RTO) is the maximum acceptable time an application is
unavailable after an incident.
Recovery point objective (RPO) is the maximum duration of data loss that's
acceptable during a disaster.
If the MTTR value of any critical component in a highly available setup exceeds the
system RTO, a failure in the system might cause an unacceptable business disruption.
That is, you can't restore the system within the defined RTO.

Availability metrics
Use these measures to plan for redundancy and determine customer SLAs.
Mean time to recover (MTTR) is the average time it takes to restore a component
after a failure.
Mean time between failures (MTBF) is how long a component can reasonably
expect to last between outages.

Understand service-level agreements
In Azure, the Service Level Agreement

describes Microsoft's commitments for uptime

and connectivity. If the SLA for a particular service is 99.9% , you should expect the
service to be available 99.9% of the time. Different services have different SLAs.
The Azure SLA also includes procedures for obtaining a service credit if the SLA isn't
met, along with specific definitions of availability for each service. That aspect of the SLA
acts as an enforcement policy.

The Service Level Agreement Estimator

sample shows how to calculate the SLA

of your architecture.

Composite SLAs
Composite SLAs involve multiple services supporting an application, with differing levels
of availability. For example, consider an App Service web app that writes to Azure SQL
Database. Currently, these Azure services have the following SLAs:
App Service web apps = 99.95%
SQL Database = 99.99%
What is the maximum downtime you would expect for this application? If either service
fails, the whole application fails. The probability of each service failing is independent, so
the composite SLA for this application is 99.95% × 99.99% = 99.94% . That value is lower
than the individual SLAs, which isn't surprising because an application that relies on
multiple services has more potential failure points.
You can improve the composite SLA by creating independent fallback paths. For
example, if SQL Database is unavailable, put transactions into a queue to be processed
later:

With this design, the application is still available even if it can't connect to the database.
However, it fails if the database and the queue both fail at the same time. The expected
percentage of time for a simultaneous failure is 0.0001 × 0.001 , so the composite SLA
for this combined path is:
Database or queue = 1.0 − (0.0001 × 0.001) = 99.99999%
The total composite SLA is:
Web app and (database or queue) = 99.95% × 99.99999% = ~99.95%

There are tradeoffs to this approach. The application logic is more complex, you're
paying for the queue, and you need to consider data consistency issues.

SLAs for multiregion deployments
SLAs for multiregion deployments involve a high-availability technique to deploy the
application in more than one region and use Azure Traffic Manager to fail over if the
application fails in one region.
The composite SLA for a multiregion deployment is calculated as follows:
N is the composite SLA for the application deployed in one region.
R is the number of regions where the application is deployed.
The expected chance that the application fails in all regions at the same time is ( (1 − N)
^ R ). For example, if the single-region SLA is 99.95% :

The combined SLA for two regions = (1 − (1 − 0.9995) ^ 2) = 99.999975%
The combined SLA for four regions = (1 − (1 − 0.9995) ^ 4) = 99.999999%
The SLA for Traffic Manager

is also a factor. Failing over isn't instantaneous in active-

passive configurations, which can result in downtime during a failover. See Traffic
Manager endpoint monitoring.

Best practices for designing reliability in
Azure applications
Article • 05/30/2023

This article describes best practices to design Azure applications for reliability. These
best practices are derived from our experience with Azure reliability and the experiences
of customers like yourself.
During the architectural phase, implement practices that meet your business
requirements, identify failure points, and minimize the scope of failures.

Build availability targets and recovery targets
into your design
A service-level agreement (SLA) is an availability target that represents a commitment
around performance and availability of the application. Understanding the SLA of
individual components within the system is essential in order to define reliability targets.
Recovery targets identify how long the workload can be unavailable and how much data
is acceptable to lose during a disaster.
Define target reports for the application and key scenarios. There might be penalties,
such as financial charges, associated with failing to meet SLA commitments. The
consequences of not satisfying availability targets should be fully understood.

Ensure the application and data platforms meet
your reliability requirements
Designing application platform and data platform resiliency and availability are critical
to ensure overall application reliability.

Ensure connectivity
To ensure connection availability and improve reliability with Azure services:
Use a global load balancer to distribute traffic and failover across regions.
For cross-premises connectivity with Azure ExpressRoute or VPN, ensure that there
are redundant connections from different locations.

Simulate a failure path to ensure that connectivity is available over alternative
paths.
Eliminate all single points of failure from the data path, both on-premises and
hosted by Azure.

Use zone-aware services
Zone-aware services can improve reliability and ensure availability during failure
scenarios that affect a datacenter within a region. They can also be used to deploy
gateway instances across zones for improved reliability and availability during failure
scenarios that affect a datacenter within a region.

Design resilience to respond to outages
Applications should be designed to operate even when affected by regional, zonal,
service, or component failures across critical application scenarios and functionality.
Application operations might experience reduced functionality or degraded
performance during an outage.

Perform a failure mode analysis
Failure mode analysis (FMA) builds resiliency into an application early in the design
stage. It helps you identify the types of failures that your application might experience,
the potential effects of each, and possible recovery strategies.
Have all single points of failure been eliminated? A single point of failure describes a
specific fault-point that, if it were to fail, would bring down the entire application. Single
points of failure introduce significant risk since any failure of this component causes an
application outage.
Have all fault-points and fault-modes been identified? Fault-points describe the
elements within an application architecture that are capable of failing, while fault-modes
capture the various ways by which a fault-point might fail. To ensure that an application
is resilient to end-to-end failures, it's essential that all fault-points and fault-modes are
understood and operationalized.

Understand the effect of an outage with each
dependency

Strong dependencies play a critical role in application function and availability. Their
absence has a significant effect, while the absence of weak dependencies might only
affect specific features and not affect overall availability. Dependencies can be
categorized as either strong or weak based on whether the application is able to
continue operating in a degraded fashion in their absence.

Design for scalability
A cloud application must be able to scale to accommodate changes in usage. Begin with
discrete components and design the application to respond automatically to load
changes whenever possible. Keep scaling limits in mind during design so you can
expand easily in the future.

Next steps
Testing for reliability
Go back to the main article: Design for reliability

Checklist for reliability testing
Article • 05/30/2023

Regular testing should be performed as part of each major change and, if possible, on a
regular basis to validate existing thresholds, targets, and assumptions. Testing should
also ensure the validity of the health model, capacity model, and operational
procedures.

Checklist
Have you tested your applications with reliability in mind?
＂ Test regularly to validate existing thresholds, targets, and assumptions.
＂ Automate testing as much as possible.
＂ Perform testing on both key test environments and the production environment.
＂ Perform chaos testing by injecting faults.
＂ Create and test a disaster recovery plan on a regular basis by using key failure
scenarios.
＂ Design a disaster recovery strategy to run most applications with reduced
functionality.
＂ Design a backup strategy that's tailored for the business requirements and
circumstances of the application.
＂ Test and validate the failover and failback approach successfully at least once.
＂ Configure request timeouts to manage intercomponent calls.
＂ Implement retry logic to handle transient application failures and transient failures
with internal or external dependencies.
＂ Configure and test health probes for your load balancers and traffic managers.
＂ Apply chaos principles continuously.
＂ Create and organize a central chaos engineering team.

Azure services
Azure Site Recovery
Azure Pipelines
Azure Traffic Manager
Azure Load Balancer

Reference architecture

Failure mode analysis for Azure applications
High availability and disaster recovery scenarios for IaaS apps
Back up files and applications on Azure Stack Hub

Related links
For information on performance testing, see Performance testing.
For information on chaos engineering, see Chaos engineering.
For information on failure and disaster recovery, see Backup and disaster recovery
for Azure applications.
For information on testing applications, see Testing your application and Azure
environment.

Next steps
Resiliency testing

Testing applications for availability and
resiliency
Article • 05/30/2023

Applications should be tested to ensure availability and resiliency. Availability describes
the amount of time that an application runs in a healthy state without significant
downtime. Resiliency describes how quickly an application recovers from failure.
Being able to measure availability and resiliency can answer questions like: How much
downtime is acceptable? How much does potential downtime cost your business? What
are your availability requirements? How much do you invest in making your application
highly available? What is the risk versus the cost? Testing plays a critical role in making
sure your applications can meet these requirements.

Key points
Test regularly to validate existing thresholds, targets, and assumptions.
Automate testing as much as possible.
Perform testing on both key test environments and the production environment.
Verify how the end-to-end workload performs under intermittent failure
conditions.
Test the application against critical functional and nonfunctional requirements for
performance.
Conduct load testing with expected peak volumes to test scalability and
performance under load.
Perform chaos testing by injecting faults.

When to test
Regular testing should be performed as part of each major change and, if possible, on a
regular basis to validate existing thresholds, targets, and assumptions. While most
testing should be performed within the testing and staging environments, it's often
beneficial to also run a subset of tests against the production system. Plan a 1:1 parity of
key test environments with the production environment.
７ Note
Automate testing where possible to ensure consistent test coverage and
reproducibility. Automate common testing tasks and integrate them into your build

processes. Manually testing software is tedious and susceptible to error, although
manual explorative testing can also be conducted.

Testing for resiliency
To test resiliency, you should verify how the end-to-end workload performs under
intermittent failure conditions.
Run tests in production using both synthetic and real user data. Test and production are
rarely identical, so it's important to validate your application in production using a bluegreen

or canary deployment . This way, you're testing the application under real

conditions, so you can be sure that it functions as expected when fully deployed.
As part of your test plan, include:
Chaos engineering
Automated pre-deployment testing
Fault injection testing
Peak load testing
Disaster recovery testing

Performance testing
The primary goal of performance testing is to validate benchmark behavior for the
application. Performance testing is the superset of both load testing and stress testing.
Load testing validates application scalability by rapidly and/or gradually increasing the
load on the application until it reaches a threshold or limit. Stress testing involves
various activities to overload existing resources and remove components to understand
overall resiliency and how the application responds to issues.

Simulation testing
Simulation testing involves creating small, real-life situations. Simulations demonstrate
the effectiveness of the solutions in the recovery plan and highlight any issues that
weren't adequately addressed.
As you perform simulation testing, follow best practices:
Conduct simulations in a manner that doesn't disrupt actual business but feels like
a real situation.

Make sure that simulated scenarios are completely controllable. If the recovery
plan seems to be failing, you can restore the situation back to normal without
causing damage.
Inform management about when and how the simulation exercises are conducted.
Your plan should detail the time frame and the resources affected during the
simulation.

Fault injection testing
For fault injection testing, check the resiliency of the system during failures, either by
triggering actual failures or by simulating them. Here are some strategies to induce
failures:
Shut down virtual machine (VM) instances.
Crash processes.
Expire certificates.
Change access keys.
Shut down the DNS service on domain controllers.
Limit available system resources, such as RAM or number of threads.
Unmount disks.
Redeploy a VM.
Your test plan should incorporate possible failure points identified during the design
phase, in addition to common failure scenarios:
Test your application in an environment as close to production as possible.
Test failures in combination.
Measure the recovery times, and be sure that your business requirements are met.
Verify that failures don't cascade and are handled in an isolated way.

Test under peak loads
Load testing is crucial to identify failures that only happen under load, such as the
backend database being overwhelmed or service throttling. Test for peak load and
anticipated increase in peak load, using production data or synthetic data that's as close
to production data as possible. Your goal is to see how the application behaves under
real-world conditions.

Related links
For more test types, see Test types.

To learn about load and stress tests, see Performance testing.
To learn about chaos testing, see Chaos engineering.
Go back to the main article: Checklist for reliability testing

Next steps
Backup and disaster recovery

Backup and disaster recovery for Azure
applications
Article • 05/30/2023

Disaster recovery is the process of restoring application functionality after a catastrophic
loss.
In cloud environments, we acknowledge up front that failures happen. Instead of trying
to prevent failures altogether, the goal is to minimize the effects of a single failing
component. Testing is one way to minimize these effects. You should automate testing
of your applications where possible, but you also need to be prepared for when they
fail. When a failure happens, having backup and recovery strategies becomes important.
Your tolerance for reduced functionality during a disaster is a business decision that
varies from one application to the next. It might be acceptable for some applications to
be temporarily unavailable, or partially available with reduced functionality or delayed
processing. For other applications, any reduced functionality is unacceptable.

Key points
Create and test a disaster recovery plan regularly using key failure scenarios.
Design a disaster recovery strategy to run most applications with reduced
functionality.
Design a backup strategy that's tailored for the business requirements and
circumstances of the application.
Automate failover and failback steps and processes.
Test and validate the failover and failback approach successfully at least once.

Disaster recovery plan
Start by creating a recovery plan. The plan is considered complete after it's been fully
tested. Include the people, processes, and applications needed to restore functionality
within the service-level agreement (SLA) that you've defined for your customers.
Consider the following suggestions when you create and test your disaster recovery
plan:
Describe how to contact support and how to escalate issues. This information
helps to avoid prolonged downtime as you work out the recovery process for the
first time.

Evaluate the business impact of application failures.
Choose a cross-region recovery architecture for mission-critical applications.
Identify a specific owner of the disaster recovery plan, including automation and
testing.
Document the process, especially any manual steps.
Automate the process as much as possible.
Establish a backup strategy for all reference and transactional data, and test
backup restoration regularly.
Set up alerts for the stack of Azure services consumed by your application.
Train operations staff to execute the plan.
Perform regular disaster simulations to validate and improve the plan.
If you use Azure Site Recovery to replicate virtual machines (VMs), create a fully
automated recovery plan to failover the entire application.

Operational readiness testing
Perform an operational readiness test for failover to the secondary region and for
failback to the primary region. Many Azure services support manual failover or test
failover for disaster recovery drills. You can simulate an outage by shutting down or
removing Azure services.
Automated operational responses should be tested frequently as part of the normal
application lifecycle to ensure operational effectiveness.

Failover and failback testing
Test failover and failback to verify that your application's dependent services come back
up in a synchronized manner during disaster recovery. Changes to systems and
operations might affect failover and failback functions, but the impact might not be
detected until the main system fails or becomes overloaded. Test failover capabilities
before they're required to compensate for a live problem. Also, be sure dependent
services failover and failback in the correct order.
If you use Azure Site Recovery to replicate VMs, run disaster recovery drills periodically
by testing failovers to validate your replication strategy. A test failover doesn't affect the
ongoing VM replication or your production environment. For more information, see Run
a disaster recovery drill to Azure.

Dependent service outage

For each dependent service, you should understand the implications of service
disruption and how the application responds. Many services include features that
support resiliency and availability, so evaluating each service independently is likely to
improve your disaster recovery plan. For example, Azure Event Hubs supports failing
over to the secondary namespace.

Network outage
When parts of the Azure network are inaccessible, you might not be able to access your
application or data. For this situation, you should design the disaster recovery strategy
to run most applications with reduced functionality.
If reducing functionality isn't an option, the remaining options are application downtime
or failover to an alternate region.
In a reduced functionality scenario:
If your application can't access its data because of an Azure network outage, you
can run locally with reduced application functionality by using cached data.
You can store data in an alternate location until connectivity is restored.

Recovery automation
The steps required to recover or failover the application to a secondary Azure region in
failure situations should be codified, preferably in an automated manner, to ensure
capabilities exist to respond effectively to an outage in a way that limits impact. Similar
codified steps should also exist to capture the process required to failback the
application to the primary region once a failover triggering issue has been addressed.
When automating failover procedures, ensure that the tooling used for orchestrating
the failover is also considered in the failover strategy. For example, if you run your
failover from Jenkins running on a VM, you'll be in trouble if that virtual machine is part
of the outage. Azure DevOps Projects are scoped to a region too.

Backup strategy
Many alternative strategies are available for implementing distributed compute across
regions. These strategies must be tailored to the specific business requirements and
circumstances of the application. At a high level, the approaches can be divided into the
following categories:

Redeploy on disaster: In this approach, the application is redeployed from scratch
at the time of disaster. Redeploying from scratch is appropriate for non-critical
applications that don't require a guaranteed recovery time.
Warm spare (Active/Passive): Create a secondary hosted service in an alternate
region, and deploy roles to guarantee minimal capacity. However, these roles don't
receive production traffic. This approach is useful for applications that haven't
been designed to distribute traffic across regions.
Hot spare (Active/Active): The application is designed to receive production load
in multiple regions. The cloud services in each region might be configured for
higher capacity than required for disaster recovery purposes. Instead, the cloud
services might scale out as necessary at the time of a disaster and failover. This
approach requires a large investment in application design, but it has significant
benefits. These include low and guaranteed recovery time, continuous testing of all
recovery locations, and efficient usage of capacity.

Plan for regional failures
Azure is divided physically and logically into units called regions. A region consists of
one or more datacenters in close proximity. Many regions and services also support
availability zones, which can be used to provide more resiliency against outages in a
single datacenter. Consider using regions with availability zones to improve the
availability of your solution.
Under rare circumstances, it's possible that facilities in an entire availability zone or
region can become inaccessible, for example, because of network failures. Or, facilities
can be lost entirely, for example, because of a natural disaster. Azure has capabilities for
creating applications that are distributed across zones and regions. Such distribution
helps to minimize the possibility that a failure in one zone or region could affect other
zones or regions.

Related links
For information on testing failovers, see Run a disaster recovery drill to Azure.
For information on Event Hubs, see Azure Event Hubs .
Go back to the main article: Testing for reliability

Next step

Automatic retry of failed backup jobs

Automatic retry of failed backup jobs
Article • 05/30/2023

Azure Backup is a simple, secure, and cost-effective solution that comprehensively
protects your data assets in Azure and requires zero infrastructure. Azure's built-in data
protection covers a wide range of workloads, and helps protect your mission-critical
workloads running in the cloud. Azure ensures that your backups are always available
and managed at scale across your entire backup estate.
As a backup user or administrator, you can monitor all backup solutions and configure
alerts to notify you about important events.
Many failures or outages are transient. You can solve them just by retrying the backup,
or the restore job. However, waiting for an engineer to retry the job manually or assign
the relevant permission wastes valuable time. Automation is the smarter way to retry
failed jobs, and ensures that you continue to meet your target Recovery Point Objectives
(RPOs) with one successful backup per day.
Retrieve relevant backup data through Azure Resource Graph (ARG) and combine the
data with corrective PowerShell and CLI steps. This article explains how you can retry
backups for all failed jobs using ARG and PowerShell.

Prerequisites
You need an Azure Automation account. You can use an existing account or create a
new account with one user-assigned managed identity, at minimum.

Add modules
After you create the automation account, install the following modules by navigating to
the individual module gallery:
Az.Accounts
Az.RecoveryServices
Az.Resources
Az.ManagedServiceIdentity
Az.Graph

Assign permissions to managed identities

To assign permissions to managed identities, complete the following steps:
1. Sign in to Azure interactively using the Connect-AzAccount cmdlet and follow the
instructions:
Azure PowerShell

# Sign in to your Azure subscription
$sub = Get-AzSubscription -ErrorAction SilentlyContinue
if(-not($sub))
{
Connect-AzAccount
}
# If you have multiple subscriptions, set the one to use
# Select-AzSubscription -SubscriptionId <SUBSCRIPTIONID>

2. Provide an appropriate value for the following variables, and then run the script:
Azure PowerShell

$resourceGroup = "resourceGroupName"
# These values are used in this tutorial
$automationAccount = "xAutomationAccount"
$userAssignedManagedIdentity = "xUAMI"

3. Use the PowerShell cmdlet New-AzRoleAssignment to assign a role to the systemassigned managed identity:
PowerShell

$role1 = "DevTest Labs User"
$SAMI = (Get-AzAutomationAccount -ResourceGroupName $resourceGroup
-Name $automationAccount).Identity.PrincipalId
New-AzRoleAssignment
-ObjectId $SAMI
-ResourceGroupName $resourceGroup
-RoleDefinitionName $role1

4. You need the same role assignment for the user-assigned managed identity:
PowerShell

$UAMI = (Get-AzUserAssignedIdentity -ResourceGroupName
$resourceGroup -Name $userAssignedManagedIdentity).PrincipalId

New-AzRoleAssignment
-ObjectId $UAMI
-ResourceGroupName $resourceGroup
-RoleDefinitionName $role1

5. You need extra permissions for the system-assigned managed identity to run the
cmdlets Get-AzUserAssignedIdentity and Get-AzAutomationAccount :
PowerShell

$role2 = "Reader"
New-AzRoleAssignment
-ObjectId $SAMI
-ResourceGroupName $resourceGroup
-RoleDefinitionName $role2

Create a PowerShell runbook
To create a runbook that can be run by managed identities, complete the following
steps:
1. Sign in to the Azure portal

and navigate to your Automation account.

2. Under Process Automation in the side panel, select Runbooks.
3. Select Create a runbook:
a. Name the runbook miTesting.
b. From the Runbook type dropdown menu, select PowerShell.
c. Select Create.
4. In the runbook editor, paste the following code:
PowerShell

$connection = Get-AutomationConnection -Name AzureRunAsConnection
$connectionResult = Connect-AzAccount
-ServicePrincipal
-Tenant $connection.TenantID
-ApplicationId $connection.ApplicationID
-CertificateThumbprint $connection.CertificateThumbprint
"Login successful.."
$query = "RecoveryServicesResources
| where type in~ ('microsoft.recoveryservices/vaults/backupjobs')
| extend vaultName = case(type =~
'microsoft.dataprotection/backupVaults/backupJobs',

properties.vaultName,type =~
'Microsoft.RecoveryServices/vaults/backupJobs', split(split(id,
'/Microsoft.RecoveryServices/vaults/')[1],'/')[0],'--')
| extend friendlyName = case(type =~
'microsoft.dataprotection/backupVaults/backupJobs',
strcat(properties.dataSourceSetName , '/', properties.dataSourceName),
type =~ 'Microsoft.RecoveryServices/vaults/backupJobs',
properties.entityFriendlyName, '--')
| extend dataSourceType = case(type =~
'Microsoft.RecoveryServices/vaults/backupJobs',
properties.backupManagementType, type =~
'microsoft.dataprotection/backupVaults/backupJobs',
properties.dataSourceType, '--')
| extend protectedItemName = split(split(properties.backupInstanceId,
'protectedItems')[1],'/')[1]
| extend vaultId = tostring(split(id, '/backupJobs')[0])
| extend vaultSub = tostring( split(id, '/')[2])
| extend jobStatus = case (properties.status == 'Completed' or
properties.status ==
'CompletedWithWarnings','Succeeded',properties.status == 'Failed',
'Failed', properties.status == 'InProgress', 'Started',
properties.status), operation = case(type =~
'microsoft.dataprotection/backupVaults/backupJobs' and
tolower(properties.operationCategory) =~ 'backup' and
properties.isUserTriggered == 'true',
strcat('adhoc',properties.operationCategory), type =~
'microsoft.dataprotection/backupVaults/backupJobs',
tolower(properties.operationCategory), type =~
'Microsoft.RecoveryServices/vaults/backupJobs' and
tolower(properties.operation) =~ 'backup' and
properties.isUserTriggered == 'true', strcat('adhoc',
properties.operation), type =~
'Microsoft.RecoveryServices/vaults/backupJobs',
tolower(properties.operation), '--'), startTime =
todatetime(properties.startTime), endTime = properties.endTime,
duration = properties.duration
| where startTime >= ago(24h)
| where (dataSourceType in~ ('AzureIaasVM'))
| where jobStatus=='Failed'
| where operation == 'backup' or operation == 'adhocBackup'
| project vaultSub, vaultId, protectedItemName, startTime, endTime,
jobStatus, operation
| sort by vaultSub"
$subscriptions = Get-AzSubscription | foreach {$_.SubscriptionId}
$result = Search-AzGraph -Subscription $subscriptions -Query $query First 5
$result = $result.data

$prevsub = ""
foreach($jobresponse in $result)
{

if($jobresponse.vaultSub -ne $prevsub)
{
Set-AzContext -SubscriptionId
$jobresponse.vaultSub
$prevsub = $jobresponse.vaultSub
}
$item = Get-AzRecoveryServicesBackupItem -VaultId
$jobresponse.vaultId -BackupManagementType AzureVM -WorkloadType
AzureVM -Name
$jobresponse.protectedItemName

Backup-AzRecoveryServicesBackupItem -ExpiryDateTimeUTC
(get-date).AddDays(10) -Item $item -VaultId $jobresponse.vaultId
}

5. Select Save and then Test pane.
You successfully created a PowerShell runbook.

Create a new schedule with PowerShell
To create a new schedule with PowerShell:
Use the New-AzAutomationSchedule cmdlet to create schedules.
Specify the start time for the schedule and the frequency it should run.
The following code example shows how to create a recurring schedule that runs every
day at 1:00 PM for one year:
PowerShell

PS C:\> $StartTime = Get-Date "13:00:00"
PS C:\> $EndTime = $StartTime.AddYears(1)
PS C:\> New-AzAutomationSchedule -AutomationAccountName
"MyAutomationAccount" -Name "Schedule02" -StartTime $StartTime -ExpiryTime
$EndTime -DayInterval 1 -ResourceGroupName "ResourceGroup01"

The first command creates a date object using the Get-Date cmdlet and then stores the
object in the $StartDate variable. The specified time must be, at least, five minutes in
the future.

The second command creates a date object using the Get-Date cmdlet and then stores
the object in the $EndDate variable. The command specifies a future time.
The final command creates a daily schedule named Schedule02 to begin at the time
stored in $StartDate and expires at the time stored in $EndDate .

Link a schedule to a runbook
Consider the following concepts when you link a schedule to a runbook:
You can link a runbook to multiple schedules, and a schedule can have multiple
runbooks linked to it.
If a runbook has parameters, you can provide values for them.
Provide values for any mandatory parameters and any optional parameters. These
values are used each time the runbook is started by this schedule.
You can attach the same runbook to another schedule and specify different
parameter values.

Link a schedule to a runbook by using
PowerShell
To link a schedule to a runbook by using PowerShell:
Use the Register-AzAutomationScheduledRunbook cmdlet to link a schedule.
You can specify parameter values for the runbook with the Parameters parameter.
For more information about how to specify parameter values, see Start a runbook in
Azure Automation.
The following code example shows how to link a schedule to a runbook by using an
Azure Resource Manager cmdlet with parameters:
PowerShell

$automationAccountName = "MyAutomationAccount"
$runbookName = "Test-Runbook"
$scheduleName = "Sample-DailySchedule"
$params =
@{"FirstName"="Joe";"LastName"="Smith";"RepeatCount"=2;"Show"=$true}
Register-AzAutomationScheduledRunbook -AutomationAccountName
$automationAccountName
-Name $runbookName -ScheduleName $scheduleName -Parameters $params `
-ResourceGroupName "ResourceGroup01"

Next steps
Error handling

Error handling for resilient applications
in Azure
Article • 05/30/2023

In a distributed system, ensuring that your application can recover from errors is critical.
You can test your applications to prevent errors and failure, but you need to prepare for
a wide range of issues. Testing doesn't always catch everything, so you should
understand how to handle errors and prevent potential failure.
Many things in a distributed system, such as underlying cloud infrastructure and thirdparty runtime dependencies, are outside your span of control and your means to test.
You can be sure something will fail eventually, so you need to be prepared.

Key points
Implement retry logic to handle transient application failures and transient failures
with internal or external dependencies.
Uncover issues or failures in your application's retry logic.
Configure request timeouts to manage intercomponent calls.
Configure and test health probes for your load balancers and traffic managers.
Segregate read operations from update operations across application data stores.

Implement retry logic
A retry pattern describes how an application handles anticipated temporary failures
when it tries to connect to a service or network resource by transparently retrying an
operation that has previously failed.
When you use a retry pattern, pay particular attention to issues and considerations.
Avoid overwhelming dependent services by implementing the Circuit Breaker pattern.
Review and incorporate other best practices for transient fault handling. While calling
systems that have throttling pattern implemented, ensure that your retries aren't
counter productive.
Samples related to this pattern

are available on GitHub.

Uncover retry logic issues

Track the number of transient exceptions and retries over time to uncover issues or
failures in your application's retry logic. A trend of increasing exceptions over time
might indicate that the service has an issue and might fail. To learn more, see Retry
guidance for Azure services.
The Circuit Breaker pattern provides stability while the system recovers from a failure
and minimizes the impact on performance. It can help to maintain the response time of
the system by quickly rejecting a request for an operation that's likely to fail, rather than
waiting for the operation to time out, or never return.
A circuit breaker might be able to test the health of a service by sending a request to an
endpoint exposed by the service. The service should return information indicating its
status.
This reference implementation

on GitHub uses Polly

and IHttpClientBuilder to

implement the Circuit Breaker pattern.

Configure request timeouts
For a service call or a database call, ensure that appropriate request timeouts are set.
Database connection timeouts are typically set to 30 seconds. For guidance on how to
troubleshoot, diagnose, and prevent SQL connection errors, see transient errors for SQL
Database.
Use design patterns that encapsulate robust timeout strategies like Choreography
pattern or Compensating Transaction pattern.
A reference implementation

is available on GitHub.

Application health probes
Configure and test health probes for your load balancers and traffic managers. Ensure
that your health endpoint checks the critical parts of the system and responds
appropriately.
For Azure Front Door and Azure Traffic Manager, the health probe determines
whether to fail over to another region. Your health endpoint should check any
critical dependencies that are deployed within the same region.
For Azure Load Balancer, the health probe determines whether to remove a virtual
machine (VM) from rotation. The health endpoint should report the health of the

VM. Don't include other tiers or external services. Otherwise, a failure that occurs
outside the VM causes the load balancer to remove the VM from rotation.
Samples related to heath probes

are available on GitHub. The samples include:

ARM template that deploys an Azure Load Balancer and health probes that detect
the health of the sample service endpoint.
An ASP.NET Core Web API that shows configuration of health checks at startup.

Command and query responsibility segregation
(CQRS)
Segregate read and write interfaces by implementing the CQRS pattern to achieve the
levels of scale and performance needed for your solution.

Related links
For information on transient faults, see Troubleshoot transient connection errors.
For guidance on implementing health monitoring in your application, see Health
Endpoint Monitoring pattern.
Go back to the main article: Testing for reliability

Next steps
Chaos engineering

Use chaos engineering to test Azure
applications
Article • 05/30/2023

Chaos engineering is a methodology that helps developers attain consistent reliability by
hardening services against production failures. Another way to think about chaos
engineering is that it's about embracing the inherent chaos in complex systems and,
through experimentation, growing confidence in your solution's ability to handle it.
A common way to introduce chaos is to deliberately inject faults that cause system
components to fail. The goal is to observe, monitor, respond to, and improve your
system's reliability under adverse circumstances. For example, taking dependencies
offline (stopping API apps, shutting down VMs, etc.), restricting access (enabling firewall
rules, changing connection strings, etc.), or forcing failover (database level, Front Door,
etc.), is a good way to validate that the application is able to handle faults gracefully.
It's difficult to simulate the characteristics of a service's behavior at scale outside a
production environment. The transient nature of cloud platforms can exacerbate this
difficulty. Architecting your service to expect failure is a core approach to creating a
modern service. Chaos engineering embraces the uncertainty of the production
environment and strives to anticipate rare, unpredictable, and disruptive outcomes, so
that you can minimize any potential effect on your customers.

Key points
Increase service resiliency and ability to react to failures.
Apply chaos principles continuously.
Create and organize a central chaos engineering team.
Follow best practices for chaos testing.

Increase resiliency
Chaos engineering is aimed at increasing your service's resiliency and its ability to react
to failures. By conducting experiments in a controlled environment, you can identify
issues that are likely to arise during development and deployment. During this process,
be vigilant in adopting the following guidelines:
Be proactive.
Embrace failure.

Break the system.
Identify and address single points of failure early.
Install guardrails and graceful mitigation.
Minimize the blast radius.
Build immunity.
Chaos engineering should be an integral part of development team culture and an
ongoing practice, not a short-term tactical effort in response to a single outage.
Development team members are partners in the process. They must be equipped with
the resources to triage issues, implement the testability that's required for fault injection,
and drive the necessary product changes.

When to apply chaos
Ideally, you should apply chaos principles continuously. There's constant change in the
environments in which software and hardware run, so monitoring the changes is key. By
constantly applying stress or faults on components, you can help expose issues early,
before small problems are compounded by many other factors.
Apply chaos engineering principles when you:
Deploy new code.
Add dependencies.
Observe changes in usage patterns.
Mitigate problems.

Process
Chaos engineering requires specialized expertise, technology, and practices. As with
security and performance teams, the model of a central team supporting the service
teams is a common, effective approach.
If you plan to practice the simulated handling of potentially catastrophic scenarios
under controlled conditions, here's a simplified way to organize your teams:
Attacker

Defender for Cloud

Inject faults

Assess

Provide hints

Analyze
Mitigate

Goals
Familiarize team members with monitoring tools.
Recognize outage patterns.
Learn how to assess the impact.
Determine the root cause and mitigate accordingly.
Practice log analysis.

Overall method
1. Start with a hypothesis.
2. Measure baseline behavior.
3. Inject a fault or faults.
4. Monitor the resulting behavior.
5. Document the process and observations.
6. Identify and act on the result.
Periodically validate your process, architecture choices, and code. By conducting faultinjection experiments, you can confirm that monitoring is in place and alerts are set up,
the directly responsible individual (DRI) process is effective, and your documentation and
investigation processes are up to date. Keep in mind a few key considerations:
Challenge system assumptions.
Validate change (topology, platform, resources).
Use service-level agreement (SLA) buffers.
Use live-site outages as opportunities.

Best practices
Shift left
Shift-left testing means experiment early, experiment often. Incorporate fault-injection
configurations and create resiliency-validation gates during the development stages and
in the deployment pipeline.

Shift right
Shift-right testing means that you verify that the service is resilient where it counts in a
preproduction or production environment with actual customer load. Adopt a proactive

approach as opposed to reacting to failures. Be a part of determining and controlling
requirements for the blast radius.

Blast radius
Stop the experiment when it goes beyond scope. Unknown results are an expected
outcome of chaos experiments. Strive to achieve balance between collecting substantial
result data and affecting as few production users as possible. For an example of this
principle in practice, see the Bulkhead pattern article.

Error budget testing
Establish an error budget as an investment in chaos and fault injection. Your error
budget is the difference between achieving 100% of the service-level objective (SLO)
and achieving the agreed-upon SLO.

Considerations for chaos testing
The following questions and answers discuss considerations about chaos engineering,
based on its application inside Azure.
Have you identified faults that are relevant to the development team?
Work closely with development teams to ensure the relevance of the injected
failures. Use past incidents or issues as a guide. Examine dependencies, and
evaluate the results when those dependencies are removed.
An external team can't hypothesize faults for your team. A study of failures from an
artificial source might be relevant to your team's purposes, but the effort must be
justified.
Have you injected faults in a way that accurately reflects production failures?
Simulate production failures. Treat injected faults in the same way that you treat
production-level faults. Enforcing a tighter limit on the blast radius lets you
simulate a production environment. Each fault-injection effort must be
accompanied by tooling that's designed to inject the types of faults that are
relevant to your team's scenarios. Here are two basic ways:
Inject faults in a non-production environment, such as Canary or Testing In
Production (TIP).
Partition the production service or environment.

If the state seems severe, halt all faults and roll back the state to its last-known
good configuration.
Have you built confidence incrementally?
Start by hardening the core, and then expand out in layers. At each point, lock in
progress with automated regression tests. Each team should have a long-term
strategy based on a progression that makes sense for the team's circumstances.
By applying the shift left strategy, you can help ensure that any obstacles to
developer usage are removed early and the testing results are actionable.
The process must be very low tax. That is, the process must make it easy for
developers to understand what happened and to fix the issues. The effort must fit
easily into your developers' normal workflow, not burden them with one-off
special activities.

Related links
For information on release testing, see Testing your application and Azure
environment.
Learn more about the Bulkhead pattern.
Go back to the main article: Testing for reliability

Next steps
Testing best practices

Best practices for testing reliability in
Azure applications
Article • 05/30/2023

This article lists Azure best practices to enhance the testing of Azure applications for
reliability. These best practices are derived from our experience with Azure reliability and
the experiences of customers like yourself.
While you design the architecture, focus on implementing practices that meet your
business requirements, and ensure that applications run in a healthy state without
significant downtime.

Test regularly
Test regularly to validate existing thresholds, targets, and assumptions. Regular testing
should be performed as part of each major change and, if possible, on a regular basis.
While most testing should be performed within the testing and staging environments,
it's often beneficial to also run a subset of tests against the production system.

Test for resiliency
To test resiliency, you should verify how the end-to-end workload performs under
intermittent failure conditions. Consider performing the following tests:
Performance testing
Simulation testing
Fault injection testing
Load testing
Operational readiness testing
Failover and failback testing

Design a backup strategy
Design a backup strategy that's tailored for the specific business requirements and
circumstances of the application. At a high level, the approaches can be divided into
these categories: 1) Redeploy on disaster, 2) Warm spare (Active/Passive), and 3) Hot
spare (Active/Active).

Design a disaster recovery strategy
When parts of the Azure network are inaccessible, you might not be able to access your
application or data. For this scenario, design a disaster recovery strategy to run most
applications with reduced functionality.

Codify steps to failover and fallback
Codify steps, preferably automatically, to failover and fallback the application to the
primary region once a failover-triggering issue has been addressed. Doing this should
ensure capabilities exist to effectively respond to an outage in a way that limits its
impact.

Plan for regional failures
Use Azure to create applications that are distributed across regions. Such distribution
helps to minimize the possibility that a failure in one region affects other regions.

Implement retry logic
Track the number of transient exceptions and retries over time to uncover issues or
failures in your application's retry logic. A trend of increasing exceptions over time
might indicate that the service has an issue and might fail.

Configure and test health probes
Configure and test health probes for your load balancers and traffic managers. Ensure
that your health endpoint checks the critical parts of the system and responds
appropriately.

Segregate read and write interfaces
By implementing the Command and Query Responsibility Segregation (CQRS) pattern to
segregate read and write interfaces, you can achieve levels of scale and performance
needed for your solution.

Next steps

Monitoring for reliability
Go back to the main article: Checklist for reliability testing

Monitoring for reliability
Article • 05/30/2023

Monitoring and diagnostics are crucial for reliability. If something fails, you need to
know that it failed, when it failed, and why.

Checklist
How do you monitor and measure application health?
＂ The application is instrumented with semantic logs and metrics.
＂ Application logs are correlated across components.
＂ All components are monitored and correlated with application telemetry.
＂ Key metrics, thresholds, and indicators are defined and captured.
＂ A health model has been defined based on performance, availability, and recovery
targets.
＂ Azure Service Health events are used to alert on applicable service level events.
＂ Azure Resource Health events are used to alert on resource health events.
＂ Monitor long-running workflows for failures.

Azure services for monitoring
Azure Monitor
Application Insights
Azure Service Health
Azure Resource Health
Azure Resource Manager
Azure Policy

Reference architecture
Hybrid availability and performance monitoring
Unified logging for microservices applications

Related links
Azure Monitor
Cloud monitoring guide

Next steps
Monitoring application health for reliability

Monitoring application health for
reliability
Article • 05/30/2023

Monitoring and diagnostics are crucial for availability and resiliency. If something fails,
you need to know that it failed, when it failed, and why.
Monitoring isn't the same as failure detection. For example, your application might
detect a transient error and retry, avoiding downtime. It should also log the retry
operation so that you can monitor the error rate to get an overall picture of application
health.

Key points
Define alerts that are actionable and effectively prioritized.
Create alerts that poll for services nearing their limits and quotas.
Use application instrumentation to detect and resolve performance anomalies.
Track the progress of long-running processes.
Troubleshoot issues to gain an overall view of application health.

Alerting
Alerts are notifications of system health issues that are found during monitoring. Alerts
only deliver value if they're actionable and effectively prioritized by on-call engineers
through defined operational procedures. Present data in a dashboard or email alert
format that makes it easy for an operator to notice problems or trends quickly.

Service-level alerts
Use Azure Service Health to respond to service level events. Azure Service Health
provides a view into the health of Azure services and regions. It issues communications
that affect the following services:
Outages
Planned maintenance activities
Other health advisories
Azure Service Health alerts should be configured to operationalize Service Health
events. However, Service Health alerts shouldn't be used to detect issues because of

associated latencies. There's a five-minute service-level objective (SLO) for automated
issues. Many issues require manual interpretation to define a root cause analysis (RCA).
Instead, alerts should be used to provide useful information to help interpret issues that
have been detected and surfaced through the health model to inform an operational
response.
For more information, see Azure Service Health.

Resource-level alerts
Use Azure Resource Health to respond to resource level events. Azure Resource Health
provides information about the health of individual resources such as a specific virtual
machine. It's useful to diagnose unavailable resources.
Azure Resource Health alerts should be configured for specific resource groups and
resource types. These alerts should be adjusted to maximize signal to noise ratios. For
example, only distribute a notification when a resource becomes unhealthy according to
the application health model or due to an Azure platform initiated event.
It's important to consider transient issues when setting an appropriate threshold for
resource unavailability. For example, configure an alert for a virtual machine with a
threshold of one minute for unavailability before an alert is triggered.
For more information, see Azure Resource Health.

Dashboards
You can also get a full-stack view of application state by using Azure dashboards to
create a combined view of monitoring graphs from the following sources:
Application Insights
Azure Monitor Logs
Azure Monitor metrics
Service Health

Samples
Here are some samples about creating and querying alerts:
HealthAlerts . A sample about creating resource-level health activity log alerts.
The sample uses Azure Resource Manager to create alerts.

GraphAlertsPsSample

. Azure PowerShell and Azure commands that query for

alerts generated against your subscription.

Azure subscription and service limits
Azure subscriptions have limits on certain resource types, such as number of resource
groups, cores, and storage accounts. To ensure that your application doesn't run up
against Azure subscription limits, create alerts that poll for services nearing their limits
and quotas.
Address the following subscription limits with alerts.

Individual services
Individual Azure services have consumption limits on:
Storage
Throughput
Number of connections
Requests per second
Your application fails if it attempts to use resources beyond these limits. This situation
results in service throttling and possible downtime.
Depending on the specific service and your application requirements, you can often stay
under these limits by scaling up or scaling out. Scaling up could involve choosing
another pricing tier. Scaling out involves adding new instances.

Azure storage scalability and performance targets
Azure allows a maximum number of storage accounts per subscription. If your
application requires more storage accounts than are currently available in your
subscription, create a new subscription with extra storage accounts. For more
information, see Azure subscription and service limits, quotas, and constraints.

Scalability targets for virtual machine disks
An Azure infrastructure as a service (IaaS) virtual machine supports attaching many data
disks, depending on several factors. The factors include the virtual machine size and the
type of storage account. If your application exceeds the scalability targets for virtual

machine disks, provision more storage accounts and create the virtual machine disks
there. For more information, see Scalability and performance targets for VM disks.

Virtual machine size
If the actual CPU, memory, disk, and I/O of your virtual machines approach the limits of
the virtual machine size, your application might experience capacity issues. To correct
the issues, increase the virtual machine size.
If your workload fluctuates over time, consider using Azure Virtual Machine Scale Sets to
automatically scale the number of virtual instances. Otherwise, you need to manually
increase or decrease the number of virtual machines.

Azure SQL Database
If your Azure SQL Database tier isn't adequate to handle your application's Database
Transaction Unit (DTU) requirements, your data use is throttled. For more information on
selecting the correct service plan, see Compare vCore and DTU-based purchasing
models.

Instrumentation
Use instrumentation to measure the customer experience. Effective instrumentation is
vital for detecting and resolving performance anomalies that can affect customer
experience and application availability. To build a robust application health model, it's
vital that you achieve visibility into the operational state of critical internal
dependencies, such as a shared Network Virtual Appliance (NVA) or Azure ExpressRoute
connection.
Automated failover and failback systems depend on the correct functioning of
monitoring and instrumentation. Dashboards that visualize system health and operator
alerts also depend on having accurate monitoring and instrumentation. These elements
might fail, miss critical information, or report inaccurate data. If so, an operator might
not realize that the system is unhealthy or failing. Make sure that you include
monitoring systems in your test plan.
Use applications to track calls to dependent services. Dependency tracking and
measuring the duration or status of dependency calls is also vital to measuring overall
application health. It should be used to inform a health model for the application.
We recommend collecting and storing logs and key metrics of critical components.

Provide rich instrumentation:
For failures that are likely, but haven't yet occurred, provide enough data to
determine the cause, mitigate the situation, and ensure that the system remains
available.
For failures that have already occurred, the application should return an
appropriate error message to the user. The application should attempt to continue
running despite reduced functionality.
Monitoring systems should capture comprehensive details so that applications can be
restored efficiently. Designers and developers can modify the system to prevent the
situation from recurring.

Long-running workflow failures
Long-running workflows often include multiple steps, each of which should be
independent.
Track the progress of long-running processes to minimize the likelihood that the entire
workflow needs to be rolled back or that multiple compensating transactions need to be
run.
 Tip
Monitor and manage the progress of long-running workflows by implementing a
pattern such as Scheduler Agent Supervisor.

Analysis and diagnosis
Analyze data combined in the data stores to troubleshoot issues and gain an overall
view of application health. Generally, you can search for and analyze the data in
Application Insights and Azure Monitor Logs using Kusto queries. View preconfigured
graphs using management solutions. Use Azure Advisor to view recommendations with
a focus on resiliency and performance.

Related links
For information on dashboards, see Azure dashboards.
For information on virtual machine sizes, see Sizes for virtual machines in Azure.
For information on scale sets, see Virtual Machine Scale Sets overview.

Next steps
Health modeling for reliability
Go back to the main article: Monitoring for reliability

Health modeling for reliability
Article • 05/30/2023

The health model should be able to surface the health of critical system flows or key
subsystems to ensure that appropriate operational prioritization is applied. For example,
the health model should be able to represent the current state of the user sign-in
transaction flow.
The health model shouldn't treat all failures the same. The health model should
distinguish between transient and nontransient faults. It should clearly distinguish
between expected-transient but recoverable failures and a true disaster state.

Key points
Know how to tell if an application is healthy or unhealthy.
Understand the effects of logs in diagnostic data.
Ensure the consistent use of diagnostic settings across the application.
Use critical system flows in your health model.

Healthy and unhealthy states
A health model defines what healthy and unhealthy states represent for the application.
A holistic application health model should be used to quantify what healthy and
unhealthy states represent across all application components.
We highly recommend that a traffic light model is used to indicate a green or healthy
state when key nonfunctional requirements and targets are fully satisfied. Indicate a
healthy state when resources are optimally utilized. For example, 95 percent of requests
are processed in <= 500 ms with AKS node utilization at x% . Once established, this
health model should inform critical monitoring metrics across system components and
operational subsystem composition.

Quantify application states
Application level events should be automatically correlated with resource level metrics
to quantify the current application state. The overall health state can be affected by both
application level issues and resource level failures.

Application logs
Application logs are an important source of diagnostics data. To gain insight when you
need it most, follow these best practices for application logging:
Use semantic, or structured, logging.
With structured logs, it's easier to automate the consumption and analysis of the
log data, which is especially important at cloud scale. We recommend storing
Azure resources metrics and diagnostics data in an Azure Monitor Logs workspace
rather than in a storage account. This way, you can use Kusto queries to obtain the
data you want quickly and in a structured format. You can also use Azure Monitor
APIs.
Log data in the production environment.
Capture robust data while the application is running in the production
environment. You need sufficient information to diagnose the cause of issues in
the production state.
Log events at service boundaries.
Include a correlation ID that flows across service boundaries. If a transaction flows
through multiple services and one of them fails, the correlation ID helps you track
requests across your application and pinpoint why the transaction failed.
Use asynchronous logging.
Synchronous logging operations sometimes block your application code. This
situation causes requests to back up as logs are written. Use asynchronous logging
to preserve availability during application logging.
Separate application logging from auditing.
Audit records are commonly maintained for compliance or regulatory
requirements and must be complete. To avoid dropped transactions, maintain
audit logs separately from diagnostic logs.
All application resources should be configured to route diagnostic logs and metrics to
the chosen log aggregation technology. Azure Policy

should also be used to ensure

the consistent use of diagnostic settings across the application, which enforces the
desired configuration for each Azure service.
Telemetry correlation should be used to ensure that transactions can be mapped
through the end-to-end application and critical system flows. This process is vital to root

cause analysis (RCA) for failures. Platform level metrics and logs, such as CPU
percentage, network in/out, and disk operations/sec, should be collected from the
application to inform a health model and to detect and predict issues. This approach can
also help to distinguish between transient and nontransient faults.

White-box and black-box monitoring
Use white-box monitoring to instrument the application with semantic logs and metrics.
Application level metrics and logs, such as current memory consumption or request
latency, should be collected from the application to inform a health model and to detect
and predict issues.
Use black-box monitoring to measure platform services and the resulting customer
experience. Black-box monitoring tests externally visible application behavior without
knowledge of the internals of the system. This approach is common for measuring
customer-centric service-level indicators (SLIs), service-level objectives (SLOs), and
service-level agreements (SLAs).

Use critical system flows in the health model
The health model should be able to surface the respective health of critical system flows
or key subsystems to ensure that appropriate operational prioritization is applied. For
example, the health model should be able to represent the current state of the user
sign-in transaction flow.

Create good health probes
The health and performance of an application can degrade over time. That degradation
might not be noticeable until the application fails.
Implement probes or check functions. Run them regularly from outside the application.
These checks can be as simple as measuring response time for the application as a
whole, for individual parts of the application, for specific services that the application
uses, or for separate components.
Check functions can run processes to ensure that they produce valid results, measure
latency and check availability, and extract information from the system.
The HealthProbesSample

sample shows how to set up health probes. It provides

an Azure Resource Manager template to set up the infrastructure. A load balancer

accepts public requests and load balances to a set of virtual machines. The health probe
is set up so that it can check for service's path /Health.

Related links
For information on monitoring metrics, see Azure Monitor Metrics overview.
For information on using Application Insights, see Application Insights.

Next steps
Monitoring best practices for reliability
Go back to the main article: Monitoring for reliability

Best practices for monitoring reliability
in Azure applications
Article • 05/30/2023

This article describes Azure best practices to enhance monitoring Azure applications for
reliability. These best practices are derived from our experience with Azure reliability and
the experiences of customers like yourself.
Implement these best practices for monitoring and alerts in your application so that you
can detect failures and alert an operator to fix them.

Implement health probes and check functions
Run health probes and check functions regularly from outside the application to identify
degradation of application health and performance.

Check long-running workflows
Catching issues early can minimize the need to roll back the entire workflow or run
multiple compensating transactions.

Maintain application logs
Log applications in production and at service boundaries.
Use semantic and asynchronous logging.
Separate application logs from audit logs.

Measure remote call statistics
Measure remote call statistics, and share the data with the application team. This data
gives the team an instantaneous view into application health and summarizes remote
call metrics, such as latency, throughput, and errors in the 99 and 95 percentiles.
Perform statistical analysis on the metrics to uncover errors that occur in each percentile.

Track transient exceptions and retries

A trend of increasing exceptions over time indicates that the service has an issue and
might fail. Track transient exceptions and retries over an appropriate time frame to
prevent failure.

Set up an early warning system
Identify the key performance indicators (KPIs) of an application's health, such as
transient exceptions and remote call latency. Set appropriate threshold values for each
KPI. Send an alert to operations when the threshold value is reached.

Operate within Azure subscription limits
Azure subscriptions have limits on certain resource types, such as the number of
resource groups, cores, and storage accounts. Watch your use of resource types.

Monitor third-party services
Log your invocations and correlate them with your application's health and diagnostic
logging using a unique identifier.

Train multiple operators
Train multiple operators to monitor the application and to perform manual recovery
steps. Make sure there's always at least one trained operator active.

Next steps
Go back to the main article: Monitoring for reliability

Reliability patterns
Article • 06/16/2023

The document offers an insightful and comprehensive resource for understanding the
principles and techniques behind building highly reliable and resilient systems in the
cloud. Covering a wide range of topics such as fault tolerance, redundancy, monitoring,
and recovery, this guide equips architects and developers with essential knowledge to
design robust solutions that can withstand failures and deliver continuous availability.

Availability
Availability is measured as a percentage of uptime, and defines the proportion of time
that a system is functional and working. Availability is affected by system errors,
infrastructure problems, malicious attacks, and system load. Cloud applications typically
provide users with a service-level agreement (SLA), which means that applications must
be designed and implemented to maximize availability.
Pattern

Summary

Deployment
Stamps

Deploy multiple independent copies of application components, including data
stores.

Geode

Deploy backend services into a set of geographical nodes, each of which can
service any client request in any region.

Health

Implement functional checks in an application that external tools can access

Endpoint
Monitoring

through exposed endpoints at regular intervals.

Queue-Based

Use a queue that acts as a buffer between a task and a service that it invokes to

Load Leveling

smooth intermittent heavy loads.

Rate Limit

Limiting pattern to help you avoid or minimize throttling errors related to these

Pattern

throttling limits and to help you more accurately predict throughput.

Throttling

Control the consumption of resources by an instance of an application, an
individual tenant, or an entire service.

To mitigate against availability risks from malicious distributed denial of service (DDoS)
attacks, implement the native Azure DDoS protection service or a third-party capability.

High availability

Azure infrastructure is composed of geographies, regions, and availability zones. These
divisions limit the radius of a failure and therefore limit potential effect on customer
applications and data. The Azure availability zones construct was developed to provide a
software and networking solution to protect against datacenter failures and to provide
increased high availability. With high availability architecture, there's a balance between
high resilience, low latency, and cost.
Pattern

Summary

Deployment
Stamps

Deploy multiple independent copies of application components, including
data stores.

Geode

Deploy backend services into a set of geographical nodes. Each node can
service any client request in any region.

Health Endpoint

Implement functional checks in an application that external tools can access

Monitoring

through exposed endpoints at regular intervals.

Bulkhead

Isolate elements of an application into pools. If one element fails, the others
continue to function.

Circuit Breaker

Handle faults that might take a variable amount of time to fix when
connecting to a remote service or resource.

Resiliency
Resiliency is the ability of a system to gracefully handle and recover from failures, both
inadvertent and malicious.
In cloud hosting, applications are often multi-tenant, use shared platform services,
compete for resources and bandwidth, communicate over the Internet, and run on
commodity hardware. This situation means there's an increased likelihood for both
transient and permanent faults to arise. The connected nature of the internet and the
rise in sophistication and volume of attacks increase the likelihood of a security
disruption.
To detect failures and recovering quickly and efficiently, it's necessary to maintain
resiliency.
Pattern

Summary

Bulkhead

Isolate elements of an application into pools. If one element fails, the others
continue to function.

Circuit Breaker

Handle faults that might take a variable amount of time to fix when connecting
to a remote service or resource.

Pattern

Summary

Compensating

Undo the work performed by a series of steps, which together define an

Transaction

eventually consistent operation.

Health

Implement functional checks in an application that external tools can access

Endpoint
Monitoring

through exposed endpoints at regular intervals.

Leader
Election

Coordinate the actions performed by a collection of collaborating task instances
in a distributed application by electing one instance as the leader. The leader
assumes responsibility for managing the other instances.

Queue-Based

Use a queue that acts as a buffer between a task and a service that it invokes.

Load Leveling

This queue smooths intermittent heavy loads.

Retry

Enable an application to handle anticipated, temporary failures when it tries to
connect to a service or network resource by transparently retrying an operation
that's previously failed.

Scheduler

Coordinate a set of actions across a distributed set of services and other remote

Agent
Supervisor

resources.

Security documentation
Apply security principles to your architecture to protect against attacks on your data and
systems.

Key points

ｆ

QUICKSTART

Overview
Principles
Design governance
Identity checklist
Network checklist
Data checklist
Build and deploy checklist
Monitor checklist
Governance, risk, and compliance

ｄ

TRAINING

Security

ｑ

VIDEO

Cloud Security Posture Management (CSPM) with Microsoft Defender for Cloud

Design for security

ｂ

GET STARTED

Plan segmentation
Consider team roles and responsibilities
Implement network segmentation
Encrypt data

Understand application security

ｐ

CONCEPT

Support segmentation with management groups
Identity management and access control best practices
Network best practices
Encryption best practices
Analyze application threats
Gather compliance requirements
Secure application configuration and dependencies

ｄ

TRAINING

Design and implement network security

ｈ

WHAT'S NEW

What's new in Azure Network Security?

Secure build and deploy

ｅ

OVERVIEW

Consider secure deployment governance
Understand infrastructure provisioning
Deploy code

ｐ

CONCEPT

Minimize access
Understand Infrastructure as Code (IaC)
Roll back and roll forward
Scanning credentials

ｑ

VIDEO

Ask the right questions about secure application development on Azure

Security monitoring

ｅ

OVERVIEW

Security monitoring tools in Azure
Security operations in Azure
Validate and test security design
Review and audit security posture
Check for identity, network, and data risks

ｐ

CONCEPT

Prevent, detect, and respond to threats
Security operations best practices
Penetration testing (pentesting)
Review critical access
Review identity risks

ｑ

VIDEO

Improving app security with Application Security Groups

Optimize security

ｐ

CONCEPT

Prioritize security best practices investments
Use Azure Secure Score
Manage connected tenants
Designate clear lines of responsibility

ｑ

VIDEO

Enabling secure remote work with using Windows Virtual Desktop

Security tools and services

ｉ

REFERENCE

Azure AD Conditional Access
Azure AD Connect
Azure AD Privileged Identity Management (PIM)
Azure Key Vault
Azure Resource Manager
Azure role-based access control (RBAC)
Azure Storage Service Encryption
Microsoft Azure Well-Architected Review
Multifactor Authentication
Passwordless

Security APIs

ｉ

REFERENCE

Microsoft Defender for Cloud
Adaptive Network Hardenings
Alerts
Iot Security Solution
Secure Scores

Overview of the security pillar
Article • 11/30/2022

Information security has always been a complex subject, and it evolves quickly with the
creative ideas and implementations of attackers and security researchers. The origin of
security vulnerabilities started with identifying and exploiting common programming
errors and unexpected edge cases. However over time, the attack surface that an
attacker may explore and exploit has expanded well beyond these common errors and
edge cases. Attackers now freely exploit vulnerabilities in system configurations,
operational practices, and the social habits of the systems' users. As system complexity,
connectedness, and the variety of users increase, attackers have more opportunities to
identify unprotected edge cases. Attackers can hack systems into doing things they
weren't designed to do.
Security is one of the most important aspects of any architecture. It provides the
following assurances against deliberate attacks and abuse of your valuable data and
systems:
Confidentiality
Integrity
Availability
Losing these assurances can negatively affect your business operations and revenue,
and your organization's reputation. For the security pillar, we'll discuss key architectural
considerations and principles for security and how they apply to Azure.
The security of complex systems depends on understanding the business context, social
context, and technical context. As you design your system, cover these areas:

Understanding an IT solution as it interacts with its surrounding environment holds the
key to preventing unauthorized activity and to identifying anomalous behavior that may

represent a security risk.
Another key factor in success: Adopt a mindset of assuming failure of security controls.
Assuming failure allows you to design compensating controls that limit risk and damage
if a primary control fails.
Assuming failures can be referred to as assume breach or assume compromise. Assume
breach is closely related to the Zero Trust approach of continuously validating security
assurances. The Zero Trust approach is described in the Security Design Principles
section in more detail.
Cloud architectures can help simplify the complex task of securing an enterprise estate
through specialization and shared responsibilities:
Specialization: Specialist teams at cloud providers can develop advanced capabilities to
operate and secure systems on behalf of organizations. This approach is preferable to
numerous organizations individually developing deep expertise on managing and
securing common elements, such as:
Datacenter physical security
Firmware patching
Hypervisor configuration
The economies of scale allow cloud provider specialist teams to invest in optimization of
management and security that far exceeds the ability of most organizations.
Cloud providers must be compliant with the same IT regulatory requirements as the
aggregate of all their customers. Providers must develop expertise to defend against the
aggregate set of adversaries who attack their customers. As a consequence, the default
security posture of applications deployed to the cloud is frequently much better than
that of applications hosted on-premises.
Shared Responsibility Model: As computing environments move from customercontrolled datacenters to the cloud, the responsibility of security also shifts. Security of
the operational environment is now a concern shared by both cloud providers and
customers. Organizations can reduce focus on activities that aren't core business
competencies by shifting these responsibilities to a cloud service like Azure. Depending
on the specific technology choices, some security protections will be built into the
particular service, while addressing others will remain the customer's responsibility. To
ensure that proper security controls are provided, organizations must carefully evaluate
the services and technology choices.

Shared Responsibility and Key Strategies:
After reading this document, you'll be equipped with key insights about how to improve
the security posture of your architecture.
As part of your architecture design, you should consider all relevant areas that affect the
success of your application. While this article is concerned primarily with security
principles, you should also prioritize other requirements of a well-designed system, such
as:
Availability
Scalability
Costs
Operational characteristics (trading off one over the other as necessary)
Consistently sacrificing security for gains in other areas isn't advisable because security
risks tend to increase dynamically over time.
Increasing security risks result in three key strategies:
Establish a modern perimeter: For the elements that your organization controls to
ensure you have a consistent set of controls (a perimeter) between those assets
and the threats to them. Perimeters should be designed based on intercepting
authentication requests for the resources (identity controls) versus intercepting
network traffic on enterprise networks. This traditional approach isn't feasible for
enterprise assets outside the network.
More on perimeters and how they relate to Zero Trust and Enterprise Segmentation are
in the Governance, Risk, and Compliance and Network Security & Containment sections.
Modernize infrastructure security: For operating systems and middleware
elements that legacy applications require, take advantage of cloud technology to
reduce security risk to the organization. For example, knowing whether all servers

in a physical datacenter are updated with security patches has always been
challenging because of discoverability. Software-defined datacenters allow easy
and rapid discovery of all resources. This rapid discovery enables technology like
Microsoft Defender for Cloud to measure quickly and accurately the patch state of
all servers and remediate them.
"Trust but verify" each cloud provider: For the elements, which are under the
control of the cloud provider. You should ensure the security practices and
regulatory compliance of each cloud provider (large and small) meet your
requirements.
To assess your workload using the tenets found in the Microsoft Azure Well-Architected
Framework, see the Microsoft Azure Well-Architected Review.

We cover the following areas in the security pillar of the Microsoft Azure WellArchitected Framework:
Security
Topic

Description

Security
design

These principles describe a securely architected system hosted on cloud or onpremises datacenters, or a combination of both.

principles
Governance,
risk, and

How is the organization's security going to be monitored, audited, and
reported? What types of risks does the organization face while trying to protect

compliance

identifiable information, Intellectual Property (IP), financial information? Is there
specific industry, government, or regulatory requirements that dictate or provide
recommendations on criteria that your organization's security controls must
meet?

Regulatory
compliance

Governments and other organizations frequently publish standards to help
define good security practices (due diligence) so that organizations can avoid
being negligent in security.

Security

Description

Topic
Administration

Administration is the practice of monitoring, maintaining, and operating
Information Technology (IT) systems to meet service levels that the business
requires. Administration introduces some of the highest impact security risks
because performing these tasks requires privileged access to a broad set of
these systems and applications.

Applications
and services

Applications and the data associated with them ultimately act as the primary
store of business value on a cloud platform.

Identity and
access
management

Identity provides the basis of a large percentage of security assurances.

Information

Protecting data at rest is required to maintain confidentiality, integrity, and

protection
and storage

availability assurances across all workloads.

Network

Network security has been the traditional linchpin of enterprise security efforts.

security and
containment

However, cloud computing has increased the requirement for network
perimeters to be more porous and many attackers have mastered the art of
attacks on identity system elements (which nearly always bypass network
controls).

Security
Operations

Security operations maintain and restores the security assurances of the system
as live adversaries attack it. The tasks of security operations are described well by
the NIST Cybersecurity Framework functions of Detect, Respond, and Recover.

Identity management
Consider using Azure Active Directory (Azure AD) to authenticate and authorize users.
Azure AD is a fully managed identity and access management service. You can use it to
create domains that exist purely on Azure, or integrate with your on-premises Active
Directory identities.
Azure AD is also used by:
Microsoft 365
Dynamics 365
Many third-party applications
For consumer-facing applications, Azure Active Directory B2C lets users authenticate
with their existing social accounts, such as:
Facebook

Google
LinkedIn
Users can also create a new user account managed by Azure AD.
If you want to integrate an on-premises Active Directory environment with an Azure
network, several approaches are possible, depending on your requirements. For more
information, reference Identity Management reference architectures.

Protect your infrastructure
Control access to the Azure resources that you deploy. Every Azure subscription has a
trust relationship with an Azure AD tenant.
Use Azure role-based access control (Azure RBAC role) to grant users within your
organization the correct permissions to Azure resources. Grant access by assigning
Azure roles to users or groups at a certain scope. The scope can be a:
Subscription
Resource group
Single resource
Audit all changes to infrastructure.

Application security
In general, the security best practices for application development still apply in the
cloud. Best practices include:
Encrypt data in-transit with the latest supported TLS versions
Protect against CSRF and XSS attacks
Prevent SQL injection attacks
Cloud applications often use managed services that have access keys. Never check these
keys into source control. Consider storing application secrets in Azure Key Vault.

Data sovereignty and encryption
Make sure that your data remains in the correct geopolitical zone when using Azure
data services. Azure's geo-replicated storage uses the concept of a paired region in the
same geopolitical region.

Use Key Vault to safeguard cryptographic keys and secrets. By using Key Vault, you can
encrypt keys and secrets by using keys that are protected by hardware security modules
(HSMs). Many Azure storage and DB services support data encryption at rest, including:
Azure Storage
Azure SQL Database
Azure Synapse Analytics
Azure Cosmos DB

Security resources
Microsoft Defender for Cloud

provides integrated security monitoring and policy

management for your workload.
Azure Security Documentation
Microsoft Trust Center
The security pillar is part of a comprehensive set of security guidance that also includes:
Security in the Microsoft Cloud Adoption Framework for Azure: A high-level
overview of a cloud security end state.
Security architecture design: Implementation-level journey of our security
architectures.
Browse our security architectures
Azure security benchmarks: Prescriptive best practices and controls for Azure
security.
End-to-end security in Azure: Documentation that introduces you to the security
services in Azure.
Top 10 security best practices for Azure: Top Azure security best practices that
Microsoft recommends based on lessons learned across customers and our own
environments.
Microsoft Cybersecurity Architectures: The diagrams describe how Microsoft
security capabilities integrate with Microsoft platforms and 3rd-party platforms.

Next step
Principles

Security design principles
Article • 11/30/2022

Security design principles describe a securely architected system hosted on cloud or onpremises datacenters (or a combination of both). Application of these principles
dramatically increases the likelihood your security architecture assures confidentiality,
integrity, and availability.
To assess your workload using the tenets found in the Azure Well-Architected
Framework, reference the Microsoft Azure Well-Architected Review.
The following design principles provide:
Context for questions
Why a certain aspect is important
How an aspect is applicable to Security
These critical design principles are used as lenses to assess the Security of an application
deployed on Azure. These lenses provide a framework for the application assessment
questions.

Plan resources and how to harden them
Recommendations:
Consider security when planning workload resources.
Understand how individual cloud services are protected.
Use a service enablement framework to evaluate.

Automate and use least privilege
Recommendations:
Implement least privilege throughout the application and control plane to protect
against data exfiltration and malicious actor scenarios.
Drive automation through DevSecOps to minimize the need for human interaction.

Classify and encrypt data
Recommendations:

Classify data according to risk.
Apply industry-standard encryption at rest and in transit, which ensures keys and
certificates are stored securely and managed properly.

Monitor system security, plan incident response
Recommendations:
Correlate security and audit events to model application health.
Correlate security and audit events to identify active threats.
Establish automated and manual procedures to respond to incidents.
Use security information and event management (SIEM) tooling for tracking.

Identify and protect endpoints
Recommendations:
Monitor and protect the network integrity of internal and external endpoints
through security appliances or Azure services, such as:
Firewalls
Web application firewalls
Use industry standard approaches to protect against common attack vectors, such
as distributed denial of service (DDoS) attacks like SlowLoris.

Protect against code-level vulnerabilities
Recommendations:
Identify and mitigate code-level vulnerabilities, such as cross-site scripting and
structured query language (SQL) injection.
In the operational lifecycle, regularly incorporate:
Security fixes
Codebase and dependency patching

Model and test against potential threats
Recommendations:
Establish procedures to identify and mitigate known threats.
Use penetration testing to verify threat mitigation.
Use static code analysis to detect and prevent future vulnerabilities.

Use code scanning to detect and prevent future vulnerabilities

Next step
Design governance

Governance, risk, and compliance
Article • 04/19/2023

As part of overall design, prioritize where to invest the available resources: finances,
people, and time. Constraints on resources also affect the security implementation
across the organization. To achieve an appropriate return on investment (ROI) on
security, the organization needs to first understand and define its security priorities.
Governance: How does the organization monitor, audit, and report on its security?
The design and implementation of security controls within an organization are only
the beginning of the story. How does the organization know that things are
actually working? Are they improving? Are there new requirements? Is there
mandatory reporting? Similar to compliance, there might be external industry,
government, or regulatory standards that need to be considered.
Risk: What risk types does the organization face while trying to protect identifiable
information, intellectual property (IP), and financial information? Who might be
interested or could use this information if it's stolen, such as external and internal
threats and unintentional or malicious threats? A commonly forgotten but
important consideration within risk is addressing disaster recovery and business
continuity.
Compliance: Is there a specific industry, government, or regulatory requirements
that dictate or provide recommendations on criteria that your organization's
security controls must meet? Examples of such standards, organizations, controls,
and legislation include ISO27001 , NIST

, and PCI-DSS .

The collective role of organization(s) is to manage the security standards of the
organization through their lifecycle:
Define: Set organizational policies for operations, technologies, and configurations
based on internal factors (business requirements, risks, and asset evaluation) and
external factors (benchmarks, regulatory standards, and threat environment).
Improve: Continually push security standards incrementally towards the ideal state
to ensure continual risk reduction.
Sustain: Ensure the security posture doesn't degrade naturally over time by
instituting auditing and monitoring compliance with organizational standards.
Take action
Establish security best practices across all workloads

Establish governance best practices to detect, enforce, and automate governance
decisions

Prioritize security best practices investments
Security best practices are ideally applied proactively and completely to all systems as
you build your cloud program, but this ideal isn't the reality for most enterprise
organizations. Business goals, project constraints, and other factors often cause
organizations to balance security risk against other risks and apply a subset of best
practices at any given point.
We recommend applying as many of the best practices as early as possible, and then
working to retrofit any gaps over time as you mature your security program. Your
security program should include review, prioritization, and proactive application of best
practices to cloud resources. We recommend evaluating the following considerations
when prioritizing which to follow first:
High business impact and highly exposed systems: These include systems with
direct intrinsic value and the systems that provide attackers a path to them. For
more information, see Identify and classify business critical applications.
Easiest to implement mitigations: Identify quick wins by prioritizing the best
practices, which your organization can execute quickly because you already have
the required skills, tools, and knowledge to do it. For example, implementing a web
app firewall (WAF) to protect a legacy application. Be careful not to exclusively use
(or overuse) this short-term prioritization method. Doing so can increase your risk
by preventing your program from growing and leaving critical risks exposed for
extended periods.
Use the provided lists of prioritized security initiatives to help organizations start with
these decisions. The provided lists are based on Microsoft's experience with threats and
mitigation initiatives in internal environments and across Microsoft's customers. See
Module 4a of the Microsoft CISO Workshop.
Take action
Security in the Microsoft Cloud Adoption Framework for Azure
What is an Azure landing zone?

Checklist

What considerations for compliance and governance did you make?
＂ Create a landing zone for the workload. The infrastructure must have appropriate
controls and be repeatable with every deployment.
＂ Enforce creation and deletion of services and their configuration through Azure
Policy.
＂ Ensure consistency across the enterprise by applying policies, permissions, and tags
across all subscriptions through careful implementation of root management
group.
＂ Understand regulatory requirements and operational data that might be used for
audits.
＂ Continuously monitor and assess the compliance of your workload. Perform regular
attestations to avoid fines.
＂ Review and apply recommendations from Azure.
＂ Remediate basic vulnerabilities to keep the attacker costs high.

In this section
Follow these questions to assess the workload at a deeper level.
Assessment

Description

Are there any regulatory

Understand all regulatory requirements. Check the Microsoft

requirements for this

Trust Center for the latest information, news, and best practices

workload?

in security, privacy, and compliance.

Is the organization using a
landing zone for this
workload?

Consider the security controls placed on the infrastructure into
which the workload is deployed.

Do you have a segmentation

Reference model and strategies of how the functions and teams

strategy?

can be segmented.

Are you using management
groups as part of your

Strategies using management groups to manage resources
across multiple subscriptions consistently and efficiently.

segmentation strategy?
What security controls do you
have in place for access to
Azure infrastructure?

Guidance on reducing risk exposure in scope and time when
configuring critical impact accounts such as Administrators.

Azure security benchmark

The Azure Security Benchmark includes a collection of high-impact security
recommendations you can use to help secure the services you use in Azure:

The questions in this section are aligned to these controls:
Governance and strategy
Posture and vulnerability management

Reference architecture
Here are some reference architectures related to governance:
Cloud Adoption Framework enterprise-scale landing zone architecture

Next steps
Provide security assurance through identity management to authenticate and grant
permission to users, partners, customers, applications, services, and other entities.
Identity and access management

Related links
Go back to the main article: Security

Regulatory compliance
Article • 11/30/2022

A workload can have regulatory requirements, which may mandate that operational
data, such as application logs and metrics, remain within a certain geo-political region.
These requirements may need strict security measures that affect the overall
architecture, the selection, and configuration of specific PaaS, and SaaS services. The
requirements also have implications for how the workload should be operationalized.

Key points
＂ Make sure that all regulatory and governance requirements are known, and well
understood.
＂ Periodically perform external and, or internal workload security audits.
＂ Have compliance checks as part of the workload operations.
＂ Use Microsoft Trust Center.

Review the requirements
Regulatory organizations frequently publish standards and updates to help define good
security practices so that organizations can avoid negligence. The purpose and scope of
these standards, and regulations vary. The security requirements, however, can influence
the design for data protection and retention, network access, and system security.
Knowing whether your cloud resources are in compliance with standards mandated by
governments or industry organizations is essential in today's globalized world.
For example, a workload that handles credit card transactions is subject to the Payment
Card Industry (PCI) standard. One of the requirements prohibits access between the
internet and any system component in the cardholder data environment.
To provide a restrictive environment, you can choose to do the following:
Host the workload in different Azure compute options that supports bring your
own VNet.
Remove any internet-facing endpoints by using Private Endpoints.
Use network security groups (NSGs) rules that define authorized inbound and
outbound access.

Noncompliance can lead to fines or other business impact. Work with your regulators
and carefully review the standard to understand both the intent and the literal wording
of each requirement. Here are some questions that may help you understand each
requirement.
How is compliance measured?
Who approves that the workload meets the requirements?
Are there processes for obtaining attestations?
What are the documentation requirements?

Suggested action
Use Microsoft Defender for Cloud to assess your current compliance score and to
identify the gaps.
Learn more
Tutorial: Improve your regulatory compliance

Use the Microsoft Trust Center
Keep checking the Microsoft Trust Center

for the latest information, news, and best

practices in security, privacy, and compliance.
Data governance. Focus on protecting information in cloud services, mobile
devices, workstations, or collaboration platforms. Build the security strategy by
classifying and labeling information. Use strong access control and encryption
technology.
Compliance offerings. Microsoft offers a comprehensive set of compliance
offerings to help your organization follow national, regional, and industry-specific
requirements governing the collection and use of data. For information, see
Compliance offerings.
Compliance score. Use Microsoft Compliance Score to assess your data protection
controls on an ongoing basis. Act on the recommendations to make progress
toward compliance.
Audit reports. Use audit reports to stay current on the latest privacy, security, and
compliance-related information for Microsoft's cloud services. See Audit Reports

.

Shared responsibility. The workload can be hosted on Software as a Service (SaaS),
Platform as a Service (PaaS), Infrastructure as a Service (IaaS), or in an on-premises

datacenter. Have a clear understanding about the portions of the architecture
you're responsible for versus Azure. Whatever the hosting model, the following
responsibilities are always retained by you:
Data
Endpoints
Account
Access management
For more information, reference Shared responsibility in the cloud.

Elevated security capabilities
Consider whether to use specialized security capabilities in your enterprise architecture.
Dedicated HSMs and Confidential Computing have the potential to enhance security
and meet regulatory requirements, but can introduce complexity that may negatively
impact your operations and efficiency.

Suggested actions
We recommend careful consideration and judicious use of these security measures as
required:
Dedicated Hardware Security Modules (HSMs)
Dedicated Hardware Security Modules (HSMs) may help meet regulatory or
security requirements.
Confidential Computing
Confidential Computing may help meet regulatory or security requirements
Learn more about elevated security capabilities for Azure workloads

.

.

Operational considerations
Regulatory requirements may influence the workload operations. For example, there
might be a requirement that operational data, such as application logs and metrics,
remain within a certain geo-political region.
Consider automation of deployment and maintenance tasks. Automation reduces
security and compliance risk by limiting opportunity to introduce human errors during
manual tasks.

Related links
Azure maintains a compliance portfolio that covers US government, industry specific,
and region/country standards. For more information, reference Azure compliance
offerings.
Monitor the compliance of the workload to check if the security controls are aligned to
the regulatory requirements. For more information, reference Security audits.
Go back to the main article: Governance

Next
Azure landing zone

Azure landing zone integration
Article • 04/19/2023

From a workload perspective, a landing zone refers to a prepared platform into which
the application gets deployed. A landing zone implementation can have compute, data
sources, access controls, and networking components already provisioned. With the
required plumbing ready in place; the workload needs to plug into it. When considering
the overall security, a landing zone offers centralized security capabilities that adds a
threat mitigation layer for the workload. Implementations can vary but here are some
common strategies that enhance the security posture.
Isolation through segmentation. You can isolate assets at several layers from Azure
enrollment down to a subscription that has the resources for the workload. This
strategy of having resources within a boundary that is separate from other parts of
the organization is an effective way of detecting and containing adversary
movements.
Consistent adoption of organizational policies. Policies govern which resources can
be used and their usage limits. Policies also provide identity controls. Only
authenticated and authorized entities are allowed access. This approach decouples
the governance requirements from the workload requirements. It's crucial that a
landing zone is handed over to the workload owner with the security guardrails
deployed.
Configurations that align with principles of Zero Trust . For instance an
implementation might have network connectivity to on-premises data centers.
When designing networking controls, the landing zone may apply the leastprivilege principle by opening communication paths only when necessary and only
to trusted entities.
The preceding examples are conceptually simple but the implementation can get
complicated for an enterprise-scale deployment. Azure landing zone as part of the
Cloud Adoption Framework (CAF) provides architecture guidance about identity and
access management, networking, and other design areas necessary to achieve an
optimal implementation.
Learn more
What is an Azure landing zone?
Landing zone implementation options

Increase automation with Azure Blueprints
Use Azure's native automation capabilities to increase consistency, compliance, and
deployment speed for workloads. A recommended way to implement a landing zone is
with Azure Blueprints and Azure Policies.
Automation of deployment and maintenance tasks reduces security and compliance risk
by limiting opportunity to introduce human errors during manual tasks. This will also
allow both IT Operations teams and security teams to shift their focus from repeated
manual tasks to higher value tasks like enabling developers and business initiatives,
protecting information, and so on.
Utilize the Azure Blueprint service to rapidly and consistently deploy application
environments that are compliant with your organization's policies and external
regulations. Azure Blueprint Service automates deployment of environments including
Azure roles, policies, resources, such as virtual machines, networking, storage, and more.
Azure Blueprints builds on Microsoft's significant investment into the Azure Resource
Manager to standardize resource deployment in Azure and enable resource deployment
and governance based on a desired-state approach. You can use built in configurations
in Azure Blueprint, make your own, or just use Resource Manager scripts for smaller
scope.
Several Security and Compliance Blueprints samples are available to use as a starting
template.

Enforce policy compliance
Organizations of all sizes will have security compliance requirements. Industry,
government, and internal corporate security policies all need to be audited and
enforced. Policy monitoring is critical to check that initial configurations are correct and
that it continues to be compliant over time.
In Azure, you can take advantage of Azure Policy to create and manage policies that
enforce compliance. Like Azure Blueprints, Azure Policies are built on the underlying
Azure Resource Manager capabilities in the Azure platform (and Azure Policy can also be
assigned via Azure Blueprints).
For more information on how to do this in Azure, please review Tutorial: Create and
manage policies to enforce compliance.
How do you consistently deploy landing zones that follow organizational policies?
Key Azure services that can help in creating a landing zone:

Azure Blueprints sketches a solution's design parameters based on an
organization's standards, patterns, and requirements.
Azure Resource Manager template specs stores an Azure Resource Manager
template (ARM template) in Azure for later deployment.
Azure Policy enforces organizational standards and to assess compliance at-scale.
Azure AD

and Azure role-based access control (Azure RBAC) work in conjunction

to provide identity and access controls.
Microsoft Defender for Cloud

Architecture
For information about an enterprise-scale reference architecture, see Cloud Adoption
Framework enterprise-scale landing zone architecture. The architecture provides
considerations in these critical design areas:
Enterprise Agreement (EA) enrollment and Azure Active Directory tenants
Identity and access management
Management group and subscription organization
Network topology and connectivity
Management and monitoring
Business continuity and disaster recovery
Security, governance, and compliance
Platform automation and DevOps

Next
Use management groups to manage resources across multiple subscriptions
consistently and efficiently.
Management groups
Back to the main article: Governance

Segmentation strategies
Article • 04/19/2023

Segmentation refers to the isolation of resources from other parts of the organization.
Segmentation is an effective way of detecting and containing adversary movements.
One approach to segmentation is network isolation. This approach isn't ideal, because
different technical teams may not be aligned with the business use cases and
application workloads. One outcome of such a mismatch is complexity, as especially
seen with on-premises networking, and can lead to reduced velocity, or in worse cases,
broad network firewall exceptions. Although network control should be considered as a
segmentation strategy, it should be part of a unified segmentation strategy.
Network security has been the traditional linchpin of enterprise security efforts.
However, cloud computing has increased the requirement for network perimeters to be
more porous. Many attackers have mastered the art of attacks on identity system
elements (which nearly always bypass network controls). These factors have increased
the need to focus primarily on identity-based access controls to protect resources rather
than network-based access controls.
An effective segmentation strategy guides all technical teams (IT, security, applications)
to consistently isolate access using networking, applications, identity, and any other
access controls. The strategy should aim to:
Minimize operational friction by aligning to business practices and applications
Contain risk by adding cost to attackers. You can contain risk by:
Isolating sensitive workloads from compromise by other assets.
Isolating high-exposure systems from being used as a pivot to other systems.
Monitor operations that might lead to potential violation of the integrity of the
segments (account usage, unexpected traffic).
Here are some recommendations for creating a unified strategy:
Ensure alignment of technical teams to a single strategy based on assessing
business risks.
Establish a modern perimeter based on zero-trust principles, focused on identity,
devices, applications, and other signals. Establishing modern perimeters helps to
overcome limitations of network controls in protecting from new resources and
attack types.
Reinforce network controls for legacy applications by exploring microsegmentation
strategies.
Centralize the organizational responsibility to manage and secure:

Core networking functions, such as cross-premises links, virtual networking,
subnetting, and IP address schemes.
Network security elements, such as virtual network appliances, cloud virtual
network activity and cross-premises traffic encryption, network-based access
controls, and other traditional network security components.

Reference model
If your workload requires multiple segments with shared services across each segment,
start with this reference model and adapt it to your organization's needs. This model
shows how functions and resources can be segmented to support an application with
multiple segments.
２ Warning
Segmentation and multiple teams suggests that your segmentation solution will
expand beyond the scope of the Well Architected Framework, impacting multiple
workloads consistently. When centralized teams are responsible for broad
architecture decisions, like segmentation, the best practice is to begin with Azure
landing zones in the Cloud Adoption Framework. Azure landing zones provide a
conceptual architecture, reference implementations, and proven design processes
to customize and implement the platform (or shared) services needed to support
multiple applications. Those best practices aid in making platform wide decisions
regarding network topology and connectivity, segmentation and governance,
which should be used when these decisions impact more than one workload.

Example segments

Consider isolating shared and individual resources as shown in the preceding image.

Core Services segment
This segment hosts shared services utilized across the organization. These shared
services typically include Active Directory Domain Services, DNS/DHCP, and system
management tools hosted on Azure Infrastructure as a Service (IaaS) virtual machines.

Other segments
Other segments can contain grouped resources based on certain criteria. For instance,
resources that are used by one specific workload or application might be contained in a
separate segment. You may also segment or subsegment by lifecycle stage, like
development, test, and production. Some resources might intersect, such as applications,
and can use virtual networks for lifecycle stages.

Clear lines of responsibility
The following table describes the main functions for this reference model. See Roles,
responsibilities, and permissions to learn more about permissions for the main
functions.
Function

Scope

Responsibility

Policy
management

Some or
all

Monitor and enforce compliance with external (or internal)
regulations, standards, and security policy assign appropriate

(Core and
individual
segments)

resources.

permission to those roles.

Central IT

Across all

Grant permissions to the central IT department (often the

operations
(Core)

resources.

infrastructure team) to create, modify, and delete resources like
virtual machines and storage.

Central

All

Centralize network management and security to reduce the potential

networking
group (Core
and

network
resources.

for inconsistent strategies that create potential attacker exploitable
security risks. Because all divisions of the IT and development
organizations don't have the same level of network management and

individual
segments)

security knowledge and sophistication, organizations benefit from
using a centralized network team's expertise and tooling.
Ensure consistency and avoid technical conflicts, assign network
resource responsibilities to a single central networking organization.
These resources should include virtual networks, subnets, network
security groups (NSG), and the virtual machines hosting virtual
network appliances.

Function

Scope

Responsibility

Resource
role

-

For most core services, administrative privileges required are granted
through the application (Active Directory, DNS/DHCP, system

permissions
(Core)

management tools). No other Azure resource permissions are
required. If your organizational model requires these teams to
manage their own VMs, storage, or other Azure resources, you can
assign these permissions to those roles.

Security
operations

All
resources.

Assess risk factors, identify potential mitigations, and advise
organizational stakeholders who accept the risk.

IT operations

All

Grant permission to create, modify, and delete resources. The

(individual
segments)

resources.

purpose of the segment (and resulting permissions) depends on your
organization structure.
Segments with resources managed by a centralized IT

(Core and
individual
segments)

organization can grant the central IT department (often the
infrastructure team) permission to modify these resources.
Segments managed by independent business units or functions
(such as a Human Resources IT Team) can grant those teams
permission to all resources in the segment.
Segments with autonomous DevOps teams don't need to grant
permissions across all resources because the resource role
grants permissions to application teams. For emergencies, use
the service admin account (break-glass account).

Service
admin (Core

Use the service admin role only for emergencies (and initial setup if
necessary). Don't use this role for daily tasks.

and
individual
segments)

Next steps
Start with this reference model and manage resources across multiple subscriptions
consistently and efficiently with management groups.
Management groups

Establish segmentation with
management groups
Article • 04/19/2023

Management groups can manage resources across multiple subscriptions consistently
and efficiently. However, due to its flexibility, your design can become complex and
compromise security and operations.
７ Note
Management groups could be defined as part of the workload architecture. More
commonly, centralized teams use management groups to consistently apply
governance and segmentation strategies across multiple workloads. If a centralized
team is responsible for design and operations of your management groups,
reference Cloud Adoption Framework's Azure landing zones. The Resource
organization design area outlines the best practice recommendations and
considerations for segmentation through management groups, subscriptions, and
application landing zones.

Support your segmentation strategy with
management groups
Structure management groups into a simple design that guides the enterprise
segmentation model.
Management groups offer the ability to consistently and efficiently manage resources
(including multiple subscriptions as needed). However, because of their flexibility, it's
possible to create an overly complex design. Complexity creates confusion and
negatively impacts both operations and security (as illustrated by overly complex
Organizational Unit (OU) and Group Policy Object (GPO) designs for Active Directory).
Microsoft recommends aligning the top level of management groups (MGs) into a
simple enterprise segmentation strategy and limiting the levels to no more than two.
In the example Reference model, there are enterprise-wide resources used by all
segments, a set of core services that share services, and more segments for each
workload.
Root management group for enterprise-wide resources.

Use the root management group to include identities that have the requirement to
apply policies across every resource. For example, regulatory requirements, such as
restrictions related to data sovereignty. This group is effective in by applying
policies, permissions, tags, across all subscriptions.
Ｕ Caution
Be careful when using the root management group because the policies can
affect all resources on Azure and potentially cause downtime or other
negative impacts. For considerations, see Use root management group with
caution later in this article.
For complete guidance about using management groups for an enterprise,
see Management groups.
Management group for each workload segment.
Use a separate management group for teams with limited scope of responsibility.
This group is typically required because of organizational boundaries or regulatory
requirements.
Root or segment management group for the core set of services.

Use root management group with caution
Use the Root Management Group (MG) for enterprise consistency, but test changes
carefully to minimize risk of operational disruption.
The root management group enables you to ensure consistency across the enterprise by
applying policies, permissions, and tags across all subscriptions. Take care when you're
planning and implementing assignments to the root management group. Assignments
can affect every resource on Azure and potentially cause downtime or other negative
impacts on productivity if there are errors or unanticipated effects.
Plan carefully: Select enterprise-wide elements to the root management group
that have a clear requirement to be applied across every resource or to be low
impact.
Select enterprise-wide identities that have a clear requirement to be applied across
all resources. Good candidates include:
Regulatory requirements with clear business risk or impact. For example,
restrictions related to data sovereignty.

Near-zero potential negative impact. For example, policy with audit effect, tag
assignment, and Azure RBAC permissions assignments that have been carefully
reviewed.
Use a dedicated service principal name (SPN) to execute management group
management operations, subscription management operations, and role
assignment. SPN reduces the number of users who have elevated rights and
follows least-privilege guidelines. Assign the User Access Administrator at the root
management group scope ( / ) to grant the SPN access at the root level. After the
SPN is granted permissions, the User Access Administrator role can be safely
removed. In this way, only the SPN is part of the User Access Administrator role.
Assign Contributor permission to the SPN, which allows tenant-level operations.
This permission level ensures that you can use the SPN to deploy and manage
resources to any subscription within your organization.
Limit the number of Azure Policy assignments made at the root management
group scope ( / ). This limitation minimizes debugging inherited policies in lowerlevel management groups.
Don't create any subscriptions under the root management group. This hierarchy
ensures that subscriptions don't only inherit the small set of Azure policies
assigned at the root-level management group, as the small set of Azure policies
don't represent a full set necessary for a workload.
Test first: Plan, test, and validate all enterprise-wide changes on the root
management group before applying (policy, tags, Azure RBAC model, and so on).
Test lab: The representative lab tenant or lab segment in the production tenant.
Production pilot: The production pilot can be a segment management group or
designated subset in the subscription(s) management group.
Validate changes: Validate changes to ensure they have the desired effect.

Next steps
Administrative account security

Administrative account security
Article • 11/30/2022

Administration is the practice of monitoring, maintaining, and operating Information
Technology (IT) systems to meet service levels that the business requires. Administration
introduces some of the highest impact security risks because performing these tasks
requires privileged access to a very broad set of these systems and applications.
Attackers know that gaining access to an account with administrative privileges can get
them access to most or all of the data they would target, making the security of
administration one of the most critical security areas.
As an example, Microsoft makes significant investments in protection and training of
administrators for our cloud systems and IT systems:

Microsoft's recommended core strategy for administrative privileges is to use the
available controls to reduce risk.
Reduce risk exposure (scope and time): The principle of least privilege is best
accomplished with modern controls that provide privileges on demand. This help to
limit risk by limiting administrative privileges exposure by:
Scope: Just enough access (JEA) provides only the required privileges for the
administrative operation required (vs. having direct and immediate privileges to
many or all systems at a time, which is almost never required).
Time: Just in time (JIT) approaches provided the required privileged as they are
needed.

Mitigate the remaining risks: Use a combination of preventive and detective
controls to reduce risks such as isolating administrator accounts from the most
common risks phishing and general web browsing, simplifying and optimizing
their workflow, increasing assurance of authentication decisions, and identifying
anomalies from normal baseline behavior that can be blocked or investigated.
Microsoft has captured and documented best practices for protecting administrative
accounts and published prioritized roadmaps for protecting privileged access that can
be used as references for prioritizing mitigations for accounts with privileged access.
Securing Privileged Access (SPA) roadmap for administrators of on-premises Active
Directory
Guidance for securing administrators of Azure Active Directory

Minimize number of critical impact admins
Grant the fewest number of accounts to privileges that can have a critical business
impact.
Each admin account represents potential attack surface that an attacker can target, so
minimizing the number of accounts with that privilege helps limit the overall
organizational risk. Experience has taught us that membership of these privileged
groups grows naturally over time as people change roles if membership not actively
limited and managed.
We recommend an approach that reduces this attack surface risk while ensuring
business continuity in case something happens to an administrator:
Assign at least two accounts to the privileged group for business continuity.
When two or more accounts are required, provide justification for each member
including the original two.
Regularly review membership & justification for each group member.

Managed accounts for admins
Ensure all critical impact admins are managed by enterprise directory to follow
organizational policy enforcement.
Consumer accounts such as Microsoft accounts like @Hotmail.com, @live.com,
@outlook.com, don't offer sufficient security visibility and control to ensure the

organization's policies and any regulatory requirements are being followed. Because
Azure deployments often start small and informally before growing into enterprisemanaged tenants, some consumer accounts remain as administrative accounts long
afterward for example, original Azure project managers, creating blind spots, and
potential risks.

Separate accounts for admins
Ensure all critical impact admins have a separate account for administrative tasks (vs the
account they use for email, web browsing, and other productivity tasks).
Phishing and web browser attacks represent the most common attack vectors to
compromise accounts, including administrative accounts.
Create a separate administrative account for all users that have a role requiring critical
privileges. For these administrative accounts, block productivity tools like Office 365
email (remove license). If possible, block arbitrary web browsing (with proxy and/or
application controls) while allowing exceptions for browsing to the Azure portal and
other sites required for administrative tasks.

No standing access / just in time privileges
Avoid providing permanent "standing" access for any critical impact accounts.
Permanent privileges increase business risk by increasing the time an attacker can use
the account to do damage. Temporary privileges force attackers targeting an account to
either work within the limited times the admin is already using the account or to initiate
privilege elevation (which increases their chance of being detected and removed from
the environment).
Grant privileges required only as required using one of these methods:
Just in time: Enable Azure AD Privileged Identity Management (PIM) or a third
party solution to require following an approval workflow to obtain privileges for
critical impact accounts.
Break glass: For rarely used accounts, follow an emergency access process to gain
access to the accounts. This is preferred for privileges that have little need for
regular operational usage like members of global admin accounts.

Emergency access or 'Break Glass' accounts

Ensure you have a mechanism for obtaining administrative access in case of an
emergency.
While rare, sometimes extreme circumstances arise where all normal means of
administrative access are unavailable.
We recommend following the instructions at Managing emergency access
administrative accounts in Azure AD and ensure that security operations monitor these
accounts carefully.

Admin workstation security
Ensure critical impact admins use a workstation with elevated security protections and
monitoring.
Attack vectors that use browsing and email like phishing are cheap and common.
Isolating critical impact admins from these risks will significantly lower your risk of a
major incident where one of these accounts is compromised and used to materially
damage your business or mission.
Choose level of admin workstation security based on the options available at
https://aka.ms/securedworkstation
Highly Secure Productivity Device (Enhanced Security Workstation or Specialized
Workstation)
You can start this security journey for critical impact admins by providing them
with a higher security workstation that still allows for general browsing and
productivity tasks. Using this as an interim step helps ease the transition to fully
isolated workstations for both the critical impact admins as well as the IT staff
supporting these users and their workstations.
Privileged Access Workstation (Specialized Workstation or Secured Workstation)
These configurations represent the ideal security state for critical impact admins as
they heavily restrict access to phishing, browser, and productivity application
attack vectors. These workstations don't allow general internet browsing, only
allow browser access to Azure portal and other administrative sites.

Critical impact admin dependencies –
Account/Workstation
Carefully choose the on-premises security dependencies for critical impact accounts and
their workstations.

To contain the risk from a major incident on-premises spilling over to become a major
compromise of cloud assets, you must eliminate or minimize the means of control that
on premises resources have to critical impact accounts in the cloud. As an example,
attackers who compromise the on-premises Active Directory can access and
compromise cloud-based assets that rely on those accounts like resources in Azure,
Amazon Web Services (AWS), ServiceNow, and so on. Attackers can also use
workstations joined to those on premises domains to gain access to accounts and
services managed from them.
Choose the level of isolation from on premises means of control also known as security
dependencies for critical impact accounts.
User Accounts: Choose where to host the critical impact accounts
Native Azure AD Accounts - Create Native Azure AD Accounts that are not
synchronized with on-premises active directory.
Synchronize from On Premises Active Directory.
Use existing accounts hosted in the on-premises active directory.
Workstations: Choose how you will manage and secure the workstations used by
critical admin accounts:
Native Cloud Management and Security (Recommended): Join workstations to
Azure AD & Manage/Patch them with Intune or other cloud services. Protect
and Monitor with Windows Microsoft Defender for Endpoint or another cloud
service not managed by on premises based accounts.
Manage with Existing Systems: Join existing AD domain and use existing
management/security.

Passwordless or multifactor authentication for
admins
Require all critical impact admins to use passwordless authentication or multifactor
authentication (MFA).
Attack methods have evolved to the point where passwords alone cannot reliably
protect an account. This is well documented in a Microsoft Ignite Session .
Administrative accounts and all critical accounts should use one of the following
methods of authentication. These capabilities are listed in preference order by highest

cost/difficulty to attack (strongest/preferred options) to lowest cost/difficult to attack:
Passwordless (such as Windows Hello)
Passwordless (Authenticator App)
Multifactor Authentication
Note that SMS Text Message based MFA has become very inexpensive for attackers to
bypass, so we recommend you avoid relying on it. This option is still stronger than
passwords alone, but is much weaker than other MFA options.

Enforce conditional access for admins - Zero
Trust
Authentication for all admins and other critical impact accounts should include
measurement and enforcement of key security attributes to support a Zero Trust
strategy.
Attackers compromising Azure Admin accounts can cause significant harm. Conditional
Access can significantly reduce that risk by enforcing security hygiene before allowing
access to Azure management.
Configure Conditional Access policy for Azure management that meets your
organization's risk appetite and operational needs.
Require Multifactor Authentication and/or connection from designated work
network.
Require Device integrity with Microsoft Defender for Endpoint (Strong
Assurance).

Avoid granular and custom permissions
Avoid permissions that specifically reference individual resources or users.
Specific permissions create unneeded complexity and confusion as they don't carry the
intention to new similar resources. This then accumulates into a complex legacy
configuration that is difficult to maintain or change without fear of "breaking
something" – negatively impacting both security and solution agility.
Instead of assigning specific resource-specific permissions, use either:

Management Groups for enterprise-wide permissions.
Resource groups for permissions within subscriptions.
Instead of granting permissions to specific users, assign access to groups in Azure AD. If
there isn't an appropriate group, work with the identity team to create one. This allows
you to add and remove group members externally to Azure and ensure permissions are
current, while also allowing the group to be used for other purposes such as mailing
lists.

Use built-in roles
Use built-in roles for assigning permissions where possible.
Customization leads to complexity that increases confusion and makes automation
more complex, challenging, and fragile. These factors all negatively impact security.
We recommend that you evaluate the built-in roles designed to cover most normal
scenarios. Custom roles are a powerful and sometimes useful capability, but they should
be reserved for cases when built in roles won't work.

Establish lifecycle management for critical
impact accounts
Ensure you have a process for disabling or deleting administrative accounts when admin
personnel leave the organization (or leave administrative positions).
See Regularly review critical access for more details.

Attack simulation for critical impact accounts
Regularly simulate attacks against administrative users with current attack techniques to
educate and empower them.
People are a critical part of your defense, especially your personnel with access to critical
impact accounts. Ensuring these users (and ideally all users) have the knowledge and
skills to avoid and resist attacks will reduce your overall organizational risk.
You can use Office 365 Attack Simulation capabilities or any number of third party
offerings.

Azure identity and access management
considerations
Article • 04/19/2023

Most architectures have shared services that are hosted and accessed across networks.
Those services share common infrastructure and users need to access resources and
data from anywhere. For such architectures, a common way to secure resources is to use
network controls. However, that isn't enough.
Provide security assurance through identity management: the process of authenticating
and authorizing security principals. Use identity management services to authenticate
and grant permission to users, partners, customers, applications, services, and other
entities.
７ Note
Identity management is typically a centralized function not controlled by the
workload team as a part of the workload's architecture. Unless the workload team is
responsible for a dedicated identity store, the guidance in the Azure identity and
access management design area of the Cloud Adoption Framework should be
referenced when implementing identity solutions which support multiple
workloads.

Checklist
How are you managing the identity for your workload?
＂ Define clear lines of responsibility and separation of duties for each function.
Restrict access based on a need-to-know basis and least privilege security
principles.
＂ Assign permissions to users, groups, and applications at a certain scope through
Azure RBAC. Use built-in roles when possible.
＂ Prevent deletion or modification of a resource, resource group, or subscription
through management locks.
＂ Use managed identities to access resources in Azure.
＂ Support a single enterprise directory. Keep the cloud and on-premises directories
synchronized, except for critical-impact accounts.
＂ Set up Azure AD Conditional Access. Enforce and measure key security attributes
when authenticating all users, especially for critical-impact accounts.

＂ Have a separate identity source for non-employees.
＂ Preferably use passwordless methods or opt for modern password methods.
＂ Block legacy protocols and authentication methods.

Azure security benchmark
The Azure Security Benchmark includes a collection of high-impact security
recommendations you can use to help secure the services you use in Azure:

The questions in this section are aligned to the Azure Security Benchmarks
Identity and Access Control.

Azure services for identity
The considerations and best practices in this section are based on these Azure services:
Azure AD
Azure AD B2B
Azure AD B2C

Reference architecture
Here are some reference architectures related to identity and access management:
Integrate on-premises AD domains with Azure AD
Integrate on-premises AD with Azure

Next steps
Monitor the communication between segments. Use data to identify anomalies, set
alerts, or block traffic to mitigate the risk of attackers crossing segmentation boundaries.
Network security

Related links
Five steps to securing your identity infrastructure

Go back to the main article: Overview of the security pillar

Roles, responsibilities, and permissions
Article • 04/19/2023

In an organization, several teams work together to make sure that the workload and the
supporting infrastructure are secure. To avoid confusion that can create security risks,
define clear lines of responsibility and separation of duties.
Based on Microsoft's experience with many cloud adoption projects, establishing clearly
defined roles and responsibilities for specific functions in Azure avoids confusion that
can lead to human and automation errors creating security risk.

Clear lines of responsibility
Do the teams have a clear view on responsibilities and individual/group access levels?
Designate the parties responsible for specific functions in Azure.
Clearly documenting and sharing the contacts responsible for each of these functions
creates consistency and facilitates communication. Based on Microsoft's experience with
many cloud adoption projects, consistency and communication prevent confusion that
can lead to human and automation errors that create security risks.
Designate groups (or individual roles) that are responsible for key functions.
７ Note
A centralized team might be responsible for establishing these roles across your
organization to provide consistent support across all workload teams. If your team
is not solely responsible for each of the following roles, consult the guidance on
Aligning responsibilities across teams with a focus on understanding how your
workload team will interface with a Cloud platform team, Central IT, or a Cloud
center of excellence.

Group or
individual

Responsibility

role
Network

Typically an existing network security team. Configuration and maintenance of

Security

Azure Firewall, Network Virtual Appliances (and associated routing), Web
Application Firewall (WAF), network security groups, application security groups
(ASG), and other cross-network traffic.

Group or
individual

Responsibility

role
Network

Typically an existing network operations team. Enterprise-wide virtual network and

Management

subnet allocation.

Server

Typically IT operations, security, or jointly. Monitor and remediate server security

Endpoint
Security

(patching, configuration, endpoint security).

Incident
Monitoring

Typically a security operations team. Incident monitoring and response to
investigate and remediate security incidents in security information and event

and
Response

management (SIEM) or source console such as Microsoft Defender for Cloud
Azure AD Identity Protection.

Policy
Management

Typically a GRC team and an architecture team. Apply governance based on risk
analysis and compliance requirements. Set direction for use of Azure role-based
access control (Azure RBAC), Microsoft Defender for Cloud, administrator
protection strategy, and Azure Policy to govern Azure resources.

Identity

Typically a security team and an identity team jointly. Set direction for Azure AD

Security and

directories, PIM/PAM usage, multifactor authentication, password and

Standards

synchronization configuration, and application identity standards.

７ Note
Application roles and responsibilities should cover different access level of each
operational function. For example, publish production release, access customer
data, manipulate database records, and so on. Application teams should include
central functions listed in the preceding table.

Assign permissions
Grant roles the appropriate permissions that start with least privilege and add more
based on your operational needs. Provide clear guidance to your technical teams that
implement permissions. This clarity makes it easier to detect and correct that reduces
human errors such as overpermissioning.
７ Note
Many organizations manage identity, access, and permissions from a centralized
cloud platform team using Cloud Adoption Framework Azure landing zones as a
guide for configuration and permissions across multiple workloads. If identity and

access are managed outside of the workload team, see the Identity and access
management design area to understand how to apply the proper level of
permissions in your application's landing zone.
Assign permissions at the management group level for the segment instead of
individual subscriptions. Assigning permissions drives consistency and ensures
application to future subscriptions. In general, avoid granular and custom
permissions.
Consider the built-in roles in Azure before creating custom roles to grant the
appropriate permissions to VMs and other objects.
Security managers group membership might be appropriate for smaller teams or
organizations where security teams have extensive operational responsibilities.
When assigning permissions for a segment, consider consistency while allowing
flexibility to accommodate several organizational models. These models can range from
a single centralized IT group to mostly independent IT and DevOps teams.

Reference model example
This section uses a reference model to demonstrate the considerations for assigning
permissions for different segments. If your workload architecture requires segmentation
and shared services spanning multiple segments for the same workload, Microsoft
recommends starting from these models and adapting to your organization.
２ Warning
Shared services are seldom deployed or managed as part of a single workload or
by the workload team. When centralized teams provide shared service, the best
practice is to begin with Azure landing zones in the Cloud Adoption Framework.
Azure Landing Zones provide a conceptual architecture, reference implementations,
and proven design processes to customize and implement the platform (or shared)
services needed to support multiple applications. Those best practices aid in
making platform wide decisions regarding network topology and connectivity,
segmentation and governance, which should be used when these decisions impact
more than one workload.

Core services reference permissions

This segment hosts shared services utilized across the organization. These shared
services typically include Active Directory Domain Services, DNS/DHCP, System
Management Tools hosted on Azure Infrastructure as a Service (IaaS) virtual machines.

Security visibility across all resources: For security teams, grant read-only access to
security attributes for all technical environments. This access level is needed to assess
risk factors, identify potential mitigations, and advise organizational stakeholders who
accept the risk. For more information, see Security team visibility.
Policy management across some or all resources: To monitor and enforce compliance
with external (or internal) regulations, standards, and security policy, assign appropriate
permission to those roles. The roles and permissions you choose depend on the
organizational culture and expectations of the policy program. See Microsoft Cloud
Adoption Framework for Azure.
Before defining the policies, consider:
How is the organization's security audited and reported? Is there mandatory
reporting?
Are the existing security practices working?
Are there any requirements specific to industry, government, or regulatory
requirements?
Designate group(s) (or individual roles) for central functions that affect shared services
and applications.
After the policies are set, continuously improve those standards incrementally. Make
sure that the security posture doesn't degrade over time by having auditing and

monitoring compliance. For information about managing security standards of an
organization, see governance, risk, and compliance (GRC).
Central IT operations across all resources: Grant permissions to the central IT
department (often the infrastructure team) to create, modify, and delete resources like
virtual machines and storage. Contributor or owner roles are appropriate for this
function.
Central networking group across network resources: To ensure consistency and avoid
technical conflicts, assign network resource responsibilities to a single central
networking organization. These resources should include virtual networks, subnets,
Network Security Groups (NSG), and the virtual machines hosting virtual network
appliances. Assign network resource responsibilities to a single central networking
organization. The network contributor role is appropriate for this group. For more
information, see Centralize network management and security.
Resource role permissions: For most core services, administrative privileges required to
manage them are granted through the application (Active Directory, DNS/DHCP, System
Management Tools), so no other Azure resource permissions are required. If your
organizational model requires these teams to manage their own VMs, storage, or other
Azure resources, you can assign these permissions to those roles.
Workload segments with autonomous DevOps teams manage the resources associated
with each application. The actual roles and permissions depend on the application size
and complexity, the application team's size and complexity, and the organization and
application team's culture.
Service admin (break glass account): Use the service administrator role only for
emergencies and initial setup. Don't use this role for daily tasks. For more information,
see Emergency access ('break glass' accounts).

Segment reference permissions
This segment permission design provides consistency while allowing enough flexibility
to accommodate the range of organizational models. The organizational models span
from a single centralized IT group to mostly independent IT and DevOps teams.

Security visibility across all resources: For security teams, grant read-only access to
security attributes for all technical environments. This access level is needed to assess
risk factors, identify potential mitigations, and advise organizational stakeholders who
accept the risk. See Security Team Visibility.
Policy management across some or all resources: To monitor and enforce compliance
with external (or internal) regulations, standards, and security policy assign appropriate
permission to those roles. The roles and permissions you choose depend on the
organizational culture and expectations of the policy program. See Security Baseline
discipline overview.
IT Operations across all resources: Grant permission to create, modify, and delete
resources. The purpose of the segment (and resulting permissions) depends on your
organization structure.
Segments with resources managed by a centralized IT organization can grant the
central IT department (often the infrastructure team) permission to modify these
resources.
Segments managed by independent business units or functions (such as a Human
Resources IT Team) can grant those teams permission to all resources in the
segment.
Segments with autonomous DevOps teams don't need to grant permissions across
all resources because the resource role grants permissions to application teams.
For emergencies, use the service admin account (break-glass account).

Central networking group across network resources: To ensure consistency and avoid
technical conflicts, assign network resource responsibilities to a single central
networking organization. These resources should include virtual networks, subnets,
Network Security Groups (NSG), and the virtual machines hosting virtual network
appliances. See Centralize Network Management And Security.
Resource role permissions: Segments with autonomous DevOps teams manage the
resources associated with each application. The actual roles and permissions depend on
the application size and complexity, the application team's size and complexity, and the
organization and application team's culture.
Service admin (break glass account): Use the service admin role only for emergencies
(and initial setup if necessary). Don't use this role for daily tasks. For more information,
see Emergency access or 'Break Glass' accounts).

Security team visibility
An application team needs to be aware of security initiatives to align their security
improvement plans with the outcome of those activities. Provide security teams readonly access to the security aspects of all technical resources in their purview.
Security organizations need visibility into the technical environment to perform their
duties of assessing and reporting on organizational risk. Without this visibility, security
has to rely on information provided from groups operating in the environment, which
have potential conflict of interest (and other priorities).
Security teams might separately be granted other privileges if they have operational
responsibilities or a requirement to enforce compliance on Azure resources.
For example in Azure, assign security teams to the security readers permission that
provides access to measure security risk (without providing access to the data itself).
For enterprise security groups with broad responsibility for security of Azure, you can
assign this permission using:
Root management group – for teams responsible for assessing and reporting risk
on all resources
Segment management group(s) – for teams with limited scope of responsibility
(typically required because of organizational boundaries or regulatory
requirements)
） Important

Because security will have broad access to the environment (and visibility into
potentially exploitable vulnerabilities), treat security teams as critical impact
accounts and apply the same protections as administrators. The Administrative
account security section details these controls for Azure.
Suggested actions
Define a process for aligning communication, investigation, and hunting activities
with the application team.
Following the principle of least privilege, establish access control to all cloud
environment resources for security teams with sufficient access. Security teams
gain the required visibility into the technical environment and to perform their
duties of assessing, and reporting on organizational risk.
Learn more
Engage your organization's security team

Manage connected tenants
Does your security team have visibility into all existing subscriptions and cloud
environments? How do they discover new ones?
Ensure your security organization is aware of all enrollments and associated
subscriptions connected to your existing environment (via ExpressRoute or a site-to-site
VPN) and monitoring as part of the overall enterprise.
These Azure resources are part of your enterprise environment and security
organizations require visibility into them. Security organizations need this access to
assess risk and to identify whether organizational policies and applicable regulatory
requirements are being followed.
The organizations' cloud infrastructure should be well documented, with security team
access to all resources required for monitoring and insight. Frequent scans of the cloudconnected assets should be performed to ensure no other subscriptions or tenants have
been added outside of organizational controls. Regularly review Microsoft guidance to
ensure security team access best practices are consulted and followed.

Suggested actions
Ensure all Azure environments that connect to your production environment and
network apply your organization's policy, and IT governance controls for security.

You can discover existing connected tenants using a tool provided by Microsoft for
guidance on permissions.

Next steps
Restrict access to Azure resources based on a need-to-know basis starting with the
principle of least privilege security and add more based on your operational needs.
Azure control plane security

Related links
For considerations about using management groups to reflect the organization's
structure within an Azure Active Directory (Azure AD) tenant, see Management groups.
Back to the main article: Azure identity and access management considerations

Azure control plane security
Article • 11/30/2022

The term control plane refers to the management of resources in your subscription.
These activities include creating, updating, and deleting Azure resources as required by
the technical team.
Azure Resource Manager handles all control plane requests and applies restrictions that
you specify through Azure role-based access control (Azure RBAC), Azure Policy, locks.
Apply those restrictions based on the requirement of the organization.
It's recommended to implement Infrastructure as Code, and to deploy application
infrastructure through automation, and CI/CD for consistency and auditing purposes.

Key points
＂ Restrict access based on a need-to-know basis and least privilege security
principles.
＂ Assign permissions to users, groups, and applications at a certain scope through
Azure RBAC.
＂ Use built-in roles when possible.
＂ Prevent deletion or modification of a resource, resource group, or subscription
through management locks.
＂ Use less critical control in your CI/CD pipeline for development and test
environments.

Roles and permission assignment
Is the workload infrastructure protected with Azure role-based access control (Azure
RBAC)?
Azure role-based access control (Azure RBAC) provides the necessary tools to maintain
separation of concerns for administration and access to application infrastructure.
Decide who has access to resources at the granular level and what they can do with
those resources. For example:
Developers can't access production infrastructure.
Only the SecOps team can read and manage Key Vault secrets.
If there are multiple teams, Project A team can access and manage Resource Group
A and all resources within.

Grant roles the appropriate permissions that start with least privilege and add
more based on your operational needs. Provide clear guidance to your technical
teams that implement permissions. This clarity makes it easier to detect and correct
which reduces human errors such as overpermissioning.
Azure RBAC helps you manage that separation. You can assign permissions to users,
groups, and applications at a certain scope. The scope of a role assignment can be a
subscription, a resource group, or a single resource. For details, see Azure role-based
access control (Azure RBAC).
Assign permissions at management group instead of individual subscriptions to
drive consistency and ensure application to future subscriptions.
Consider the built-in roles before creating custom roles to grant the appropriate
permissions to resources and other objects.
For example, assign security teams with the Security Readers permission that provides
access needed to assess risk factors, identify potential mitigations, without providing
access to the data.
） Important
Treat security teams as critical accounts and apply the same protections as
administrators.
Learn more
Azure RBAC documentation

Management locks
Are there resource locks applied on critical parts of the infrastructure?
Unlike Azure role-based access control, management locks are used to apply a
restriction across all users and roles.
Critical infrastructure typically doesn't change often. Use management locks to prevent
deletion or modification of a resource, resource group, or subscription. Lock in use cases
where only specific roles and users with permissions can delete, or modify resources.
As an administrator, you may need to lock a subscription, resource group, or resource to
prevent other users in your organization from accidentally deleting or modifying critical

resources. You can set the lock level to CanNotDelete or ReadOnly . In the portal, the
locks are called Delete and Read-only, respectively:
CanNotDelete means authorized users can still read and modify a resource, but
they can't delete the resource.
ReadOnly means authorized users can read a resource, but they can't delete or
update the resource. Applying this lock is similar to restricting all authorized users
to the permissions granted by the Reader role.
When you apply a lock at a parent scope, all resources within that scope inherit the
same lock. Even resources you add later inherit the lock from the parent. The most
restrictive lock in the inheritance takes precedence.
Unlike role-based access control, you use management locks to apply a restriction
across all users and roles. To learn about setting permissions for users and roles, see
Azure role-based access control (Azure RBAC).
Identify critical infrastructure and evaluate resource lock suitability.
Set locks in the DevOps process carefully because modification locks can sometimes
block automation. For examples of those blocks and considerations, see Considerations
before applying locks.

Suggested actions
Restrict application infrastructure access to CI/CD only.
Use conditional access policies to restrict access to Microsoft Azure Management.
Configure role-based and resource-based authorization within Azure AD.

Learn more
Manage access to Azure management with Conditional Access
Role-based and resource-based authorization

Next steps
Grant or deny access to a system by verifying whether the accessor has the permissions
to perform the requested action.
Authentication

Related links
Back to the main article: Azure identity and access management considerations

Authentication with Azure AD
Article • 11/30/2022

Authentication is a process that grants or denies access to a system by verifying the
accessor's identity. Use a managed identity service for all resources to simplify overall
management (such as password policies) and minimize the risk of oversights or human
errors. Azure Active Directory (Azure AD) is the one-stop-shop for identity and access
management service for Azure.

Key points
Use Managed Identities to access resources in Azure.
Keep the cloud and on-premises directories synchronized, except for high-privilege
accounts.
Preferably use passwordless methods or opt for modern password methods.
Enable Azure AD conditional access based on key security attributes when
authenticating all users, especially for high-privilege accounts.

Use identity-based authentication
How is the application authenticated when communicating with Azure platform
services?
Managed identities enable Azure Services to authenticate to each other without
presenting explicit credentials via code.
Managed identities for Azure resources is a feature of Azure Active Directory. Each of
the Azure services that support managed identities for Azure resources are subject to
their own timeline. Make sure you review the availability status of managed identities for
your resource and known issues before you begin. The feature provides Azure services
with an automatically managed identity in Azure AD. You can use the identity to
authenticate to any service that supports Azure AD authentication, including Key Vault,
without any credentials in your code. The managed identities for Azure resources
feature is free with Azure AD for Azure subscriptions, there's no additional cost.
There are two types of managed identities:
A system-assigned managed identity is enabled directly on an Azure service
instance. When the identity is enabled, Azure creates an identity for the instance in
the Azure AD tenant that's trusted by the subscription of the instance. After the

identity is created, the credentials are provisioned onto the instance. The life cycle
of a system-assigned identity is directly tied to the Azure service instance that it's
enabled on. If the instance is deleted, Azure automatically cleans up the credentials
and the identity in Azure AD.
A user-assigned managed identity is created as a standalone Azure resource.
Through a create process, Azure creates an identity in the Azure AD tenant that's
trusted by the subscription in use. After the identity is created, the identity can be
assigned to one or more Azure service instances. The life cycle of a user-assigned
identity is managed separately from the life cycle of the Azure service instances to
which it's assigned.
Authenticate with identity services instead of cryptographic keys. On Azure, Managed
Identities eliminate the need to store credentials that might be leaked inadvertently.
When Managed Identity is enabled for an Azure resource, it's assigned an identity that
you can use to obtain Azure AD tokens. For more information, see Azure AD-managed
identities for Azure resources.
For example, an Azure Kubernetes Service (AKS) cluster needs to pull images from Azure
Container Registry (ACR). To access the image, the cluster needs to know the ACR
credentials. The recommended way is to enable Managed Identities during cluster
configuration. That configuration assigns an identity to the cluster and allows it to
obtain Azure AD tokens.
This approach is secure because Azure handles the management of the underlying
credentials for you.
The identity is tied to the lifecycle of the resource, in the AKS cluster example.
When the resource is deleted, Azure automatically deletes the identity.
Azure AD manages the timely rotation of secrets for you.
 Tip
Here are the resources for the preceding example:

GitHub: Azure Kubernetes Service (AKS) Secure Baseline Reference
Implementation .
The design considerations are described in Azure Kubernetes Service (AKS)
production baseline.
Suggested actions

Review workload authentication and identify opportunities to convert explicit
credentials (for example, connection string and API key) to use managed identities.
For all new Azure workloads, standardize on using managed identities where
applicable.
Learn more
What are managed identities for Azure resources?
What kind of authentication is required by application APIs?
Don't assume that API URLs used by a workload are hidden and can't get exposed to
attackers. For example, JavaScript code on a website can be viewed. A mobile
application can be decompiled and inspected. Even for internal APIs used only on the
backend, a requirement of authentication can increase the difficulty of lateral movement
if an attacker gets network access. Typical mechanisms include API keys, authorization
tokens and IP restrictions.
Managed Identity can help an API be more secure because it replaces the use of
human-managed service principals and can request authorization tokens.
How is user authentication handled in the application?
Don't use custom implementations to manage user credentials. Instead, use Azure AD or
other managed identity providers such as Microsoft account Azure B2C. Managed
identity providers provide additional security features such as modern password
protections, multifactor authentication (MFA), and resets. In general, passwordless
protections are preferred. Also, modern protocols like OAuth 2.0 use token-based
authentication with limited timespan.
Are authentication tokens cached securely and encrypted when sharing across web
servers?
Application code should first try to get OAuth access tokens silently from a cache before
attempting to acquire a token from the identity provider, to optimize performance and
maximize availability. Tokens should be stored securely and handled as any other
credentials. When there's a need to share tokens across application servers (instead of
each server acquiring and caching their own) encryption should be used.
For information, see Acquire and cache tokens.

Choose a system with cross-platform support

Use a single identity provider for authentication on all platforms (operating systems,
cloud providers, and third-party services.
Azure AD can be used to authenticate Windows, Linux, Azure, Office 365, other cloud
providers, and third-party services as service providers.
For example, improve the security of Linux virtual machines (VMs) in Azure with Azure
AD integration. For details, see Log in to a Linux virtual machine in Azure using Azure
Active Directory authentication.

Centralize all identity systems
Keep your cloud identity synchronized with the existing identity systems to ensure
consistency and reduce human errors.
Consistency of identities across cloud and on-premises will reduce human error and
resulting security risk. Teams managing resources in both environments need a
consistent authoritative source to achieve security assurances. For monitoring, if identity
can be determined without an intermediate mapping process, security efficiency is
improved.
Synchronization is all about providing users an identity in the cloud based on their onpremises identity. Whether or not they will use synchronized account for authentication
or federated authentication, the users will still need to have an identity in the cloud. This
identity will need to be maintained and updated periodically. The updates can take
many forms, from title changes to password changes.
Start by evaluating the organization's on-premises identity solution and user
requirements. This evaluation is important, as it defines the technical requirements for
how user identities will be created and maintained in the cloud. For the majority of
organizations, Active Directory is established on-premises and will be the on-premises
directory from which users will be synchronized, but this is not always the case.
Consider using Azure AD Connect for synchronizing Azure AD with your existing onpremises directory. For migration projects, have a requirement to complete this task
before an Azure migration and development projects begin.
） Important
Don't synchronize high-privilege accounts to an on-premises directory. If an
attacker gets full control of on-premises assets, they can compromise a cloud

account. This strategy will limit the scope of an incident. For more information, see
Critical impact account dependencies.
Synchronization is blocked by default in the default Azure AD Connect
configuration. Make sure that you haven't customized this configuration. For
information about filtering in Azure AD, see Azure AD Connect sync: Configure
filtering.
For more information, see hybrid identity providers.
 Tip
Here are the resources for the preceding example::
The design considerations are described in Integrate on-premises Active Directory
domains with Azure AD.
Learn more
Synchronize the hybrid identity systems

Use passwordless authentication
Attackers constantly scan public cloud IP ranges for open management ports. They
attempt to exploit weak credentials (password spray) and unpatched vulnerabilities in
management protocols like SSH, and RDP. Preventing direct internet access to virtual
machines stops a misconfiguration or oversight becoming more serious.
Attack methods have evolved to the point where passwords alone cannot reliably
protect an account. Modern authentication solutions including passwordless and
multifactor authentication increase security posture through strong authentication.
Remove the use of passwords, when possible. Also, require the same set of credentials
to sign in and access the resources on-premises or in the cloud. This requirement is
crucial for accounts that require passwords, such as admin accounts.
With modern authentication and security features in Azure AD, that basic password
should be supplemented or replaced with more secure authentication methods. Each
organization has different needs when it comes to authentication. Microsoft offers the
following three passwordless authentication options that integrate with Azure Active
Directory (Azure AD):

Windows Hello for Business
Microsoft Authenticator app
FIDO2 security keys
It's recommended to follow a four-stage plan to become passwordless:
Develop password replacement offering
Reduce user-visible password surface area
Transition into password-less deployment
Eliminate passwords from the identity directory
The following methods of authentication are ordered by highest cost/difficulty to attack
(strongest/preferred options) to lowest cost/difficult to attack:
Passwordless authentication. Some examples of this method include Windows
Hello or Authenticator App.
MFA. Although this method is more effective than passwords, we recommend that
you avoid relying on SMS text message-based MFA. For more information, see
Enable per-user Azure Active Directory MFA to secure sign-in events.
Managed Identities. See Use identity-based authentication.
Those methods apply to all users, but should be applied first and strongest to accounts
with administrative privileges.
An implementation of this strategy is enabling single sign-on (SSO) to devices, apps,
and services. By signing in once using a single user account, you can grant access to all
the applications and resources per business needs. Users don't have to manage multiple
sets of usernames and passwords. You can provision or de-provision application access
automatically. For more information, see Single sign-on .
Suggested actions
Develop a passwordless strategy that requires MFA for all users without
significantly impacting operations.
Ensure policy and processes require restricting, and monitoring direct internet
connectivity by virtual machines.
Learn more
Passwordless Strategy
Remove Virtual Machine (VM) direct internet connectivity

Use modern password protection

Require modern protections through methods that reduce the use of passwords.
Modern authentication protocols support strong controls such as MFA and should be
used instead of legacy authentication methods. Use of legacy methods increases risk of
credential exposure.
Modern authentication is a method of identity management that offers more secure
user authentication and authorization. It's available for Office 365 hybrid deployments of
Skype for Business server on-premises and Exchange server on-premises, and splitdomain Skype for Business hybrids.
Modern authentication is an umbrella term for a combination of authentication and
authorization methods between a client (for example, your laptop or your phone) and a
server, as well as some security measures that rely on access policies that you may
already be familiar with. It includes:
Authentication methods: MFA; smart card authentication; client certificate-based
authentication
Authorization methods: Microsoft's implementation of Open Authorization (OAuth)
Conditional access policies: Mobile Application Management (MAM) and Azure
Active Directory (Azure AD) Conditional Access
Review workloads that do not leverage modern authentication protocols and convert
where possible. In addition, standardize using modern authentication protocols for all
future workloads.
For Azure, enable protections in Azure AD:
1. Configure Azure AD Connect to synchronize password hashes. For information, see
Implement password hash synchronization with Azure AD Connect sync.
2. Choose whether to automatically or manually remediate issues found in a report.
For more information, see Monitor identity risks.
For more information about supporting modern passwords in Azure AD, see the
following articles:
What is Identity Protection?
Enforce on-premises Azure AD Password Protection for Active Directory Domain
Services
Users at risk security report
Risky sign-ins security report
For more information about supporting modern passwords in Office 365, see the
following article:

What is modern authentication?

Enable conditional access
Modern cloud-based applications are typically accessible over the internet, making
network location-based access inflexible and single-factor passwords a liability.
Conditional access describes your authentication policy for an access decision. For
example, if a user is connecting from an InTune-managed corporate PC, they might not
be challenged for MFA every time, but if the user suddenly connects from a different
device in a different geography, MFA is required.
Grant access requests based on the requestors' trust level and the target resources'
sensitivity.
Are there any conditional access requirements for the application?
Workloads can be exposed over public internet and location-based network controls are
not applicable. To enable conditional access, understand what restrictions are required
for the use case. For example, MFA is a necessity for remote access; IP-based filtering
can be used to enable adhoc debugging (VPNs are preferred).
Configure Azure AD Conditional Access by setting up Access policy for Azure
management based on your operational needs. For information, see Manage access to
Azure management with Conditional Access.
Conditional access can be an effective way to phase out legacy authentication and
associated protocols. The policies must be enforced for all admins and other critical
impact accounts. Start by using metrics and logs to determine users who still
authenticate with old clients. Next, disable any down-level protocols that aren't used,
and set up conditional access for all users who aren't using legacy protocols. Finally, give
notice and guidance to users about upgrading before blocking legacy authentication
completely. For more information, see Azure AD Conditional Access support for
blocking legacy auth .

Suggested actions
Implement conditional access policies for this workload.
Learn more about Azure AD Conditional Access.

Next

Grant or deny access to a system by verifying the accessor's identity.
Authorization

Related links
Back to the main article: Azure identity and access management considerations

Authorization with Azure AD
Article • 11/30/2022

Authorization is a process that grants or denies access to a system by verifying whether
the accessor has the permissions to perform the requested action. The accessor in this
context is the workload (cloud application) or the user of the workload. The action might
be operational or related to resource management. There are two main approaches to
authorization: role-based and resource-based. Both can be configured with Azure AD.

Key points
Use a mix of role-based and resource-based authorization. Start with the principle
of least privilege and add more actions based on your needs.
Define clear lines of responsibility and separation of duties for application roles
and the resources it can manage. Consider the access levels of each operational
function, such as permissions needed to publish production release, access
customer data, manipulate database records.
Do not provide permanent access for any critical accounts. Elevate access
permissions that are based on approval and is time bound using Azure AD
Privileged Identity Management (Azure AD PIM).|

Role-based authorization
This approach authorizes an action based on the role assigned to a user. For example,
some actions require an administrator role.
A role is a set of permissions. For example, the administrator role has permissions to
perform all read, write, and delete operations. Also, the role has a scope. The scope
specifies the management groups, subscriptions, or resource groups within which the
role is allowed to operate.
Applying consistent permissions to resources via management groups or resource
groups reduces proliferation of custom, specific, per-resource permissions. Custom
resource-based permissions are often unnecessary, and can cause confusion because
they do not carry their intent to new similar resources. This process can accumulate into
a complex legacy configuration that is difficult to maintain or change without fear of
breaking something, and negatively impacting both security, and solution agility.
When assigning a role to a user consider what actions the role can perform and what is
the scope of those operations. Here are some considerations for role assignment:

Use built-in roles before creating custom roles to grant the appropriate
permissions to VMs and other objects. You can assign built-in roles to users,
groups, service principals, and managed identities. For more information, see
Azure built-in roles.
If you need to create custom roles, grant roles with the appropriate action. Actions
are categorized into operational and data actions. Start with actions that have least
privilege and add more based your operational or data access needs. Provide clear
guidance to your technical teams that implement permissions. For more
information, see Azure custom roles.
If you have a segmentation strategy, assign permissions with a scope. For example,
if you use management group to support your strategy, set the scope to the group
rather than the individual subscriptions. This will drive consistency and ensure
application to future subscriptions. When assigning permissions for a segment,
consider consistency while allowing flexibility to accommodate several
organizational models. These models can range from a single centralized IT group
to mostly independent IT and DevOps teams. For information about assigning
scope, see AssignableScopes.
You can use security groups to assign permissions. However, there are
disadvantages. It can get complex because the workload needs to keep track of
which security groups correspond to which application roles, for each tenant. Also,
access tokens can grow significantly and Azure AD includes an "overage" claim to
limit the token size. See Microsoft identity platform access tokens.
Instead of granting permissions to specific users, assign access to Azure AD
groups. In addition, build a comprehensive delegation model that includes
management groups, subscription, or resource groups RBAC. For more
information, see Azure role-based access control (Azure RBAC).
For information about implementing role-based authorization in an ASP.NET
application, see Role-based authorization.
Learn more
Avoid granular and custom permissions
Delegate administration in Azure AD

Resource-based authorization
With role-based authorization, a user gets the same level of control on a resource based
on the user's role. However, there might be situations where you need to define access

rights per resource. For example, in a resource group, you want to allow some users to
delete the resource; other users cannot. In such situations, use resource-based
authorization that authorizes an action based on a particular resource. Every resource
has an Owner. Owner can delete the resource. Contributors can read and update but
can't delete it.
７ Note
The owner and contributor roles for a resource are not the same as application
roles.
You'll need to implement custom logic for resource-based authorization. That logic
might be a mapping of resources, Azure AD object (like role, group, user), and
permissions.
For information and code sample about implementing resource-based authorization in
an ASP.NET application, see Resource-based authorization.

Authorization for critical accounts
There might be cases when you need to do activities that require access to important
resources. Those resources might already be accessible to critical accounts such as an
administrator account. Or, you might need to elevate the access permissions until the
activities are complete. Both approaches can pose significant risks.
Critical accounts are those which can produce a business-critical outcome, whether
cloud administrators or workload-specific privileged users. Compromise or misuse of
such an account can have a detrimental-to-material effect on the business and its
information systems. It's important to identify those accounts and adopt processes
including close monitoring, and lifecycle management, including retirement.
Securing privileged access is a critical first step to establishing security assurances for
business assets in a modern organization. The security of most or all business assets in
an IT organization depends on the integrity of the privileged accounts used to
administer, manage, and develop. Cyberattackers often target these accounts and other
elements of privileged access to gain access to data, and systems using credential theft
attacks like Pass-the-Hash, and Pass-the-Ticket.
Protecting privileged access against determined adversaries requires you to take a
complete and thoughtful approach to isolate these systems from risks.
Are there any processes and tools leveraged to manage privileged activities?

Do not provide permanent access for any critical accounts and lower permissions when
access is no longer required. Some strategies include:
Just-in-time privileged access to Azure AD and Azure resources.
Time-bound access.
Approval-based access.
Break glass for emergency access process to gain access.
Limit write access to production systems to service principals. No user accounts should
have regular write-access.
Ensure there's a process for disabling or deleting administrative accounts that are
unused.
You can use native and third-party options to elevate access permissions for at least
highly privileged if not all activities. Azure AD Privileged Identity Management (Azure
AD PIM) is the recommended native solution on Azure.
For more information about PIM, see What is Azure AD Privileged Identity
Management?

Learn more
Establish lifecycle management for critical impact accounts

Related links
Back to the main article: Azure identity and access management considerations

Azure Identity Management and access
control security best practices
Article • 08/29/2023

In this article, we discuss a collection of Azure identity management and access control
security best practices. These best practices are derived from our experience with Azure
AD and the experiences of customers like yourself.
For each best practice, we explain:
What the best practice is
Why you want to enable that best practice
What might be the result if you fail to enable the best practice
Possible alternatives to the best practice
How you can learn to enable the best practice
This Azure identity management and access control security best practices article is
based on a consensus opinion and Azure platform capabilities and feature sets, as they
exist at the time this article was written.
The intention in writing this article is to provide a general roadmap to a more robust
security posture after deployment guided by our “5 steps to securing your identity
infrastructure” checklist, which walks you through some of our core features and
services.
Opinions and technologies change over time and this article will be updated on a
regular basis to reflect those changes.
Azure identity management and access control security best practices discussed in this
article include:
Treat identity as the primary security perimeter
Centralize identity management
Manage connected tenants
Enable single sign-on
Turn on Conditional Access
Plan for routine security improvements
Enable password management
Enforce multi-factor verification for users
Use role-based access control
Lower exposure of privileged accounts

Control locations where resources are located
Use Azure AD for storage authentication

Treat identity as the primary security perimeter
Many consider identity to be the primary perimeter for security. This is a shift from the
traditional focus on network security. Network perimeters keep getting more porous,
and that perimeter defense can’t be as effective as it was before the explosion of BYOD
devices and cloud applications.
Azure Active Directory (Azure AD) is the Azure solution for identity and access
management. Azure AD is a multitenant, cloud-based directory and identity
management service from Microsoft. It combines core directory services, application
access management, and identity protection into a single solution.
The following sections list best practices for identity and access security using Azure AD.
Best practice: Center security controls and detections around user and service identities.
Detail: Use Azure AD to collocate controls and identities.

Centralize identity management
In a hybrid identity scenario we recommend that you integrate your on-premises and
cloud directories. Integration enables your IT team to manage accounts from one
location, regardless of where an account is created. Integration also helps your users be
more productive by providing a common identity for accessing both cloud and onpremises resources.
Best practice: Establish a single Azure AD instance. Consistency and a single
authoritative source will increase clarity and reduce security risks from human errors and
configuration complexity.
Detail: Designate a single Azure AD directory as the authoritative source for corporate
and organizational accounts.
Best practice: Integrate your on-premises directories with Azure AD.
Detail: Use Azure AD Connect to synchronize your on-premises directory with your
cloud directory.
７ Note
There are factors that affect the performance of Azure AD Connect. Ensure Azure
AD Connect has enough capacity to keep underperforming systems from impeding

security and productivity. Large or complex organizations (organizations
provisioning more than 100,000 objects) should follow the recommendations to
optimize their Azure AD Connect implementation.
Best practice: Don’t synchronize accounts to Azure AD that have high privileges in your
existing Active Directory instance.
Detail: Don’t change the default Azure AD Connect configuration that filters out these
accounts. This configuration mitigates the risk of adversaries pivoting from cloud to onpremises assets (which could create a major incident).
Best practice: Turn on password hash synchronization.
Detail: Password hash synchronization is a feature used to synch user password hashes
from an on-premises Active Directory instance to a cloud-based Azure AD instance. This
sync helps to protect against leaked credentials being replayed from previous attacks.
Even if you decide to use federation with Active Directory Federation Services (AD FS) or
other identity providers, you can optionally set up password hash synchronization as a
backup in case your on-premises servers fail or become temporarily unavailable. This
sync enables users to sign in to the service by using the same password that they use to
sign in to their on-premises Active Directory instance. It also allows Identity Protection
to detect compromised credentials by comparing synchronized password hashes with
passwords known to be compromised, if a user has used the same email address and
password on other services that aren't connected to Azure AD.
For more information, see Implement password hash synchronization with Azure AD
Connect sync.
Best practice: For new application development, use Azure AD for authentication.
Detail: Use the correct capabilities to support authentication:
Azure AD for employees
Azure AD B2B for guest users and external partners
Azure AD B2C to control how customers sign up, sign in, and manage their profiles
when they use your applications
Organizations that don’t integrate their on-premises identity with their cloud identity
can have more overhead in managing accounts. This overhead increases the likelihood
of mistakes and security breaches.
７ Note
You need to choose which directories critical accounts will reside in and whether
the admin workstation used is managed by new cloud services or existing

